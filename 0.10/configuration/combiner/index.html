
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
  
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Declarative machine learning: End-to-end machine learning pipelines using data-driven configurations.">
      
      
        <meta name="author" content="Piero Molino">
      
      
        <link rel="canonical" href="https://ludwig.ai/latest/configuration/combiner/">
      
      
        <link rel="prev" href="../defaults/">
      
      
        <link rel="next" href="../trainer/">
      
      
      <link rel="icon" href="../../favicon.ico">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.6">
    
  <meta content="http://raw.githubusercontent.com/ludwig-ai/ludwig-docs/master/docs/images/og-image.jpg"
    property="og:image">
  <meta content="https://raw.githubusercontent.com/ludwig-ai/ludwig-docs/master/docs/images/og-image.jpg"
    property="og:image:secure_url">

    
      
        <title>Combiner - Ludwig</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.35e1ed30.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../stylesheets/monokai.css">
    
      <link rel="stylesheet" href="../../stylesheets/colorful.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-H8VVJF9L6G"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-H8VVJF9L6G",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-H8VVJF9L6G",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="deep-orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#combiner-types" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Ludwig" class="md-header__button md-logo" aria-label="Ludwig" data-md-component="logo">
      
<img alt="logo" src="../../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ludwig
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Combiner
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="grey" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ludwig-ai/ludwig" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ludwig-ai/ludwig
  </div>
</a>
      </div>
    
  </nav>
  
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Ludwig" class="md-nav__button md-logo" aria-label="Ludwig" data-md-component="logo">
      
<img alt="logo" src="../../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    Ludwig
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ludwig-ai/ludwig" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ludwig-ai/ludwig
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ludwig
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../getting_started/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    🚀 Getting Started
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            🚀 Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/prepare_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dataset preparation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/train/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/evaluate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prediction and Evaluation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/hyperopt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperopt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/serve/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serving
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/ray/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed training on Ray
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/llm_finetuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLM Fine-tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ludwig with Docker
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../user_guide/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    📖 User Guide
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            📖 User Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/what_is_ludwig/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is Ludwig?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/how_ludwig_works/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How Ludwig Works
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/command_line_interface/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Command Line Interface
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            Python API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/api/LudwigModel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LudwigModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/api/visualization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualization
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Datasets
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            Datasets
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/datasets/supported_formats/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supported Formats
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/datasets/data_preprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Preprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/datasets/data_postprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Postprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/datasets/dataset_zoo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dataset Zoo
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../user_guide/llms/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Large Language Models
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            Large Language Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/llms/finetuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-Tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/llms/in_context_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    In-Context Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/llms/text_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text Classification
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/gpus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPUs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../user_guide/distributed_training/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Distributed Training
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_9">
            <span class="md-nav__icon md-icon"></span>
            Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/distributed_training/finetuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-Tuning Pretrained Models
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/hyperopt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter Optimization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/cloud_storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cloud Storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/automl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AutoML
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/visualizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/model_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Export
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serving
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../user_guide/integrations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Third-Party Integrations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    📚 Configuration
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            📚 Configuration
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../model_type/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../large_language_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Large Language Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../preprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Features
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            Features
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/supported_data_types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supported Data Types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/input_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Input Features (↑)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/output_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Output Features (↓)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/binary_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Binary Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/number_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Number Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/category_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Category Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/bag_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Bag Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/set_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Set Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/sequence_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Sequence Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/text_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Text Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/vector_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Vector Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/audio_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ↑ Audio Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/date_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ↑ Date Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/h3_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ↑ H3 Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/image_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⇅ Image Features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../features/time_series_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ↑ Time Series Features
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../defaults/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Defaults
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Combiner
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Combiner
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#combiner-types" class="md-nav__link">
    Combiner Types
  </a>
  
    <nav class="md-nav" aria-label="Combiner Types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#concat-combiner" class="md-nav__link">
    Concat Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-concat-combiner" class="md-nav__link">
    Sequence Concat Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-combiner" class="md-nav__link">
    Sequence Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tabnet-combiner" class="md-nav__link">
    TabNet Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-combiner" class="md-nav__link">
    Transformer Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tabtransformer-combiner" class="md-nav__link">
    TabTransformer Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparator-combiner" class="md-nav__link">
    Comparator Combiner
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-parameters" class="md-nav__link">
    Common Parameters
  </a>
  
    <nav class="md-nav" aria-label="Common Parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#normalization" class="md-nav__link">
    Normalization
  </a>
  
    <nav class="md-nav" aria-label="Normalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    Batch Normalization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layer-normalization" class="md-nav__link">
    Layer Normalization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ghost-batch-normalization" class="md-nav__link">
    Ghost Batch Normalization
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../trainer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trainer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../hyperparameter_optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperopt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../backend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Backend
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../examples/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    💡 Examples
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            💡 Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    LLMs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            LLMs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tuning for classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_finetuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Instruction-tuning llama-2-7b
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_finetuning_deepspeed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adapter-based encoder fine-tuning for text classification with deepspeed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adapter-based fine-tuning for text generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_zero_shot_text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Zero-shot batch inference for text generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_zero_shot_batch_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Zero-shot batch inference for text classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_few_shot_batch_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Few-shot batch inference for text classification (RAG)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_tabular_zero_shot_batch_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Zero-shot batch inference for tabular classification (TabLLM)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llms/llm_tabular_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tuning for tabular classification (TabLLM)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Supervised ML
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Supervised ML
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/text_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/adult_census_income/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tabular Data Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/mnist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/multimodal_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multimodal Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/hyperopt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter Optimization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/gbm_fraud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fraud with GBMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/sentiment_analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentiment Analysis
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Use Cases
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            Use Cases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/ner_tagging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Named Entity Recognition Tagging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/nlu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Natural Language Understanding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/machine_translation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Machine Translation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/seq2seq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chit-Chat Dialogue Modeling through Sequence2Sequence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/sentiment_analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentiment Analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/oneshot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    One-shot Learning with Siamese Networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/visual_qa/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visual Question Answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/speech_recognition/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spoken Digit Speech Recognition
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/speaker_verification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speaker Verification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/titanic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Binary Classification (Titanic)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/forecasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Timeseries forecasting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/weather/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Timeseries forecasting (Weather)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/movie_ratings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Movie rating prediction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/multi_label/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-label classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/multi_task/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Task Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/fuel_efficiency/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple Regression - Fuel Efficiency Prediction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/fraud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fraud Detection
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../developer_guide/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    🛠️ Developer Guide
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            🛠️ Developer Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/contributing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to Contribute
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/codebase_structure/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Codebase Structure
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/api_annotations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ludwig API Guarantees
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_an_encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add an Encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_combiner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Combiner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_feature_type/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Feature Type
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_metric/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Metric
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_loss_function/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Loss Function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_tokenizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Tokenizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_hyperopt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Hyperopt Algorithm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_pretrained_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Pretrained Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_an_integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add an Integration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/add_a_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Add a Dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/style_guidelines_and_tests/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Style Guidelines and Tests
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/unit_test_design_guidelines/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Unit Test Design Guidelines
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/run_tests_on_gpu_using_ray/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Run Tests on GPU Using Ray
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../developer_guide/release_process/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Release Process
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../community/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    👋 Community
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ❓ FAQ
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#combiner-types" class="md-nav__link">
    Combiner Types
  </a>
  
    <nav class="md-nav" aria-label="Combiner Types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#concat-combiner" class="md-nav__link">
    Concat Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-concat-combiner" class="md-nav__link">
    Sequence Concat Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-combiner" class="md-nav__link">
    Sequence Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tabnet-combiner" class="md-nav__link">
    TabNet Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-combiner" class="md-nav__link">
    Transformer Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tabtransformer-combiner" class="md-nav__link">
    TabTransformer Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparator-combiner" class="md-nav__link">
    Comparator Combiner
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-parameters" class="md-nav__link">
    Common Parameters
  </a>
  
    <nav class="md-nav" aria-label="Common Parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#normalization" class="md-nav__link">
    Normalization
  </a>
  
    <nav class="md-nav" aria-label="Normalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    Batch Normalization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layer-normalization" class="md-nav__link">
    Layer Normalization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ghost-batch-normalization" class="md-nav__link">
    Ghost Batch Normalization
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Combiner</h1>

<p>Combiners take the outputs of all input features encoders and combine them before providing the combined representation
to the output feature decoders.</p>
<p>You can specify which one to use in the <code>combiner</code> section of the configuration, and if you don't specify a combiner,
the <code>concat</code> combiner will be used.</p>
<h3 id="combiner-types">Combiner Types<a class="headerlink" href="#combiner-types" title="Permanent link">&para;</a></h3>
<h4 id="concat-combiner">Concat Combiner<a class="headerlink" href="#concat-combiner" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  I1[Encoder Output 1] --&gt; C[Concat];
  IK[...] --&gt; C;
  IN[Encoder Output N] --&gt; C;
  C --&gt; FC[Fully Connected Layers];
  FC --&gt; ...;
  subgraph COMBINER..
  C
  FC
  end</code></pre></p>
<p>The <code>concat</code> combiner assumes all outputs from encoders are tensors of size <code>b x h</code> where <code>b</code> is the batch size and <code>h</code>
is the hidden dimension, which can be different for each input.
If any inputs have more than 2 dimensions, a sequence or set feature for example, set the <code>flatten_inputs</code> parameter to <code>true</code>.
It concatenates along the <code>h</code> dimension, and then (optionally) passes the concatenated tensor through a stack of fully connected layers.
It returns the final <code>b x h'</code> tensor where <code>h'</code> is the size of the last fully connected layer or the sum of the sizes of
the <code>h</code> of all inputs in the case there are no fully connected layers.
If only a single input feature and no fully connected layer is specified, the output of the input feature encoder is
passed through the combiner unchanged.</p>
<div class="highlight"><pre><span></span><code><span class="nt">combiner</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">concat</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">flatten_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">residual</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Number of stacked fully connected layers to apply. Increasing layers adds capacity to the model, enabling it to learn more complex feature interactions.</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Output size of a fully connected layer.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default normalization applied at the beginnging of fully connected layers. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>. See <a href="#normalization">Normalization</a> for details.</li>
<li><strong><code>activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>flatten_inputs</code></strong> (default: <code>false</code>): Whether to flatten input tensors to a vector. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>residual</code></strong> (default: <code>false</code>): Whether to add a residual connection to each fully connected layer block. Requires all fully connected layers to have the same <code>output_size</code>. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether the layer uses a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module. See <a href="#normalization">Normalization</a> for details.</p>
</li>
<li><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</li>
</ul>
<h4 id="sequence-concat-combiner">Sequence Concat Combiner<a class="headerlink" href="#sequence-concat-combiner" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  I1 --&gt; X1{Tile};
  IK --&gt; X1;
  IN --&gt; X1;
  IO --&gt; X1;

  X1 --&gt; SC1;
  X1 --&gt; SCK;
  X1 --&gt; SCN;

  SC1 --&gt; R[Reduce];
  SCK --&gt; R;
  SCN --&gt; R;
  R --&gt; ...;
  subgraph CONCAT["TENSOR.."]
    direction TB
    SC1["emb seq 1 | emb oth" ];
    SCK[...];
    SCN["emb seq n | emb oth"];
  end
  subgraph COMBINER..
  X1
  CONCAT
  R
  end
  subgraph SF[SEQUENCE FEATS..]
  direction TB
  I1["emb seq 1" ];
  IK[...];
  IN["emb seq n"];
  end
  subgraph OF[OTHER FEATS..]
  direction TB
  IO["emb oth"]
  end</code></pre></p>
<p>The <code>sequence_concat</code> combiner assumes at least one output from encoders is a tensors of size <code>b x s x h</code> where <code>b</code> is
the batch size, <code>s</code> is the length of the sequence and <code>h</code> is the hidden dimension.
A sequence-like (sequence, text or time series) input feature can be specified with the <code>main_sequence_feature</code>
parameter which takes the name of sequence-like input feature as its value.
If no <code>main_sequence_feature</code> is specified, the combiner will look through all the features in the order they are
defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text or time series).
If it cannot find one it will raise an exception, otherwise the output of that feature will be used for concatenating
the other features along the sequence <code>s</code> dimension.</p>
<p>If there are other input features with a rank 3 output tensor, the combiner will concatenate them alongside the <code>s</code>
dimension, which means that all of them must have identical <code>s</code> dimension, otherwise a dimension mismatch error will be
returned thrown during training when a datapoint with two sequential features of different lengths are provided.</p>
<p>Other features that have a <code>b x h</code> rank 2 tensor output will be replicated <code>s</code> times and concatenated to the <code>s</code> dimension.
The final output is a <code>b x s x h'</code> tensor where <code>h'</code> is the size of the concatenation of the <code>h</code> dimensions of all input features.</p>
<div class="highlight"><pre><span></span><code><span class="nt">combiner</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sequence_concat</span>
<span class="w">    </span><span class="nt">main_sequence_feature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li>
<p><strong><code>main_sequence_feature</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: 
Name of a sequence, text, or time series feature to concatenate the outputs
of the other features to. If no <code>main_sequence_feature</code> is specified, the combiner will look through all the features in
the order they are defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text
or time series). If it cannot find one it will raise an exception, otherwise the output of that feature will be used for
concatenating the other features along the sequence <code>s</code> dimension. If there are other input features with a rank 3
output tensor, the combiner will concatenate them alongside the <code>s</code> dimension. All sequence-like input features must
have identical <code>s</code> dimension, otherwise an error will be thrown.</p>
</li>
<li>
<p><strong><code>reduce_output</code></strong> (default: <code>null</code>): Strategy to use to aggregate the embeddings of the items of the set. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</p>
</li>
</ul>
<h4 id="sequence-combiner">Sequence Combiner<a class="headerlink" href="#sequence-combiner" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  I1 --&gt; X1{Tile};
  IK --&gt; X1;
  IN --&gt; X1;
  IO --&gt; X1;

  X1 --&gt; SC1;
  X1 --&gt; SCK;
  X1 --&gt; SCN;

  SC1 --&gt; R["Sequence Encoder"];
  SCK --&gt; R;
  SCN --&gt; R;
  R --&gt; ...;
  subgraph CONCAT["TENSOR.."]
    direction TB
    SC1["emb seq 1 | emb oth" ];
    SCK[...];
    SCN["emb seq n | emb oth"];
  end
  subgraph COMBINER..
  X1
  CONCAT
  R
  end
  subgraph SF[SEQUENCE FEATS..]
  direction TB
  I1["emb seq 1" ];
  IK[...];
  IN["emb seq n"];
  end
  subgraph OF[OTHER FEATS..]
  direction TB
  IO["emb oth"]
  end</code></pre></p>
<p>The <code>sequence</code> combiner stacks a sequence concat combiner with a sequence encoder.
All the considerations about input tensor ranks described for the <a href="#sequence-concat-combiner">sequence concat combiner</a>
apply also in this case, but the main difference is that this combiner uses the <code>b x s x h'</code> output of the sequence
concat combiner, where <code>b</code> is the batch size, <code>s</code> is the sequence length and <code>h'</code> is the sum of the hidden dimensions of
all input features, as input for any of the sequence encoders described in the <a href="../features/sequence_features#sequence-input-features-and-encoders">sequence features encoders section</a>.
Refer to that section for more detailed information about the sequence encoders and their parameters.
All considerations on the shape of the outputs for the sequence encoders also apply to sequence combiner.</p>
<div class="highlight"><pre><span></span><code><span class="nt">combiner</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="w">    </span><span class="nt">main_sequence_feature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">encoder</span><span class="p">:</span>
<span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">parallel_cnn</span>
<span class="w">        </span><span class="nt">skip</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">        </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">        </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">        </span><span class="nt">max_sequence_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">        </span><span class="nt">vocab</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">        </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">        </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">        </span><span class="nt">should_embed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">        </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">        </span><span class="nt">embeddings_on_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">        </span><span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">        </span><span class="nt">pretrained_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">        </span><span class="nt">num_conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">        </span><span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">        </span><span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="w">        </span><span class="nt">pool_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">        </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">        </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li>
<p><strong><code>main_sequence_feature</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: 
Name of a sequence, text, or time series feature to concatenate the outputs
of the other features to. If no <code>main_sequence_feature</code> is specified, the combiner will look through all the features in
the order they are defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text
or time series). If it cannot find one it will raise an exception, otherwise the output of that feature will be used for
concatenating the other features along the sequence <code>s</code> dimension. If there are other input features with a rank 3
output tensor, the combiner will concatenate them alongside the <code>s</code> dimension. All sequence-like input features must
have identical <code>s</code> dimension, otherwise an error will be thrown.</p>
</li>
<li>
<p><strong><code>reduce_output</code></strong> (default: <code>null</code>): Strategy to use to aggregate the embeddings of the items of the set. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</p>
</li>
<li><strong><code>encoder</code></strong> (default: <code>{"type": "parallel_cnn"}</code>): Encoder to apply to <code>main_sequence_feature</code>. The encoder must produce a tensor of size [batch_size, sequence_length, hidden_size]</li>
</ul>
<h4 id="tabnet-combiner">TabNet Combiner<a class="headerlink" href="#tabnet-combiner" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  I1[Encoder Output 1] --&gt; C[TabNet];
  IK[...] --&gt; C;
  IN[Encoder Output N] --&gt; C;
  C --&gt; ...;</code></pre></p>
<p>The <code>tabnet</code> combiner implements the <a href="https://arxiv.org/abs/1908.07442">TabNet</a> model, which uses attention and sparsity
to achieve high performance on tabular data. It assumes all outputs from encoders are tensors of size <code>b x h</code> where <code>b</code>
is the batch size and <code>h</code> is the hidden dimension, which can be different for each input.
If the input tensors have a different shape, it automatically flattens them.
It returns the final <code>b x h'</code> tensor where <code>h'</code> is the user-specified output size.</p>
<div class="highlight"><pre><span></span><code><span class="nt">combiner</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tabnet</span>
<span class="w">    </span><span class="nt">size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">    </span><span class="nt">num_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">    </span><span class="nt">num_total_blocks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">num_shared_blocks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">relaxation_factor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.5</span>
<span class="w">    </span><span class="nt">bn_epsilon</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.001</span>
<span class="w">    </span><span class="nt">bn_momentum</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
<span class="w">    </span><span class="nt">bn_virtual_bs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">    </span><span class="nt">sparsity</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0001</span>
<span class="w">    </span><span class="nt">entmax_mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sparsemax</span>
<span class="w">    </span><span class="nt">entmax_alpha</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.5</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>size</code></strong> (default: <code>32</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Size of the hidden layers. <code>N_a</code> in (Arik and Pfister, 2019).</li>
<li><strong><code>dropout</code></strong> (default: <code>0.05</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate for the transformer block.</li>
<li><strong><code>output_size</code></strong> (default: <code>128</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Output size of a fully connected layer. <code>N_d</code> in (Arik and Pfister, 2019).</li>
<li><strong><code>num_steps</code></strong> (default: <code>3</code>): Number of steps / repetitions of the the attentive transformer and feature transformer computations. <code>N_steps</code> in (Arik and Pfister, 2019).</li>
<li><strong><code>num_total_blocks</code></strong> (default: <code>4</code>): Total number of feature transformer blocks at each step.</li>
<li><strong><code>num_shared_blocks</code></strong> (default: <code>2</code>): Number of shared feature transformer blocks across the steps.</li>
<li><strong><code>relaxation_factor</code></strong> (default: <code>1.5</code>): Factor that influences how many times a feature should be used across the steps of computation. a value of 1 implies it each feature should be use once, a higher value allows for multiple usages. <code>gamma</code> in (Arik and Pfister, 2019).</li>
<li><strong><code>bn_epsilon</code></strong> (default: <code>0.001</code>): Epsilon to be added to the batch norm denominator.</li>
<li><strong><code>bn_momentum</code></strong> (default: <code>0.05</code>): Momentum of the batch norm. 1 - <code>m_B</code> from the TabNet paper.</li>
<li><strong><code>bn_virtual_bs</code></strong> (default: <code>1024</code>): Size of the virtual batch size used by ghost batch norm. If null, regular batch norm is used instead. <code>B_v</code> from the TabNet paper. See <a href="#ghost-batch-normalization">Ghost Batch Normalization</a> for details.</li>
<li><strong><code>sparsity</code></strong> (default: <code>0.0001</code>): Multiplier of the sparsity inducing loss. <code>lambda_sparse</code> in (Arik and Pfister, 2019).</li>
<li><strong><code>entmax_mode</code></strong> (default: <code>sparsemax</code>): Entmax is a sparse family of probability mapping which generalizes softmax and sparsemax. <code>entmax_mode</code> controls the sparsity Options: <code>entmax15</code>, <code>sparsemax</code>, <code>constant</code>, <code>adaptive</code>.</li>
<li><strong><code>entmax_alpha</code></strong> (default: <code>1.5</code>): Must be a number between 1.0 and 2.0. If entmax_mode is <code>adaptive</code>, <code>entmax_alpha</code> is used as the initial value for the learnable parameter. 1 corresponds to softmax, 2 is sparsemax.</li>
</ul>
<h4 id="transformer-combiner">Transformer Combiner<a class="headerlink" href="#transformer-combiner" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  I1[Encoder Output 1] --&gt; C["Transformer Stack"];
  IK[...] --&gt; C;
  IN[Encoder Output N] --&gt; C;
  C --&gt; R[Reduce];
  R --&gt; FC[Fully Connected Layers];
  FC --&gt; ...;
  subgraph COMBINER..
  C
  R
  FC
  end</code></pre></p>
<p>The <code>transformer</code> combiner combines input features using a stack of Transformer blocks (from <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>).
It assumes all outputs from encoders are tensors of size <code>b x h</code> where <code>b</code> is the batch size and <code>h</code> is the hidden
dimension, which can be different for each input.
If the input tensors have a different shape, it automatically flattens them.
It then projects each input tensor to the same hidden / embedding size and encodes them with a stack of Transformer layers.
Finally, the transformer combiner applies a reduction to the outputs of the Transformer stack, followed by optional
fully connected layers.
The output is a <code>b x h'</code> tensor where <code>h'</code> is the size of the last fully connected layer or the hidden / embedding
size, or a <code>b x n x h'</code> where <code>n</code> is the number of input features and <code>h'</code> is the hidden / embedding size if no reduction
is applied.</p>
<p>Resources to learn more about transformers:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=OyFJWRnt_AY&amp;list=PLk4mwFjvagV3vp1JZ3lNohb1LalMp-VOY&amp;index=1">CS480/680 Lecture 19: Attention and Transformer Networks</a> (VIDEO)</li>
<li><a href="https://www.youtube.com/watch?v=rBCqOTEfxvg&amp;list=PLk4mwFjvagV3vp1JZ3lNohb1LalMp-VOY&amp;index=2">Attention is all you need - Attentional Neural Network Models Masterclass</a> (VIDEO)</li>
<li><a href="https://colab.research.google.com/drive/1rPk3ohrmVclqhH7uQ7qys4oznDdAhpzF">Illustrated: Self-Attention</a> (Colab notebook)</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="nt">combiner</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">transformer</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">transformer_output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">num_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">fc_residual</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mean</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.1</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate for the transformer block.</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The number of stacked fully connected layers (only applies if <code>reduce_output</code> is not null).</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Output size of a fully connected layer.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default normalization applied at the beginnging of fully connected layers. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>. See <a href="#normalization">Normalization</a> for details.</li>
<li><strong><code>fc_dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>transformer_output_size</code></strong> (default: <code>256</code>): Size of the fully connected layer after self attention in the transformer block. This is usually the same as <code>hidden_size</code> and <code>embedding_size</code>.</li>
<li><strong><code>hidden_size</code></strong> (default: <code>256</code>): The number of hidden units of the TransformerStack as well as the dimension that each incoming input feature is projected to before feeding to the TransformerStack.</li>
<li><strong><code>num_layers</code></strong> (default: <code>1</code>): The number of transformer layers.</li>
<li><strong><code>num_heads</code></strong> (default: <code>8</code>): Number of heads of the self attention in the transformer block.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether the layer uses a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module. See <a href="#normalization">Normalization</a> for details.</p>
</li>
<li><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</li>
<li><strong><code>fc_activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>fc_residual</code></strong> (default: <code>false</code>): Whether to add a residual connection to each fully connected layer block. Requires all fully connected layers to have the same <code>output_size</code>. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>mean</code>): Strategy to use to aggregate the output of the transformer. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
</ul>
<h4 id="tabtransformer-combiner">TabTransformer Combiner<a class="headerlink" href="#tabtransformer-combiner" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  I1[Cat Emb 1] --&gt; T1["Concat"];
  IK[...] --&gt; T1;
  IN[Cat Emb N] --&gt; T1;
  N1[Number ...] --&gt; T4["Concat"];
  B1[Binary ...] --&gt; T4;
  T1 --&gt; T2["Transformer"];
  T2 --&gt; T3["Reduce"];
  T3 --&gt; T4;
  T4 --&gt; T5["FC Layers"];
  T5 --&gt; ...;
  subgraph COMBINER..
  CAT
  T4
  T5
  end
  subgraph ENCODER OUT..
  I1
  IK
  IN
  N1
  B1
  end
  subgraph CAT["CATEGORY PIPELINE.."]
  direction TB
  T1
  T2
  T3
  end</code></pre></p>
<p>The <code>tabtransformer</code> combiner combines input features in the following sequence of operations. The combiner projects all encoder outputs except binary and number features into an embedding space. These features are concatenated as if they were a sequence and passed through a transformer. After the transformer, the number and binary features are concatenated (which are of size 1) and then concatenated  with the output of the transformer and is passed to a stack of fully connected layers (from <a href="https://arxiv.org/abs/2012.06678">TabTransformer: Tabular Data Modeling Using Contextual Embeddings</a>).
It assumes all outputs from encoders are tensors of size <code>b x h</code> where <code>b</code> is the batch size and <code>h</code> is the hidden
dimension, which can be different for each input.
If the input tensors have a different shape, it automatically flattens them.
It then projects each input tensor to the same hidden / embedding size and encodes them with a stack of Transformer layers.
Finally, the transformer combiner applies a reduction to the outputs of the Transformer stack, followed by the above concatenation and optional fully connected layers.
The output is a <code>b x h'</code> tensor where <code>h'</code> is the size of the last fully connected layer or the hidden / embedding
size, or a <code>b x n x h'</code> where <code>n</code> is the number of input features and <code>h'</code> is the hidden / embedding size if no reduction
is applied.</p>
<div class="highlight"><pre><span></span><code><span class="nt">combiner</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tabtransformer</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">embed_input_feature_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">transformer_output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">num_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">fc_residual</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">concat</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.1</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate for the transformer block.</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The number of stacked fully connected layers (only applies if <code>reduce_output</code> is not null).</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Output size of a fully connected layer.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default normalization applied at the beginnging of fully connected layers. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>. See <a href="#normalization">Normalization</a> for details.</li>
<li><strong><code>fc_dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>embed_input_feature_name</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: This value controls the size of the embeddings. Valid values are <code>add</code> which uses the <code>hidden_size</code> value or an integer that is set to a specific value. In the case of an integer value, it must be smaller than hidden_size.</li>
<li><strong><code>transformer_output_size</code></strong> (default: <code>256</code>): Size of the fully connected layer after self attention in the transformer block. This is usually the same as <code>hidden_size</code> and <code>embedding_size</code>.</li>
<li><strong><code>hidden_size</code></strong> (default: <code>256</code>): The number of hidden units of the TransformerStack as well as the dimension that each incoming input feature is projected to before feeding to the TransformerStack.</li>
<li><strong><code>num_layers</code></strong> (default: <code>1</code>): The number of transformer layers.</li>
<li><strong><code>num_heads</code></strong> (default: <code>8</code>): Number of heads of the self attention in the transformer block.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether the layer uses a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module. See <a href="#normalization">Normalization</a> for details.</p>
</li>
<li><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</li>
<li><strong><code>fc_activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>fc_residual</code></strong> (default: <code>false</code>): Whether to add a residual connection to each fully connected layer block. Requires all fully connected layers to have the same <code>output_size</code>. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>concat</code>): Strategy to use to aggregate the output of the transformer. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
</ul>
<h4 id="comparator-combiner">Comparator Combiner<a class="headerlink" href="#comparator-combiner" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  I1[Entity 1 Embed 1] --&gt; C1[Concat];
  IK[...] --&gt; C1;
  IN[Entity 1 Embed N] --&gt; C1;
  C1 --&gt; FC1[FC Layers];
  FC1 --&gt; COMP[Compare];

  I2[Entity 2 Embed 1] --&gt; C2[Concat];
  IK2[...] --&gt; C2;
  IN2[Entity 2 Embed N] --&gt; C2;
  C2 --&gt; FC2[FC Layers];
  FC2 --&gt; COMP;

  COMP --&gt; ...;

  subgraph ENTITY1["ENTITY 1.."]
  I1
  IK
  IN
  end

  subgraph ENTITY2["ENTITY 2.."]
  I2
  IK2
  IN2
  end

  subgraph COMBINER..
  C1
  FC1
  C2
  FC2
  COMP
  end</code></pre></p>
<p>The <code>comparator</code> combiner compares the hidden representation of two entities defined by lists of features.
It assumes all outputs from encoders are tensors of size <code>b x h</code> where <code>b</code> is the batch size and <code>h</code> is the hidden
dimension, which can be different for each input.
If the input tensors have a different shape, it automatically flattens them.
It then concatenates the representations of each entity and projects them both to vectors of size <code>output_size</code>.
Finally, it compares the two entity representations by dot product, element-wise multiplication, absolute difference and bilinear product.
It returns the final <code>b x h'</code> tensor where <code>h'</code> is the size of the concatenation of the four comparisons.</p>
<div class="highlight"><pre><span></span><code><span class="nt">combiner</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">comparator</span>
<span class="w">    </span><span class="nt">entity_1</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">feature_1</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">feature_2</span>
<span class="w">    </span><span class="nt">entity_2</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">feature_3</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>entity_1</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The list of input feature names <code>[feature_1, feature_2, ...]</code> constituting the first entity to compare. <em>Required</em>.</li>
<li><strong><code>entity_2</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The list of input feature names <code>[feature_1, feature_2, ...]</code> constituting the second entity to compare. <em>Required</em>.</li>
<li><strong><code>dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>1</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Number of stacked fully connected layers to apply. Increasing layers adds capacity to the model, enabling it to learn more complex feature interactions.</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Output size of a fully connected layer.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default normalization applied at the beginnging of fully connected layers. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>. See <a href="#normalization">Normalization</a> for details.</li>
<li><strong><code>activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether the layer uses a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module. See <a href="#normalization">Normalization</a> for details.</p>
</li>
<li><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</li>
</ul>
<h3 id="common-parameters">Common Parameters<a class="headerlink" href="#common-parameters" title="Permanent link">&para;</a></h3>
<p>These parameters are used across multiple combiners (and some encoders / decoders) in similar ways.</p>
<h4 id="normalization">Normalization<a class="headerlink" href="#normalization" title="Permanent link">&para;</a></h4>
<p>Normalization applied at the beginnging of the fully-connected stack. If a <code>norm</code> is not already specified for the <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. One of:</p>
<ul>
<li><code>null</code>: no normalization</li>
<li><code>batch</code>: batch normalization</li>
<li><code>layer</code>: layer normalization</li>
<li><code>ghost</code>: ghost batch normalization</li>
</ul>
<h5 id="batch-normalization">Batch Normalization<a class="headerlink" href="#batch-normalization" title="Permanent link">&para;</a></h5>
<p>Applies Batch Normalization as described in the paper <a href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>. See <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">PyTorch documentation on batch normalization</a> for more details.</p>
<div class="highlight"><pre><span></span><code><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">batch</span>
<span class="nt">norm_params</span><span class="p">:</span>
<span class="w">  </span><span class="nt">eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.001</span>
<span class="w">  </span><span class="nt">momentum</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">  </span><span class="nt">affine</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">  </span><span class="nt">track_running_stats</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>eps</code></strong> (default: <code>0.001</code>): Epsilon to be added to the batch norm denominator.</li>
<li><strong><code>momentum</code></strong> (default: <code>0.1</code>): The value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: <code>0.1</code>.</li>
<li><strong><code>affine</code></strong> (default: <code>true</code>): A boolean value that when set to <code>true</code>, this module has learnable affine parameters.</li>
<li><strong><code>track_running_stats</code></strong> (default: <code>true</code>): A boolean value that when set to <code>true</code>, this module tracks the running mean and variance, and when set to <code>false</code>, this module does not track such statistics, and initializes statistics buffers running_mean and running_var as <code>null</code>. When these buffers are <code>null</code>, this module always uses batch statistics. in both training and eval modes.</li>
</ul>
<h5 id="layer-normalization">Layer Normalization<a class="headerlink" href="#layer-normalization" title="Permanent link">&para;</a></h5>
<p>Applies Layer Normalization over a mini-batch of inputs as described in the paper <a href="https://arxiv.org/abs/1607.06450">Layer Normalization</a>. See <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">PyTorch documentation on layer normalization</a> for more details.</p>
<div class="highlight"><pre><span></span><code><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">layer</span>
<span class="nt">norm_params</span><span class="p">:</span>
<span class="w">  </span><span class="nt">eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.00001</span>
<span class="w">  </span><span class="nt">elementwise_affine</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>eps</code></strong> (default: <code>0.00001</code>): A value added to the denominator for numerical stability.</li>
<li><strong><code>elementwise_affine</code></strong> (default: <code>true</code>): A boolean value that when set to <code>true</code>, this module has learnable per-element affine parameters initialized to ones (for weights) and zeros (for biases)</li>
</ul>
<h5 id="ghost-batch-normalization">Ghost Batch Normalization<a class="headerlink" href="#ghost-batch-normalization" title="Permanent link">&para;</a></h5>
<p>Ghost Batch Norm is a technique designed to address the "generalization gap" whereby the training process breaks down with very large batch sizes.
If you are using a large batch size (typically in the thousands) to maximize GPU utilization, but the model is not converging well, enabling ghost
batch norm can be a useful technique to improve convergence.</p>
<p>When using ghost batch norm, you specify a <code>virtual_batch_size</code> (default <code>128</code>) representing the "ideal" batch size to train with (ignoring throughput or GPU utilization). The ghost batch norm will then subdivide each batch into subbatches of size <code>virtual_batch_size</code> and apply batch normalization to each.</p>
<p>A notable downside to ghost batch norm is that it is more computationally expensive than traditional batch norm, so it is only recommended to use it
when the batch size that maximizes throughput is significantly higher than the batch size that yields the best convergence (one or more orders of magnitude higher).</p>
<p>The approach was introduced in <a href="https://arxiv.org/abs/1705.08741">Train Longer, Generalize Better: Closing the Generalization Gap in Large Batch Training of Neural Networks</a> and since popularized by its use in <a href="#tabnet-combiner">TabNet</a>.</p>
<div class="highlight"><pre><span></span><code><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ghost</span>
<span class="nt">norm_params</span><span class="p">:</span>
<span class="w">  </span><span class="nt">virtual_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">  </span><span class="nt">epsilon</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.001</span>
<span class="w">  </span><span class="nt">momentum</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>virtual_batch_size</code></strong> (default: <code>128</code>): Size of the virtual batch size used by ghost batch norm. If null, regular batch norm is used instead. <code>B_v</code> from the TabNet paper.</li>
<li><strong><code>epsilon</code></strong> (default: <code>0.001</code>): Epsilon to be added to the batch norm denominator.</li>
<li><strong><code>momentum</code></strong> (default: <code>0.05</code>): Momentum of the batch norm. 1 - <code>m_B</code> from the TabNet paper.</li>
</ul>


  




                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <!--
  Copyright (c) 2016-2022 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->

<!-- Footer -->
<footer class="md-footer">

    <!-- Link to previous and/or next page -->
    
    <nav class="md-footer__inner md-grid" aria-label="footer.title">

        <!-- Link to previous page -->
        
        
        <a href="../defaults/" class="md-footer__link md-footer__link--prev"
            aria-label="Previous: Defaults" rel="prev">
            <div class="md-footer__button md-icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
                <div class="md-ellipsis">
                    <span class="md-footer__direction">
                        Previous
                    </span>
                    Defaults
                </div>
            </div>
        </a>
        

        <!-- Link to next page -->
        
        
        <a href="../trainer/" class="md-footer__link md-footer__link--next"
            aria-label="Next: Trainer" rel="next">
            <div class="md-footer__title">
                <div class="md-ellipsis">
                    <span class="md-footer__direction">
                        Next
                    </span>
                    Trainer
                </div>
            </div>
            <div class="md-footer__button md-icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
        </a>
        
    </nav>
    

    <!-- Further information -->
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">
            <!--
  Copyright (c) 2016-2021 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->

<!-- Copyright and theme information -->
<div class="md-copyright">
    
    <div class="md-copyright__highlight">
        Copyright &copy; 2018 - 2020 Uber Technologies Inc., 2021 - 2022 Linux Foundation Data & AI
    </div>
    
    

    Website by <a href="http://w4nderlu.st">w4nderlust</a> powered by
    <a href="https://www.mkdocs.org" target="_blank" rel="noopener">MkDocs</a>,
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">Material for MkDocs</a>,
    <a href="http://www.styleshout.com/" target="_blank" rel="noopener">styleshout</a> and
    <a href="http://cables.gl/" target="_blank" rel="noopener">cables</a>.
    
</div>

            <!-- Social links -->
            
        </div>
    </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes", "navigation.tabs.sticky"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.aecac24b.min.js"></script>
      
    
  </body>
</html>