
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
  
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Declarative machine learning: End-to-end machine learning pipelines using data-driven configurations.">
      
      
        <meta name="author" content="Piero Molino">
      
      
        <link rel="canonical" href="https://ludwig-ai.github.io/ludwig-docs/latest/configuration/features/text_features/">
      
      <link rel="icon" href="../../../favicon.ico">
      <meta name="generator" content="mkdocs-1.2.4, mkdocs-material-8.2.7">
    
  <meta content="http://raw.githubusercontent.com/ludwig-ai/ludwig-docs/master/docs/images/og-image.jpg"
    property="og:image">
  <meta content="https://raw.githubusercontent.com/ludwig-ai/ludwig-docs/master/docs/images/og-image.jpg"
    property="og:image:secure_url">

    
      
        <title>⇅ Text Features - Ludwig</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.9d5733d3.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../../stylesheets/monokai.css">
    
      <link rel="stylesheet" href="../../../stylesheets/colorful.css">
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-H8VVJF9L6G"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-H8VVJF9L6G",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-H8VVJF9L6G"></script>


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="deep-orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#text-features-preprocessing" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-component="outdated" hidden>
        <aside class="md-banner md-banner--warning">
          
        </aside>
      </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Ludwig" class="md-header__button md-logo" aria-label="Ludwig" data-md-component="logo">
      
<img alt="logo" src="../../../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ludwig
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ⇅ Text Features
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="grey" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ludwig-ai/ludwig/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ludwig-ai/ludwig
  </div>
</a>
      </div>
    
  </nav>
  
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Ludwig" class="md-nav__button md-logo" aria-label="Ludwig" data-md-component="logo">
      
<img alt="logo" src="../../../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    Ludwig
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ludwig-ai/ludwig/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ludwig-ai/ludwig
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Ludwig
      </a>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../getting_started/">Getting Started</a>
          
            <label for="__nav_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Getting Started" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Getting Started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/installation/" class="md-nav__link">
        Installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/prepare_data/" class="md-nav__link">
        Dataset preparation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/train/" class="md-nav__link">
        Training
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/evaluate/" class="md-nav__link">
        Prediction and Evaluation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/hyperopt/" class="md-nav__link">
        Hyperopt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/serve/" class="md-nav__link">
        Serving
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/ray/" class="md-nav__link">
        Distributed training on Ray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/docker/" class="md-nav__link">
        Ludwig with Docker
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../user_guide/">User Guide</a>
          
            <label for="__nav_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="User Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/what_is_ludwig/" class="md-nav__link">
        What is Ludwig?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/how_ludwig_works/" class="md-nav__link">
        How Ludwig Works
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/command_line_interface/" class="md-nav__link">
        Command Line Interface
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_5" type="checkbox" id="__nav_3_5" >
      
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3_5">
          Python API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Python API" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          Python API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/api/LudwigModel/" class="md-nav__link">
        LudwigModel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/api/visualization/" class="md-nav__link">
        Visualization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_6" type="checkbox" id="__nav_3_6" >
      
      
      
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3_6">
          Datasets
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Datasets" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_6">
          <span class="md-nav__icon md-icon"></span>
          Datasets
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/datasets/supported_formats/" class="md-nav__link">
        Supported Formats
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/datasets/data_preprocessing/" class="md-nav__link">
        Data Preprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/datasets/data_postprocessing/" class="md-nav__link">
        Data Postprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/datasets/dataset_zoo/" class="md-nav__link">
        Dataset Zoo
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/distributed_training/" class="md-nav__link">
        Distributed Training
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/hyperopt/" class="md-nav__link">
        Hyperparameter Optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/automl/" class="md-nav__link">
        AutoML
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/visualizations/" class="md-nav__link">
        Visualizations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/serving/" class="md-nav__link">
        Serving
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/integrations/" class="md-nav__link">
        Third-Party Integrations
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../">Configuration</a>
          
            <label for="__nav_4">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Configuration" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Configuration
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../preprocessing/" class="md-nav__link">
        Preprocessing
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" checked>
      
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_3">
          Features
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Features" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          Features
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../supported_data_types/" class="md-nav__link">
        Supported Data Types
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../input_features/" class="md-nav__link">
        Input Features (↑)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../output_features/" class="md-nav__link">
        Output Features (↓)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../binary_features/" class="md-nav__link">
        ⇅ Binary Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../number_features/" class="md-nav__link">
        ⇅ Number Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../category_features/" class="md-nav__link">
        ⇅ Category Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../bag_features/" class="md-nav__link">
        ⇅ Bag Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../set_features/" class="md-nav__link">
        ⇅ Set Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../sequence_features/" class="md-nav__link">
        ⇅ Sequence Features
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          ⇅ Text Features
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        ⇅ Text Features
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#text-features-preprocessing" class="md-nav__link">
    Text Features Preprocessing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-input-features-and-encoders" class="md-nav__link">
    Text Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Text Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-cnn-encoder" class="md-nav__link">
    Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-cnn-encoder" class="md-nav__link">
    Stacked CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-parallel-cnn-encoder" class="md-nav__link">
    Stacked Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-encoder" class="md-nav__link">
    RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-rnn-encoder" class="md-nav__link">
    CNN RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-encoder" class="md-nav__link">
    Transformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#huggingface-encoders" class="md-nav__link">
    Huggingface encoders
  </a>
  
    <nav class="md-nav" aria-label="Huggingface encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#albert-encoder" class="md-nav__link">
    ALBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autotransformer" class="md-nav__link">
    AutoTransformer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bert-encoder" class="md-nav__link">
    BERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camembert-encoder" class="md-nav__link">
    CamemBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ctrl-encoder" class="md-nav__link">
    CTRL Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distilbert-encoder" class="md-nav__link">
    DistilBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#electra-encoder" class="md-nav__link">
    ELECTRA Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flaubert-encoder" class="md-nav__link">
    FlauBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-encoder" class="md-nav__link">
    GPT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-2-encoder" class="md-nav__link">
    GPT-2 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#longformer-encoder" class="md-nav__link">
    Longformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roberta-encoder" class="md-nav__link">
    RoBERTa Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-xl-encoder" class="md-nav__link">
    Transformer XL Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t5-encoder" class="md-nav__link">
    T5 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mt5-encoder" class="md-nav__link">
    MT5 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlm-encoder" class="md-nav__link">
    XLM Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlm-roberta-encoder" class="md-nav__link">
    XLM-RoBERTa Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlnet-encoder" class="md-nav__link">
    XLNet Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-output-features-and-decoders" class="md-nav__link">
    Text Output Features and Decoders
  </a>
  
    <nav class="md-nav" aria-label="Text Output Features and Decoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tagger-decoder" class="md-nav__link">
    Tagger Decoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generator-decoder" class="md-nav__link">
    Generator Decoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-features-metrics" class="md-nav__link">
    Text Features Metrics
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../vector_features/" class="md-nav__link">
        ⇅ Vector Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../audio_features/" class="md-nav__link">
        ↑ Audio Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../date_features/" class="md-nav__link">
        ↑ Date Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../h3_features/" class="md-nav__link">
        ↑ H3 Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../image_features/" class="md-nav__link">
        ↑ Image Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../time_series_features/" class="md-nav__link">
        ↑ Time Series Features
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../combiner/" class="md-nav__link">
        Combiner
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../trainer/" class="md-nav__link">
        Trainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../hyperparameter_optimization/" class="md-nav__link">
        Hyperopt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../backend/" class="md-nav__link">
        Backend
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../examples/">Examples</a>
          
            <label for="__nav_5">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Examples" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_2" type="checkbox" id="__nav_5_2" >
      
      
      
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_2">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tutorials" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/text_classification/" class="md-nav__link">
        Text Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/adult_census_income/" class="md-nav__link">
        Tabular Data Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/mnist/" class="md-nav__link">
        Image Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/multimodal_classification/" class="md-nav__link">
        Multimodal Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/hyperopt/" class="md-nav__link">
        Hyperparameter Optimization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3" type="checkbox" id="__nav_5_3" >
      
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3">
          Example Use Cases
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Example Use Cases" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          Example Use Cases
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/ner_tagging/" class="md-nav__link">
        Named Entity Recognition Tagging
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/nlu/" class="md-nav__link">
        Natural Language Understanding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/machine_translation/" class="md-nav__link">
        Machine Translation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/seq2seq/" class="md-nav__link">
        Chit-Chat Dialogue Modeling through Sequence2Sequence
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/sentiment_analysis/" class="md-nav__link">
        Sentiment Analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/oneshot/" class="md-nav__link">
        One-shot Learning with Siamese Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/visual_qa/" class="md-nav__link">
        Visual Question Answering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/speech_recognition/" class="md-nav__link">
        Spoken Digit Speech Recognition
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/speaker_verification/" class="md-nav__link">
        Speaker Verification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/titanic/" class="md-nav__link">
        Binary Classification (Titanic)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/forecasting/" class="md-nav__link">
        Timeseries forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/weather/" class="md-nav__link">
        Timeseries forecasting (Weather)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/movie_ratings/" class="md-nav__link">
        Movie rating prediction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/multi_label/" class="md-nav__link">
        Multi-label classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/multi_task/" class="md-nav__link">
        Multi-Task Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/fuel_efficiency/" class="md-nav__link">
        Simple Regression - Fuel Efficiency Prediction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/fraud/" class="md-nav__link">
        Fraud Detection
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../developer_guide/">Developer Guide</a>
          
            <label for="__nav_6">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Developer Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Developer Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/contributing/" class="md-nav__link">
        How to Contribute
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/codebase_structure/" class="md-nav__link">
        Codebase Structure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_an_encoder/" class="md-nav__link">
        Add an Encoder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_combiner/" class="md-nav__link">
        Add a Combiner
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_decoder/" class="md-nav__link">
        Add a Decoder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_feature_type/" class="md-nav__link">
        Add a Feature Type
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_metric/" class="md-nav__link">
        Add a Metric
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_loss_function/" class="md-nav__link">
        Add a Loss Function
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_tokenizer/" class="md-nav__link">
        Add a Tokenizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_hyperopt/" class="md-nav__link">
        Add a Hyperopt Algorithm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_pretrained_model/" class="md-nav__link">
        Add a Pretrained Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_an_integration/" class="md-nav__link">
        Add an Integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_dataset/" class="md-nav__link">
        Add a Dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/style_guidelines_and_tests/" class="md-nav__link">
        Style Guidelines and Tests
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/unit_test_design_guidelines/" class="md-nav__link">
        Unit Test Design Guidelines
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/run_tests_on_gpu_using_ray/" class="md-nav__link">
        Run Tests on GPU Using Ray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/release_process/" class="md-nav__link">
        Release Process
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../community/" class="md-nav__link">
        Community
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../faq/" class="md-nav__link">
        FAQ
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#text-features-preprocessing" class="md-nav__link">
    Text Features Preprocessing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-input-features-and-encoders" class="md-nav__link">
    Text Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Text Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-cnn-encoder" class="md-nav__link">
    Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-cnn-encoder" class="md-nav__link">
    Stacked CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-parallel-cnn-encoder" class="md-nav__link">
    Stacked Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-encoder" class="md-nav__link">
    RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-rnn-encoder" class="md-nav__link">
    CNN RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-encoder" class="md-nav__link">
    Transformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#huggingface-encoders" class="md-nav__link">
    Huggingface encoders
  </a>
  
    <nav class="md-nav" aria-label="Huggingface encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#albert-encoder" class="md-nav__link">
    ALBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autotransformer" class="md-nav__link">
    AutoTransformer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bert-encoder" class="md-nav__link">
    BERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camembert-encoder" class="md-nav__link">
    CamemBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ctrl-encoder" class="md-nav__link">
    CTRL Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distilbert-encoder" class="md-nav__link">
    DistilBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#electra-encoder" class="md-nav__link">
    ELECTRA Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flaubert-encoder" class="md-nav__link">
    FlauBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-encoder" class="md-nav__link">
    GPT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-2-encoder" class="md-nav__link">
    GPT-2 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#longformer-encoder" class="md-nav__link">
    Longformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roberta-encoder" class="md-nav__link">
    RoBERTa Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-xl-encoder" class="md-nav__link">
    Transformer XL Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t5-encoder" class="md-nav__link">
    T5 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mt5-encoder" class="md-nav__link">
    MT5 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlm-encoder" class="md-nav__link">
    XLM Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlm-roberta-encoder" class="md-nav__link">
    XLM-RoBERTa Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlnet-encoder" class="md-nav__link">
    XLNet Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-output-features-and-decoders" class="md-nav__link">
    Text Output Features and Decoders
  </a>
  
    <nav class="md-nav" aria-label="Text Output Features and Decoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tagger-decoder" class="md-nav__link">
    Tagger Decoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generator-decoder" class="md-nav__link">
    Generator Decoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-features-metrics" class="md-nav__link">
    Text Features Metrics
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
<a href="https://github.com/ludwig-ai/ludwig-docs/edit/master/src/docs/configuration/features/text_features.md" title="Edit this page" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
</a>



  <h1>⇅ Text Features</h1>

<h3 id="text-features-preprocessing">Text Features Preprocessing<a class="headerlink" href="#text-features-preprocessing" title="Permanent link">&para;</a></h3>
<p>Text features are an extension of <a href="../sequence_features">sequence features</a>. Text inputs are processed by a tokenizer
which maps the raw text input into a sequence of tokens. An integer id is assigned to each unique token. Using this
mapping, each text string is converted first to a sequence of tokens, and next to a sequence of integers.</p>
<p>The list of tokens and their integer representations (vocabulary) is stored in the metadata of the model. In the case of
a text output feature, this same mapping is used to post-process predictions to text.</p>
<p>The parameters for text preprocessing are as follows:</p>
<ul>
<li><code>tokenizer</code> (default <code>space_punct</code>): defines how to map from the raw string content of the dataset column to a
sequence of elements. For all available options see <a href="../../preprocessing#tokenizers">Tokenizers</a>.</li>
<li><code>vocab_file</code> (default <code>null</code>): filepath string to a UTF-8 encoded file containing the sequence's vocabulary. On each
line the first string until <code>\t</code> or <code>\n</code> is considered a word.</li>
<li><code>max_sequence_length</code> (default <code>256</code>): the maximum length (number of tokens) of the text. Texts that are longer than
this value will be truncated, while texts that are shorter will be padded.</li>
<li><code>most_common</code> (default <code>20000</code>): the maximum number of most common tokens in the vocabulary. If the data contains more
than this amount, the most infrequent symbols will be treated as unknown.</li>
<li><code>padding_symbol</code> (default <code>&lt;PAD&gt;</code>): the string used as a padding symbol. This special token is mapped to the integer
ID 0 in the vocabulary.</li>
<li><code>unknown_symbol</code> (default <code>&lt;UNK&gt;</code>): the string used as an unknown placeholder. This special token is mapped to the
integer ID 1 in the vocabulary.</li>
<li><code>padding</code> (default <code>right</code>): the direction of the padding. <code>right</code> and <code>left</code> are available options.</li>
<li><code>lowercase</code> (default <code>false</code>): If true, converts the string to lowercase before tokenizing.</li>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in the
dataset. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with
the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column),
<code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the
missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>""</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is
<code>fill_value</code>.</li>
</ul>
<p>Configuration example:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">preprocessing</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">tokenizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">space_punct</span><span class="w"></span>
<span class="w">    </span><span class="nt">vocab_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"></span>
<span class="w">    </span><span class="nt">max_sequence_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="w">    </span><span class="nt">most_common</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20000</span><span class="w"></span>
<span class="w">    </span><span class="nt">padding_symbol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;PAD&gt;</span><span class="w"></span>
<span class="w">    </span><span class="nt">unknown_symbol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;UNK&gt;</span><span class="w"></span>
<span class="w">    </span><span class="nt">padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">right</span><span class="w"></span>
<span class="w">    </span><span class="nt">lowercase</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"></span>
<span class="w">    </span><span class="nt">missing_value_strategy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fill_with_const</span><span class="w"></span>
<span class="w">    </span><span class="nt">fill_value</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="w"></span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a text feature's encoder specifies a huggingface model, then the tokenizer for that model will be used
automatically.</p>
</div>
<h3 id="text-input-features-and-encoders">Text Input Features and Encoders<a class="headerlink" href="#text-input-features-and-encoders" title="Permanent link">&para;</a></h3>
<p>Text input feature parameters are</p>
<ul>
<li><code>encoder</code> (default <code>parallel_cnn</code>): encoder to use for the input text feature. The available encoders include encoders
used for <a href="../sequence_features#sequence-input-features-and-encoders">Sequence Features</a> as well as pre-trained text
encoders from the huggingface transformers library: <code>albert</code>, <code>auto_transformer</code>, <code>bert</code>, <code>camembert</code>, <code>ctrl</code>,
<code>distilbert</code>, <code>electra</code>, <code>flaubert</code>, <code>gpt</code>, <code>gpt2</code>, <code>longformer</code>, <code>roberta</code>, <code>t5</code>, <code>mt5</code>, <code>transformer_xl</code>, <code>xlm</code>,
<code>xlmroberta</code>, <code>xlnet</code>.</li>
<li><code>tied</code> (default <code>null</code>): name of the input feature to tie the weights of the encoder with. Tied must name a feature of
the same type with the same encoder parameters.</li>
</ul>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bert</span><span class="w"></span>
<span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
</code></pre></div>
<h4 id="embed-encoder">Embed Encoder<a class="headerlink" href="#embed-encoder" title="Permanent link">&para;</a></h4>
<p>The embed encoder simply maps each token in the input sequence to an embedding, creating a <code>b x s x h</code> tensor where <code>b</code>
is the batch size, <code>s</code> is the length of the sequence and <code>h</code> is the embedding size.
The tensor is reduced along the <code>s</code> dimension to obtain a single vector of size <code>h</code> for each element of the batch.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|   +-----------+
|43|   +------+   |Aggregation|
|65+---&gt;Emb 65+---&gt;Reduce     +--&gt;
|23|   +------+   |Operation  |
|4 |   |Emb 23|   +-----------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>
<p>These are the parameters available for the embed encoder</p>
<ul>
<li><code>representation</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are
initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be
<code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code>
encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the
number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code>
embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter
has effect only when <code>representation</code> is <code>dense</code>, <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter
allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>.
When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept,
the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings
are initialized with the average of all other embedding plus some random noise to make them different from each other.
This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embedding matrices are stored on GPU memory if a GPU is used, as it
allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the
placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the
process as a result of data transfer between CPU and GPU memory.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weight matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>reduce_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if
the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates
along the sequence dimension), <code>last</code> (selects the last vector of the sequence dimension) and  <code>null</code> (which does not
reduce and returns the full tensor).</li>
</ul>
<p>Example text feature entry in the input features list using an embed encoder:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">embed</span><span class="w"></span>
<span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span><span class="w"></span>
<span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span><span class="w"></span>
</code></pre></div>
<h4 id="parallel-cnn-encoder">Parallel CNN Encoder<a class="headerlink" href="#parallel-cnn-encoder" title="Permanent link">&para;</a></h4>
<p>The parallel cnn encoder is inspired by
<a href="https://arxiv.org/abs/1408.5882">Yoon Kim's Convolutional Neural Network for Sentence Classification</a>.
It works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the
sequence) into a sequence of embeddings, then it passes the embedding through a number of parallel 1d convolutional
layers with different filter size (by default 4 layers with filter size 2, 3, 4 and 5), followed by max pooling and
concatenation.
This single vector concatenating the outputs of the parallel convolutional layers is then passed through a stack of
fully connected layers and returned as a <code>b x h</code> tensor where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code>                    +-------+   +----+
                 +--&gt;1D Conv+---&gt;Pool+--+
       +------+  |  |Width 2|   +----+  |
       |Emb 12|  |  +-------+           |
       +------+  |                      |
+--+   |Emb 7 |  |  +-------+   +----+  |
|12|   +------+  +--&gt;1D Conv+---&gt;Pool+--+
|7 |   |Emb 43|  |  |Width 3|   +----+  |            +---------+
|43|   +------+  |  +-------+           |  +------+  |Fully    |
|65+--&gt;Emb 65 +--+                      +--&gt;Concat+--&gt;Connected+--&gt;
|23|   +------+  |  +-------+   +----+  |  +------+  |Layers   |
|4 |   |Emb 23|  +--&gt;1D Conv+---&gt;Pool+--+            +---------+
|1 |   +------+  |  |Width 4|   +----+  |
+--+   |Emb 4 |  |  +-------+           |
       +------+  |                      |
       |Emb 1 |  |  +-------+   +----+  |
       +------+  +--&gt;1D Conv+---&gt;Pool+--+
                    |Width 5|   +----+
                    +-------+
</code></pre></div>
<p>These are the available parameters for a parallel cnn encoder:</p>
<ul>
<li><code>representation</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are
initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be
<code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code>
encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the
number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code>
embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter
has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter
allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>.
When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept,
the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings
are initialized with the average of all other embedding plus some random noise to make them different from each other.
This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embedding matrices are stored on GPU memory if a GPU is used, as it
allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the
placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the
process as a result of data transfer between CPU and GPU memory.</li>
<li><code>conv_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the convolutional layers. The
length of the list determines the number of parallel convolutional layers and the content of each dictionary determines
the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>,
<code>norm_params</code>, <code>num_filters</code>, <code>filter_size</code>, <code>strides</code>, <code>padding</code>, <code>dilation_rate</code>, <code>use_bias</code>, <code>pool_function</code>,
<code>pool_padding</code>, <code>pool_size</code>, <code>pool_strides</code>, <code>bias_initializer</code>, <code>weights_initializer</code>. If any of those values is
missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value
<code>[{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}]</code>.</li>
<li><code>num_conv_layers</code> (default <code>null</code>): if <code>conv_layers</code> is <code>null</code>, this is the number of parallel convolutional layers.</li>
<li><code>filter_size</code> (default <code>3</code>): if a <code>filter_size</code> is not already specified in <code>conv_layers</code> this is the default
<code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>conv_layers</code> this is the default
<code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output
channels of the 1d convolution.</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value. Any of <code>average</code>, <code>avg</code> or
<code>mean</code> will compute the mean value.</li>
<li><code>pool_size</code> (default <code>null</code>): if a <code>pool_size</code> is not already specified in <code>conv_layers</code> this is the default
<code>pool_size</code> that will be used for each layer. It indicates the size of the max pooling that will be performed along the
<code>s</code> sequence dimension after the convolution operation.</li>
<li><code>fc_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the fully connected
layers. The length of the list determines the number of stacked fully connected layers and the content of each
dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>,
<code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of
those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used
instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the
value <code>[{output_size: 512}, {output_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only
applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>output_size</code> (default <code>256</code>): if <code>output_size</code> is not already specified in <code>fc_layers</code> this is the default
<code>output_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weights matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>bias_initializer</code> (default <code>zeros</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>,
<code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be
used for each layer. It indicates how the output should be normalized and may be one of <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters
used with <code>batch</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">Torch documentation on batch normalization</a>
or for <code>layer</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">Torch documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default
<code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if
the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates
along the sequence dimension), <code>last</code> (selects the last vector of the sequence dimension) and  <code>null</code> (which does not
reduce and returns the full tensor).</li>
</ul>
<p>Example text feature entry in the input features list using a parallel cnn encoder:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">parallel_cnn</span><span class="w"></span>
<span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span><span class="w"></span>
<span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span><span class="w"></span>
<span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span><span class="w"></span>
<span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span><span class="w"></span>
<span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span><span class="w"></span>
<span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"></span>
<span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span><span class="w"></span>
</code></pre></div>
<h4 id="stacked-cnn-encoder">Stacked CNN Encoder<a class="headerlink" href="#stacked-cnn-encoder" title="Permanent link">&para;</a></h4>
<p>The stacked cnn encoder is inspired by <a href="https://arxiv.org/abs/1509.01626">Xiang Zhang at all's Character-level Convolutional Networks for Text Classification</a>.
It works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the
sequence) into a sequence of embeddings, then it passes the embedding through a stack of 1d convolutional layers with
different filter size (by default 6 layers with filter size 7, 7, 3, 3, 3 and 3), followed by an optional final pool and
by a flatten operation.
This single flatten vector is then passed through a stack of fully connected layers and returned as a <code>b x h</code> tensor
where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify the <code>pool_size</code> of all your <code>conv_layers</code> to be
<code>null</code>  and <code>reduce_output: null</code>, while if <code>pool_size</code> has a value different from <code>null</code> and <code>reduce_output: null</code> the
returned tensor will be of shape <code>b x s' x h</code>, where <code>s'</code> is width of the output of the last convolutional layer.</p>
<div class="highlight"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|   +----------------+   +---------+
|43|   +------+   |1D Conv         |   |Fully    |
|65+---&gt;Emb 65+---&gt;Layers          +---&gt;Connected+--&gt;
|23|   +------+   |Different Widths|   |Layers   |
|4 |   |Emb 23|   +----------------+   +---------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>
<p>These are the parameters available for the stack cnn encoder:</p>
<ul>
<li><code>representation</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are
initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): the maximum embedding size, the actual size will be
<code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code>
encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the
number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code>
embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter
has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter
allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>.
When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept,
the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings
are initialized with the average of all other embedding plus some random noise to make them different from each other.
This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embedding matrices are stored on GPU memory if a GPU is used, as it
allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the
placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the
process as a result of data transfer between CPU and GPU memory.</li>
<li><code>conv_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the convolutional layers.
The length of the list determines the number of stacked convolutional layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>num_filters</code>, <code>filter_size</code>, <code>strides</code>, <code>padding</code>, <code>dilation_rate</code>, <code>use_bias</code>, <code>pool_function</code>,
<code>pool_padding</code>, <code>pool_size</code>, <code>pool_strides</code>, <code>bias_initializer</code>, <code>weights_initializer</code>. If any of those values is
missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value
<code>[{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}]</code>.</li>
<li><code>num_conv_layers</code> (default <code>null</code>): if <code>conv_layers</code> is <code>null</code>, this is the number of stacked convolutional layers.</li>
<li><code>filter_size</code> (default <code>3</code>): if a <code>filter_size</code> is not already specified in <code>conv_layers</code> this is the default
<code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>conv_layers</code> this is the default
<code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution.</li>
<li><code>strides</code> (default <code>1</code>): stride length of the convolution</li>
<li><code>padding</code> (default <code>same</code>):  one of <code>valid</code> or <code>same</code>.</li>
<li><code>dilation_rate</code> (default <code>1</code>): dilation rate to use for dilated convolution</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value.  Any of <code>average</code>, <code>avg</code> or
<code>mean</code> will compute the mean value.</li>
<li><code>pool_size</code> (default <code>null</code>): if a <code>pool_size</code> is not already specified in <code>conv_layers</code> this is the default
<code>pool_size</code> that will be used for each layer. It indicates the size of the max pooling that will be performed along the
<code>s</code> sequence dimension after the convolution operation.</li>
<li><code>pool_strides</code> (default <code>null</code>): factor to scale down</li>
<li><code>pool_padding</code> (default <code>same</code>): one of <code>valid</code> or <code>same</code></li>
<li><code>fc_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the fully connected layers.
The length of the list determines the number of stacked fully connected layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values
is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value
<code>[{output_size: 512}, {output_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only
applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>output_size</code> (default <code>256</code>): if an <code>output_size</code> is not already specified in <code>fc_layers</code> this is the default
<code>output_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weight matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>bias_initializer</code> (default <code>zeros</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>,
<code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be
used for each layer. It indicates how the output should be normalized and may be one of <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters
used with <code>batch</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">Torch documentation on batch normalization</a>
or for <code>layer</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">Torch documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default
<code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>max</code>): defines how to reduce the output tensor of the convolutional layers along the <code>s</code>
sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>,
<code>max</code>, <code>concat</code> (concatenates along the sequence dimension), <code>last</code> (returns the last vector of the sequence dimension)
and <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example text feature entry in the input features list using a parallel cnn encoder:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">stacked_cnn</span><span class="w"></span>
<span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span><span class="w"></span>
<span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span><span class="w"></span>
<span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">strides</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">same</span><span class="w"></span>
<span class="nt">dilation_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span><span class="w"></span>
<span class="nt">pool_padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">same</span><span class="w"></span>
<span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span><span class="w"></span>
<span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span><span class="w"></span>
<span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span><span class="w"></span>
</code></pre></div>
<h4 id="stacked-parallel-cnn-encoder">Stacked Parallel CNN Encoder<a class="headerlink" href="#stacked-parallel-cnn-encoder" title="Permanent link">&para;</a></h4>
<p>The stacked parallel cnn encoder is a combination of the Parallel CNN and the Stacked CNN encoders where each layer of
the stack is composed of parallel convolutional layers.
It works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the
sequence) into a sequence of embeddings, then it passes the embedding through a stack of several parallel 1d
convolutional layers with different filter size, followed by an optional final pool and by a flatten operation.
This single flattened vector is then passed through a stack of fully connected layers and returned as a <code>b x h</code> tensor
where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code>                  +-------+                     +-------+
                +-&gt;1D Conv+-+                 +-&gt;1D Conv+-+
      +------+  | |Width 2| |                 | |Width 2| |
      |Emb 12|  | +-------+ |                 | +-------+ |
      +------+  |           |                 |           |
+--+  |Emb 7 |  | +-------+ |                 | +-------+ |
|12|  +------+  +-&gt;1D Conv+-+                 +-&gt;1D Conv+-+
|7 |  |Emb 43|  | |Width 3| |                 | |Width 3| |                 +---------+
|43|  +------+  | +-------+ | +------+  +---+ | +-------+ | +------+ +----+ |Fully    |
|65+-&gt;Emb 65 +--+           +-&gt;Concat+--&gt;...+-+           +-&gt;Concat+-&gt;Pool+-&gt;Connected+--&gt;
|23|  +------+  | +-------+ | +------+  +---+ | +-------+ | +------+ +----+ |Layers   |
|4 |  |Emb 23|  +-&gt;1D Conv+-+                 +-&gt;1D Conv+-+                 +---------+
|1 |  +------+  | |Width 4| |                 | |Width 4| |
+--+  |Emb 4 |  | +-------+ |                 | +-------+ |
      +------+  |           |                 |           |
      |Emb 1 |  | +-------+ |                 | +-------+ |
      +------+  +-&gt;1D Conv+-+                 +-&gt;1D Conv+-+
                  |Width 5|                     |Width 5|
                  +-------+                     +-------+
</code></pre></div>
<p>These are the available parameters for the stack parallel cnn encoder:</p>
<ul>
<li><code>representation</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are
initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): the maximum embedding size, the actual size will be
<code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code>
encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the
number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code>
embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter
has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter
allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>.
When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept,
the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings
are initialized with the average of all other embedding plus some random noise to make them different from each other.
This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embedding matrices are stored on GPU memory if a GPU is used, as it
allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the
placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the
process as a result of data transfer between CPU and GPU memory.</li>
<li><code>stacked_layers</code> (default <code>null</code>): a nested list of lists of dictionaries containing the parameters of the stack of
parallel convolutional layers. The length of the list determines the number of stacked parallel convolutional layers,
length of the sub-lists determines the number of parallel conv layers and the content of each dictionary determines the
parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>,
<code>norm_params</code>, <code>num_filters</code>, <code>filter_size</code>, <code>strides</code>, <code>padding</code>, <code>dilation_rate</code>, <code>use_bias</code>, <code>pool_function</code>,
<code>pool_padding</code>, <code>pool_size</code>, <code>pool_strides</code>, <code>bias_initializer</code>, <code>weights_initializer</code>. If any of those values is
missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>stacked_layers</code> and <code>num_stacked_layers</code> are <code>null</code>, a default list will be assigned to <code>stacked_layers</code> with the value
<code>[[{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}]]</code>.</li>
<li><code>num_stacked_layers</code> (default <code>null</code>): if <code>stacked_layers</code> is <code>null</code>, this is the number of elements in the stack of
parallel convolutional layers.</li>
<li><code>filter_size</code> (default <code>3</code>): if a <code>filter_size</code> is not already specified in <code>stacked_layers</code> this is the default
<code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>stacker_layers</code> this is the default
<code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output
channels of the 1d convolution.</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value.  Any of <code>average</code>, <code>avg</code> or
<code>mean</code> will compute the mean value.</li>
<li><code>pool_size</code> (default <code>null</code>): if a <code>pool_size</code> is not already specified in <code>stacked_layers</code> this is the default
<code>pool_size</code> that will be used for each layer. It indicates the size of the max pooling that will be performed along the
<code>s</code> sequence dimension after the convolution operation.</li>
<li><code>fc_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the fully connected layers.
The length of the list determines the number of stacked fully connected layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values
is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value
<code>[{output_size: 512}, {output_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only
applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>output_size</code> (default <code>256</code>): if an <code>output_size</code> is not already specified in <code>fc_layers</code> this is the default
<code>output_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weights matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>bias_initializer</code> (default <code>zeros</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>,
<code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be
used for each layer. It indicates how the output should be normalized and may be one of <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters
used with <code>batch</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">Torch documentation on batch normalization</a>
or for <code>layer</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">Torch documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default
<code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if
the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates
along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce
and returns the full tensor).</li>
</ul>
<p>Example text feature entry in the input features list using a parallel cnn encoder:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">stacked_parallel_cnn</span><span class="w"></span>
<span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span><span class="w"></span>
<span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span><span class="w"></span>
<span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span><span class="w"></span>
<span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span><span class="w"></span>
<span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span><span class="w"></span>
<span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span><span class="w"></span>
</code></pre></div>
<h4 id="rnn-encoder">RNN Encoder<a class="headerlink" href="#rnn-encoder" title="Permanent link">&para;</a></h4>
<p>The rnn encoder works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the
length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of recurrent layers
(by default 1 layer), followed by a reduce operation that by default only returns the last output, but can perform other
reduce functions.
If you want to output the full <code>b x s x h</code> where <code>h</code> is the size of the output of the last rnn layer, you can specify
<code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|                 +---------+
|43|   +------+   +----------+  |Fully    |
|65+---&gt;Emb 65+---&gt;RNN Layers+--&gt;Connected+--&gt;
|23|   +------+   +----------+  |Layers   |
|4 |   |Emb 23|                 +---------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>
<p>These are the available parameters for the rnn encoder:</p>
<ul>
<li><code>representation</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are
initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): the maximum embedding size, the actual size will be
<code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code>
encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the
number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code>
embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter
has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter
allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>.
When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept,
the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings
are initialized with the average of all other embedding plus some random noise to make them different from each other.
This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embedding matrices are stored on GPU memory if a GPU is used, as it
allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the
placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the
process as a result of data transfer between CPU and GPU memory.</li>
<li><code>num_layers</code> (default <code>1</code>): the number of stacked recurrent layers.</li>
<li><code>state_size</code> (default <code>256</code>): the size of the state of the rnn.</li>
<li><code>cell_type</code> (default <code>rnn</code>): the type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>gru</code>. For
reference about the differences between the cells please refer to
<a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers">torch.nn Recurrent Layers</a>.</li>
<li><code>bidirectional</code> (default <code>false</code>): if <code>true</code> two recurrent networks will perform encoding in the forward and backward
direction and their outputs will be concatenated.</li>
<li><code>activation</code> (default <code>tanh</code>): activation function to use.</li>
<li><code>recurrent_activation</code> (default <code>sigmoid</code>): activation function to use in the recurrent step</li>
<li><code>unit_forget_bias</code> (default <code>true</code>): If <code>true</code>, add 1 to the bias of the forget gate at initialization</li>
<li><code>recurrent_initializer</code> (default <code>orthogonal</code>): initializer for recurrent matrix weights</li>
<li><code>dropout</code> (default <code>0.0</code>): dropout rate</li>
<li><code>recurrent_dropout</code> (default <code>0.0</code>): dropout rate for recurrent state</li>
<li><code>fc_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the fully connected layers.
The length of the list determines the number of stacked fully connected layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values
is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value
<code>[{output_size: 512}, {output_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only
applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>output_size</code> (default <code>256</code>): if an <code>output_size</code> is not already specified in <code>fc_layers</code> this is the default
<code>output_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weight matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>bias_initializer</code> (default <code>zeros</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>,
<code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be
used for each layer. It indicates how the output should be normalized and may be one of <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>. For information on parameters
used with <code>batch</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">Torch documentation on batch normalization</a>
or for <code>layer</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">Torch documentation on layer normalization</a>.</li>
<li><code>fc_activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default
<code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>fc_dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>last</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if
the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates
along the sequence dimension), <code>last</code> (returns the last vector of the sequence dimension) and  <code>null</code> (which does not
reduce and returns the full tensor).</li>
</ul>
<p>Example text feature entry in the input features list using a parallel cnn encoder:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rnn</span><span class="w"></span>
<span class="l l-Scalar l-Scalar-Plain">representation&#39;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span><span class="w"></span>
<span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">state_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">cell_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rnn</span><span class="w"></span>
<span class="nt">bidirectional</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"></span>
<span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tanh</span><span class="w"></span>
<span class="nt">recurrent_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sigmoid</span><span class="w"></span>
<span class="nt">unit_forget_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">recurrent_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">orthogonal</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"></span>
<span class="nt">recurrent_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"></span>
<span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span><span class="w"></span>
<span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span><span class="w"></span>
<span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">last</span><span class="w"></span>
</code></pre></div>
<h4 id="cnn-rnn-encoder">CNN RNN Encoder<a class="headerlink" href="#cnn-rnn-encoder" title="Permanent link">&para;</a></h4>
<p>The <code>cnnrnn</code> encoder works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is
the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of convolutional
layers (by default 2), that is followed by a stack of recurrent layers (by default 1), followed by a reduce operation
that by default only returns the last output, but can perform other reduce functions.
If you want to output the full <code>b x s x h</code> where <code>h</code> is the size of the output of the last rnn layer, you can specify
<code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|                              +---------+
|43|   +------+  +----------+  +----------+  |Fully    |
|65+---&gt;Emb 65+--&gt;CNN Layers+--&gt;RNN Layers+--&gt;Connected+--&gt;
|23|   +------+  +----------+  +----------+  |Layers   |
|4 |   |Emb 23|                              +---------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>
<p>These are the available parameters of the cnn rnn encoder:</p>
<ul>
<li><code>representation</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are
initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): the maximum embedding size, the actual size will be
<code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code>
encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the
number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code>
embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter
has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter
allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>.
When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept,
the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings
are initialized with the average of all other embedding plus some random noise to make them different from each other.
This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embedding matrices are stored on GPU memory if a GPU is used, as it
allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the
placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the
process as a result of data transfer between CPU and GPU memory.</li>
<li><code>conv_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the convolutional layers.
The length of the list determines the number of stacked convolutional layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>num_filters</code>, <code>filter_size</code>, <code>strides</code>, <code>padding</code>, <code>dilation_rate</code>, <code>use_bias</code>, <code>pool_function</code>,
<code>pool_padding</code>, <code>pool_size</code>, <code>pool_strides</code>, <code>bias_initializer</code>, <code>weights_initializer</code>. If any of those values is
missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value
<code>[{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}]</code>.</li>
<li><code>num_conv_layers</code> (default <code>1</code>): the number of stacked convolutional layers.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>conv_layers</code> this is the default
<code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output
channels of the 1d convolution.</li>
<li><code>filter_size</code> (default <code>5</code>): if a <code>filter_size</code> is not already specified in <code>conv_layers</code> this is the default
<code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>strides</code> (default <code>1</code>): stride length of the convolution</li>
<li><code>padding</code> (default <code>same</code>):  one of <code>valid</code> or <code>same</code>.</li>
<li><code>dilation_rate</code> (default <code>1</code>): dilation rate to use for dilated convolution</li>
<li><code>conv_activation</code> (default <code>relu</code>): activation for the convolution layer</li>
<li><code>conv_dropout</code> (default <code>0.0</code>): dropout rate for the convolution layer</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value.  Any of <code>average</code>, <code>avg</code> or
<code>mean</code> will compute the mean value.</li>
<li><code>pool_size</code> (default 2 ): if a <code>pool_size</code> is not already specified in <code>conv_layers</code> this is the default <code>pool_size</code>
that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence
dimension after the convolution operation.</li>
<li><code>pool_strides</code> (default <code>null</code>): factor to scale down</li>
<li><code>pool_padding</code> (default <code>same</code>): one of <code>valid</code> or <code>same</code></li>
<li><code>num_rec_layers</code> (default <code>1</code>): the number of recurrent layers</li>
<li><code>state_size</code> (default <code>256</code>): the size of the state of the rnn.</li>
<li><code>cell_type</code> (default <code>rnn</code>): the type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>gru</code>. For
reference about the differences between the cells please refer to
<a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers">torch.nn Recurrent Layers</a>.</li>
<li><code>bidirectional</code> (default <code>false</code>): if <code>true</code> two recurrent networks will perform encoding in the forward and backward
direction and their outputs will be concatenated.</li>
<li><code>activation</code> (default <code>tanh</code>): activation function to use</li>
<li><code>recurrent_activation</code> (default <code>sigmoid</code>): activation function to use in the recurrent step</li>
<li><code>unit_forget_bias</code> (default <code>true</code>): If <code>true</code>, add 1 to the bias of the forget gate at initialization</li>
<li><code>recurrent_initializer</code> (default <code>orthogonal</code>): initializer for recurrent matrix weights</li>
<li><code>dropout</code> (default <code>0.0</code>): dropout rate</li>
<li><code>recurrent_dropout</code> (default <code>0.0</code>): dropout rate for recurrent state</li>
<li><code>fc_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the fully connected
layers. The length of the list determines the number of stacked fully connected layers and the content of each
dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>,
<code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of
those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used
instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the
value <code>[{output_size: 512}, {output_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only
applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>output_size</code> (default <code>256</code>): if an <code>output_size</code> is not already specified in <code>fc_layers</code> this is the default
<code>output_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weights matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>bias_initializer</code> (default <code>zeros</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>,
<code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be
used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters
used with <code>batch</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">Torch documentation on batch normalization</a>
or for <code>layer</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">Torch documentation on layer normalization</a>.</li>
<li><code>fc_activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default
<code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>fc_dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>last</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if
the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates
along the sequence dimension), <code>last</code> (returns the last vector of the sequence dimension) and <code>null</code> (which does not
reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the inputs features list using a cnn rnn encoder:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cnnrnn</span><span class="w"></span>
<span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span><span class="w"></span>
<span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">num_conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span><span class="w"></span>
<span class="nt">strides</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">same</span><span class="w"></span>
<span class="nt">dilation_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">conv_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">conv_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"></span>
<span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span><span class="w"></span>
<span class="nt">pool_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span><span class="w"></span>
<span class="nt">pool_padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">same</span><span class="w"></span>
<span class="nt">num_rec_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">state_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">cell_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rnn</span><span class="w"></span>
<span class="nt">bidirectional</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"></span>
<span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tanh</span><span class="w"></span>
<span class="nt">recurrent_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sigmoid</span><span class="w"></span>
<span class="nt">unit_forget_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">recurrent_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">orthogonal</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"></span>
<span class="nt">recurrent_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"></span>
<span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span><span class="w"></span>
<span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span><span class="w"></span>
<span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">last</span><span class="w"></span>
</code></pre></div>
<h4 id="transformer-encoder">Transformer Encoder<a class="headerlink" href="#transformer-encoder" title="Permanent link">&para;</a></h4>
<p>The <code>transformer</code> encoder implements a stack of transformer blocks, replicating the architecture introduced in the
<a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a> paper, and adds am optional stack of fully connected
layers at the end.</p>
<div class="highlight"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|   +-------------+   +---------+
|43|   +------+   |             |   |Fully    |
|65+---+Emb 65+---&gt; Transformer +---&gt;Connected+--&gt;
|23|   +------+   | Blocks      |   |Layers   |
|4 |   |Emb 23|   +-------------+   +---------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>
<ul>
<li><code>representation</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are
initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): the maximum embedding size, the actual size will be
<code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code>
encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the
number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code>
embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter
has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter
allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>.
When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept,
the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings
are initialized with the average of all other embedding plus some random noise to make them different from each other.
This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embedding matrices are stored on GPU memory if a GPU is used, as it
allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the
placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the
process as a result of data transfer between CPU and GPU memory.</li>
<li><code>num_layers</code> (default <code>1</code>): number of transformer blocks.</li>
<li><code>hidden_size</code> (default <code>256</code>): the size of the hidden representation within the transformer block. It is usually the
same as the <code>embedding_size</code>, but if the two values are different, a projection layer will be added before the first
transformer block.</li>
<li><code>num_heads</code> (default <code>8</code>): number of attention heads in each transformer block.</li>
<li><code>transformer_output_size</code> (default <code>256</code>): Size of the fully connected layer after self attention in the transformer
block. This is usually the same as <code>hidden_size</code> and <code>embedding_size</code>.</li>
<li><code>dropout</code> (default <code>0.1</code>): dropout rate for the transformer block</li>
<li><code>fc_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the fully connected layers.
The length of the list determines the number of stacked fully connected layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values
is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value
<code>[{output_size: 512}, {output_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>0</code>): This is the number of stacked fully connected layers (only applies if <code>reduce_output</code>
is not <code>null</code>).</li>
<li><code>output_size</code> (default <code>256</code>): if an <code>output_size</code> is not already specified in <code>fc_layers</code> this is the default
<code>output_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weights matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>bias_initializer</code> (default <code>zeros</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>,
<code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be
used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters
used with <code>batch</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">Torch documentation on batch normalization</a>
or for <code>layer</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">Torch documentation on layer normalization</a>.</li>
<li><code>fc_activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default
<code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>fc_dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>last</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if
the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates
along the sequence dimension), <code>last</code> (returns the last vector of the sequence dimension) and  <code>null</code> (which does not
reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the inputs features list using a Transformer encoder:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">transformer</span><span class="w"></span>
<span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span><span class="w"></span>
<span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">num_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span><span class="w"></span>
<span class="nt">transformer_output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span><span class="w"></span>
<span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span><span class="w"></span>
<span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span><span class="w"></span>
<span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">last</span><span class="w"></span>
</code></pre></div>
<h4 id="huggingface-encoders">Huggingface encoders<a class="headerlink" href="#huggingface-encoders" title="Permanent link">&para;</a></h4>
<p>All huggingface-based text encoders are configured with the following parameters:</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default is the huggingface default model path for the specified encoder, i.e. <code>bert-base-uncased</code> for BERT). This can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/docs/transformers/">Hugging Face documentation</a>.</li>
<li><code>reduce_output</code> (default <code>cls_pooled</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>cls_pooled</code>, <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Any hyperparameter of any huggingface encoder can be overridden. Check the
<a href="https://huggingface.co/transformers/model_doc/">huggingface documentation</a> for which parameters are used for which models.</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bert</span><span class="w"></span>
<span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">num_attention_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span><span class="w"> </span><span class="c1"># Instead of 12</span><span class="w"></span>
</code></pre></div>
</div>
<h5 id="albert-encoder">ALBERT Encoder<a class="headerlink" href="#albert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>albert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1909.11942">ALBERT</a> (default <code>albert-base-v2</code>) model
using the Hugging Face transformers package. Albert is similar to BERT, with significantly lower memory usage and
somewhat faster training time.</p>
<h5 id="autotransformer">AutoTransformer<a class="headerlink" href="#autotransformer" title="Permanent link">&para;</a></h5>
<p>The <code>auto_transformer</code> encoder automatically instantiates the model architecture for the specified
<code>pretrained_model_name_or_path</code>. Unlike the other HF encoders, <code>auto_transformer</code> does not provide a default value for
<code>pretrained_model_name_or_path</code>, this is its only mandatory parameter. See the Hugging Face
<a href="https://huggingface.co/transformers/v3.0.2/model_doc/auto.html">AutoModels documentation</a> for more details.</p>
<h5 id="bert-encoder">BERT Encoder<a class="headerlink" href="#bert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>bert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1810.04805">BERT</a> (default <code>bert-base-uncased</code>) model using
the Hugging Face transformers package.</p>
<h5 id="camembert-encoder">CamemBERT Encoder<a class="headerlink" href="#camembert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>camembert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1911.03894">CamemBERT</a>
(default <code>jplu/tf-camembert-base</code>) model using the Hugging Face transformers package. CamemBERT is pre-trained on a
large French language web-crawled text corpus.</p>
<h5 id="ctrl-encoder">CTRL Encoder<a class="headerlink" href="#ctrl-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>ctrl</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1909.05858">CTRL</a> (default <code>ctrl</code>) model using the Hugging
Face transformers package. CTRL is a conditional transformer language model trained to condition on control codes that
govern style, content, and task-specific behavior.</p>
<h5 id="distilbert-encoder">DistilBERT Encoder<a class="headerlink" href="#distilbert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>distilbert</code> encoder loads a pretrained <a href="https://medium.com/huggingface/distilbert-8cf3380435b5">DistilBERT</a>
(default <code>distilbert-base-uncased</code>) model using the Hugging Face transformers package. A compressed version of BERT,
60% faster and smaller that BERT.</p>
<h5 id="electra-encoder">ELECTRA Encoder<a class="headerlink" href="#electra-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>electra</code> encoder loads a pretrained <a href="https://openreview.net/pdf?id=r1xMH1BtvB">ELECTRA</a> model using the Hugging
Face transformers package.</p>
<h5 id="flaubert-encoder">FlauBERT Encoder<a class="headerlink" href="#flaubert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>flaubert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1912.05372">FlauBERT</a>
(default <code>jplu/tf-flaubert-base-uncased</code>) model using the Hugging Face transformers package. FlauBERT has an architecture
similar to BERT and is pre-trained on a large French language corpus.</p>
<h5 id="gpt-encoder">GPT Encoder<a class="headerlink" href="#gpt-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>gpt</code> encoder loads a pretrained
<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a>
(default <code>openai-gpt</code>) model using the Hugging Face transformers package.</p>
<h5 id="gpt-2-encoder">GPT-2 Encoder<a class="headerlink" href="#gpt-2-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>gpt2</code> encoder loads a pretrained
<a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a>
(default <code>gpt2</code>) model using the Hugging Face transformers package.</p>
<h5 id="longformer-encoder">Longformer Encoder<a class="headerlink" href="#longformer-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>longformer</code> encoder loads a pretrained <a href="https://arxiv.org/pdf/2004.05150.pdf">Longformer</a>
(default <code>allenai/longformer-base-4096</code>) model using the Hugging Face transformers package. Longformer is a good choice
for longer text, as it supports sequences up to 4096 tokens long.</p>
<h5 id="roberta-encoder">RoBERTa Encoder<a class="headerlink" href="#roberta-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>roberta</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a> (default <code>roberta-base</code>) model
using the Hugging Face transformers package. Replication of BERT pretraining which may match or exceed the performance
of BERT.</p>
<h5 id="transformer-xl-encoder">Transformer XL Encoder<a class="headerlink" href="#transformer-xl-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>transformer_xl</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1901.02860">Transformer-XL</a>
(default <code>transfo-xl-wt103</code>) model using the Hugging Face transformers package. Adds novel positional encoding scheme
which improves understanding and generation of long-form text up to thousands of tokens.</p>
<h5 id="t5-encoder">T5 Encoder<a class="headerlink" href="#t5-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>t5</code> encoder loads a pretrained <a href="https://arxiv.org/pdf/1910.10683.pdf">T5</a> (default <code>t5-small</code>) model using the
Hugging Face transformers package. T5 (Text-to-Text Transfer Transformer) is pre-trained on a huge text dataset crawled
from the web and shows good transfer performance on multiple tasks.</p>
<h5 id="mt5-encoder">MT5 Encoder<a class="headerlink" href="#mt5-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>mt5</code> encoder loads a pretrained <a href="https://arxiv.org/abs/2010.11934">MT5</a> (default <code>google/mt5-base</code>) model using the
Hugging Face transformers package. MT5 is a multilingual variant of T5 trained on a dataset of 101 languages.</p>
<h5 id="xlm-encoder">XLM Encoder<a class="headerlink" href="#xlm-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>xlm</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1901.07291">XLM</a> (default <code>xlm-mlm-en-2048</code>) model using the
Hugging Face transformers package. Pre-trained by cross-language modeling.</p>
<h5 id="xlm-roberta-encoder">XLM-RoBERTa Encoder<a class="headerlink" href="#xlm-roberta-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>xlmroberta</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1911.02116">XLM-RoBERTa</a>
(default <code>jplu/tf-xlm-reoberta-base</code>) model using the Hugging Face transformers package. XLM-RoBERTa is a multi-language
model similar to BERT, trained on 100 languages.</p>
<h5 id="xlnet-encoder">XLNet Encoder<a class="headerlink" href="#xlnet-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>xlnet</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1906.08237">XLNet</a> (default <code>xlnet-base-cased</code>) model
using the Hugging Face transformers package. XLNet outperforms BERT on a variety of benchmarks.</p>
<h3 id="text-output-features-and-decoders">Text Output Features and Decoders<a class="headerlink" href="#text-output-features-and-decoders" title="Permanent link">&para;</a></h3>
<p>Text output features are a special case of <a href="#sequence-output-features-and-decoders">Sequence Features</a>, so all options
of sequence features are available for text features as well.</p>
<p>Text output features can be used for either tagging (classifying each token of an input sequence) or text
generation (generating text by repeatedly sampling from the model). There are two decoders available for these tasks
named <code>tagger</code> and <code>generator</code> respectively.</p>
<p>The following are the available parameters of a text output feature:</p>
<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order
tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>,
<code>max</code>, <code>concat</code> (concatenates along the sequence dimension), <code>last</code> (returns the last vector of the sequence dimension).</li>
<li><code>dependencies</code> (default <code>[]</code>): the output features this one is dependent on. For a detailed explanation refer to
<a href="../output_features#output-feature-dependencies">Output Feature Dependencies</a>.</li>
<li><code>reduce_dependencies</code> (default <code>sum</code>): defines how to reduce the output of a dependent feature that is not a vector,
but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available
values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the sequence dimension), <code>last</code> (returns the
last vector of the sequence dimension).</li>
<li><code>loss</code> (default <code>{type: softmax_cross_entropy, class_similarities_temperature: 0, class_weights: 1,
confidence_penalty: 0, robust_lambda: 0}</code>): is a dictionary containing a loss <code>type</code>. The only available loss <code>type</code> for
text features is <code>softmax_cross_entropy</code>. For more details on losses and their options, see also
<a href="../category_features#category-output-features-and-decoders">Category Output Features and Decoders</a>.</li>
</ul>
<h4 id="tagger-decoder">Tagger Decoder<a class="headerlink" href="#tagger-decoder" title="Permanent link">&para;</a></h4>
<p>In the case of <code>tagger</code> the decoder is a (potentially empty) stack of fully connected layers, followed by a projection
into a tensor of size <code>b x s x c</code>, where <code>b</code> is the batch size, <code>s</code> is the length of the sequence and <code>c</code> is the number
of classes, followed by a softmax_cross_entropy.
This decoder requires its input to be shaped as <code>b x s x h</code>, where <code>h</code> is a hidden dimension, which is the output of a
sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner.
If a <code>b x h</code> input is provided instead, an error will be raised during model building.</p>
<div class="highlight"><pre><span></span><code>Combiner
Output

+---+                 +----------+   +-------+
|emb|   +---------+   |Projection|   |Softmax|
+---+   |Fully    |   +----------+   +-------+
|...+---&gt;Connected+---&gt;...       +---&gt;...    |
+---+   |Layers   |   +----------+   +-------+
|emb|   +---------+   |Projection|   |Softmax|
+---+                 +----------+   +-------+
</code></pre></div>
<p>These are the available parameters of a tagger decoder:</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the fully connected
layers. The length of the list determines the number of stacked fully connected layers and the content of each
dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>,
<code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of
those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): the number of stacked fully connected layers that the input to the feature passes
through. Their output is projected in the feature's output space.</li>
<li><code>output_size</code> (default <code>256</code>): if an <code>output_size</code> is not already specified in <code>fc_layers</code> this is the default
<code>output_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weights matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>bias_initializer</code> (default <code>zeros</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>,
<code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be
used for each layer. It indicates how the output should be normalized and may be one of <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters
used with <code>batch</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">Torch documentation on batch normalization</a>
or for <code>layer</code> see the <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">Torch documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default
<code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>attention</code> (default <code>false</code>): If <code>true</code>, applies a multi-head self attention layer before prediction.</li>
<li><code>attention_embedding_size</code> (default <code>256</code>): the embedding size of the multi-head self attention layer.</li>
<li><code>attention_num_heads</code> (default <code>8</code>): number of attention heads in the multi-head self attention layer.</li>
</ul>
<p>Example text feature entry using a tagger decoder (with default parameters) in the output features list:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">decoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tagger</span><span class="w"></span>
<span class="nt">reduce_input</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"></span>
<span class="nt">dependencies</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[]</span><span class="w"></span>
<span class="nt">reduce_dependencies</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span><span class="w"></span>
<span class="nt">loss</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">softmax_cross_entropy</span><span class="w"></span>
<span class="w">    </span><span class="nt">confidence_penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="w">    </span><span class="nt">robust_lambda</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="w">    </span><span class="nt">class_weights</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">    </span><span class="nt">class_similarities_temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span><span class="w"></span>
<span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span><span class="w"></span>
<span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">attention</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"></span>
<span class="nt">attention_embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">attention_num_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span><span class="w"></span>
</code></pre></div>
<h4 id="generator-decoder">Generator Decoder<a class="headerlink" href="#generator-decoder" title="Permanent link">&para;</a></h4>
<p>In the case of <code>generator</code> the decoder is a (potentially empty) stack of fully connected layers, followed by an RNN that
generates outputs feeding on its own previous predictions and generates a tensor of size <code>b x s' x c</code>, where <code>b</code> is the
batch size, <code>s'</code> is the length of the generated sequence and <code>c</code> is the number of classes, followed by a
softmax_cross_entropy.
During training teacher forcing is adopted, meaning the list of targets is provided as both inputs and outputs (shifted
by 1), while at evaluation time greedy decoding (generating one token at a time and feeding it as input for the next
step) is performed by beam search, using a beam of 1 by default.
In general a generator expects a <code>b x h</code> shaped input tensor, where <code>h</code> is a hidden dimension.
The <code>h</code> vectors are (after an optional stack of fully connected layers) fed into the rnn generator.
One exception is when the generator uses attention, as in that case the expected size of the input tensor is
<code>b x s x h</code>, which is the output of a sequence, text or time series input feature without reduced outputs or the output
of a sequence-based combiner.
If a <code>b x h</code> input is provided to a generator decoder using an RNN with attention instead, an error will be raised
during model building.</p>
<div class="highlight"><pre><span></span><code>                            Output     Output
                               1  +-+    ... +--+    END
                               ^    |     ^     |     ^
+--------+   +---------+       |    |     |     |     |
|Combiner|   |Fully    |   +---+--+ | +---+---+ | +---+--+
|Output  +---&gt;Connected+---+RNN   +---&gt;RNN... +---&gt;RNN   |
|        |   |Layers   |   +---^--+ | +---^---+ | +---^--+
+--------+   +---------+       |    |     |     |     |
                              GO    +-----+     +-----+
</code></pre></div>
<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order
tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>,
<code>max</code>, <code>concat</code> (concatenates along the sequence dimension), <code>last</code> (returns the last vector of the sequence dimension).</li>
</ul>
<p>These are the available parameters of a Generator decoder:</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): a list of dictionaries containing the parameters of all the fully connected
layers. The length of the list determines the number of stacked fully connected layers and the content of each
dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>,
<code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of
those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): the number of stacked fully connected layers that the input to the feature passes
through. Their output is projected in the feature's output space.</li>
<li><code>output_size</code> (default <code>256</code>): if an <code>output_size</code> is not already specified in <code>fc_layers</code> this is the default
<code>output_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>glorot_uniform</code>): initializer for the weight matrix. Options are: <code>constant</code>,
<code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>bias_initializer</code> (default <code>zeros</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>,
<code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>,
<code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>.
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other
keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please
refer to <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be
used for each layer. It indicates how the output should be normalized and may be one of <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters
used with <code>batch</code> see <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">Torch documentation on batch normalization</a>
or for <code>layer</code> see <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">Torch documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default
<code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>cell_type</code> (default <code>rnn</code>): the type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>gru</code>. For
reference about the differences between the cells please refer to
<a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers">torch.nn Recurrent Layers</a>.</li>
<li><code>state_size</code> (default <code>256</code>): the size of the state of the rnn.</li>
<li><code>embedding_size</code> (default <code>256</code>): The size of the embeddings of the inputs of the generator.</li>
<li><code>beam_width</code> (default <code>1</code>): sampling from the RNN generator is performed using beam search. By default, with a beam of
one, only a greedy sequence using always the most probable next token is generated, but the beam size can be increased.
This usually leads to better performance at the expense of more computation and slower generation.</li>
<li><code>tied</code> (default <code>null</code>): if <code>null</code> the embeddings of the targets are initialized randomly. If <code>tied</code> names an input
feature, the embeddings of that input feature will be used as embeddings of the target.
The <code>vocabulary_size</code> of that input feature has to be the same as the output feature and it has to have an embedding
matrix (binary and number features will not have one, for instance). In this case the <code>embedding_size</code> will be the same
as the <code>state_size</code>. This is useful for implementing autoencoders where the encoding and decoding part of the model
share parameters.</li>
<li><code>max_sequence_length</code> (default <code>256</code>): The maximum sequence length.</li>
</ul>
<p>Example text feature entry using a generator decoder in the output features list:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span><span class="w"></span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
<span class="nt">decoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">generator</span><span class="w"></span>
<span class="nt">reduce_input</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span><span class="w"></span>
<span class="nt">dependencies</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[]</span><span class="w"></span>
<span class="nt">reduce_dependencies</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span><span class="w"></span>
<span class="nt">loss</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">softmax_cross_entropy</span><span class="w"></span>
<span class="w">    </span><span class="nt">confidence_penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="w">    </span><span class="nt">robust_lambda</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="w">    </span><span class="nt">class_weights</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">    </span><span class="nt">class_similarities_temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span><span class="w"></span>
<span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span><span class="w"></span>
<span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span><span class="w"></span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="nt">cell_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rnn</span><span class="w"></span>
<span class="nt">state_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
<span class="nt">beam_width</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">max_sequence_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span><span class="w"></span>
</code></pre></div>
<h3 id="text-features-metrics">Text Features Metrics<a class="headerlink" href="#text-features-metrics" title="Permanent link">&para;</a></h3>
<p>The metrics available for text features are the same as for <a href="../sequence_features#sequence-features-metrics">Sequence Features</a>:</p>
<ul>
<li><code>sequence_accuracy</code> The rate at which the model predicted the correct sequence.</li>
<li><code>token_accuracy</code> The number of tokens correctly predicted divided by the total number of tokens in all sequences.</li>
<li><code>last_accuracy</code> Accuracy considering only the last element of the sequence. Useful to ensure special end-of-sequence
tokens are generated or tagged.</li>
<li><code>edit_distance</code> Levenshtein distance: the minimum number of single-token edits (insertions, deletions or substitutions)
required to change predicted sequence to ground truth.</li>
<li><code>perplexity</code> Perplexity is the inverse of the predicted probability of the ground truth sequence, normalized by the
number of tokens. The lower the perplexity, the higher the probability of predicting the true sequence.</li>
<li><code>loss</code> The value of the loss function.</li>
</ul>
<p>You can set any of the above as <code>validation_metric</code> in the <code>training</code> section of the configuration if <code>validation_field</code>
names a sequence feature.</p>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <!--
  Copyright (c) 2016-2022 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->

<!-- Footer -->
<footer class="md-footer">

    <!-- Link to previous and/or next page -->
    
    <nav class="md-footer__inner md-grid" aria-label="Footer">

        <!-- Link to previous page -->
        
        
        <a href="../sequence_features/" class="md-footer__link md-footer__link--prev"
            aria-label="Previous: ⇅ Sequence Features" rel="prev">
            <div class="md-footer__button md-icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer__title">
                <div class="md-ellipsis">
                    <span class="md-footer__direction">
                        Previous
                    </span>
                    ⇅ Sequence Features
                </div>
            </div>
        </a>
        

        <!-- Link to next page -->
        
        
        <a href="../vector_features/" class="md-footer__link md-footer__link--next"
            aria-label="Next: ⇅ Vector Features" rel="next">
            <div class="md-footer__title">
                <div class="md-ellipsis">
                    <span class="md-footer__direction">
                        Next
                    </span>
                    ⇅ Vector Features
                </div>
            </div>
            <div class="md-footer__button md-icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
        </a>
        
    </nav>
    

    <!-- Further information -->
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">
            <!--
  Copyright (c) 2016-2021 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->

<!-- Copyright and theme information -->
<div class="md-copyright">
    
    <div class="md-copyright__highlight">
        Copyright &copy; 2018 - 2020 Uber Technologies Inc., 2021 - 2022 Linux Foundation Data & AI
    </div>
    
    

    Website by <a href="http://w4nderlu.st">w4nderlust</a> powered by
    <a href="https://www.mkdocs.org" target="_blank" rel="noopener">MkDocs</a>,
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">Material for MkDocs</a>,
    <a href="http://www.styleshout.com/" target="_blank" rel="noopener">styleshout</a> and
    <a href="http://cables.gl/" target="_blank" rel="noopener">cables</a>.
    
</div>

            <!-- Social links -->
            
        </div>
    </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.indexes", "navigation.tabs.sticky", "navigation.sections"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../assets/javascripts/workers/search.5e67fbfe.min.js", "version": {"provider": "mike", "default": "latest"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e87a5f81.min.js"></script>
      
    
  </body>
</html>