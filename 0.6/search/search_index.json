{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Declarative machine learning: End-to-end machine learning pipelines using simple and flexible data-driven configurations. What is Ludwig? \u00b6 Ludwig is a declarative machine learning framework that makes it easy to define machine learning pipelines using a simple and flexible data-driven configuration system. Ludwig is suitable for a wide variety of AI tasks, and is hosted by the Linux Foundation AI & Data . The configuration declares the input and output features, with their respective data types. Users can also specify additional parameters to preprocess, encode, and decode features, load from pre-trained models, compose the internal model architecture, set training parameters, or run hyperparameter optimization. Ludwig will build an end-to-end machine learning pipeline automatically, using whatever is explicitly specified in the configuration, while falling back to smart defaults for any parameters that are not. Declarative Machine Learning \u00b6 Ludwig\u2019s declarative approach to machine learning empowers you to have full control of the components of the machine learning pipeline that you care about, while leaving it up to Ludwig to make reasonable decisions for the rest. Analysts, scientists, engineers, and researchers use Ludwig to explore state-of-the-art model architectures, run hyperparameter search, scale up to larger than available memory datasets and multi-node clusters, and finally serve the best model in production. Finally, the use of abstract interfaces throughout the codebase makes it easy for users to extend Ludwig by adding new models, metrics, losses, and preprocessing functions that can be registered to make them immediately useable in the same unified configuration system. Main Features \u00b6 Data-Driven configuration system A config YAML file that describes the schema of your data (input features, output features, and their types) is all you need to start training deep learning models. Ludwig uses declared features to compose a deep learning model accordingly. input_features : - name : data_column_1 type : number - name : data_column_2 type : category - name : data_column_3 type : text - name : data_column_4 type : image ... output_features : - name : data_column_5 type : number - name : data_column_6 type : category ... Training, prediction, and evaluation from the command line Simple commands can be used to train models and predict new data. ludwig train --config config.yaml --dataset data.csv ludwig predict --model_path results/experiment_run/model --dataset test.csv ludwig eval --model_path results/experiment_run/model --dataset test.csv Programmatic API Ludwig also provides a simple programmatic API for all of the functionality described above and more. from ludwig.api import LudwigModel # train a model config = { \"input_features\" : [ ... ], \"output_features\" : [ ... ], } model = LudwigModel ( config ) data = pd . read_csv ( \"data.csv\" ) train_stats , _ , model_dir = model . train ( data ) # or load a model model = LudwigModel . load ( model_dir ) # obtain predictions predictions = model . predict ( data ) Distributed training Train models in a distributed setting using Horovod , which allows training on a single machine with multiple GPUs or multiple machines with multiple GPUs. Serving Serve models using FastAPI. ludwig serve --model_path ./results/experiment_run/model curl http://0.0.0.0:8000/predict -X POST -F \"movie_title=Friends With Money\" -F \"content_rating=R\" -F \"genres=Art House & International, Comedy, Drama\" -F \"runtime=88.0\" -F \"top_critic=TRUE\" -F \"review_content=The cast is terrific, the movie isn't.\" Hyperparameter optimization Run hyperparameter optimization locally or using Ray Tune . ludwig hyperopt --config config.yaml --dataset data.csv AutoML Ludwig AutoML takes a dataset, the target column, and a time budget, and returns a trained Ludwig model. Third-Party integrations Ludwig provides an extendable interface to integrate with third-party systems for tracking experiments. Third-party integrations exist for Comet ML, Weights & Biases, WhyLabs, and MLFlow. Extensibility Ludwig is built from the ground up with extensibility in mind. It is easy to add new data types by implementing clear, well-documented abstract classes that define functions to preprocess, encode, and decode data. Furthermore, new torch nn.Module models can be easily added by them to a registry. This encourages reuse and sharing new models with the community. Refer to the Developer Guide for further details. Quick Start \u00b6 For a full tutorial, check out the official getting started guide , or take a look at end-to-end Examples . Step 1: Install \u00b6 Install from PyPi. Be aware that Ludwig requires Python 3.7+. pip install ludwig Step 2: Define a configuration \u00b6 Create a config that describes the schema of your data. Assume we have a text classification task, with data containing a sentence and class column like the following. sentence class Former president Barack Obama ... politics Juventus hired Cristiano Ronaldo ... sport LeBron James joins the Lakers ... sport ... ... A configuration will look like this. input_features : - name : sentence type : text output_features : - name : class type : category Starting from a simple config like the one above, any and all aspects of the model architecture, training loop, hyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration to customize the pipeline to meet your requirements. input_features : - name : sentence type : text encoder : transformer layers : 6 embedding_size : 512 output_features : - name : class type : category loss : cross_entropy trainer : epochs : 50 batch_size : 64 optimizer : type : adamw beat1 : 0.9 learning_rate : 0.001 backend : type : ray cache_format : parquet processor : type : dask trainer : use_gpu : true num_workers : 4 resources_per_worker : CPU : 4 GPU : 1 hyperopt : metric : f1 sampler : random parameters : title.num_layers : lower : 1 upper : 5 trainer.learning_rate : values : [ 0.01 , 0.003 , 0.001 ] For details on what can be configured, check out Ludwig Configuration docs. Step 3: Train a model \u00b6 Simple commands can be used to train models and predict new data. ludwig train --config config.yaml --dataset data.csv Step 4: Predict and evaluate \u00b6 The training process will produce a model that can be used for evaluating on and obtaining predictions for new data. ludwig predict --model path/to/trained/model --dataset heldout.csv ludwig evaluate --model path/to/trained/model --dataset heldout.csv Step 5: Visualize \u00b6 Ludwig provides a suite of visualization tools allows you to analyze models' training and test performance and to compare them. ludwig visualize --visualization compare_performance --test_statistics path/to/test_statistics_model_1.json path/to/test_statistics_model_2.json For the full set of visualization see the Visualization Guide . Step 6: Happy modeling \u00b6 Try applying Ludwig to your data. Reach out if you have any questions. Advantages \u00b6 Minimal machine learning boilerplate Ludwig takes care of the engineering complexity of machine learning out of the box, enabling research scientists to focus on building models at the highest level of abstraction. Data preprocessing, hyperparameter optimization, device management, and distributed training for torch.nn.Module models come completely free. Easily build your benchmarks Creating a state-of-the-art baseline and comparing it with a new model is a simple config change. Easily apply new architectures to multiple problems and datasets Apply new models across the extensive set of tasks and datasets that Ludwig supports. Ludwig includes a full benchmarking toolkit accessible to any user, for running experiments with multiple models across multiple datasets with just a simple configuration. Highly configurable data preprocessing, modeling, and metrics Any and all aspects of the model architecture, training loop, hyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration to customize the pipeline to meet your requirements. For details on what can be configured, check out Ludwig Configuration docs. Multi-modal, multi-task learning out-of-the-box Mix and match tabular data, text, images, and even audio into complex model configurations without writing code. Rich model exporting and tracking Automatically track all trials and metrics with tools like Tensorboard, Comet ML, Weights & Biases, MLFlow, and Aim Stack. Automatically scale training to multi-GPU, multi-node clusters Go from training on your local machine to the cloud without code changes. Low-code interface for state-of-the-art models, including pre-trained Huggingface Transformers Ludwig also natively integrates with pre-trained models, such as the ones available in Huggingface Transformers . Users can choose from a vast collection of state-of-the-art pre-trained PyTorch models to use without needing to write any code at all. For example, training a BERT-based sentiment analysis model with Ludwig is as simple as: ludwig train --dataset sst5 --config_str \u201c { input_features: [{ name: sentence, type: text, encoder: bert }] , output_features: [{ name: label, type: category }]} \u201d Low-code interface for AutoML Ludwig AutoML allows users to obtain trained models by providing just a dataset, the target column, and a time budget. auto_train_results = ludwig . automl . auto_train ( dataset = my_dataset_df , target = target_column_name , time_limit_s = 7200 ) Easy productionisation Ludwig makes it easy to serve deep learning models, including on GPUs. Launch a REST API for your trained Ludwig model. ludwig serve --model_path = /path/to/model Ludwig supports exporting models to efficient Torschscript bundles. ludwig export_torchscript -\u2013model_path = /path/to/model Tutorials \u00b6 Text Classification Tabular Data Classification Image Classification Multimodal Classification Example Use Cases \u00b6 Named Entity Recognition Tagging Natural Language Understanding Machine Translation Chit-Chat Dialogue Modeling through seq2seq Sentiment Analysis One-shot Learning with Siamese Networks Visual Question Answering Spoken Digit Speech Recognition Speaker Verification Binary Classification (Titanic) Timeseries forecasting Timeseries forecasting (Weather) Movie rating prediction Multi-label classification Multi-Task Learning Simple Regression: Fuel Efficiency Prediction Fraud Detection More Information \u00b6 Read our publications on Ludwig , declarative ML , and Ludwig\u2019s SoTA benchmarks . Learn more about how Ludwig works , how to get started , and work through more examples . If you are interested in contributing, have questions, comments, or thoughts to share, or if you just want to be in the know, please consider joining the Ludwig Slack and follow us on Twitter ! Getting Involved \u00b6 Slack Twitter Medium GitHub Issues","title":"Ludwig"},{"location":"#what-is-ludwig","text":"Ludwig is a declarative machine learning framework that makes it easy to define machine learning pipelines using a simple and flexible data-driven configuration system. Ludwig is suitable for a wide variety of AI tasks, and is hosted by the Linux Foundation AI & Data . The configuration declares the input and output features, with their respective data types. Users can also specify additional parameters to preprocess, encode, and decode features, load from pre-trained models, compose the internal model architecture, set training parameters, or run hyperparameter optimization. Ludwig will build an end-to-end machine learning pipeline automatically, using whatever is explicitly specified in the configuration, while falling back to smart defaults for any parameters that are not.","title":"What is Ludwig?"},{"location":"#declarative-machine-learning","text":"Ludwig\u2019s declarative approach to machine learning empowers you to have full control of the components of the machine learning pipeline that you care about, while leaving it up to Ludwig to make reasonable decisions for the rest. Analysts, scientists, engineers, and researchers use Ludwig to explore state-of-the-art model architectures, run hyperparameter search, scale up to larger than available memory datasets and multi-node clusters, and finally serve the best model in production. Finally, the use of abstract interfaces throughout the codebase makes it easy for users to extend Ludwig by adding new models, metrics, losses, and preprocessing functions that can be registered to make them immediately useable in the same unified configuration system.","title":"Declarative Machine Learning"},{"location":"#main-features","text":"Data-Driven configuration system A config YAML file that describes the schema of your data (input features, output features, and their types) is all you need to start training deep learning models. Ludwig uses declared features to compose a deep learning model accordingly. input_features : - name : data_column_1 type : number - name : data_column_2 type : category - name : data_column_3 type : text - name : data_column_4 type : image ... output_features : - name : data_column_5 type : number - name : data_column_6 type : category ... Training, prediction, and evaluation from the command line Simple commands can be used to train models and predict new data. ludwig train --config config.yaml --dataset data.csv ludwig predict --model_path results/experiment_run/model --dataset test.csv ludwig eval --model_path results/experiment_run/model --dataset test.csv Programmatic API Ludwig also provides a simple programmatic API for all of the functionality described above and more. from ludwig.api import LudwigModel # train a model config = { \"input_features\" : [ ... ], \"output_features\" : [ ... ], } model = LudwigModel ( config ) data = pd . read_csv ( \"data.csv\" ) train_stats , _ , model_dir = model . train ( data ) # or load a model model = LudwigModel . load ( model_dir ) # obtain predictions predictions = model . predict ( data ) Distributed training Train models in a distributed setting using Horovod , which allows training on a single machine with multiple GPUs or multiple machines with multiple GPUs. Serving Serve models using FastAPI. ludwig serve --model_path ./results/experiment_run/model curl http://0.0.0.0:8000/predict -X POST -F \"movie_title=Friends With Money\" -F \"content_rating=R\" -F \"genres=Art House & International, Comedy, Drama\" -F \"runtime=88.0\" -F \"top_critic=TRUE\" -F \"review_content=The cast is terrific, the movie isn't.\" Hyperparameter optimization Run hyperparameter optimization locally or using Ray Tune . ludwig hyperopt --config config.yaml --dataset data.csv AutoML Ludwig AutoML takes a dataset, the target column, and a time budget, and returns a trained Ludwig model. Third-Party integrations Ludwig provides an extendable interface to integrate with third-party systems for tracking experiments. Third-party integrations exist for Comet ML, Weights & Biases, WhyLabs, and MLFlow. Extensibility Ludwig is built from the ground up with extensibility in mind. It is easy to add new data types by implementing clear, well-documented abstract classes that define functions to preprocess, encode, and decode data. Furthermore, new torch nn.Module models can be easily added by them to a registry. This encourages reuse and sharing new models with the community. Refer to the Developer Guide for further details.","title":"Main Features"},{"location":"#quick-start","text":"For a full tutorial, check out the official getting started guide , or take a look at end-to-end Examples .","title":"Quick Start"},{"location":"#step-1-install","text":"Install from PyPi. Be aware that Ludwig requires Python 3.7+. pip install ludwig","title":"Step 1: Install"},{"location":"#step-2-define-a-configuration","text":"Create a config that describes the schema of your data. Assume we have a text classification task, with data containing a sentence and class column like the following. sentence class Former president Barack Obama ... politics Juventus hired Cristiano Ronaldo ... sport LeBron James joins the Lakers ... sport ... ... A configuration will look like this. input_features : - name : sentence type : text output_features : - name : class type : category Starting from a simple config like the one above, any and all aspects of the model architecture, training loop, hyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration to customize the pipeline to meet your requirements. input_features : - name : sentence type : text encoder : transformer layers : 6 embedding_size : 512 output_features : - name : class type : category loss : cross_entropy trainer : epochs : 50 batch_size : 64 optimizer : type : adamw beat1 : 0.9 learning_rate : 0.001 backend : type : ray cache_format : parquet processor : type : dask trainer : use_gpu : true num_workers : 4 resources_per_worker : CPU : 4 GPU : 1 hyperopt : metric : f1 sampler : random parameters : title.num_layers : lower : 1 upper : 5 trainer.learning_rate : values : [ 0.01 , 0.003 , 0.001 ] For details on what can be configured, check out Ludwig Configuration docs.","title":"Step 2: Define a configuration"},{"location":"#step-3-train-a-model","text":"Simple commands can be used to train models and predict new data. ludwig train --config config.yaml --dataset data.csv","title":"Step 3: Train a model"},{"location":"#step-4-predict-and-evaluate","text":"The training process will produce a model that can be used for evaluating on and obtaining predictions for new data. ludwig predict --model path/to/trained/model --dataset heldout.csv ludwig evaluate --model path/to/trained/model --dataset heldout.csv","title":"Step 4: Predict and evaluate"},{"location":"#step-5-visualize","text":"Ludwig provides a suite of visualization tools allows you to analyze models' training and test performance and to compare them. ludwig visualize --visualization compare_performance --test_statistics path/to/test_statistics_model_1.json path/to/test_statistics_model_2.json For the full set of visualization see the Visualization Guide .","title":"Step 5: Visualize"},{"location":"#step-6-happy-modeling","text":"Try applying Ludwig to your data. Reach out if you have any questions.","title":"Step 6: Happy modeling"},{"location":"#advantages","text":"Minimal machine learning boilerplate Ludwig takes care of the engineering complexity of machine learning out of the box, enabling research scientists to focus on building models at the highest level of abstraction. Data preprocessing, hyperparameter optimization, device management, and distributed training for torch.nn.Module models come completely free. Easily build your benchmarks Creating a state-of-the-art baseline and comparing it with a new model is a simple config change. Easily apply new architectures to multiple problems and datasets Apply new models across the extensive set of tasks and datasets that Ludwig supports. Ludwig includes a full benchmarking toolkit accessible to any user, for running experiments with multiple models across multiple datasets with just a simple configuration. Highly configurable data preprocessing, modeling, and metrics Any and all aspects of the model architecture, training loop, hyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration to customize the pipeline to meet your requirements. For details on what can be configured, check out Ludwig Configuration docs. Multi-modal, multi-task learning out-of-the-box Mix and match tabular data, text, images, and even audio into complex model configurations without writing code. Rich model exporting and tracking Automatically track all trials and metrics with tools like Tensorboard, Comet ML, Weights & Biases, MLFlow, and Aim Stack. Automatically scale training to multi-GPU, multi-node clusters Go from training on your local machine to the cloud without code changes. Low-code interface for state-of-the-art models, including pre-trained Huggingface Transformers Ludwig also natively integrates with pre-trained models, such as the ones available in Huggingface Transformers . Users can choose from a vast collection of state-of-the-art pre-trained PyTorch models to use without needing to write any code at all. For example, training a BERT-based sentiment analysis model with Ludwig is as simple as: ludwig train --dataset sst5 --config_str \u201c { input_features: [{ name: sentence, type: text, encoder: bert }] , output_features: [{ name: label, type: category }]} \u201d Low-code interface for AutoML Ludwig AutoML allows users to obtain trained models by providing just a dataset, the target column, and a time budget. auto_train_results = ludwig . automl . auto_train ( dataset = my_dataset_df , target = target_column_name , time_limit_s = 7200 ) Easy productionisation Ludwig makes it easy to serve deep learning models, including on GPUs. Launch a REST API for your trained Ludwig model. ludwig serve --model_path = /path/to/model Ludwig supports exporting models to efficient Torschscript bundles. ludwig export_torchscript -\u2013model_path = /path/to/model","title":"Advantages"},{"location":"#tutorials","text":"Text Classification Tabular Data Classification Image Classification Multimodal Classification","title":"Tutorials"},{"location":"#example-use-cases","text":"Named Entity Recognition Tagging Natural Language Understanding Machine Translation Chit-Chat Dialogue Modeling through seq2seq Sentiment Analysis One-shot Learning with Siamese Networks Visual Question Answering Spoken Digit Speech Recognition Speaker Verification Binary Classification (Titanic) Timeseries forecasting Timeseries forecasting (Weather) Movie rating prediction Multi-label classification Multi-Task Learning Simple Regression: Fuel Efficiency Prediction Fraud Detection","title":"Example Use Cases"},{"location":"#more-information","text":"Read our publications on Ludwig , declarative ML , and Ludwig\u2019s SoTA benchmarks . Learn more about how Ludwig works , how to get started , and work through more examples . If you are interested in contributing, have questions, comments, or thoughts to share, or if you just want to be in the know, please consider joining the Ludwig Slack and follow us on Twitter !","title":"More Information"},{"location":"#getting-involved","text":"Slack Twitter Medium GitHub Issues","title":"Getting Involved"},{"location":"community/","text":"Chat \u00b6 We use Slack as a chat solution for allowing both Ludwig users and developers to interact in a timely, more synchronous way. Click here to receive an invitation. Forum \u00b6 We use GitHub Discussions to provide a forum for the community to discuss. Everything that is not an issue and relates Ludwig can be discussed here: use-cases, requests for help and suggestions, discussions on the future of the project, and other similar topics. The forum is ideal for asynchronous communication. Community Policy \u00b6 We craft Ludwig with love and care, to the best of our skills and knowledge, and this project would not be possible without the contribution of an incredible community. Members of the Ludwig community provide fixes, new features, functionality, and documentation, which not only improves Ludwig but also shapes technical direction. We are really grateful for that and in exchange we strive to make the development process as open as possible and communication with the development team easy and direct. We strive to create an inclusive community where everyone is respected. Harassment and any other form of non-inclusive behavior will not be tolerated. Issues \u00b6 If you encounter an issue when using Ludwig, please add it to our GitHub Issues tracker . Please make sure we are able to replicate the issue by providing the model definition + command + data or code + data. If your data cannot be shared, please use the synthesize_dataset command line utility to create a synthetic data with the same feature types. Example: ludwig synthesize_dataset --features = \"[ \\ {name: text, type: text}, \\ {name: category, type: category}, \\ {name: number, type: number}, \\ {name: binary, type: binary}, \\ {name: set, type: set}, \\ {name: bag, type: bag}, \\ {name: sequence, type: sequence}, \\ {name: timeseries, type: timeseries}, \\ {name: date, type: date}, \\ {name: h3, type: h3}, \\ {name: vector, type: vector}, \\ {name: image, type: image} \\ ]\" --dataset_size = 10 --output_path = synthetic_dataset.csv","title":"Community"},{"location":"community/#chat","text":"We use Slack as a chat solution for allowing both Ludwig users and developers to interact in a timely, more synchronous way. Click here to receive an invitation.","title":"Chat"},{"location":"community/#forum","text":"We use GitHub Discussions to provide a forum for the community to discuss. Everything that is not an issue and relates Ludwig can be discussed here: use-cases, requests for help and suggestions, discussions on the future of the project, and other similar topics. The forum is ideal for asynchronous communication.","title":"Forum"},{"location":"community/#community-policy","text":"We craft Ludwig with love and care, to the best of our skills and knowledge, and this project would not be possible without the contribution of an incredible community. Members of the Ludwig community provide fixes, new features, functionality, and documentation, which not only improves Ludwig but also shapes technical direction. We are really grateful for that and in exchange we strive to make the development process as open as possible and communication with the development team easy and direct. We strive to create an inclusive community where everyone is respected. Harassment and any other form of non-inclusive behavior will not be tolerated.","title":"Community Policy"},{"location":"community/#issues","text":"If you encounter an issue when using Ludwig, please add it to our GitHub Issues tracker . Please make sure we are able to replicate the issue by providing the model definition + command + data or code + data. If your data cannot be shared, please use the synthesize_dataset command line utility to create a synthetic data with the same feature types. Example: ludwig synthesize_dataset --features = \"[ \\ {name: text, type: text}, \\ {name: category, type: category}, \\ {name: number, type: number}, \\ {name: binary, type: binary}, \\ {name: set, type: set}, \\ {name: bag, type: bag}, \\ {name: sequence, type: sequence}, \\ {name: timeseries, type: timeseries}, \\ {name: date, type: date}, \\ {name: h3, type: h3}, \\ {name: vector, type: vector}, \\ {name: image, type: image} \\ ]\" --dataset_size = 10 --output_path = synthetic_dataset.csv","title":"Issues"},{"location":"faq/","text":"Where can I find Ludwig's development roadmap? \u00b6 Larger projects are tracked in GitHub Projects . Smaller feature requests are tracked in Github Issues . We try our best to keep these up to date, but if there's a specific feature or model you are interested in, feel free to ping the Ludwig Slack . How can I help? \u00b6 Join the Ludwig Slack ! Sometimes we'll organize community fixit, documentation, and bug bash efforts, or consider taking on an easy bug to start. Can I use Ludwig for my project? \u00b6 Yes! The people behind Ludwig are veterans of research and open source. If your work does get published, please consider citing Ludwig and submitting improvements back to Ludwig. How to cite: @misc{Molino2019, author = {Piero Molino and Yaroslav Dudin and Sai Sumanth Miryala}, title = {Ludwig: a type-based declarative deep learning toolbox}, year = {2019}, eprint = {arXiv:1909.07930}, } Can I use Ludwig models in production? \u00b6 Yes! Ludwig models can be exported to Neuropod, MLFlow, and Torchscript. ludwig serve provides basic POST/GET serving endpoints, powered by FastAPI. If you are interested in a more sophisticated, hosted cloud infrastructure solution with reliable SLAs, check out Predibase. Does Ludwig's Architecture work for model X? \u00b6 Most likely. Ludwig's encoder-combiner-decoder framework is designed to generally mapping some input to some output. Encoders parse raw input data into tensors (potentially using a model). Combiners combine the outputs of Input Encoders (potentially using a model). Decoders decode the outputs of Encoders and Combiners into output tensors (potentially using a model). Decoder-only, encoder-only, encoder-decoder, vanilla feed-forward, transformers, and more have all been implemented in Ludwig. What does Ludwig not support (yet)? \u00b6 Domains of deep learning that Ludwig does not support (yet): Self-supervised learning. Reinforcement learning. Generative image and audio models (generative text models are supported). We are actively working on supporting self-supervised learning. Do all datasets need to be loaded in memory? \u00b6 Locally, it depends on the type of feature: image features can be dynamically loaded from disk from an opened hdf5 file, while other types of features are loaded entirely in memory for speed. Ludwig supports training with very large datasets on Ray using Ray Datasets . Read more about using Ludwig on Ray . If you are interested in a premium hosted Ludwig infrastructure and APIs, with a richer set of APIs to support modeling with large datasets, check out Predibase. Who develops Ludwig? \u00b6 Ludwig was created in 2019 by Piero Molino, with help from Yaroslav Dudin, and Sai Sumanth Miryala while at Uber AI. Today, Ludwig is open source, supported by the Linux Foundation, with source code hosted on Github. Ludwig is actively developed and maintained by Ludwig Maintainers , which consists mostly of staff at Predibase, and community contributors, all of whom are listed in each of Ludwig's release notes. Happy contributing!","title":"FAQ"},{"location":"faq/#where-can-i-find-ludwigs-development-roadmap","text":"Larger projects are tracked in GitHub Projects . Smaller feature requests are tracked in Github Issues . We try our best to keep these up to date, but if there's a specific feature or model you are interested in, feel free to ping the Ludwig Slack .","title":"Where can I find Ludwig's development roadmap?"},{"location":"faq/#how-can-i-help","text":"Join the Ludwig Slack ! Sometimes we'll organize community fixit, documentation, and bug bash efforts, or consider taking on an easy bug to start.","title":"How can I help?"},{"location":"faq/#can-i-use-ludwig-for-my-project","text":"Yes! The people behind Ludwig are veterans of research and open source. If your work does get published, please consider citing Ludwig and submitting improvements back to Ludwig. How to cite: @misc{Molino2019, author = {Piero Molino and Yaroslav Dudin and Sai Sumanth Miryala}, title = {Ludwig: a type-based declarative deep learning toolbox}, year = {2019}, eprint = {arXiv:1909.07930}, }","title":"Can I use Ludwig for my project?"},{"location":"faq/#can-i-use-ludwig-models-in-production","text":"Yes! Ludwig models can be exported to Neuropod, MLFlow, and Torchscript. ludwig serve provides basic POST/GET serving endpoints, powered by FastAPI. If you are interested in a more sophisticated, hosted cloud infrastructure solution with reliable SLAs, check out Predibase.","title":"Can I use Ludwig models in production?"},{"location":"faq/#does-ludwigs-architecture-work-for-model-x","text":"Most likely. Ludwig's encoder-combiner-decoder framework is designed to generally mapping some input to some output. Encoders parse raw input data into tensors (potentially using a model). Combiners combine the outputs of Input Encoders (potentially using a model). Decoders decode the outputs of Encoders and Combiners into output tensors (potentially using a model). Decoder-only, encoder-only, encoder-decoder, vanilla feed-forward, transformers, and more have all been implemented in Ludwig.","title":"Does Ludwig's Architecture work for model X?"},{"location":"faq/#what-does-ludwig-not-support-yet","text":"Domains of deep learning that Ludwig does not support (yet): Self-supervised learning. Reinforcement learning. Generative image and audio models (generative text models are supported). We are actively working on supporting self-supervised learning.","title":"What does Ludwig not support (yet)?"},{"location":"faq/#do-all-datasets-need-to-be-loaded-in-memory","text":"Locally, it depends on the type of feature: image features can be dynamically loaded from disk from an opened hdf5 file, while other types of features are loaded entirely in memory for speed. Ludwig supports training with very large datasets on Ray using Ray Datasets . Read more about using Ludwig on Ray . If you are interested in a premium hosted Ludwig infrastructure and APIs, with a richer set of APIs to support modeling with large datasets, check out Predibase.","title":"Do all datasets need to be loaded in memory?"},{"location":"faq/#who-develops-ludwig","text":"Ludwig was created in 2019 by Piero Molino, with help from Yaroslav Dudin, and Sai Sumanth Miryala while at Uber AI. Today, Ludwig is open source, supported by the Linux Foundation, with source code hosted on Github. Ludwig is actively developed and maintained by Ludwig Maintainers , which consists mostly of staff at Predibase, and community contributors, all of whom are listed in each of Ludwig's release notes. Happy contributing!","title":"Who develops Ludwig?"},{"location":"configuration/","text":"Ludwig models are configured by a single config with the following keys: input_features : [] combiner : {} output_features : [] trainer : {} preprocessing : {} hyperopt : {} The config specifies input features, output features, preprocessing, model architecture, training loop, hyperparameter search, and backend infrastructure -- everything that's needed to build, train, and evaluate a model. The Ludwig configuration mixes ease of use, by means of reasonable defaults, with flexibility, by means of detailed control over the parameters of your model. Only input_features and output_features are required while all other fields use reasonable defaults, but can be optionally set or modified manually. The config can be expressed as a python dictionary ( --config_str for Ludwig's CLI ), or as a YAML file ( --config ). YAML Python Dict input_features : - name : Pclass type : category - name : Sex type : category - name : Age type : number preprocessing : missing_value_strategy : fill_with_mean - name : SibSp type : number - name : Parch type : number - name : Fare type : number preprocessing : missing_value_strategy : fill_with_mean - name : Embarked type : category output_features : - name : Survived type : binary { \"input_features\" : [ { \"name\" : \"Pclass\" , \"type\" : \"category\" }, { \"name\" : \"Sex\" , \"type\" : \"category\" }, { \"name\" : \"Age\" , \"type\" : \"number\" , \"preprocessing\" : { \"missing_value_strategy\" : \"fill_with_mean\" } }, { \"name\" : \"SibSp\" , \"type\" : \"number\" }, { \"name\" : \"Parch\" , \"type\" : \"number\" }, { \"name\" : \"Fare\" , \"type\" : \"number\" , \"preprocessing\" : { \"missing_value_strategy\" : \"fill_with_mean\" } }, { \"name\" : \"Embarked\" , \"type\" : \"category\" } ], \"output_features\" : [ { \"name\" : \"Survived\" , \"type\" : \"binary\" } ] }","title":"Configuration"},{"location":"configuration/backend/","text":"The same Ludwig config / Python code that runs on your local machine can be executed remotely in a distributed manner with zero code changes. This distributed execution includes preprocessing, training, and batch prediction. In most cases, Ludwig will be able to automatically detect if you're running in an environment that supports distributed execution, but you can also make this explicit on the command line with the --backend arg or by providing a backend section to the Ludwig config YAML: backend : type : ray cache_dir : s3://my_bucket/cache cache_credentials : /home/user/.credentials.json processor : type : dask trainer : type : horovod loader : {} Parameters: type : How the job will be distributed, one of local , ray , horovod . cache_dir : Where the preprocessed data will be written on disk, defaults to the location of the input dataset. cache_credentials : Optional dictionary of credentials (or path to credential JSON file) used to write to the cache. processor : (Ray only) parameters to configure execution of distributed data processing. trainer : (Ray only) parameters to configure execution of distributed training. loader : (Ray only) parameters to configure data loading from processed data to training batches. Processor \u00b6 The processor section configures distributed data processing. The local backend uses the Pandas dataframe library, which runs in a single process with the entire datasets in memory. To make the data processing scalable to large datasets, we support two distributed dataframe libraries with the ray backend: dask : (default) a lazily executed version of distributed Pandas. modin : an eagerly executed version of distributed Pandas. Dask \u00b6 Dask is the default distributed data processing library when using Ludwig on Ray. It executes distributed Pandas operations on partitions of the data in parallel. One beneficial property of Dask is that it is executed lazily, which allows it to stream very large datasets without needing to hold the entire dataset in distributed memory at once. One downside to Dask is that it can require some tuning to get the best performance. There are two knobs we expose in Ludwig for tuning Dask: parallelism : the number of partitions to divide the dataset into (defaults to letting Dask figure this out automatically). persist : whether intermediate stages of preprocessing should be cached in distributed memory (default: true ). Increasing parallelism can reduce memory pressure during preprocessing for large datasets and increase parallelism (horizontal scaling). The downside to too much parallelism is that there is some overhead for each partition-level operation (serialization and deserialization), which can dominate the runtime if set too high. Setting persist to false can be useful if the dataset is too large for all the memory and disk of the entire Ray cluster. Only set this to false if you're seeing issues running out of memory or disk space. Example: backend : type : ray processor : type : dask parallelism : 100 persist : true Modin \u00b6 Modin is an eagerly-executed distributed dataframe library that closely mirrors the behavior of Pandas. Because it behaves almost identically to Pandas but is able to distribute the dataset across the Ray cluster, there are fewer things to configure to optimize its performance. Support for Modin is currently experimental. Example: backend : type : ray processor : type : modin Trainer \u00b6 The trainer section configures distributed training. Currently, only horovod is supported as a distributed trainer, but we will be adding support for more frameworks in future releases. Horovod \u00b6 Horovod is a distributed data-parallel framework that is optimized for bandwidth-constrained computing environments. It makes use of Nvidia's NCCL for fast GPU-to-GPU communication. The following parameters can be configured for Horovod: use_gpu : whether to use GPUs for training (defaults to true when the cluster has at least one GPU). num_workers : how many Horovod workers to use for training (defaults to the number of GPUs, or 1 if no GPUs are found). resources_per_worker : the Ray resources to assign to each Horovod worker (defaults to 1 CPU and 1 GPU if available). logdir : path to the file directory where logs should be persisted. max_retries : number of retries when Ray actors fail (defaults to 3). See the Ray Train API for more details on these parameters. Note Currently Ray Train will attempt to pack multiple Horovod workers onto the same node by default. As such, if you are training on CPUs, you will likely want to increase the CPU resources_per_worker to force Ray to spread workers across nodes. In the near future, Ray will support SPREAD scheduling, at which point we will change the default number of workers during CPU training to the number of nodes in the cluster. Example: backend : type : ray trainer : type : horovod use_gpu : true num_workers : 4 resources_per_worker : CPU : 2 GPU : 1 Loader \u00b6 The loader section configures the \"last mile\" data ingest from processed data (typically cached in the Parquet format) to tensor batches used for training the model. When training a deep learning model at scale, the chain is only as strong as its weakest link -- in other words, the data loading pipeline needs to be at least as fast as the GPU forward / backward passes, otherwise the whole process will be bottlenecked by the data loader. In most cases, Ludwig's defaults will be sufficient to get good data loading performance, but if you notice GPU utilization dropping even after scaling the batch size, or going long periods at 0% utilization before spiking up again, you may need to tune the loader parameters below to improve throughput: fully_executed : Force full evaluation of the preprocessed dataset by loading all blocks into cluster memory / storage (defaults to true ). Disable this if the dataset is much larger than the total amount of cluster memory allocated to the Ray object store and you notice that object spilling is occurring frequently during training. window_size_bytes : Load and shuffle the preprocessed dataset in discrete windows of this size (defaults to null , meaning data will not be windowed). Try configuring this is if shuffling is taking a very long time, indicated by every epoch of training taking many minutes to start. In general, larger window sizes result in more uniform shuffling (which can lead to better model performance in some cases), while smaller window sizes will be faster to load. This setting is particularly useful when running hyperopt over a large dataset. Example: backend : type : ray loader : fully_executed : false window_size_bytes : 500000000","title":"Backend"},{"location":"configuration/backend/#processor","text":"The processor section configures distributed data processing. The local backend uses the Pandas dataframe library, which runs in a single process with the entire datasets in memory. To make the data processing scalable to large datasets, we support two distributed dataframe libraries with the ray backend: dask : (default) a lazily executed version of distributed Pandas. modin : an eagerly executed version of distributed Pandas.","title":"Processor"},{"location":"configuration/backend/#dask","text":"Dask is the default distributed data processing library when using Ludwig on Ray. It executes distributed Pandas operations on partitions of the data in parallel. One beneficial property of Dask is that it is executed lazily, which allows it to stream very large datasets without needing to hold the entire dataset in distributed memory at once. One downside to Dask is that it can require some tuning to get the best performance. There are two knobs we expose in Ludwig for tuning Dask: parallelism : the number of partitions to divide the dataset into (defaults to letting Dask figure this out automatically). persist : whether intermediate stages of preprocessing should be cached in distributed memory (default: true ). Increasing parallelism can reduce memory pressure during preprocessing for large datasets and increase parallelism (horizontal scaling). The downside to too much parallelism is that there is some overhead for each partition-level operation (serialization and deserialization), which can dominate the runtime if set too high. Setting persist to false can be useful if the dataset is too large for all the memory and disk of the entire Ray cluster. Only set this to false if you're seeing issues running out of memory or disk space. Example: backend : type : ray processor : type : dask parallelism : 100 persist : true","title":"Dask"},{"location":"configuration/backend/#modin","text":"Modin is an eagerly-executed distributed dataframe library that closely mirrors the behavior of Pandas. Because it behaves almost identically to Pandas but is able to distribute the dataset across the Ray cluster, there are fewer things to configure to optimize its performance. Support for Modin is currently experimental. Example: backend : type : ray processor : type : modin","title":"Modin"},{"location":"configuration/backend/#trainer","text":"The trainer section configures distributed training. Currently, only horovod is supported as a distributed trainer, but we will be adding support for more frameworks in future releases.","title":"Trainer"},{"location":"configuration/backend/#horovod","text":"Horovod is a distributed data-parallel framework that is optimized for bandwidth-constrained computing environments. It makes use of Nvidia's NCCL for fast GPU-to-GPU communication. The following parameters can be configured for Horovod: use_gpu : whether to use GPUs for training (defaults to true when the cluster has at least one GPU). num_workers : how many Horovod workers to use for training (defaults to the number of GPUs, or 1 if no GPUs are found). resources_per_worker : the Ray resources to assign to each Horovod worker (defaults to 1 CPU and 1 GPU if available). logdir : path to the file directory where logs should be persisted. max_retries : number of retries when Ray actors fail (defaults to 3). See the Ray Train API for more details on these parameters. Note Currently Ray Train will attempt to pack multiple Horovod workers onto the same node by default. As such, if you are training on CPUs, you will likely want to increase the CPU resources_per_worker to force Ray to spread workers across nodes. In the near future, Ray will support SPREAD scheduling, at which point we will change the default number of workers during CPU training to the number of nodes in the cluster. Example: backend : type : ray trainer : type : horovod use_gpu : true num_workers : 4 resources_per_worker : CPU : 2 GPU : 1","title":"Horovod"},{"location":"configuration/backend/#loader","text":"The loader section configures the \"last mile\" data ingest from processed data (typically cached in the Parquet format) to tensor batches used for training the model. When training a deep learning model at scale, the chain is only as strong as its weakest link -- in other words, the data loading pipeline needs to be at least as fast as the GPU forward / backward passes, otherwise the whole process will be bottlenecked by the data loader. In most cases, Ludwig's defaults will be sufficient to get good data loading performance, but if you notice GPU utilization dropping even after scaling the batch size, or going long periods at 0% utilization before spiking up again, you may need to tune the loader parameters below to improve throughput: fully_executed : Force full evaluation of the preprocessed dataset by loading all blocks into cluster memory / storage (defaults to true ). Disable this if the dataset is much larger than the total amount of cluster memory allocated to the Ray object store and you notice that object spilling is occurring frequently during training. window_size_bytes : Load and shuffle the preprocessed dataset in discrete windows of this size (defaults to null , meaning data will not be windowed). Try configuring this is if shuffling is taking a very long time, indicated by every epoch of training taking many minutes to start. In general, larger window sizes result in more uniform shuffling (which can lead to better model performance in some cases), while smaller window sizes will be faster to load. This setting is particularly useful when running hyperopt over a large dataset. Example: backend : type : ray loader : fully_executed : false window_size_bytes : 500000000","title":"Loader"},{"location":"configuration/combiner/","text":"Combiners take the outputs of all input features encoders and combine them before providing the combined representation to the output feature decoders. You can specify which one to use in the combiner section of the configuration, and if you don't specify a combiner, the concat combiner will be used. Concat Combiner \u00b6 The concat combiner assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If any inputs have more than 2 dimensions, a sequence or set feature for example, set the flatten_inputs parameter to true . It concatenates along the h dimension, and then (optionally) passes the concatenated tensor through a stack of fully connected layers. It returns the final b x h' tensor where h' is the size of the last fully connected layer or the sum of the sizes of the h of all inputs in the case there are no fully connected layers. If only a single input feature and no fully connected layer is specified, the output of the input feature encoder is passed through the combiner unchanged. +-----------+ |Input | |Feature 1 +-+ +-----------+ | +---------+ +-----------+ | +------+ |Fully | |... +--->Concat+--->Connected+-> +-----------+ | +------+ |Layers | +-----------+ | +---------+ |Input +-+ |Feature N | +-----------+ These are the available parameters of a concat combiner: fc_layers (default null ): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . For a description of the parameters of each initializer, see torch.nn.init . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . For a description of the parameters of each initializer, see torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate. flatten_inputs (default false ): if true flatten the tensors from all the input features into a vector. residual (default false ): if true adds a residual connection to each fully connected layer block. It is required that all fully connected layers have the same size for this parameter to work correctly. Example configuration of a concat combiner: type : concat fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : 'glorot_uniform' bias_initializer : 'zeros' norm : null norm_params : null activation : relu dropout : 0 flatten_inputs : false residual : false Sequence Concat Combiner \u00b6 The sequence_concat combiner assumes at least one output from encoders is a tensors of size b x s x h where b is the batch size, s is the length of the sequence and h is the hidden dimension. A sequence-like (sequence, text or time series) input feature can be specified with the main_sequence_feature parameter which takes the name of sequence-like input feature as its value. If no main_sequence_feature is specified, the combiner will look through all the features in the order they are defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text or time series). If it cannot find one it will raise an exception, otherwise the output of that feature will be used for concatenating the other features along the sequence s dimension. If there are other input features with a rank 3 output tensor, the combiner will concatenate them alongside the s dimension, which means that all of them must have identical s dimension, otherwise a dimension mismatch error will be returned thrown during training when a datapoint with two sequential features of different lengths are provided. Other features that have a b x h rank 2 tensor output will be replicated s times and concatenated to the s dimension. The final output is a b x s x h' tensor where h' is the size of the concatenation of the h dimensions of all input features. Sequence Feature Output +---------+ |emb seq 1| +---------+ |... +--+ +---------+ | +-----------------+ |emb seq n| | |emb seq 1|emb oth| +------+ +---------+ | +-----------------+ | | +-->... |... +-->+Reduce+-> Other | +-----------------+ | | Feature | |emb seq n|emb oth| +------+ Output | +-----------------+ | +-------+ | |emb oth+----+ +-------+ These are the available parameters of a sequence_concat combiner: main_sequence_feature (default null ): name of a sequence, text, or time series feature to concatenate the outputs of the other features to. If no main_sequence_feature is specified, the combiner will look through all the features in the order they are defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text or time series). If it cannot find one it will raise an exception, otherwise the output of that feature will be used for concatenating the other features along the sequence s dimension. If there are other input features with a rank 3 output tensor, the combiner will concatenate them alongside the s dimension. All sequence-like input features must have identical s dimension, otherwise an error will be thrown. reduce_output (default null ): describes the strategy to use to aggregate the embeddings of the items of the set. Possible values are null , sum , mean and sqrt (the weighted sum divided by the square root of the sum of the squares of the weights). Example configuration of a sequence_concat combiner: type : sequence_concat main_sequence_feature : null reduce_output : null Sequence Combiner \u00b6 The sequence combiner stacks a sequence concat combiner with a sequence encoder. All the considerations about input tensor ranks described for the sequence concat combiner apply also in this case, but the main difference is that this combiner uses the b x s x h' output of the sequence concat combiner, where b is the batch size, s is the sequence length and h' is the sum of the hidden dimensions of all input features, as input for any of the sequence encoders described in the sequence features encoders section . Refer to that section for more detailed information about the sequence encoders and their parameters. All considerations on the shape of the outputs for the sequence encoders also apply to sequence combiner. Sequence Feature Output +---------+ |emb seq 1| +---------+ |... +--+ +---------+ | +-----------------+ |emb seq n| | |emb seq 1|emb oth| +--------+ +---------+ | +-----------------+ |Sequence| +-->... |... +-->+Encoder +-> Other | +-----------------+ | | Feature | |emb seq n|emb oth| +--------+ Output | +-----------------+ | +-------+ | |emb oth+----+ +-------+ Example configuration of a sequence combiner: type : sequence main_sequence_feature : null encoder : parallel_cnn ... encoder parameters ... TabNet Combiner \u00b6 The tabnet combiner implements the TabNet model, which uses attention and sparsity to achieve high performance on tabular data. It assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If the input tensors have a different shape, it automatically flattens them. It returns the final b x h' tensor where h' is the user-specified output size. +-----------+ |Input | |Feature 1 +-+ +-----------+ | +-----------+ | +------+ |... +--->TabNet+--> +-----------+ | +------+ +-----------+ | |Input +-+ |Feature N | +-----------+ These are the available parameters of a tabnet combiner: size : the size of the hidden layers. N_a in the paper. output_size : the size of the output of each step and of the final aggregated representation. N_d in the paper. num_steps (default 1 ): number of steps / repetitions of the attentive transformer and feature transformer computations. N_steps in the paper. num_total_blocks (default 4 ): total number of feature transformer blocks at each step. num_shared_blocks (default 2 ): number of shared feature transformer blocks across the steps. relaxation_factor (default 1.5 ): Factor that influences how many times a feature should be used across the steps of computation. a value of 1 implies it each feature should be use once, a higher value allows for multiple usages. gamma in the paper. bn_epsilon (default 0.001 ): epsilon to be added to the batch norm denominator. bn_momentum (default 0.7 ): momentum of the batch norm. m_B in the paper. bn_virtual_bs (default null ): size of the virtual batch size used by ghost batch norm. If null , regular batch norm is used instead. B_v from the paper. sparsity (default 0.00001 ): multiplier of the sparsity inducing loss. lambda_sparse in the paper. dropout (default 0 ): dropout rate. Example configuration of a tabnet combiner: type : tabnet size : 32 ooutput_size : 32 num_steps : 5 num_total_blocks : 4 num_shared_blocks : 2 relaxation_factor : 1.5 bn_epsilon : 0.001 bn_momentum : 0.7 bn_virtual_bs : 128 sparsity : 0.00001 dropout : 0 Transformer Combiner \u00b6 The transformer combiner combines input features using a stack of Transformer blocks (from Attention Is All You Need ). It assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If the input tensors have a different shape, it automatically flattens them. It then projects each input tensor to the same hidden / embedding size and encodes them with a stack of Transformer layers. Finally, the transformer combiner applies a reduction to the outputs of the Transformer stack, followed by optional fully connected layers. The output is a b x h' tensor where h' is the size of the last fully connected layer or the hidden / embedding size, or a b x n x h' where n is the number of input features and h' is the hidden / embedding size if no reduction is applied. +-----------+ |Input | |Feature 1 +-+ +-----------+ | +-----------+ | +------------+ +------+ +----------+ |... +--->|Transformer +-->|Reduce+-->|Fully +-> | | | |Stack | +------+ |Connected | +-----------+ | +------------+ |Layers | +-----------+ | +----------+ |Input +-+ |Feature N | +-----------+ These are the available parameters of a transformer combiner: num_layers (default 1 ): number of layers in the stack of transformer blocks. hidden_size (default 256 ): hidden / embedding size of each transformer block. num_heads (default 8 ): number of attention heads of each transformer block. transformer_output_size (default 256 ): size of the fully connected layers inside each transformer block. dropout (default 0 ): dropout rate after the transformer. fc_layers (default null ): is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers to apply after reduction of the transformer output sequence. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate for the fully connected layers. fc_residual (default false ): if true adds a residual connection to each fully connected layer block. It is required that all fully connected layers have the same size for this parameter to work correctly. reduce_output (default mean ): describes the strategy to use to aggregate the output of the transformer. Possible values include last , sum , mean , concat , or none . Example configuration of a transformer combiner: type : transformer num_layers : 1 hidden_size : 256 num_heads : 8 transformer_output_size : 256 dropout : 0.1 fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : True weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null fc_activation : relu fc_dropout : 0 fc_residual : null reduce_output : mean Resources to learn more about transformers: CS480/680 Lecture 19: Attention and Transformer Networks (VIDEO) Attention is all you need - Attentional Neural Network Models Masterclass (VIDEO) Illustrated: Self-Attention (Colab notebook) TabTransformer Combiner \u00b6 The tabtransformer combiner combines input features in the following sequence of operations. Except for binary and number features, the combiner projects features to an embedding size. These features are concatenated as if they were a sequence and passed through a transformer. After the transformer, the number and binary features are concatenated (which are of size 1) and then concatenated with the output of the transformer and is passed to a stack of fully connected layers (from TabTransformer: Tabular Data Modeling Using Contextual Embeddings ). It assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If the input tensors have a different shape, it automatically flattens them. It then projects each input tensor to the same hidden / embedding size and encodes them with a stack of Transformer layers. Finally, the transformer combiner applies a reduction to the outputs of the Transformer stack, followed by the above concatenation and optional fully connected layers. The output is a b x h' tensor where h' is the size of the last fully connected layer or the hidden / embedding size, or a b x n x h' where n is the number of input features and h' is the hidden / embedding size if no reduction is applied. +-----------+ |Input | |Feature 1 +-+ +-----------+ | +-----------+ | +-------------+ +--------------+ +------ + +----------+ +----------+ | +--->| Categoricial+->|TabTransformer +-->|Reduce +-> | Combined +->|Fully +-> | | | | Embeddings | |Stack | +-------+ | Hidden | |Connected | | | | +-------------+ +---------------+ | Layers | |Layers | |... | | +----------+ +----------+ | | | +-----------+ ^ | | | | Binary & | | +-----------+ |------------------------->| Numerical |------------------ +-----------+ | | Encodings | |Input +-+ +-----------+ |Feature N | +-----------+ These are the available parameters of a transformer combiner: num_layers (default 1 ): number of layers in the stack of transformer blocks. hidden_size (default 256 ): hidden / embedding size of each transformer block. num_heads (default 8 ): number of attention heads of each transformer block. transformer_output_size (default 256 ): size of the fully connected layers inside each transformer block. dropout (default 0 ): dropout rate after the transformer. fc_layers (default null ): is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers to apply after reduction of the transformer output sequence. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate for the fully connected layers. fc_residual (default false ): if true adds a residual connection to each fully connected layer block. It is required that all fully connected layers have the same size for this parameter to work correctly. reduce_output (default mean ): describes the strategy to use to aggregate the output of the transformer. Possible values include last , sum , mean , concat , or none . embed_input_feature_name (default null ) controls the size of the embeddings. Valid values are add which uses the hidden_size value or an integer to set a specific value. In the case of an integer value, it must be smaller than hidden_size . Example configuration of a tabtransformer combiner: type : tabtransformer num_layers : 1 hidden_size : 256 num_heads : 8 transformer_output_size : 256 dropout : 0.1 fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : True weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null fc_activation : relu fc_dropout : 0 fc_residual : null reduce_output : mean embed_input_fature_name : null Comparator Combiner \u00b6 The comparator combiner compares the hidden representation of two entities defined by lists of features. It assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If the input tensors have a different shape, it automatically flattens them. It then concatenates the representations of each entity and projects them both to vectors of size output_size . Finally, it compares the two entity representations by dot product, element-wise multiplication, absolute difference and bilinear product. It returns the final b x h' tensor where h' is the size of the concatenation of the four comparisons. +-----------+ |Entity 1 | |Input | |Feature 1 +-+ +-----------+ | +-----------+ | +-------+ +----------+ |... +--->|Concat +-->|FC Layers +--+ | | | +-------+ +----------+ | +-----------+ | | +-----------+ | | |Entity 1 +-+ | |Input | | |Feature N | | +-----------+ | +---------+ +-->| Compare +-> +-----------+ | +---------+ |Entity 2 | | |Input | | |Feature 1 +-+ | +-----------+ | | +-----------+ | +-------+ +----------+ | |... +--->|Concat +-->|FC Layers +--+ | | | +-------+ +----------+ +-----------+ | +-----------+ | |Entity 2 +-+ |Input | |Feature N | +-----------+ These are the available parameters of a comparator combiner: entity_1 : list of input features that compose the first entity to compare. entity_2 : list of input features that compose the second entity to compare. fc_layers (default null ): is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate for the fully connected layers. Example configuration of a comparator combiner: type : comparator entity_1 : [ feature_1 , feature_2 ] entity_2 : [ feature_3 , feature_4 ] fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : 'glorot_uniform' bias_initializer : 'zeros' norm : null norm_params : null activation : relu dropout : 0","title":"Combiner"},{"location":"configuration/combiner/#concat-combiner","text":"The concat combiner assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If any inputs have more than 2 dimensions, a sequence or set feature for example, set the flatten_inputs parameter to true . It concatenates along the h dimension, and then (optionally) passes the concatenated tensor through a stack of fully connected layers. It returns the final b x h' tensor where h' is the size of the last fully connected layer or the sum of the sizes of the h of all inputs in the case there are no fully connected layers. If only a single input feature and no fully connected layer is specified, the output of the input feature encoder is passed through the combiner unchanged. +-----------+ |Input | |Feature 1 +-+ +-----------+ | +---------+ +-----------+ | +------+ |Fully | |... +--->Concat+--->Connected+-> +-----------+ | +------+ |Layers | +-----------+ | +---------+ |Input +-+ |Feature N | +-----------+ These are the available parameters of a concat combiner: fc_layers (default null ): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . For a description of the parameters of each initializer, see torch.nn.init . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . For a description of the parameters of each initializer, see torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate. flatten_inputs (default false ): if true flatten the tensors from all the input features into a vector. residual (default false ): if true adds a residual connection to each fully connected layer block. It is required that all fully connected layers have the same size for this parameter to work correctly. Example configuration of a concat combiner: type : concat fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : 'glorot_uniform' bias_initializer : 'zeros' norm : null norm_params : null activation : relu dropout : 0 flatten_inputs : false residual : false","title":"Concat Combiner"},{"location":"configuration/combiner/#sequence-concat-combiner","text":"The sequence_concat combiner assumes at least one output from encoders is a tensors of size b x s x h where b is the batch size, s is the length of the sequence and h is the hidden dimension. A sequence-like (sequence, text or time series) input feature can be specified with the main_sequence_feature parameter which takes the name of sequence-like input feature as its value. If no main_sequence_feature is specified, the combiner will look through all the features in the order they are defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text or time series). If it cannot find one it will raise an exception, otherwise the output of that feature will be used for concatenating the other features along the sequence s dimension. If there are other input features with a rank 3 output tensor, the combiner will concatenate them alongside the s dimension, which means that all of them must have identical s dimension, otherwise a dimension mismatch error will be returned thrown during training when a datapoint with two sequential features of different lengths are provided. Other features that have a b x h rank 2 tensor output will be replicated s times and concatenated to the s dimension. The final output is a b x s x h' tensor where h' is the size of the concatenation of the h dimensions of all input features. Sequence Feature Output +---------+ |emb seq 1| +---------+ |... +--+ +---------+ | +-----------------+ |emb seq n| | |emb seq 1|emb oth| +------+ +---------+ | +-----------------+ | | +-->... |... +-->+Reduce+-> Other | +-----------------+ | | Feature | |emb seq n|emb oth| +------+ Output | +-----------------+ | +-------+ | |emb oth+----+ +-------+ These are the available parameters of a sequence_concat combiner: main_sequence_feature (default null ): name of a sequence, text, or time series feature to concatenate the outputs of the other features to. If no main_sequence_feature is specified, the combiner will look through all the features in the order they are defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text or time series). If it cannot find one it will raise an exception, otherwise the output of that feature will be used for concatenating the other features along the sequence s dimension. If there are other input features with a rank 3 output tensor, the combiner will concatenate them alongside the s dimension. All sequence-like input features must have identical s dimension, otherwise an error will be thrown. reduce_output (default null ): describes the strategy to use to aggregate the embeddings of the items of the set. Possible values are null , sum , mean and sqrt (the weighted sum divided by the square root of the sum of the squares of the weights). Example configuration of a sequence_concat combiner: type : sequence_concat main_sequence_feature : null reduce_output : null","title":"Sequence Concat Combiner"},{"location":"configuration/combiner/#sequence-combiner","text":"The sequence combiner stacks a sequence concat combiner with a sequence encoder. All the considerations about input tensor ranks described for the sequence concat combiner apply also in this case, but the main difference is that this combiner uses the b x s x h' output of the sequence concat combiner, where b is the batch size, s is the sequence length and h' is the sum of the hidden dimensions of all input features, as input for any of the sequence encoders described in the sequence features encoders section . Refer to that section for more detailed information about the sequence encoders and their parameters. All considerations on the shape of the outputs for the sequence encoders also apply to sequence combiner. Sequence Feature Output +---------+ |emb seq 1| +---------+ |... +--+ +---------+ | +-----------------+ |emb seq n| | |emb seq 1|emb oth| +--------+ +---------+ | +-----------------+ |Sequence| +-->... |... +-->+Encoder +-> Other | +-----------------+ | | Feature | |emb seq n|emb oth| +--------+ Output | +-----------------+ | +-------+ | |emb oth+----+ +-------+ Example configuration of a sequence combiner: type : sequence main_sequence_feature : null encoder : parallel_cnn ... encoder parameters ...","title":"Sequence Combiner"},{"location":"configuration/combiner/#tabnet-combiner","text":"The tabnet combiner implements the TabNet model, which uses attention and sparsity to achieve high performance on tabular data. It assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If the input tensors have a different shape, it automatically flattens them. It returns the final b x h' tensor where h' is the user-specified output size. +-----------+ |Input | |Feature 1 +-+ +-----------+ | +-----------+ | +------+ |... +--->TabNet+--> +-----------+ | +------+ +-----------+ | |Input +-+ |Feature N | +-----------+ These are the available parameters of a tabnet combiner: size : the size of the hidden layers. N_a in the paper. output_size : the size of the output of each step and of the final aggregated representation. N_d in the paper. num_steps (default 1 ): number of steps / repetitions of the attentive transformer and feature transformer computations. N_steps in the paper. num_total_blocks (default 4 ): total number of feature transformer blocks at each step. num_shared_blocks (default 2 ): number of shared feature transformer blocks across the steps. relaxation_factor (default 1.5 ): Factor that influences how many times a feature should be used across the steps of computation. a value of 1 implies it each feature should be use once, a higher value allows for multiple usages. gamma in the paper. bn_epsilon (default 0.001 ): epsilon to be added to the batch norm denominator. bn_momentum (default 0.7 ): momentum of the batch norm. m_B in the paper. bn_virtual_bs (default null ): size of the virtual batch size used by ghost batch norm. If null , regular batch norm is used instead. B_v from the paper. sparsity (default 0.00001 ): multiplier of the sparsity inducing loss. lambda_sparse in the paper. dropout (default 0 ): dropout rate. Example configuration of a tabnet combiner: type : tabnet size : 32 ooutput_size : 32 num_steps : 5 num_total_blocks : 4 num_shared_blocks : 2 relaxation_factor : 1.5 bn_epsilon : 0.001 bn_momentum : 0.7 bn_virtual_bs : 128 sparsity : 0.00001 dropout : 0","title":"TabNet Combiner"},{"location":"configuration/combiner/#transformer-combiner","text":"The transformer combiner combines input features using a stack of Transformer blocks (from Attention Is All You Need ). It assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If the input tensors have a different shape, it automatically flattens them. It then projects each input tensor to the same hidden / embedding size and encodes them with a stack of Transformer layers. Finally, the transformer combiner applies a reduction to the outputs of the Transformer stack, followed by optional fully connected layers. The output is a b x h' tensor where h' is the size of the last fully connected layer or the hidden / embedding size, or a b x n x h' where n is the number of input features and h' is the hidden / embedding size if no reduction is applied. +-----------+ |Input | |Feature 1 +-+ +-----------+ | +-----------+ | +------------+ +------+ +----------+ |... +--->|Transformer +-->|Reduce+-->|Fully +-> | | | |Stack | +------+ |Connected | +-----------+ | +------------+ |Layers | +-----------+ | +----------+ |Input +-+ |Feature N | +-----------+ These are the available parameters of a transformer combiner: num_layers (default 1 ): number of layers in the stack of transformer blocks. hidden_size (default 256 ): hidden / embedding size of each transformer block. num_heads (default 8 ): number of attention heads of each transformer block. transformer_output_size (default 256 ): size of the fully connected layers inside each transformer block. dropout (default 0 ): dropout rate after the transformer. fc_layers (default null ): is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers to apply after reduction of the transformer output sequence. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate for the fully connected layers. fc_residual (default false ): if true adds a residual connection to each fully connected layer block. It is required that all fully connected layers have the same size for this parameter to work correctly. reduce_output (default mean ): describes the strategy to use to aggregate the output of the transformer. Possible values include last , sum , mean , concat , or none . Example configuration of a transformer combiner: type : transformer num_layers : 1 hidden_size : 256 num_heads : 8 transformer_output_size : 256 dropout : 0.1 fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : True weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null fc_activation : relu fc_dropout : 0 fc_residual : null reduce_output : mean Resources to learn more about transformers: CS480/680 Lecture 19: Attention and Transformer Networks (VIDEO) Attention is all you need - Attentional Neural Network Models Masterclass (VIDEO) Illustrated: Self-Attention (Colab notebook)","title":"Transformer Combiner"},{"location":"configuration/combiner/#tabtransformer-combiner","text":"The tabtransformer combiner combines input features in the following sequence of operations. Except for binary and number features, the combiner projects features to an embedding size. These features are concatenated as if they were a sequence and passed through a transformer. After the transformer, the number and binary features are concatenated (which are of size 1) and then concatenated with the output of the transformer and is passed to a stack of fully connected layers (from TabTransformer: Tabular Data Modeling Using Contextual Embeddings ). It assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If the input tensors have a different shape, it automatically flattens them. It then projects each input tensor to the same hidden / embedding size and encodes them with a stack of Transformer layers. Finally, the transformer combiner applies a reduction to the outputs of the Transformer stack, followed by the above concatenation and optional fully connected layers. The output is a b x h' tensor where h' is the size of the last fully connected layer or the hidden / embedding size, or a b x n x h' where n is the number of input features and h' is the hidden / embedding size if no reduction is applied. +-----------+ |Input | |Feature 1 +-+ +-----------+ | +-----------+ | +-------------+ +--------------+ +------ + +----------+ +----------+ | +--->| Categoricial+->|TabTransformer +-->|Reduce +-> | Combined +->|Fully +-> | | | | Embeddings | |Stack | +-------+ | Hidden | |Connected | | | | +-------------+ +---------------+ | Layers | |Layers | |... | | +----------+ +----------+ | | | +-----------+ ^ | | | | Binary & | | +-----------+ |------------------------->| Numerical |------------------ +-----------+ | | Encodings | |Input +-+ +-----------+ |Feature N | +-----------+ These are the available parameters of a transformer combiner: num_layers (default 1 ): number of layers in the stack of transformer blocks. hidden_size (default 256 ): hidden / embedding size of each transformer block. num_heads (default 8 ): number of attention heads of each transformer block. transformer_output_size (default 256 ): size of the fully connected layers inside each transformer block. dropout (default 0 ): dropout rate after the transformer. fc_layers (default null ): is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers to apply after reduction of the transformer output sequence. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate for the fully connected layers. fc_residual (default false ): if true adds a residual connection to each fully connected layer block. It is required that all fully connected layers have the same size for this parameter to work correctly. reduce_output (default mean ): describes the strategy to use to aggregate the output of the transformer. Possible values include last , sum , mean , concat , or none . embed_input_feature_name (default null ) controls the size of the embeddings. Valid values are add which uses the hidden_size value or an integer to set a specific value. In the case of an integer value, it must be smaller than hidden_size . Example configuration of a tabtransformer combiner: type : tabtransformer num_layers : 1 hidden_size : 256 num_heads : 8 transformer_output_size : 256 dropout : 0.1 fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : True weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null fc_activation : relu fc_dropout : 0 fc_residual : null reduce_output : mean embed_input_fature_name : null","title":"TabTransformer Combiner"},{"location":"configuration/combiner/#comparator-combiner","text":"The comparator combiner compares the hidden representation of two entities defined by lists of features. It assumes all outputs from encoders are tensors of size b x h where b is the batch size and h is the hidden dimension, which can be different for each input. If the input tensors have a different shape, it automatically flattens them. It then concatenates the representations of each entity and projects them both to vectors of size output_size . Finally, it compares the two entity representations by dot product, element-wise multiplication, absolute difference and bilinear product. It returns the final b x h' tensor where h' is the size of the concatenation of the four comparisons. +-----------+ |Entity 1 | |Input | |Feature 1 +-+ +-----------+ | +-----------+ | +-------+ +----------+ |... +--->|Concat +-->|FC Layers +--+ | | | +-------+ +----------+ | +-----------+ | | +-----------+ | | |Entity 1 +-+ | |Input | | |Feature N | | +-----------+ | +---------+ +-->| Compare +-> +-----------+ | +---------+ |Entity 2 | | |Input | | |Feature 1 +-+ | +-----------+ | | +-----------+ | +-------+ +----------+ | |... +--->|Concat +-->|FC Layers +--+ | | | +-------+ +----------+ +-----------+ | +-----------+ | |Entity 2 +-+ |Input | |Feature N | +-----------+ These are the available parameters of a comparator combiner: entity_1 : list of input features that compose the first entity to compare. entity_2 : list of input features that compose the second entity to compare. fc_layers (default null ): is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate for the fully connected layers. Example configuration of a comparator combiner: type : comparator entity_1 : [ feature_1 , feature_2 ] entity_2 : [ feature_3 , feature_4 ] fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : 'glorot_uniform' bias_initializer : 'zeros' norm : null norm_params : null activation : relu dropout : 0","title":"Comparator Combiner"},{"location":"configuration/hyperparameter_optimization/","text":"The hyperopt section of the Ludwig configuration defines what metrics to optimize for, which parameters to optimize, search strategy and execution strategy. hyperopt : goal : minimize output_feature : combined metric : loss split : validation parameters : title.cell_type : ... # title is a text feature type title.num_layers : ... combiner.num_fc_layers : ... section.embedding_size : ... preprocessing.text.vocab_size : ... trainer.learning_rate : ... trainer.optimizer.type : ... ... search_alg : type : variant_generator # random, hyperopt, bohb, ... # search_alg parameters... executor : type : ray num_samples : ... scheduler : type : fifo # hb_bohb, asynchyperband, ... # scheduler parameters... Hyperopt configuration parameters \u00b6 goal which indicates if to minimize or maximize a metric or a loss of any of the output features on any of the dataset splits. Available values are: minimize (default) or maximize . output_feature is a str containing the name of the output feature that we want to optimize the metric or loss of. Available values are combined (default) or the name of any output feature provided in the configuration. combined is a special output feature that allows to optimize for the aggregated loss and metrics of all output features. metric is the metric that we want to optimize for. The default one is loss , but depending on the type of the feature defined in output_feature , different metrics and losses are available. Check the metrics section of the specific output feature type to figure out what metrics are available to use. split is the split of data that we want to compute our metric on. By default it is the validation split, but you have the flexibility to specify also train or test splits. parameters section consists of a set of hyperparameters to optimize. They are provided as keys (the names of the parameters) and values associated with them (that define the search space). The values vary depending on the type of the hyperparameter. Syntax for this section is based on Ray Tune's Search Space parameters . search_alg section specifies the algorithm to sample the defined parameters space. Candidate algorithms are those found in Ray Tune's Search Algorithms . executor section specifies how to execute the hyperparameter optimization. The execution could happen locally in a serial manner or in parallel across multiple workers and with GPUs as well if available. The executor section includes specification for work scheduling and the number of samples to generate. Defining hyperparameter search spaces \u00b6 In the parameters section, hyperparameters are dot( . ) separate names. The parts of the hyperparameter names separated by . are references to nested sections in the Ludwig configuration. For instance, to reference the learning_rate , in the trainer section one would use the name trainer.learning_rate . If the parameter to reference is inside an input or output feature, the name of that feature will be be used as starting point. For instance, for referencing the cell_type of the title feature, use the name title.cell_type . Numeric Hyperparameters \u00b6 space : Use Ray Tune's Search Space types, e.g., uniform , quniform , loguniform , choice , etc. Refer the cited page for details. For numeric spaces , these define the range where the value is generated lower : the minimum value the parameter can have upper : the maximum value the parameter can have q : quantization number, used in spaces such as quniform , qloguniform , qrandn , qrandint , qlograndint base : defines the base of the log for loguniform , qloguniform , lograndint and qlograndint Note Depending on the specific numeric space , the upper parameter may be inclusive or excluse. Refer to the Ray Tune documentation for the specific distribution for details. Float example : Uniform floating point random values (in log space) between 0.001 and 0.1 trainer.learning_rate : space : loguniform lower : 0.001 upper : 0.1 Integer example : Uniform random integer values 1, 2, 3 combiner.num_fc_layers : space : randint lower : 1 upper : 4 Quantized Example : Uniform random floating point values such a 0, 0.1, 0.2, ..., 0.9 my_output_feature.dropout : space : quniform lower : 0 upper : 1 q : 0.1 Categorical Hyperparameters \u00b6 space : Use choice . categories : a list of possible values. The type of each value of the list is general, i.e., they could be strings, integers, floats and anything else, even entire dictionaries. The values will be a uniform random selection. Example: title.cell_type : space : choice categories : [ rnn , gru , lstm ] Hyperparameters in a Grid \u00b6 For space : grid_search values : is a list of values to use in creating the grid search space. The type of each value of the list is general, i.e., they could be strings, integers, floats and anything else, even entire dictionaries. Example: title.cell_type : space : grid_search values : [ rnn , gru , lstm ] More comprehensive example \u00b6 hyperopt : parameters : trainer.learning_rate : space : loguniform lower : 0.001 upper : 0.1 combiner.num_fc_layers : space : randint lower : 2 upper : 6 title.cell_type : space : grid_search values : [ \"rnn\" , \"gru\" ] title.bidirectional : space : choice categories : [ True , False ] title.fc_layers : space : choice categories : - [{ \"output_size\" : 512 }, { \"output_size\" : 256 }] - [{ \"output_size\" : 512 }] - [{ \"output_size\" : 256 }] Search Algorithm \u00b6 Ray Tune supports its own collection of search algorithms , specified by the search_alg section of the hyperopt config: search_alg : type : variant_generator You can find the full list of supported search algorithm names in Ray Tune's create_searcher function. Please note these algorithms require installation of additional packages. As of this version of Ludwig, Ludwig installs the packages for the search algorithm hyperopt . For all other search algorithms, the user is expected to install the required packages. Executor \u00b6 Ray Tune Executor \u00b6 The ray executor is used to enable Ray Tune for both local and distributed hyperopt across a cluster of machines. Parameters: num_samples : This parameter, along with the space specifications in the parameters section, controls how many trials are generated (default: 1). Note If all the hyperparameters in the parameters section have non- grid_search specifications (e.g., uniform , randn , choice , etc.), then the number of trials will be num_samples . If all the hyperparameters have grid_search , then the number of trials will be the product of the number of values specified for each hyperparameter. In this case, num_samples should be set to 1. For example, if there are three grid_search hyperparameters, with 2, 4 and 4 values, respectively. The number of trials will be 2 X 4 X 4 = 32, where each trial is a unique combination of the three grid_search hyperparameter values. If there is a mixture of grid_search and non- grid_search spaces, the number of trials will be product of the number of values specified for each grid_search hyperpameter multiplied by the value of num_samples . To illustrate this point, we take the three grid_search hyperparameters described in the preceding bullet item and add 2 hyperparameters with uniform and randint spaces. With num_samples = 10 , for each unique combination of values from the grid_search hyperparameters, 10 trials will be generated with random values selected for the uniform and randint hyperparameters. This will lead to a total of 32 X 10 = 320 trials. cpu_resources_per_trial : The number of CPU cores allocated to each trial (default: 1). gpu_resources_per_trial : The number of GPU devices allocated to each trial (default: 0). kubernetes_namespace : When running on Kubernetes, provide the namespace of the Ray cluster to sync results between pods. See the Ray docs for more info. time_budget_s : The number of seconds for the entire hyperopt run. Scheduler \u00b6 Ray Tune also allows you to specify a scheduler to support features like early stopping and other population-based strategies that may pause and resume trials during trainer. Ludwig exposes the complete scheduler API in the scheduler section of the executor config. You can find the full list of supported schedulers in Ray Tune's create_scheduler function. Example: executor : type : ray cpu_resources_per_trial : 2 gpu_resources_per_trial : 1 kubernetes_namespace : ray time_budget_s : 7200 scheduler : type : async_hyperband time_attr : training_iteration reduction_factor : 4 Running Ray Executor: See the section on Running Ludwig with Ray for guidance on setting up your Ray cluster. Full hyperparameter optimization example \u00b6 Following is a full example of a Ludwig configuration with hyperparameter optimization. Example YAML: input_features : - name : title type : text encoder : rnn cell_type : lstm num_layers : 2 combiner : type : concat num_fc_layers : 1 output_features : - name : class type : category preprocessing : text : word_vocab_size : 10000 training : learning_rate : 0.001 optimizer : type : adam hyperopt : goal : maximize output_feature : class metric : accuracy split : validation parameters : trainer.learning_rate : space : loguniform lower : 0.0001 upper : 0.1 trainer.optimizer.type : space : choice categories : [ sgd , adam , adagrad ] preprocessing.text.word_vocab_size : space : qrandint lower : 700 upper : 1200 q : 5 combiner.num_fc_layers : space : randint lower : 1 upper : 5 title.cell_type : space : choice values : [ rnn , gru , lstm ] search_alg : type : random executor : type : ray num_samples : 12 Example CLI command: ludwig hyperopt --dataset reuters-allcats.csv --config_str \"{input_features: [{name: title, type: text, encoder: rnn, cell_type: lstm, num_layers: 2}], output_features: [{name: class, type: category}], training: {learning_rate: 0.001}, hyperopt: {goal: maximize, output_feature: class, metric: accuracy, split: validation, parameters: {trainer.learning_rate: {space: loguniform, lower: 0.0001, upper: 0.1}, title.cell_type: {space: choice, categories: [rnn, gru, lstm]}}, search_alg: {type: variant_generator},executor: {type: ray, num_samples: 10}}}\"","title":"Hyperopt"},{"location":"configuration/hyperparameter_optimization/#hyperopt-configuration-parameters","text":"goal which indicates if to minimize or maximize a metric or a loss of any of the output features on any of the dataset splits. Available values are: minimize (default) or maximize . output_feature is a str containing the name of the output feature that we want to optimize the metric or loss of. Available values are combined (default) or the name of any output feature provided in the configuration. combined is a special output feature that allows to optimize for the aggregated loss and metrics of all output features. metric is the metric that we want to optimize for. The default one is loss , but depending on the type of the feature defined in output_feature , different metrics and losses are available. Check the metrics section of the specific output feature type to figure out what metrics are available to use. split is the split of data that we want to compute our metric on. By default it is the validation split, but you have the flexibility to specify also train or test splits. parameters section consists of a set of hyperparameters to optimize. They are provided as keys (the names of the parameters) and values associated with them (that define the search space). The values vary depending on the type of the hyperparameter. Syntax for this section is based on Ray Tune's Search Space parameters . search_alg section specifies the algorithm to sample the defined parameters space. Candidate algorithms are those found in Ray Tune's Search Algorithms . executor section specifies how to execute the hyperparameter optimization. The execution could happen locally in a serial manner or in parallel across multiple workers and with GPUs as well if available. The executor section includes specification for work scheduling and the number of samples to generate.","title":"Hyperopt configuration parameters"},{"location":"configuration/hyperparameter_optimization/#defining-hyperparameter-search-spaces","text":"In the parameters section, hyperparameters are dot( . ) separate names. The parts of the hyperparameter names separated by . are references to nested sections in the Ludwig configuration. For instance, to reference the learning_rate , in the trainer section one would use the name trainer.learning_rate . If the parameter to reference is inside an input or output feature, the name of that feature will be be used as starting point. For instance, for referencing the cell_type of the title feature, use the name title.cell_type .","title":"Defining hyperparameter search spaces"},{"location":"configuration/hyperparameter_optimization/#numeric-hyperparameters","text":"space : Use Ray Tune's Search Space types, e.g., uniform , quniform , loguniform , choice , etc. Refer the cited page for details. For numeric spaces , these define the range where the value is generated lower : the minimum value the parameter can have upper : the maximum value the parameter can have q : quantization number, used in spaces such as quniform , qloguniform , qrandn , qrandint , qlograndint base : defines the base of the log for loguniform , qloguniform , lograndint and qlograndint Note Depending on the specific numeric space , the upper parameter may be inclusive or excluse. Refer to the Ray Tune documentation for the specific distribution for details. Float example : Uniform floating point random values (in log space) between 0.001 and 0.1 trainer.learning_rate : space : loguniform lower : 0.001 upper : 0.1 Integer example : Uniform random integer values 1, 2, 3 combiner.num_fc_layers : space : randint lower : 1 upper : 4 Quantized Example : Uniform random floating point values such a 0, 0.1, 0.2, ..., 0.9 my_output_feature.dropout : space : quniform lower : 0 upper : 1 q : 0.1","title":"Numeric Hyperparameters"},{"location":"configuration/hyperparameter_optimization/#categorical-hyperparameters","text":"space : Use choice . categories : a list of possible values. The type of each value of the list is general, i.e., they could be strings, integers, floats and anything else, even entire dictionaries. The values will be a uniform random selection. Example: title.cell_type : space : choice categories : [ rnn , gru , lstm ]","title":"Categorical Hyperparameters"},{"location":"configuration/hyperparameter_optimization/#hyperparameters-in-a-grid","text":"For space : grid_search values : is a list of values to use in creating the grid search space. The type of each value of the list is general, i.e., they could be strings, integers, floats and anything else, even entire dictionaries. Example: title.cell_type : space : grid_search values : [ rnn , gru , lstm ]","title":"Hyperparameters in a Grid"},{"location":"configuration/hyperparameter_optimization/#more-comprehensive-example","text":"hyperopt : parameters : trainer.learning_rate : space : loguniform lower : 0.001 upper : 0.1 combiner.num_fc_layers : space : randint lower : 2 upper : 6 title.cell_type : space : grid_search values : [ \"rnn\" , \"gru\" ] title.bidirectional : space : choice categories : [ True , False ] title.fc_layers : space : choice categories : - [{ \"output_size\" : 512 }, { \"output_size\" : 256 }] - [{ \"output_size\" : 512 }] - [{ \"output_size\" : 256 }]","title":"More comprehensive example"},{"location":"configuration/hyperparameter_optimization/#search-algorithm","text":"Ray Tune supports its own collection of search algorithms , specified by the search_alg section of the hyperopt config: search_alg : type : variant_generator You can find the full list of supported search algorithm names in Ray Tune's create_searcher function. Please note these algorithms require installation of additional packages. As of this version of Ludwig, Ludwig installs the packages for the search algorithm hyperopt . For all other search algorithms, the user is expected to install the required packages.","title":"Search Algorithm"},{"location":"configuration/hyperparameter_optimization/#executor","text":"","title":"Executor"},{"location":"configuration/hyperparameter_optimization/#ray-tune-executor","text":"The ray executor is used to enable Ray Tune for both local and distributed hyperopt across a cluster of machines. Parameters: num_samples : This parameter, along with the space specifications in the parameters section, controls how many trials are generated (default: 1). Note If all the hyperparameters in the parameters section have non- grid_search specifications (e.g., uniform , randn , choice , etc.), then the number of trials will be num_samples . If all the hyperparameters have grid_search , then the number of trials will be the product of the number of values specified for each hyperparameter. In this case, num_samples should be set to 1. For example, if there are three grid_search hyperparameters, with 2, 4 and 4 values, respectively. The number of trials will be 2 X 4 X 4 = 32, where each trial is a unique combination of the three grid_search hyperparameter values. If there is a mixture of grid_search and non- grid_search spaces, the number of trials will be product of the number of values specified for each grid_search hyperpameter multiplied by the value of num_samples . To illustrate this point, we take the three grid_search hyperparameters described in the preceding bullet item and add 2 hyperparameters with uniform and randint spaces. With num_samples = 10 , for each unique combination of values from the grid_search hyperparameters, 10 trials will be generated with random values selected for the uniform and randint hyperparameters. This will lead to a total of 32 X 10 = 320 trials. cpu_resources_per_trial : The number of CPU cores allocated to each trial (default: 1). gpu_resources_per_trial : The number of GPU devices allocated to each trial (default: 0). kubernetes_namespace : When running on Kubernetes, provide the namespace of the Ray cluster to sync results between pods. See the Ray docs for more info. time_budget_s : The number of seconds for the entire hyperopt run.","title":"Ray Tune Executor"},{"location":"configuration/hyperparameter_optimization/#scheduler","text":"Ray Tune also allows you to specify a scheduler to support features like early stopping and other population-based strategies that may pause and resume trials during trainer. Ludwig exposes the complete scheduler API in the scheduler section of the executor config. You can find the full list of supported schedulers in Ray Tune's create_scheduler function. Example: executor : type : ray cpu_resources_per_trial : 2 gpu_resources_per_trial : 1 kubernetes_namespace : ray time_budget_s : 7200 scheduler : type : async_hyperband time_attr : training_iteration reduction_factor : 4 Running Ray Executor: See the section on Running Ludwig with Ray for guidance on setting up your Ray cluster.","title":"Scheduler"},{"location":"configuration/hyperparameter_optimization/#full-hyperparameter-optimization-example","text":"Following is a full example of a Ludwig configuration with hyperparameter optimization. Example YAML: input_features : - name : title type : text encoder : rnn cell_type : lstm num_layers : 2 combiner : type : concat num_fc_layers : 1 output_features : - name : class type : category preprocessing : text : word_vocab_size : 10000 training : learning_rate : 0.001 optimizer : type : adam hyperopt : goal : maximize output_feature : class metric : accuracy split : validation parameters : trainer.learning_rate : space : loguniform lower : 0.0001 upper : 0.1 trainer.optimizer.type : space : choice categories : [ sgd , adam , adagrad ] preprocessing.text.word_vocab_size : space : qrandint lower : 700 upper : 1200 q : 5 combiner.num_fc_layers : space : randint lower : 1 upper : 5 title.cell_type : space : choice values : [ rnn , gru , lstm ] search_alg : type : random executor : type : ray num_samples : 12 Example CLI command: ludwig hyperopt --dataset reuters-allcats.csv --config_str \"{input_features: [{name: title, type: text, encoder: rnn, cell_type: lstm, num_layers: 2}], output_features: [{name: class, type: category}], training: {learning_rate: 0.001}, hyperopt: {goal: maximize, output_feature: class, metric: accuracy, split: validation, parameters: {trainer.learning_rate: {space: loguniform, lower: 0.0001, upper: 0.1}, title.cell_type: {space: choice, categories: [rnn, gru, lstm]}}, search_alg: {type: variant_generator},executor: {type: ray, num_samples: 10}}}\"","title":"Full hyperparameter optimization example"},{"location":"configuration/preprocessing/","text":"The top-level preprocessing section specifies: dataset splitting (train, validation, test) data balancing type-global preprocessing Dataset Splitting \u00b6 Split data into train, validation, and test. By default, Ludwig looks for a column named split (case-sensitive) which is expected to consist of 3 possible values that correspond to different datasets: 0 : train 1 : validation 2 : test If the data does not contain the split column, then data is randomly split based on splitting percentages, defined by split_probabilities . If force_split is true , the the split column in the dataset is ignored and the dataset is randomly split based on splitting percentages, defined by split_probabilities . Summary of parameters: force_split (default false ): if true the split column in the dataset file is ignored and the dataset is randomly split. If false the split column is used if available. split_probabilities (default [0.7, 0.1, 0.2] ): the proportion of the dataset data to end up in training, validation and test, respectively. The three values must sum to 1.0. stratify (default null ): if null the split is random, otherwise you can specify the name of a category feature and the split will be stratified on that feature. preprocessing : force_split : false split_probabilities : [ 0.7 , 0.1 , 0.2 ] stratify : null category : { ... } sequence : { ... } text : { ... } ... Data Balancing \u00b6 Users working with imbalanced datasets can specify an oversampling or undersampling parameter which will balance the data during preprocessing. In this example, Ludwig will oversample the minority class to achieve a 50% representation in the overall dataset. preprocessing : oversample_minority : 0.5 In this example, Ludwig will undersample the majority class to achieve a 70% representation in the overall dataset. preprocessing : undersample_majority : 0.7 Data balancing is only supported for binary output features. Additionally, specifying both oversampling and undersampling parameters simultaneously is not supported. Type-global Preprocessing \u00b6 Specify preprocessing policies that apply globally across all features of a certain data type. For example: preprocessing : category : missing_value_strategy : fill_with_const fill_value : <UNK> The preprocessing parameters that each data type accepts can be found in datatype-specific documentation . Note that different features with the same datatype may require different preprocessing. Type-global preprocessing works in tandem with feature-specific preprocessing configuration parameters, which override the global settings. For example, a document classification model may have two text input features, one for the title of the document and one for the body. As the length of the title is much shorter than the length of the body, the parameter word_length_limit should be set to 10 for the title and 2000 for the body, but we want both features to share the same vocabulary, with most_common_words: 10000 . The way to do this is adding a preprocessing key inside the title input_feature dictionary and one in the body input feature dictionary containing the desired parameter and value. preprocessing : text : most_common_word : 10000 input_features : - name : title type : text preprocessing : word_length_limit : 20 - name : body type : text preprocessing : word_length_limit : 2000 Feature-specific preprocessing \u00b6 To configure feature-specific preprocessing, please check datatype-specific documentation . Tokenizers \u00b6 Sequence, text, and set features tokenize features as part of preprocessing. There are several tokenization options that can be specified: characters : splits every character of the input string in a separate token. space : splits on space characters using the regex \\s+ . space_punct : splits on space characters and punctuation using the regex \\w+|[^\\w\\s] . underscore : splits on the underscore character _ . comma : splits on the underscore character , . untokenized : treats the whole string as a single token. stripped : treats the whole string as a single token after removing spaces at the beginning and at the end of the string. hf_tokenizer : uses the Hugging Face AutoTokenizer which uses a pretrained_model_name_or_path parameter to decide which tokenizer to load. Language specific tokenizers: spaCy based language tokenizers. The spaCy based tokenizers are functions that use the powerful tokenization and NLP preprocessing models provided the library. Several languages are available: English (code en ), Italian (code it ), Spanish (code es ), German (code de ), French (code fr ), Portuguese (code pt ), Dutch (code nl ), Greek (code el ), Chinese (code zh ), Danish (code da ), Dutch (code el ), Japanese (code ja ), Lithuanian (code lt ), Norwegian (code nb ), Polish (code pl ), Romanian (code ro ) and Multi (code xx , useful in case you have a dataset containing different languages). For each language different functions are available: tokenize : uses spaCy tokenizer, tokenize_filter : uses spaCy tokenizer and filters out punctuation, numbers, stopwords and words shorter than 3 characters, tokenize_remove_stopwords : uses spaCy tokenizer and filters out stopwords, lemmatize : uses spaCy lemmatizer, lemmatize_filter : uses spaCy lemmatizer and filters out punctuation, numbers, stopwords and words shorter than 3 characters, lemmatize_remove_stopwords : uses spaCy lemmatize and filters out stopwords. In order to use these options, you must first download the the spaCy model: python -m spacy download <language_code> and provide <language>_<function> as tokenizer like: english_tokenizer , italian_lemmatize_filter , multi_tokenize_filter and so on. More details on the models can be found in the spaCy documentation .","title":"Preprocessing"},{"location":"configuration/preprocessing/#dataset-splitting","text":"Split data into train, validation, and test. By default, Ludwig looks for a column named split (case-sensitive) which is expected to consist of 3 possible values that correspond to different datasets: 0 : train 1 : validation 2 : test If the data does not contain the split column, then data is randomly split based on splitting percentages, defined by split_probabilities . If force_split is true , the the split column in the dataset is ignored and the dataset is randomly split based on splitting percentages, defined by split_probabilities . Summary of parameters: force_split (default false ): if true the split column in the dataset file is ignored and the dataset is randomly split. If false the split column is used if available. split_probabilities (default [0.7, 0.1, 0.2] ): the proportion of the dataset data to end up in training, validation and test, respectively. The three values must sum to 1.0. stratify (default null ): if null the split is random, otherwise you can specify the name of a category feature and the split will be stratified on that feature. preprocessing : force_split : false split_probabilities : [ 0.7 , 0.1 , 0.2 ] stratify : null category : { ... } sequence : { ... } text : { ... } ...","title":"Dataset Splitting"},{"location":"configuration/preprocessing/#data-balancing","text":"Users working with imbalanced datasets can specify an oversampling or undersampling parameter which will balance the data during preprocessing. In this example, Ludwig will oversample the minority class to achieve a 50% representation in the overall dataset. preprocessing : oversample_minority : 0.5 In this example, Ludwig will undersample the majority class to achieve a 70% representation in the overall dataset. preprocessing : undersample_majority : 0.7 Data balancing is only supported for binary output features. Additionally, specifying both oversampling and undersampling parameters simultaneously is not supported.","title":"Data Balancing"},{"location":"configuration/preprocessing/#type-global-preprocessing","text":"Specify preprocessing policies that apply globally across all features of a certain data type. For example: preprocessing : category : missing_value_strategy : fill_with_const fill_value : <UNK> The preprocessing parameters that each data type accepts can be found in datatype-specific documentation . Note that different features with the same datatype may require different preprocessing. Type-global preprocessing works in tandem with feature-specific preprocessing configuration parameters, which override the global settings. For example, a document classification model may have two text input features, one for the title of the document and one for the body. As the length of the title is much shorter than the length of the body, the parameter word_length_limit should be set to 10 for the title and 2000 for the body, but we want both features to share the same vocabulary, with most_common_words: 10000 . The way to do this is adding a preprocessing key inside the title input_feature dictionary and one in the body input feature dictionary containing the desired parameter and value. preprocessing : text : most_common_word : 10000 input_features : - name : title type : text preprocessing : word_length_limit : 20 - name : body type : text preprocessing : word_length_limit : 2000","title":"Type-global Preprocessing"},{"location":"configuration/preprocessing/#feature-specific-preprocessing","text":"To configure feature-specific preprocessing, please check datatype-specific documentation .","title":"Feature-specific preprocessing"},{"location":"configuration/preprocessing/#tokenizers","text":"Sequence, text, and set features tokenize features as part of preprocessing. There are several tokenization options that can be specified: characters : splits every character of the input string in a separate token. space : splits on space characters using the regex \\s+ . space_punct : splits on space characters and punctuation using the regex \\w+|[^\\w\\s] . underscore : splits on the underscore character _ . comma : splits on the underscore character , . untokenized : treats the whole string as a single token. stripped : treats the whole string as a single token after removing spaces at the beginning and at the end of the string. hf_tokenizer : uses the Hugging Face AutoTokenizer which uses a pretrained_model_name_or_path parameter to decide which tokenizer to load. Language specific tokenizers: spaCy based language tokenizers. The spaCy based tokenizers are functions that use the powerful tokenization and NLP preprocessing models provided the library. Several languages are available: English (code en ), Italian (code it ), Spanish (code es ), German (code de ), French (code fr ), Portuguese (code pt ), Dutch (code nl ), Greek (code el ), Chinese (code zh ), Danish (code da ), Dutch (code el ), Japanese (code ja ), Lithuanian (code lt ), Norwegian (code nb ), Polish (code pl ), Romanian (code ro ) and Multi (code xx , useful in case you have a dataset containing different languages). For each language different functions are available: tokenize : uses spaCy tokenizer, tokenize_filter : uses spaCy tokenizer and filters out punctuation, numbers, stopwords and words shorter than 3 characters, tokenize_remove_stopwords : uses spaCy tokenizer and filters out stopwords, lemmatize : uses spaCy lemmatizer, lemmatize_filter : uses spaCy lemmatizer and filters out punctuation, numbers, stopwords and words shorter than 3 characters, lemmatize_remove_stopwords : uses spaCy lemmatize and filters out stopwords. In order to use these options, you must first download the the spaCy model: python -m spacy download <language_code> and provide <language>_<function> as tokenizer like: english_tokenizer , italian_lemmatize_filter , multi_tokenize_filter and so on. More details on the models can be found in the spaCy documentation .","title":"Tokenizers"},{"location":"configuration/trainer/","text":"Overview \u00b6 The trainer section of the configuration lets you specify parameters that configure the training process, like the number of epochs or the learning rate. trainer : epochs : 100 train_steps : None early_stop : 5 batch_size : 128 eval_batch_size : null evaluate_training_set : True checkpoints_per_epoch : 0 steps_per_checkpoint : 0 regularization_lambda : 0 regularization_type : l2 learning_rate : 0.001 reduce_learning_rate_on_plateau : 0 reduce_learning_rate_on_plateau_patience : 5 reduce_learning_rate_on_plateau_rate : 0.5 increase_batch_size_on_plateau : 0 increase_batch_size_on_plateau_patience : 5 increase_batch_size_on_plateau_rate : 2 increase_batch_size_on_plateau_max : 512 decay : false decay_steps : 10000 decay_rate : 0.96 staircase : false validation_field : combined validation_metric : loss bucketing_field : null learning_rate_warmup_epochs : 1 optimizer : type : adam beta1 : 0.9 beta2 : 0.999 epsilon : 1e-08 clip_global_norm : 0.5 clipnorm : null clip_value : null Trainer parameters \u00b6 epochs (default 100 ): number of epochs the training process will run for. train_steps (default None ): Maximum number of training steps the training process will run for. If unset, then epochs is used to determine training length. early_stop (default 5 ): Number of consecutive rounds of evaluation without any improvement on the validation_metric that triggers training to stop. Can be set to -1, which disables early stopping entirely. batch_size (default 128 ): size of the batch used for training the model. eval_batch_size (default null ): size of the batch used for evaluating the model. If it is 0 or null , the same value of batch_size is used. This is useful to speedup evaluation with a much bigger batch size than training, if enough memory is available. evaluate_training_set : Whether to include the entire training set during evaluation (default: True). checkpoints_per_epoch : Number of checkpoints per epoch. For example, 2 -> checkpoints are written every half of an epoch. Note that it is invalid to specify both non-zero steps_per_checkpoint and non-zero checkpoints_per_epoch (default: 0). steps_per_checkpoint : How often the model is checkpointed. Also dictates maximum evaluation frequency. If 0 the model is checkpointed after every epoch. (default: 0). regularization_lambda (default 0 ): the lambda parameter used for adding regularization loss to the overall loss. regularization_type (default l2 ): the type of regularization. learning_rate (default 0.001 ): the learning rate to use. reduce_learning_rate_on_plateau (default 0 ): if theres a validation set, how many times to reduce the learning rate when a plateau of validation measure is reached. reduce_learning_rate_on_plateau_patience (default 5 ): if theres a validation set, number of epochs of patience without an improvement on the validation measure before reducing the learning rate. reduce_learning_rate_on_plateau_rate (default 0.5 ): if theres a validation set, the reduction rate of the learning rate. increase_batch_size_on_plateau (default 0 ): if theres a validation set, how many times to increase the batch size when a plateau of validation measure is reached. increase_batch_size_on_plateau_patience (default 5 ): if theres a validation set, number of epochs of patience without an improvement on the validation measure before increasing the learning rate. increase_batch_size_on_plateau_rate (default 2 ): if theres a validation set, the increase rate of the batch size. increase_batch_size_on_plateau_max (default 512 ): if theres a validation set, the maximum value of batch size. decay (default false ): if to use exponential decay of the learning rate or not. decay_rate (default 0.96 ): the rate of the exponential learning rate decay. decay_steps (default 10000 ): the number of steps of the exponential learning rate decay. staircase (default false ): decays the learning rate at discrete intervals. validation_field (default combined ): when there is more than one output feature, which one to use for computing if there was an improvement on validation. The measure to use to determine if there was an improvement can be set with the validation_measure parameter. Different data types have different metrics, refer to the datatype-specific section for more details. combined indicates the use the combination of all features. For instance the combination of combined and loss as measure uses a decrease in the combined loss of all output features to check for improvement on validation, while combined and accuracy considers on how many examples the predictions for all output features were correct (but consider that for some features, for instance numeric there is no accuracy measure, so you should use accuracy only if all your output features have an accuracy measure). validation_metric (default loss ): the metric to use to determine if there was an improvement. The metric is considered for the output feature specified in validation_field . Different data types have different available metrics, refer to the datatype-specific section for more details. bucketing_field (default null ): when not null , when creating batches, instead of shuffling randomly, the length along the last dimension of the matrix of the specified input feature is used for bucketing examples and then randomly shuffled examples from the same bin are sampled. Padding is trimmed to the longest example in the batch. The specified feature should be either a sequence or text feature and the encoder encoding it has to be rnn . When used, bucketing improves speed of rnn encoding up to 1.5x, depending on the length distribution of the inputs. learning_rate_warmup_epochs (default 1 ): Its the number or training epochs where learning rate warmup will be used. It is calculated as described in Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour . In the paper the authors suggest 6 epochs of warmup, that parameter is suggested for large datasets and big batches. optimizer (default {type: adam, beta1: 0.9, beta2: 0.999, epsilon: 1e-08} ): which optimizer to use with the relative parameters. The available optimizers are: sgd (or stochastic_gradient_descent , gd , gradient_descent , they are all the same), adam , adadelta , adagrad , adamax , ftrl , nadam , rmsprop . Check PyTorch optimizer documentation for a full list of parameters for each optimizer. The optimizer definition can also specify gradient clipping using clipglobalnorm , clipnorm , and clipvalue . Optimizer parameters \u00b6 The available optimizers wrap the ones available in PyTorch. For details about the parameters that can be used to configure different optimizers, please refer to the PyTorch documentation . The learning_rate parameter the optimizer will use come from the trainer section. Other optimizer specific parameters, shown with their Ludwig default settings, follow: sgd (or stochastic_gradient_descent , gd , gradient_descent ) momentum : 0.0, nesterov : false adam beta_1 : 0.9, beta_2 : 0.999, epsilon : 1e-08 adadelta rho : 0.95, epsilon : 1e-08 adagrad initial_accumulator_value : 0.1, epsilon : 1e-07 adamax beta_1 : 0.9, beta_2 : 0.999, epsilon : 1e-07 ftrl learning_rate_power : -0.5, initial_accumulator_value : 0.1, l1_regularization_strength : 0.0, l2_regularization_strength : 0.0, nadam , beta_1 : 0.9, beta_2 : 0.999, epsilon : 1e-07 rmsprop decay : 0.9, momentum : 0.0, epsilon : 1e-10, centered : false Note Gradient clipping is also configurable, through optimizers, with the following parameters: clip_global_norm : 0.5 clipnorm : null clip_value : null Configuring training length \u00b6 The length of the training process is configured by: epochs (default: 100): One epoch is one pass through the entire dataset. By default, epochs is 100 which means that the training process will run for a maximum of 100 epochs before terminating. train_steps (default: None ): The maximum number of steps to train for, using one mini-batch per step. By default this is unset, and epochs will be used to determine training length. Tip In general, it's a good idea to set up a long training runway, relying on early stopping criteria ( early_stop ) to stop training when there hasn't been any improvement for a long time. Configuring checkpoint and evaluation frequency \u00b6 Evaluation is run every time the model is checkpointed. By default, checkpoint-evaluation will occur once every epoch. The frequency of checkpoint-evaluation can be configured using: steps_per_checkpoint (default: 0): every n training steps checkpoints_per_epoch (default: 0): n times per epoch Note It is invalid to specify both non-zero steps_per_checkpoint and non-zero checkpoints_per_epoch . Tip Running evaluation once per epoch is an appropriate fit for small datasets that fit in memory and train quickly. However, this can be a poor fit for unstructured datasets, which tend to be much larger, and train more slowly due to larger models. Running evaluation too frequently can be wasteful while running evaluation not frequently enough can be uninformative. In large-scale training runs, it's common for evaluation to be configured to run on a sub-epoch time scale, or every few thousand steps. We recommend configuring evaluation such that new evaluation results are available at least several times an hour. In general, it is not necessary for models to train over the entirety of a dataset, nor evaluate over the entirety of a test set, to produce useful monitoring metrics and signals to indicate model performance. Increasing throughput \u00b6 Skip evaluation on the training set \u00b6 Consider setting evaluate_training_set=False , which skips evaluation on the training set. Note Sometimes it can be useful to monitor evaluation metrics on the training set, as a secondary validation set. However, running evaluation on the full training set, when your training set is large, can be a huge computational cost. Turning off training set evaluation will lead to significant gains in training throughput and efficiency. Increase batch size \u00b6 Users training on GPUs can often increase training throughput by increasing the batch_size so that more examples are computed every training step. Set batch_size to auto to use the largest batch size that can fit in memory.","title":"Trainer"},{"location":"configuration/trainer/#overview","text":"The trainer section of the configuration lets you specify parameters that configure the training process, like the number of epochs or the learning rate. trainer : epochs : 100 train_steps : None early_stop : 5 batch_size : 128 eval_batch_size : null evaluate_training_set : True checkpoints_per_epoch : 0 steps_per_checkpoint : 0 regularization_lambda : 0 regularization_type : l2 learning_rate : 0.001 reduce_learning_rate_on_plateau : 0 reduce_learning_rate_on_plateau_patience : 5 reduce_learning_rate_on_plateau_rate : 0.5 increase_batch_size_on_plateau : 0 increase_batch_size_on_plateau_patience : 5 increase_batch_size_on_plateau_rate : 2 increase_batch_size_on_plateau_max : 512 decay : false decay_steps : 10000 decay_rate : 0.96 staircase : false validation_field : combined validation_metric : loss bucketing_field : null learning_rate_warmup_epochs : 1 optimizer : type : adam beta1 : 0.9 beta2 : 0.999 epsilon : 1e-08 clip_global_norm : 0.5 clipnorm : null clip_value : null","title":"Overview"},{"location":"configuration/trainer/#trainer-parameters","text":"epochs (default 100 ): number of epochs the training process will run for. train_steps (default None ): Maximum number of training steps the training process will run for. If unset, then epochs is used to determine training length. early_stop (default 5 ): Number of consecutive rounds of evaluation without any improvement on the validation_metric that triggers training to stop. Can be set to -1, which disables early stopping entirely. batch_size (default 128 ): size of the batch used for training the model. eval_batch_size (default null ): size of the batch used for evaluating the model. If it is 0 or null , the same value of batch_size is used. This is useful to speedup evaluation with a much bigger batch size than training, if enough memory is available. evaluate_training_set : Whether to include the entire training set during evaluation (default: True). checkpoints_per_epoch : Number of checkpoints per epoch. For example, 2 -> checkpoints are written every half of an epoch. Note that it is invalid to specify both non-zero steps_per_checkpoint and non-zero checkpoints_per_epoch (default: 0). steps_per_checkpoint : How often the model is checkpointed. Also dictates maximum evaluation frequency. If 0 the model is checkpointed after every epoch. (default: 0). regularization_lambda (default 0 ): the lambda parameter used for adding regularization loss to the overall loss. regularization_type (default l2 ): the type of regularization. learning_rate (default 0.001 ): the learning rate to use. reduce_learning_rate_on_plateau (default 0 ): if theres a validation set, how many times to reduce the learning rate when a plateau of validation measure is reached. reduce_learning_rate_on_plateau_patience (default 5 ): if theres a validation set, number of epochs of patience without an improvement on the validation measure before reducing the learning rate. reduce_learning_rate_on_plateau_rate (default 0.5 ): if theres a validation set, the reduction rate of the learning rate. increase_batch_size_on_plateau (default 0 ): if theres a validation set, how many times to increase the batch size when a plateau of validation measure is reached. increase_batch_size_on_plateau_patience (default 5 ): if theres a validation set, number of epochs of patience without an improvement on the validation measure before increasing the learning rate. increase_batch_size_on_plateau_rate (default 2 ): if theres a validation set, the increase rate of the batch size. increase_batch_size_on_plateau_max (default 512 ): if theres a validation set, the maximum value of batch size. decay (default false ): if to use exponential decay of the learning rate or not. decay_rate (default 0.96 ): the rate of the exponential learning rate decay. decay_steps (default 10000 ): the number of steps of the exponential learning rate decay. staircase (default false ): decays the learning rate at discrete intervals. validation_field (default combined ): when there is more than one output feature, which one to use for computing if there was an improvement on validation. The measure to use to determine if there was an improvement can be set with the validation_measure parameter. Different data types have different metrics, refer to the datatype-specific section for more details. combined indicates the use the combination of all features. For instance the combination of combined and loss as measure uses a decrease in the combined loss of all output features to check for improvement on validation, while combined and accuracy considers on how many examples the predictions for all output features were correct (but consider that for some features, for instance numeric there is no accuracy measure, so you should use accuracy only if all your output features have an accuracy measure). validation_metric (default loss ): the metric to use to determine if there was an improvement. The metric is considered for the output feature specified in validation_field . Different data types have different available metrics, refer to the datatype-specific section for more details. bucketing_field (default null ): when not null , when creating batches, instead of shuffling randomly, the length along the last dimension of the matrix of the specified input feature is used for bucketing examples and then randomly shuffled examples from the same bin are sampled. Padding is trimmed to the longest example in the batch. The specified feature should be either a sequence or text feature and the encoder encoding it has to be rnn . When used, bucketing improves speed of rnn encoding up to 1.5x, depending on the length distribution of the inputs. learning_rate_warmup_epochs (default 1 ): Its the number or training epochs where learning rate warmup will be used. It is calculated as described in Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour . In the paper the authors suggest 6 epochs of warmup, that parameter is suggested for large datasets and big batches. optimizer (default {type: adam, beta1: 0.9, beta2: 0.999, epsilon: 1e-08} ): which optimizer to use with the relative parameters. The available optimizers are: sgd (or stochastic_gradient_descent , gd , gradient_descent , they are all the same), adam , adadelta , adagrad , adamax , ftrl , nadam , rmsprop . Check PyTorch optimizer documentation for a full list of parameters for each optimizer. The optimizer definition can also specify gradient clipping using clipglobalnorm , clipnorm , and clipvalue .","title":"Trainer parameters"},{"location":"configuration/trainer/#optimizer-parameters","text":"The available optimizers wrap the ones available in PyTorch. For details about the parameters that can be used to configure different optimizers, please refer to the PyTorch documentation . The learning_rate parameter the optimizer will use come from the trainer section. Other optimizer specific parameters, shown with their Ludwig default settings, follow: sgd (or stochastic_gradient_descent , gd , gradient_descent ) momentum : 0.0, nesterov : false adam beta_1 : 0.9, beta_2 : 0.999, epsilon : 1e-08 adadelta rho : 0.95, epsilon : 1e-08 adagrad initial_accumulator_value : 0.1, epsilon : 1e-07 adamax beta_1 : 0.9, beta_2 : 0.999, epsilon : 1e-07 ftrl learning_rate_power : -0.5, initial_accumulator_value : 0.1, l1_regularization_strength : 0.0, l2_regularization_strength : 0.0, nadam , beta_1 : 0.9, beta_2 : 0.999, epsilon : 1e-07 rmsprop decay : 0.9, momentum : 0.0, epsilon : 1e-10, centered : false Note Gradient clipping is also configurable, through optimizers, with the following parameters: clip_global_norm : 0.5 clipnorm : null clip_value : null","title":"Optimizer parameters"},{"location":"configuration/trainer/#configuring-training-length","text":"The length of the training process is configured by: epochs (default: 100): One epoch is one pass through the entire dataset. By default, epochs is 100 which means that the training process will run for a maximum of 100 epochs before terminating. train_steps (default: None ): The maximum number of steps to train for, using one mini-batch per step. By default this is unset, and epochs will be used to determine training length. Tip In general, it's a good idea to set up a long training runway, relying on early stopping criteria ( early_stop ) to stop training when there hasn't been any improvement for a long time.","title":"Configuring training length"},{"location":"configuration/trainer/#configuring-checkpoint-and-evaluation-frequency","text":"Evaluation is run every time the model is checkpointed. By default, checkpoint-evaluation will occur once every epoch. The frequency of checkpoint-evaluation can be configured using: steps_per_checkpoint (default: 0): every n training steps checkpoints_per_epoch (default: 0): n times per epoch Note It is invalid to specify both non-zero steps_per_checkpoint and non-zero checkpoints_per_epoch . Tip Running evaluation once per epoch is an appropriate fit for small datasets that fit in memory and train quickly. However, this can be a poor fit for unstructured datasets, which tend to be much larger, and train more slowly due to larger models. Running evaluation too frequently can be wasteful while running evaluation not frequently enough can be uninformative. In large-scale training runs, it's common for evaluation to be configured to run on a sub-epoch time scale, or every few thousand steps. We recommend configuring evaluation such that new evaluation results are available at least several times an hour. In general, it is not necessary for models to train over the entirety of a dataset, nor evaluate over the entirety of a test set, to produce useful monitoring metrics and signals to indicate model performance.","title":"Configuring checkpoint and evaluation frequency"},{"location":"configuration/trainer/#increasing-throughput","text":"","title":"Increasing throughput"},{"location":"configuration/trainer/#skip-evaluation-on-the-training-set","text":"Consider setting evaluate_training_set=False , which skips evaluation on the training set. Note Sometimes it can be useful to monitor evaluation metrics on the training set, as a secondary validation set. However, running evaluation on the full training set, when your training set is large, can be a huge computational cost. Turning off training set evaluation will lead to significant gains in training throughput and efficiency.","title":"Skip evaluation on the training set"},{"location":"configuration/trainer/#increase-batch-size","text":"Users training on GPUs can often increase training throughput by increasing the batch_size so that more examples are computed every training step. Set batch_size to auto to use the largest batch size that can fit in memory.","title":"Increase batch size"},{"location":"configuration/features/audio_features/","text":"Audio Features Preprocessing \u00b6 Example of a preprocessing specification (assuming the audio files have a sample rate of 16000): name : audio_path type : audio preprocessing : audio_file_length_limit_in_s : 7.5 audio_feature : type : stft window_length_in_s : 0.04 window_shift_in_s : 0.02 num_fft_points : 800 window_type : boxcar Ludwig supports reading audio files using PyTorch's Torchaudio library. This library supports WAV , AMB , MP3 , FLAC , OGG/VORBIS , OPUS , SPHERE , and AMR-NB formats. Preprocessing parameters: audio_file_length_limit_in_s : (default 7.5 ): float value that defines the maximum limit of the audio file in seconds. All files longer than this limit are cut off. All files shorter than this limit are padded with padding_value missing_value_strategy (default: backfill ): what strategy to follow when there's a missing value in an audio column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). in_memory (default true ): defines whether an audio dataset will reside in memory during the training process or will be dynamically fetched from disk (useful for large datasets). In the latter case a training batch of input audio files will be fetched from disk each training iteration. At the moment only in_memory = true is supported. padding_value : (default 0): float value that is used for padding. norm : (default null ) the normalization method that can be used for the input data. Supported methods: null (data is not normalized), per_file (z-norm is applied on a \u201cper file\u201d level) audio_feature : (default { type: raw } ) dictionary that takes as input the audio feature type as well as additional parameters if type != raw . The following parameters can/should be defined in the dictionary: type (default raw ): defines the type of audio features to be used. Supported types at the moment are raw , stft , stft_phase , group_delay . For more detail, check Audio Input Features and Encoders . window_length_in_s : defines the window length used for the short time Fourier transformation (only needed if type != raw ). window_shift_in_s : defines the window shift used for the short time Fourier transformation (also called hop_length) (only needed if type != raw ). num_fft_points : (default window_length_in_s * sample_rate of audio file) defines the number of fft points used for the short time Fourier transformation. If num_fft_points > window_length_in_s * sample_rate , then the signal is zero-padded at the end. num_fft_points has to be >= window_length_in_s * sample_rate (only needed if type != raw ). window_type : (default hamming ): defines the type window the signal is weighted before the short time Fourier transformation. All windows provided by scipy\u2019s window function can be used (only needed if type != raw ). num_filter_bands : defines the number of filters used in the filterbank (only needed if type == fbank ). Audio Input Features and Encoders \u00b6 Audio files are transformed into one of the following types according to type in audio_feature 's preprocessing configuration. raw : audio file is transformed into a float valued tensor of size N x L x W (where N is the size of the dataset and L corresponds to audio_file_length_limit_in_s * sample_rate and W = 1 ). stft : audio is transformed to the stft magnitude. Audio file is transformed into a float valued tensor of size N x L x W (where N is the size of the dataset, L corresponds to ceil(audio_file_length_limit_in_s * sample_rate - window_length_in_s * sample_rate + 1/ window_shift_in_s * sample_rate) + 1 and W corresponds to num_fft_points / 2 ). fbank : audio file is transformed to FBANK features (also called log Mel-filter bank values). FBANK features are implemented according to their definition in the HTK Book : Raw Signal -> Preemphasis -> DC mean removal -> stft magnitude -> Power spectrum: stft^2 -> mel-filter bank values: triangular filters equally spaced on a Mel-scale are applied -> log-compression: log() . Overall the audio file is transformed into a float valued tensor of size N x L x W with N,L being equal to the ones in stft and W being equal to num_filter_bands . stft_phase : the phase information for each stft bin is appended to the stft magnitude so that the audio file is transformed into a float valued tensor of size N x L x 2W with N,L,W being equal to the ones in stft . group_delay : audio is transformed to group delay features according to Equation (23) in this paper . Group_delay features has the same tensor size as stft . Audio feature encoders are the same as for Sequence Features . Audio Output Features and Decoders \u00b6 There are no audio decoders at the moment. If this would unlock an interesting use case for your application, please file a GitHub Issue or ping the Ludwig Slack .","title":"\u2191 Audio Features"},{"location":"configuration/features/audio_features/#audio-features-preprocessing","text":"Example of a preprocessing specification (assuming the audio files have a sample rate of 16000): name : audio_path type : audio preprocessing : audio_file_length_limit_in_s : 7.5 audio_feature : type : stft window_length_in_s : 0.04 window_shift_in_s : 0.02 num_fft_points : 800 window_type : boxcar Ludwig supports reading audio files using PyTorch's Torchaudio library. This library supports WAV , AMB , MP3 , FLAC , OGG/VORBIS , OPUS , SPHERE , and AMR-NB formats. Preprocessing parameters: audio_file_length_limit_in_s : (default 7.5 ): float value that defines the maximum limit of the audio file in seconds. All files longer than this limit are cut off. All files shorter than this limit are padded with padding_value missing_value_strategy (default: backfill ): what strategy to follow when there's a missing value in an audio column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). in_memory (default true ): defines whether an audio dataset will reside in memory during the training process or will be dynamically fetched from disk (useful for large datasets). In the latter case a training batch of input audio files will be fetched from disk each training iteration. At the moment only in_memory = true is supported. padding_value : (default 0): float value that is used for padding. norm : (default null ) the normalization method that can be used for the input data. Supported methods: null (data is not normalized), per_file (z-norm is applied on a \u201cper file\u201d level) audio_feature : (default { type: raw } ) dictionary that takes as input the audio feature type as well as additional parameters if type != raw . The following parameters can/should be defined in the dictionary: type (default raw ): defines the type of audio features to be used. Supported types at the moment are raw , stft , stft_phase , group_delay . For more detail, check Audio Input Features and Encoders . window_length_in_s : defines the window length used for the short time Fourier transformation (only needed if type != raw ). window_shift_in_s : defines the window shift used for the short time Fourier transformation (also called hop_length) (only needed if type != raw ). num_fft_points : (default window_length_in_s * sample_rate of audio file) defines the number of fft points used for the short time Fourier transformation. If num_fft_points > window_length_in_s * sample_rate , then the signal is zero-padded at the end. num_fft_points has to be >= window_length_in_s * sample_rate (only needed if type != raw ). window_type : (default hamming ): defines the type window the signal is weighted before the short time Fourier transformation. All windows provided by scipy\u2019s window function can be used (only needed if type != raw ). num_filter_bands : defines the number of filters used in the filterbank (only needed if type == fbank ).","title":"Audio Features Preprocessing"},{"location":"configuration/features/audio_features/#audio-input-features-and-encoders","text":"Audio files are transformed into one of the following types according to type in audio_feature 's preprocessing configuration. raw : audio file is transformed into a float valued tensor of size N x L x W (where N is the size of the dataset and L corresponds to audio_file_length_limit_in_s * sample_rate and W = 1 ). stft : audio is transformed to the stft magnitude. Audio file is transformed into a float valued tensor of size N x L x W (where N is the size of the dataset, L corresponds to ceil(audio_file_length_limit_in_s * sample_rate - window_length_in_s * sample_rate + 1/ window_shift_in_s * sample_rate) + 1 and W corresponds to num_fft_points / 2 ). fbank : audio file is transformed to FBANK features (also called log Mel-filter bank values). FBANK features are implemented according to their definition in the HTK Book : Raw Signal -> Preemphasis -> DC mean removal -> stft magnitude -> Power spectrum: stft^2 -> mel-filter bank values: triangular filters equally spaced on a Mel-scale are applied -> log-compression: log() . Overall the audio file is transformed into a float valued tensor of size N x L x W with N,L being equal to the ones in stft and W being equal to num_filter_bands . stft_phase : the phase information for each stft bin is appended to the stft magnitude so that the audio file is transformed into a float valued tensor of size N x L x 2W with N,L,W being equal to the ones in stft . group_delay : audio is transformed to group delay features according to Equation (23) in this paper . Group_delay features has the same tensor size as stft . Audio feature encoders are the same as for Sequence Features .","title":"Audio Input Features and Encoders"},{"location":"configuration/features/audio_features/#audio-output-features-and-decoders","text":"There are no audio decoders at the moment. If this would unlock an interesting use case for your application, please file a GitHub Issue or ping the Ludwig Slack .","title":"Audio Output Features and Decoders"},{"location":"configuration/features/bag_features/","text":"Bag Features Preprocessing \u00b6 Bag features are expected to be provided as a string of elements separated by whitespace, e.g. \"elem5 elem0 elem5 elem1\". Bags are similar to set features , the only difference being that elements may appear multiple times. The bag feature encoder outputs a matrix, similar to a set encoder, except each element of the matrix is a float value representing the frequency of the respective element in the bag. Embeddings are aggregated by summation, weighted by the frequency of each element. Bag Input Features and Encoders \u00b6 Bag features have only one encoder type available. Embed Weighted Encoder \u00b6 The embed weighted encoder first transforms the element frequency vector to sparse integer lists, which are then mapped to either dense or sparse embeddings (one-hot encodings). Lastly, embeddings are aggregated as a weighted sum where each embedding is multiplied by its respective element's frequency. Inputs are of size b while outputs are of size b x h where b is the batch size and h is the dimensionality of the embeddings. The parameters are the same used for set input features except for reduce_output which should not be used because the weighted sum already acts as a reducer. +---+ |0.0| +-----+ |1.0| +-+ |emb 0| +-----------+ |1.0| |0| +-----+ |Weighted | |0.0+--->1+---->emb 1+--->Sum +-> |0.0| |5| +-----+ |Operation | |2.0| +-+ |emb 5| +-----------+ |0.0| +-----+ +---+ Example bag feature entry in the input features list: name : bag_column_name type : bag representation : dense tied : null Bag Output Features and Decoders \u00b6 There is no bag decoder available yet. Bag Features Metrics \u00b6 As there is no decoder there is also no metric available yet for bag features.","title":"\u21c5 Bag Features"},{"location":"configuration/features/bag_features/#bag-features-preprocessing","text":"Bag features are expected to be provided as a string of elements separated by whitespace, e.g. \"elem5 elem0 elem5 elem1\". Bags are similar to set features , the only difference being that elements may appear multiple times. The bag feature encoder outputs a matrix, similar to a set encoder, except each element of the matrix is a float value representing the frequency of the respective element in the bag. Embeddings are aggregated by summation, weighted by the frequency of each element.","title":"Bag Features Preprocessing"},{"location":"configuration/features/bag_features/#bag-input-features-and-encoders","text":"Bag features have only one encoder type available.","title":"Bag Input Features and Encoders"},{"location":"configuration/features/bag_features/#embed-weighted-encoder","text":"The embed weighted encoder first transforms the element frequency vector to sparse integer lists, which are then mapped to either dense or sparse embeddings (one-hot encodings). Lastly, embeddings are aggregated as a weighted sum where each embedding is multiplied by its respective element's frequency. Inputs are of size b while outputs are of size b x h where b is the batch size and h is the dimensionality of the embeddings. The parameters are the same used for set input features except for reduce_output which should not be used because the weighted sum already acts as a reducer. +---+ |0.0| +-----+ |1.0| +-+ |emb 0| +-----------+ |1.0| |0| +-----+ |Weighted | |0.0+--->1+---->emb 1+--->Sum +-> |0.0| |5| +-----+ |Operation | |2.0| +-+ |emb 5| +-----------+ |0.0| +-----+ +---+ Example bag feature entry in the input features list: name : bag_column_name type : bag representation : dense tied : null","title":"Embed Weighted Encoder"},{"location":"configuration/features/bag_features/#bag-output-features-and-decoders","text":"There is no bag decoder available yet.","title":"Bag Output Features and Decoders"},{"location":"configuration/features/bag_features/#bag-features-metrics","text":"As there is no decoder there is also no metric available yet for bag features.","title":"Bag Features Metrics"},{"location":"configuration/features/binary_features/","text":"Binary Features Preprocessing \u00b6 Binary features are directly transformed into a binary valued vector of length n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. The parameters available for preprocessing are: missing_value_strategy (default fill_with_false ): what strategy to follow when there's a missing value in a binary column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value), or fill_with_false (default, replaces the missing value with False). fill_value (default 0 ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . fallback_true_label : In case the binary feature doesn't have conventional boolean values, we will interpret the fallback_true_label as 1 (true) and the other values as 0 (False). Binary Input Features and Encoders \u00b6 name : binary_column_name type : binary tied : null encoder : passthrough Binary features have two encoders, passthrough and dense . The passthrough encoder passes through raw binary values without any transformations. Inputs of size b are transformed to outputs of size b x 1 where b is the batch size. The dense encoder passes the raw binary values through a fully connected layer. Inputs of size b are transformed to size b x h . The available encoder parameters are: tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters. Passthrough Encoder \u00b6 There are no additional parameters for the passthrough encoder. Dense Encoder \u00b6 For the dense encoder these are the available parameters. num_layers (default 1 ): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Binary Output Features and Decoders \u00b6 name : binary_column_name type : binary reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : cross_entropy confidence_penalty : 0 robust_lambda : 0 positive_class_weight : 1 fc_layers : null num_fc_layers : 0 activation : relu norm : null dropout : 0.2 weights_initializer : glorot_uniform bias_initializer : zeros threshold : 0.5 Binary output features can be used when a binary classification needs to be performed or when the output is a single probability. There is only one decoder available for binary features and it is a (potentially empty) stack of fully connected layers, followed by a projection into a single number followed by a sigmoid function. These are the available parameters of a binary output feature. reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). calibration (default false ): if true, performs calibration by temperature scaling after training is complete. Calibration uses the validation set to find a scale factor (temperature) which is multiplied with the logits to shift output probabilities closer to true likelihoods. dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). loss (default {type: cross_entropy, confidence_penalty: 0, robust_lambda: 0, positive_class_weight: 1} ): is a dictionary containing a loss type and its hyperparameters. The only available loss type is cross_entropy (cross entropy), and the optional parameters are confidence_penalty (an additional term that penalizes too confident predictions by adding a a * (max_entropy - entropy) / max_entropy term to the loss, where a is the value of this parameter), robust_lambda (replaces the loss with (1 - robust_lambda) * loss + robust_lambda / 2 which is useful in case of noisy labels) and positive_class_weight (multiplies the loss for the positive class, increasing its importance). These are the available parameters of a binary output feature decoder. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . dropout (default 0 ): dropout rate use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . threshold (default 0.5 ): The threshold above (greater or equal) which the predicted output of the sigmoid will be mapped to 1. Binary Feature Metrics \u00b6 The only metrics that are calculated every epoch and are available for binary features are the accuracy and the loss itself. You can set either to be the validation_metric in the training section of the configuration if the validation_field is set as the name of a binary feature.","title":"\u21c5 Binary Features"},{"location":"configuration/features/binary_features/#binary-features-preprocessing","text":"Binary features are directly transformed into a binary valued vector of length n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. The parameters available for preprocessing are: missing_value_strategy (default fill_with_false ): what strategy to follow when there's a missing value in a binary column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value), or fill_with_false (default, replaces the missing value with False). fill_value (default 0 ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . fallback_true_label : In case the binary feature doesn't have conventional boolean values, we will interpret the fallback_true_label as 1 (true) and the other values as 0 (False).","title":"Binary Features Preprocessing"},{"location":"configuration/features/binary_features/#binary-input-features-and-encoders","text":"name : binary_column_name type : binary tied : null encoder : passthrough Binary features have two encoders, passthrough and dense . The passthrough encoder passes through raw binary values without any transformations. Inputs of size b are transformed to outputs of size b x 1 where b is the batch size. The dense encoder passes the raw binary values through a fully connected layer. Inputs of size b are transformed to size b x h . The available encoder parameters are: tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.","title":"Binary Input Features and Encoders"},{"location":"configuration/features/binary_features/#passthrough-encoder","text":"There are no additional parameters for the passthrough encoder.","title":"Passthrough Encoder"},{"location":"configuration/features/binary_features/#dense-encoder","text":"For the dense encoder these are the available parameters. num_layers (default 1 ): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate","title":"Dense Encoder"},{"location":"configuration/features/binary_features/#binary-output-features-and-decoders","text":"name : binary_column_name type : binary reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : cross_entropy confidence_penalty : 0 robust_lambda : 0 positive_class_weight : 1 fc_layers : null num_fc_layers : 0 activation : relu norm : null dropout : 0.2 weights_initializer : glorot_uniform bias_initializer : zeros threshold : 0.5 Binary output features can be used when a binary classification needs to be performed or when the output is a single probability. There is only one decoder available for binary features and it is a (potentially empty) stack of fully connected layers, followed by a projection into a single number followed by a sigmoid function. These are the available parameters of a binary output feature. reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). calibration (default false ): if true, performs calibration by temperature scaling after training is complete. Calibration uses the validation set to find a scale factor (temperature) which is multiplied with the logits to shift output probabilities closer to true likelihoods. dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). loss (default {type: cross_entropy, confidence_penalty: 0, robust_lambda: 0, positive_class_weight: 1} ): is a dictionary containing a loss type and its hyperparameters. The only available loss type is cross_entropy (cross entropy), and the optional parameters are confidence_penalty (an additional term that penalizes too confident predictions by adding a a * (max_entropy - entropy) / max_entropy term to the loss, where a is the value of this parameter), robust_lambda (replaces the loss with (1 - robust_lambda) * loss + robust_lambda / 2 which is useful in case of noisy labels) and positive_class_weight (multiplies the loss for the positive class, increasing its importance). These are the available parameters of a binary output feature decoder. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . dropout (default 0 ): dropout rate use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . threshold (default 0.5 ): The threshold above (greater or equal) which the predicted output of the sigmoid will be mapped to 1.","title":"Binary Output Features and Decoders"},{"location":"configuration/features/binary_features/#binary-feature-metrics","text":"The only metrics that are calculated every epoch and are available for binary features are the accuracy and the loss itself. You can set either to be the validation_metric in the training section of the configuration if the validation_field is set as the name of a binary feature.","title":"Binary Feature Metrics"},{"location":"configuration/features/category_features/","text":"Category Features Preprocessing \u00b6 Category features are transformed into integer valued vectors of size n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. Categories are mapped to integers by first collecting a dictionary of all unique category strings present in the column of the dataset, ranking them descending by frequency and assigning a sequential integer ID from the most frequent to the most rare (with 0 assigned to the special unknown placeholder token <UNK> ). The column name is added to the JSON file, with an associated dictionary containing the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the size of the set of all tokens ( vocab_size ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values) The parameters available for preprocessing are missing_value_strategy (default fill_with_const ): what strategy to follow when there is a missing value in the category column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default <UNK> ): the value to replace missing values with when missing_value_strategy is fill_with_const . lowercase (default false ): if the string has to be lowercased before being handled by the tokenizer. most_common (default 10000 ): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown. Category Input Features and Encoders \u00b6 Category features have three encoders. The passthrough encoder passes the raw integer values coming from the input placeholders to outputs of size b x 1 . The other two encoders map to either dense or sparse embeddings (one-hot encodings) and returned as outputs of size b x h , where b is the batch size and h is the dimensionality of the embeddings. Input feature parameters. encoder (default dense ): the possible values are passthrough , dense and sparse . passthrough outputs the raw integer values unaltered. dense randomly initializes a trainable embedding matrix, sparse uses one-hot encoding. tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters. Example category feature entry in the input features list: name : category_column_name type : category tied : null encoder : dense The available encoder parameters: Dense Encoder \u00b6 embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <UNK> ). embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. dropout (default 0 ): dropout rate. embedding_initializer (default null ): the initializer to use. If null , the default initialized of each variable is used ( glorot_uniform in most cases). Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Sparse Encoder \u00b6 embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <UNK> ). embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. dropout (default 0 ): dropout rate embedding_initializer (default null ): the initializer to use. If null , the default initialized of each variable is used ( glorot_uniform in most cases). Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Example category feature entry in the input features list: name : category_column_name type : category encoder : sparse tied : null embedding_size : 256 embeddings_on_cpu : false pretrained_embeddings : null embeddings_trainable : true dropout : 0 embedding_initializer : null Category Output Features and Decoders \u00b6 Category features can be used when a multi-class classification needs to be performed. There is only one decoder available for category features: a (potentially empty) stack of fully connected layers, followed by a projection into a vector of size of the number of available classes, followed by a softmax. +--------------+ +---------+ +-----------+ |Combiner | |Fully | |Projection | +-------+ |Output +--->Connected+--->into Output+--->Softmax| |Representation| |Layers | |Space | +-------+ +--------------+ +---------+ +-----------+ These are the available parameters of a category output feature reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). calibration (default false ): if true, performs calibration by temperature scaling after training is complete. Calibration uses the validation set to find a scale factor (temperature) which is multiplied with the logits to shift output probabilities closer to true likelihoods. dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Features Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). loss (default {type: softmax_cross_entropy} ): is a dictionary containing a loss type . softmax_cross_entropy is the only supported loss type for category output features. top_k (default 3 ): determines the parameter k , the number of categories to consider when computing the top_k measure. It computes accuracy but considering as a match if the true category appears in the first k predicted categories ranked by decoder's confidence. These are the loss parameters confidence_penalty (default 0 ): penalizes overconfident predictions (low entropy) by adding an additional term that penalizes too confident predictions by adding a a * (max_entropy - entropy) / max_entropy term to the loss, where a is the value of this parameter. Useful in case of noisy labels. robust_lambda (default 0 ): replaces the loss with (1 - robust_lambda) * loss + robust_lambda / c where c is the number of classes, which is useful in case of noisy labels. class_weights (default 1 ): the value can be a vector of weights, one for each class, that is multiplied to the loss of the datapoints that have that class as ground truth. It is an alternative to oversampling in case of unbalanced class distribution. The ordering of the vector follows the category to integer ID mapping in the JSON metadata file (the <UNK> class needs to be included too). Alternatively, the value can be a dictionary with class strings as keys and weights as values, like {class_a: 0.5, class_b: 0.7, ...} . class_similarities (default null ): if not null it is a c x c matrix in the form of a list of lists that contains the mutual similarity of classes. It is used if class_similarities_temperature is greater than 0. The ordering of the vector follows the category to integer ID mapping in the JSON metadata file (the <UNK> class needs to be included too). class_similarities_temperature (default 0 ): is the temperature parameter of the softmax that is performed on each row of class_similarities . The output of that softmax is used to determine the supervision vector to provide instead of the one hot vector that would be provided otherwise for each datapoint. The intuition behind it is that errors between similar classes are more tolerable than errors between really different classes. These are the available parameters of a category output feature decoder fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . dropout (default 0 ): dropout rate use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the fully connected weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . Example category feature entry (with default parameters) in the output features list: name : category_column_name type : category reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities : null class_similarities_temperature : 0 fc_layers : null num_fc_layers : 0 output_size : 256 activation : relu norm : null norm_params : null dropout : 0 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros top_k : 3 Category Features Metrics \u00b6 The measures that are calculated every epoch and are available for category features are accuracy , hits_at_k (computes accuracy considering as a match if the true category appears in the first k predicted categories ranked by decoder's confidence) and the loss itself. You can set either of them as validation_metric in the training section of the configuration if you set the validation_field to be the name of a category feature.","title":"\u21c5 Category Features"},{"location":"configuration/features/category_features/#category-features-preprocessing","text":"Category features are transformed into integer valued vectors of size n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. Categories are mapped to integers by first collecting a dictionary of all unique category strings present in the column of the dataset, ranking them descending by frequency and assigning a sequential integer ID from the most frequent to the most rare (with 0 assigned to the special unknown placeholder token <UNK> ). The column name is added to the JSON file, with an associated dictionary containing the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the size of the set of all tokens ( vocab_size ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values) The parameters available for preprocessing are missing_value_strategy (default fill_with_const ): what strategy to follow when there is a missing value in the category column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default <UNK> ): the value to replace missing values with when missing_value_strategy is fill_with_const . lowercase (default false ): if the string has to be lowercased before being handled by the tokenizer. most_common (default 10000 ): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown.","title":"Category Features Preprocessing"},{"location":"configuration/features/category_features/#category-input-features-and-encoders","text":"Category features have three encoders. The passthrough encoder passes the raw integer values coming from the input placeholders to outputs of size b x 1 . The other two encoders map to either dense or sparse embeddings (one-hot encodings) and returned as outputs of size b x h , where b is the batch size and h is the dimensionality of the embeddings. Input feature parameters. encoder (default dense ): the possible values are passthrough , dense and sparse . passthrough outputs the raw integer values unaltered. dense randomly initializes a trainable embedding matrix, sparse uses one-hot encoding. tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters. Example category feature entry in the input features list: name : category_column_name type : category tied : null encoder : dense The available encoder parameters:","title":"Category Input Features and Encoders"},{"location":"configuration/features/category_features/#dense-encoder","text":"embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <UNK> ). embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. dropout (default 0 ): dropout rate. embedding_initializer (default null ): the initializer to use. If null , the default initialized of each variable is used ( glorot_uniform in most cases). Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform .","title":"Dense Encoder"},{"location":"configuration/features/category_features/#sparse-encoder","text":"embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <UNK> ). embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. dropout (default 0 ): dropout rate embedding_initializer (default null ): the initializer to use. If null , the default initialized of each variable is used ( glorot_uniform in most cases). Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Example category feature entry in the input features list: name : category_column_name type : category encoder : sparse tied : null embedding_size : 256 embeddings_on_cpu : false pretrained_embeddings : null embeddings_trainable : true dropout : 0 embedding_initializer : null","title":"Sparse Encoder"},{"location":"configuration/features/category_features/#category-output-features-and-decoders","text":"Category features can be used when a multi-class classification needs to be performed. There is only one decoder available for category features: a (potentially empty) stack of fully connected layers, followed by a projection into a vector of size of the number of available classes, followed by a softmax. +--------------+ +---------+ +-----------+ |Combiner | |Fully | |Projection | +-------+ |Output +--->Connected+--->into Output+--->Softmax| |Representation| |Layers | |Space | +-------+ +--------------+ +---------+ +-----------+ These are the available parameters of a category output feature reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). calibration (default false ): if true, performs calibration by temperature scaling after training is complete. Calibration uses the validation set to find a scale factor (temperature) which is multiplied with the logits to shift output probabilities closer to true likelihoods. dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Features Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). loss (default {type: softmax_cross_entropy} ): is a dictionary containing a loss type . softmax_cross_entropy is the only supported loss type for category output features. top_k (default 3 ): determines the parameter k , the number of categories to consider when computing the top_k measure. It computes accuracy but considering as a match if the true category appears in the first k predicted categories ranked by decoder's confidence. These are the loss parameters confidence_penalty (default 0 ): penalizes overconfident predictions (low entropy) by adding an additional term that penalizes too confident predictions by adding a a * (max_entropy - entropy) / max_entropy term to the loss, where a is the value of this parameter. Useful in case of noisy labels. robust_lambda (default 0 ): replaces the loss with (1 - robust_lambda) * loss + robust_lambda / c where c is the number of classes, which is useful in case of noisy labels. class_weights (default 1 ): the value can be a vector of weights, one for each class, that is multiplied to the loss of the datapoints that have that class as ground truth. It is an alternative to oversampling in case of unbalanced class distribution. The ordering of the vector follows the category to integer ID mapping in the JSON metadata file (the <UNK> class needs to be included too). Alternatively, the value can be a dictionary with class strings as keys and weights as values, like {class_a: 0.5, class_b: 0.7, ...} . class_similarities (default null ): if not null it is a c x c matrix in the form of a list of lists that contains the mutual similarity of classes. It is used if class_similarities_temperature is greater than 0. The ordering of the vector follows the category to integer ID mapping in the JSON metadata file (the <UNK> class needs to be included too). class_similarities_temperature (default 0 ): is the temperature parameter of the softmax that is performed on each row of class_similarities . The output of that softmax is used to determine the supervision vector to provide instead of the one hot vector that would be provided otherwise for each datapoint. The intuition behind it is that errors between similar classes are more tolerable than errors between really different classes. These are the available parameters of a category output feature decoder fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . dropout (default 0 ): dropout rate use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the fully connected weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . Example category feature entry (with default parameters) in the output features list: name : category_column_name type : category reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities : null class_similarities_temperature : 0 fc_layers : null num_fc_layers : 0 output_size : 256 activation : relu norm : null norm_params : null dropout : 0 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros top_k : 3","title":"Category Output Features and Decoders"},{"location":"configuration/features/category_features/#category-features-metrics","text":"The measures that are calculated every epoch and are available for category features are accuracy , hits_at_k (computes accuracy considering as a match if the true category appears in the first k predicted categories ranked by decoder's confidence) and the loss itself. You can set either of them as validation_metric in the training section of the configuration if you set the validation_field to be the name of a category feature.","title":"Category Features Metrics"},{"location":"configuration/features/date_features/","text":"Date features are like 2023-06-25 15:00:00 , 2023-06-25 , 6-25-2023 , or 6/25/2023 . Date Features Preprocessing \u00b6 name : date_feature_name type : date preprocessing : missing_value_strategy : fill_with_const fill_value : '' datetime_format : \"%d %b %Y\" Ludwig will try to infer the date format automatically, but a specific format can be provided. The date string spec is the same as the one described in python's datetime . Here are some preprocessing parameters. missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter). The special value backfill replaces the missing values with the next valid value. fill_value (default \"\" ): the value to replace missing values with when missing_value_strategy is fill_with_const . This can be a datetime string. If empty, the current datetime will be used. datetime_format (default null ): this parameter can either be a datetime format string, or null , in which case the datetime format will be inferred automatically. Date Input Features and Encoders \u00b6 Input date features are transformed into a int tensors of size N x 9 (where N is the size of the dataset and the 9 dimensions contain year, month, day, weekday, yearday, hour, minute, second, and second of day). For example, the date 2022-06-25 09:30:59 would be deconstructed into: [ 2022 , # Year 6 , # June 25 , # 25th day of the month 5 , # Weekday: Saturday 176 , # 176th day of the year 9 , # Hour 30 , # Minute 59 , # Seconds 34259 , # 34259th second of the day ] Currently there are two encoders supported for dates: DateEmbed (default) and DateWave . The encoder can be set by specifying embed or wave in the feature's encoder parameter in the input feature's configuration. name : date_feature_name type : date encoder : embed Embed Encoder \u00b6 name : date_column_name type : date encoder : embed embedding_size : 10 embeddings_on_cpu : false fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 This encoder passes the year through a fully connected layer of one neuron and embeds all other elements for the date, concatenates them and passes the concatenated representation through fully connected layers. It takes the following optional parameters: embedding_size (default 10 ): it is the maximum embedding size adopted. embeddings_on_cpu (default false ): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory. dropout (default 0 ): dropout rate. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead.``` num_fc_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 10 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Wave Encoder \u00b6 name : date_column_name type : date encoder : wave fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 This encoder passes the year through a fully connected layer of one neuron and represents all other elements for the date by taking the cosine of their value with a different period (12 for months, 31 for days, etc.), concatenates them and passes the concatenated representation through fully connected layers. It takes the following parameters: fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 10 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Date Output Features and Decoders \u00b6 There is currently no support for date as an output feature. Consider using the TEXT type .","title":"\u2191 Date Features"},{"location":"configuration/features/date_features/#date-features-preprocessing","text":"name : date_feature_name type : date preprocessing : missing_value_strategy : fill_with_const fill_value : '' datetime_format : \"%d %b %Y\" Ludwig will try to infer the date format automatically, but a specific format can be provided. The date string spec is the same as the one described in python's datetime . Here are some preprocessing parameters. missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter). The special value backfill replaces the missing values with the next valid value. fill_value (default \"\" ): the value to replace missing values with when missing_value_strategy is fill_with_const . This can be a datetime string. If empty, the current datetime will be used. datetime_format (default null ): this parameter can either be a datetime format string, or null , in which case the datetime format will be inferred automatically.","title":"Date Features Preprocessing"},{"location":"configuration/features/date_features/#date-input-features-and-encoders","text":"Input date features are transformed into a int tensors of size N x 9 (where N is the size of the dataset and the 9 dimensions contain year, month, day, weekday, yearday, hour, minute, second, and second of day). For example, the date 2022-06-25 09:30:59 would be deconstructed into: [ 2022 , # Year 6 , # June 25 , # 25th day of the month 5 , # Weekday: Saturday 176 , # 176th day of the year 9 , # Hour 30 , # Minute 59 , # Seconds 34259 , # 34259th second of the day ] Currently there are two encoders supported for dates: DateEmbed (default) and DateWave . The encoder can be set by specifying embed or wave in the feature's encoder parameter in the input feature's configuration. name : date_feature_name type : date encoder : embed","title":"Date Input Features and Encoders"},{"location":"configuration/features/date_features/#embed-encoder","text":"name : date_column_name type : date encoder : embed embedding_size : 10 embeddings_on_cpu : false fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 This encoder passes the year through a fully connected layer of one neuron and embeds all other elements for the date, concatenates them and passes the concatenated representation through fully connected layers. It takes the following optional parameters: embedding_size (default 10 ): it is the maximum embedding size adopted. embeddings_on_cpu (default false ): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory. dropout (default 0 ): dropout rate. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead.``` num_fc_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 10 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate","title":"Embed Encoder"},{"location":"configuration/features/date_features/#wave-encoder","text":"name : date_column_name type : date encoder : wave fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 This encoder passes the year through a fully connected layer of one neuron and represents all other elements for the date by taking the cosine of their value with a different period (12 for months, 31 for days, etc.), concatenates them and passes the concatenated representation through fully connected layers. It takes the following parameters: fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 10 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate","title":"Wave Encoder"},{"location":"configuration/features/date_features/#date-output-features-and-decoders","text":"There is currently no support for date as an output feature. Consider using the TEXT type .","title":"Date Output Features and Decoders"},{"location":"configuration/features/h3_features/","text":"H3 is a indexing system for representing geospatial data. For more details about it refer to https://eng.uber.com/h3 . H3 Features Preprocessing \u00b6 name : h3_feature_name type : h3 preprocessing : missing_value_strategy : fill_with_const fill_value : 576495936675512319 Ludwig will parse the H3 64bit encoded format automatically. The parameters for preprocessing are: missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in a binary column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default 576495936675512319 ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . This is a 64bit integer compatible with the H3 bit layout. The default value encodes mode 1, edge 0, resolution 0, base_cell 0. H3 Input Features and Encoders \u00b6 Input H3 features are transformed into a int valued tensors of size N x 19 (where N is the size of the dataset and the 19 dimensions represent 4 H3 resolution parameters (4) - mode, edge, resolution, base cell - and 15 cell coordinate values. Currently there are three encoders supported for H3: H3Embed (default), H3WeightedSum , and H3RNN . The encoder can be set by specifying embed , weighted_sum , or rnn in the input feature's configuration. name : h3_feature_name type : h3 encoder : embed Embed Encoder \u00b6 name : h3_column_name type : h3 encoder : embed embedding_size : 10 embeddings_on_cpu : false fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and children cells) with embeddings. Children cells with value 0 will be masked out. After the embedding, all embeddings are summed and optionally passed through a stack of fully connected layers. It takes the following optional parameters: embedding_size (default 10 ): it is the maximum embedding size adopted. embeddings_on_cpu (default false ): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 10 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Weighted Sum Embed Encoder \u00b6 name : h3_column_name type : h3 encoder : weighted_sum embedding_size : 10 embeddings_on_cpu : false should_softmax : false fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and children cells) with embeddings. Children cells with value 0 will be masked out. After the embedding, all embeddings are summed with a weighted sum (with learned weights) and optionally passed through a stack of fully connected layers. It takes the following optional parameters: embedding_size (default 10 ): it is the maximum embedding size adopted.. embeddings_on_cpu (default false ): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory. should_softmax (default false ): determines if the weights of the weighted sum should be passed though a softmax layer before being used. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 10 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor). RNN Encoder \u00b6 name : h3_column_name type : h3 encoder : rnn embedding_size : 10 embeddings_on_cpu : false num_layers : 1 cell_type : rnn state_size : 10 bidirectional : false activation : tanh recurrent_activation : sigmoid use_bias : true unit_forget_bias : true weights_initializer : glorot_uniform recurrent_initializer : orthogonal bias_initializer : zeros dropout : 0.0 recurrent_dropout : 0.0 initializer : null regularize : true reduce_output : last This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and children cells) with embeddings. Children cells with value 0 will be masked out. After the embedding, all embeddings are passed through an RNN encoder. The intuition behind this is that, starting from the base cell, the sequence of children cells can be seen as a sequence encoding the path in the tree of all H3 hexes. It takes the following optional parameters: embedding_size (default 10 ): it is the maximum embedding size adopted.. embeddings_on_cpu (default false ): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): the number of stacked recurrent layers. state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use recurrent_activation (default sigmoid ): activation function to use in the recurrent step use_bias (default true ): boolean, whether the layer uses a bias vector. unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . recurrent_initializer (default 'orthogonal' ): initializer for recurrent matrix weights bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state initializer (default null ): the initializer to use. If null , the default initialized of each variable is used ( glorot_uniform in most cases). Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . regularize (default true ): if true the embedding weights are added to the set of weights that get regularized by a regularization loss (if the regularization_lambda in training is greater than 0). reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor). H3 Output Features and Decoders \u00b6 There is currently no support for H3 as an output feature. Consider using the TEXT type .","title":"\u2191 H3 Features"},{"location":"configuration/features/h3_features/#h3-features-preprocessing","text":"name : h3_feature_name type : h3 preprocessing : missing_value_strategy : fill_with_const fill_value : 576495936675512319 Ludwig will parse the H3 64bit encoded format automatically. The parameters for preprocessing are: missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in a binary column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default 576495936675512319 ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . This is a 64bit integer compatible with the H3 bit layout. The default value encodes mode 1, edge 0, resolution 0, base_cell 0.","title":"H3 Features Preprocessing"},{"location":"configuration/features/h3_features/#h3-input-features-and-encoders","text":"Input H3 features are transformed into a int valued tensors of size N x 19 (where N is the size of the dataset and the 19 dimensions represent 4 H3 resolution parameters (4) - mode, edge, resolution, base cell - and 15 cell coordinate values. Currently there are three encoders supported for H3: H3Embed (default), H3WeightedSum , and H3RNN . The encoder can be set by specifying embed , weighted_sum , or rnn in the input feature's configuration. name : h3_feature_name type : h3 encoder : embed","title":"H3 Input Features and Encoders"},{"location":"configuration/features/h3_features/#embed-encoder","text":"name : h3_column_name type : h3 encoder : embed embedding_size : 10 embeddings_on_cpu : false fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and children cells) with embeddings. Children cells with value 0 will be masked out. After the embedding, all embeddings are summed and optionally passed through a stack of fully connected layers. It takes the following optional parameters: embedding_size (default 10 ): it is the maximum embedding size adopted. embeddings_on_cpu (default false ): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 10 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate","title":"Embed Encoder"},{"location":"configuration/features/h3_features/#weighted-sum-embed-encoder","text":"name : h3_column_name type : h3 encoder : weighted_sum embedding_size : 10 embeddings_on_cpu : false should_softmax : false fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and children cells) with embeddings. Children cells with value 0 will be masked out. After the embedding, all embeddings are summed with a weighted sum (with learned weights) and optionally passed through a stack of fully connected layers. It takes the following optional parameters: embedding_size (default 10 ): it is the maximum embedding size adopted.. embeddings_on_cpu (default false ): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory. should_softmax (default false ): determines if the weights of the weighted sum should be passed though a softmax layer before being used. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 10 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor).","title":"Weighted Sum Embed Encoder"},{"location":"configuration/features/h3_features/#rnn-encoder","text":"name : h3_column_name type : h3 encoder : rnn embedding_size : 10 embeddings_on_cpu : false num_layers : 1 cell_type : rnn state_size : 10 bidirectional : false activation : tanh recurrent_activation : sigmoid use_bias : true unit_forget_bias : true weights_initializer : glorot_uniform recurrent_initializer : orthogonal bias_initializer : zeros dropout : 0.0 recurrent_dropout : 0.0 initializer : null regularize : true reduce_output : last This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and children cells) with embeddings. Children cells with value 0 will be masked out. After the embedding, all embeddings are passed through an RNN encoder. The intuition behind this is that, starting from the base cell, the sequence of children cells can be seen as a sequence encoding the path in the tree of all H3 hexes. It takes the following optional parameters: embedding_size (default 10 ): it is the maximum embedding size adopted.. embeddings_on_cpu (default false ): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): the number of stacked recurrent layers. state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use recurrent_activation (default sigmoid ): activation function to use in the recurrent step use_bias (default true ): boolean, whether the layer uses a bias vector. unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . recurrent_initializer (default 'orthogonal' ): initializer for recurrent matrix weights bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state initializer (default null ): the initializer to use. If null , the default initialized of each variable is used ( glorot_uniform in most cases). Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . regularize (default true ): if true the embedding weights are added to the set of weights that get regularized by a regularization loss (if the regularization_lambda in training is greater than 0). reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor).","title":"RNN Encoder"},{"location":"configuration/features/h3_features/#h3-output-features-and-decoders","text":"There is currently no support for H3 as an output feature. Consider using the TEXT type .","title":"H3 Output Features and Decoders"},{"location":"configuration/features/image_features/","text":"Input image features are transformed into a float valued tensors of size N x C x H x W (where N is the size of the dataset, C is the number of channels, and H x W is the height and width of the image (can be specified by the user). These tensors are added to HDF5 with a key that reflects the name of column in the dataset. The column name is added to the JSON file, with an associated dictionary containing preprocessing information about the sizes of the resizing. Supported Image Formats \u00b6 The number of channels in the image is determined by the image format. The following table lists the supported image formats and the number of channels. Format Number of channels Grayscale 1 Grayscale with Alpha 2 RGB 3 RGB with Alpha 4 Image Features Preprocessing \u00b6 During preprocessing, raw image files are transformed into numpy arrays and saved in the hdf5 format. Note Images passed to an image encoder are expected to have the same size. If images are different sizes, by default they will be resized to the dimensions of the first image in the dataset. Optionally, a resize_method together with a target width and height can be specified in the feature preprocessing parameters, in which case all images will be resized to the specified target size. height \u00b6 Image height in pixels. If set, images will be resized to the specified height using the resize_method parameter. If unspecified, images will be resized to the size of the first image in the dataset. Default: null width \u00b6 Image width in pixels. If set, images will be resized to the specified width using the resize_method parameter. If unspecified, images will be resized to the size of the first image in the dataset. Default: null num_channels \u00b6 Number of channels in the images. If specified, images will be read in the mode specified by the number of channels. If not specified, the number of channels will be inferred from the image format of the first valid image in the dataset. E.g., if num_channels = 1 , any RGB images will be converted to Grayscale. If num_channels = 3 , any images with 1 channel will be converted to RGB by repeating the channel 3 times. Default: null resize_method \u00b6 The method to use for resizing images. Default: crop_or_pad Options: crop_or_pad : If image is larger than the specified dimensions, crops images. If image is smaller, pads images using edge padding interpolate : Uses interpolation to resize images to the specified width and height infer_image_num_channels \u00b6 If true, then the number of channels in the dataset is inferred from a sample of the first image in the dataset. Default: true infer_image_dimensions \u00b6 If true, then the height and width of images in the dataset will be inferred from a sample of the first image in the dataset. Each image that doesn't conform to these dimensions will be resized according to resize_method . If set to false , then the height and width of images in the dataset will be specified by the user. This parameter will have no effect if width and height are specified. Default: true infer_image_max_height \u00b6 If infer_image_dimensions is set, this is used as the maximum height of the images in the dataset. Default: 256 infer_image_max_width \u00b6 If infer_image_dimensions is set, this is used as the maximum width of the images in the dataset. Default: 256 infer_image_sample_size \u00b6 The sample size used for inferring dimensions of images in infer_image_dimensions . Default: 100 scaling \u00b6 The scaling strategy for pixel values in the image. Default: pixel_normalization Options: pixel_normalization : Normalizes pixel values to be between 0 and 1 by dividing each pixel value by 255. pixel_standardization : Normalizes pixel values based on the mean and standard deviation of images in ImageNet. in_memory \u00b6 Defines whether image dataset will reside in memory during the training process or will be dynamically fetched from disk (useful for large datasets). In the latter case a training batch of input images will be fetched from disk each training iteration. Default: true num_processes \u00b6 Specifies the number of processes to run for preprocessing images. Default: 1 Note Depending on the application, it is preferable not to exceed a size of 256 x 256 as bigger sizes will seldom provide a significant performance advantage. Larger images will considerably slow down training and inference and consume more memory, leading to memory overflows on machines with limited amounts of RAM or OOM (out-of-memory) on GPUs. Example of a preprocessing specification: name : image_feature_name type : image preprocessing : missing_value_strategy : fill_with_const fill_value : 0.5 height : 128 width : 128 num_channels : 3 resize_method : interpolate scaling : pixel_normalization in_memory : true num_processes : 4 Image Input Features and Encoders \u00b6 The default encoder is stacked_cnn . Convolutional Stack Encoder ( stacked_cnn ) \u00b6 Stack of 2D convolutional layers with optional normalization, dropout, and downsampling pooling layers, followed by an optional stack of fully connected layers. Convolutional Stack Encoder takes the following optional parameters: conv_layers \u00b6 A list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. If a parameter for a layer is not specified in the dictionary, then the default value for the stacked CNN encoder is used. Default: null Parameters for each layer: out_channels : The number of output channels. kernel_size : The size of the convolutional kernel. stride : The stride of the convolutional kernel. padding : The padding of the convolutional kernel. dilation : The dilation of the convolutional kernel. groups : The number of groups for grouped convolution. bias : Whether to add a bias term to the convolution. padding_mode : The padding mode to use for the convolution. norm : The type of normalization to use for the convolution. norm_params : Optional parameters for the normalization. activation : The type of activation to use for the convolution. dropout : The dropout probability to use for the convolution. pool_function : The type of pooling function to use for the convolution. pool_kernel_size : The size of the pooling kernel. pool_stride : The stride of the pooling kernel. pool_padding : The padding of the pooling kernel. pool_dilation : The dilation of the pooling kernel. num_conv_layers \u00b6 If conv_layers is null , this is the number of stacked convolutional layers. Each layer will use default parameters for the convolutional layer. Default: null Note If both conv_layers and num_conv_layers are null , conv_layers is set to the following default value: conv_layers = [ { kernel_size : 3 , out_channels : 32 , pool_kernel_size : 2 , }, { kernel_size : 3 , out_channels : 64 , pool_kernel_size : 2 , }, ] out_channels \u00b6 Indicates the number of filters, and by consequence the output channels of the 2d convolution. If out_channels is not already specified in conv_layers this is the default out_channels that will be used for each layer. Default: 32 kernel_size \u00b6 An integer or pair of integers specifying the kernel size. A single integer specifies a square kernel, while a pair of integers specifies the height and width of the kernel in that order ( [h, w] ). If a kernel_size is not specified in conv_layers this kernel_size that will be used for each layer. Default: 3 stride \u00b6 An integer or pair of integers specifying the stride of the convolution along the height and width. If a stride is not already specified in conv_layers , specifies the default stride of the 2D convolutional kernel that will be used for each layer. Default: 1 padding \u00b6 An int, pair of ints [h, w] , or one of valid , same specifying the padding used for convolution kernels. Default: valid dilation \u00b6 An int or pair of ints specifying the dilation rate to use for dilated convolution. If dilation is not already specified in conv_layers , specifies the default dilation of the 2D convolutional kernel that will be used for each layer. Default: 1 groups \u00b6 Groups controls the connectivity between convolution inputs and outputs. When groups = 1 , each output channel depends on every input channel. When groups > 1 , input and output channels are divided into groups separate groups, where each output channel depends only on the inputs in its respective input channel group. in_channels and out_channels must both be divisible by groups . Default: 1 conv_bias \u00b6 If bias not already specified in conv_layers , specifies if the 2D convolutional kernel should have a bias term. Default: true padding_mode \u00b6 If padding_mode is not already specified in conv_layers , specifies the default padding_mode of the 2D convolutional kernel that will be used for each layer. Default: zeros Choices: zeros , reflect , replicate , circular conv_norm \u00b6 (default null ): if a norm is not already specified in conv_layers this is the default norm that will be used for each layer. It indicates the normalization applied to the activations and can be null , batch or layer . conv_norm_params \u00b6 (default null ): parameters used if conv_norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . conv_activation \u00b6 (default relu ): if an activation is not already specified in conv_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. conv_dropout \u00b6 (default 0 ): dropout rate pool_function \u00b6 (default max ): max will use max pooling. Any of average , avg or mean will use average pooling. pool_kernel_size \u00b6 (default 2 ): An integer or pair of integers specifying the pooling size. If pool_kernel_size is not specified in conv_layers this is the default value that will be used for each layer. pool_stride \u00b6 (default null ): An integer or pair of integers specifying the pooling stride, which is the factor by which the pooling layer downsamples the feature map. Defaults to pool_kernel_size . pool_padding \u00b6 (default 0 ): An integer or pair of ints specifying pooling padding (h, w) . pool_dilation \u00b6 (default 1 ): An integer or pair of ints specifying pooling dilation rate (h, w) . fc_layers \u00b6 (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers \u00b6 (default 1 ): The number of stacked fully connected layers. output_size \u00b6 (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. fc_use_bias \u00b6 (default true ): boolean, whether the layer uses a bias vector. fc_weights_initializer \u00b6 (default xavier_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . fc_bias_initializer \u00b6 (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . fc_norm \u00b6 (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and can be null , batch or layer . fc_norm_params \u00b6 (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . fc_activation \u00b6 (default relu ): : if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout \u00b6 (default 0 ): dropout rate Example image feature config using a convolutional stack encoder: name : image_column_name type : image encoder : stacked_cnn conv_layers : null num_conv_layers : null kernel_size : 3 out_channels : 256 padding : valid conv_use_bias : true conv_norm : batch conv_activation : relu conv_dropout : 0 pool_function : max num_fc_layers : 1 output_size : 256 fc_use_bias : true fc_weights_initializer : xavier_uniform fc_bias_initializer : zeros fc_norm : batch fc_activation : relu fc_dropout : 0 preprocessing : # example pre-processing height : 32 width : 32 num_channels : 1 ResNet Encoder \u00b6 Implements ResNet V2 as described in Identity Mappings in Deep Residual Networks . The ResNet encoder takes the following optional parameters: resnet_size (default 50 ): The ResNet size, one of: 8 , 14 , 18 , 34 , 50 , 101 , 152 , 200 . num_filters (default 16 ): The number of filters, and by consequence the output channels of the 2d convolution. kernel_size (default 3 ): An integer or pair of integers specifying the convolution kernel size. A single integer specifies a square kernel, a pair of integers specifies the height and width of the kernel in that order ( [h, w] ). conv_stride (default 1 ): An integer or pair of integers specifying the stride of the initial convolutional layer. first_pool_kernel_size (default null ): Pool size to be used for the first pooling layer. If none, the first pooling layer is skipped. first_pool_stride (default null ): Stride for first pooling layer. If null , defaults to first_pool_kernel_size . batch_norm_momentum (default 0.9 ): Momentum of the batch norm running statistics. batch_norm_epsilon (default 0.001 ): Epsilon of the batch norm. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 1 ): The number of stacked fully connected layers. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. weights_initializer (default xavier_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Example image input feature config using a ResNet encoder: name : image_column_name type : image encoder : resnet resnet_size : 50 num_filters : 16 kernel_size : 3 conv_stride : 1 batch_norm_momentum : 0.9 batch_norm_epsilon : 0.001 num_fc_layers : 1 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 preprocessing : height : 224 width : 224 num_channels : 3 MLP-Mixer Encoder \u00b6 Encodes images using MLP-Mixer, as described in MLP-Mixer: An all-MLP Architecture for Vision . MLP-Mixer divides the image into equal-sized patches, applying fully connected layers to each patch to compute per-patch representations (tokens) and combining the representations with fully-connected mixer layers. The MLP-Mixer Encoder takes the following optional parameters: patch_size (default 16 ): The image patch size. Each patch is patch_size \u00b2 pixels. Must evenly divide the image width and height. embed_size (default 512 ): The patch embedding size, the output size of the mixer if avg_pool is true. token_size (default 2048 ): The per-patch embedding size. channel_dim (default 256 ): Number of channels in hidden layer. num_layers (default 8 ): The depth of the network (the number of Mixer blocks). dropout (default 0 ): Dropout rate. avg_pool (default true ): If true, pools output over patch dimension, outputs a vector of shape (embed_size) . If false, the output tensor is of shape (n_patches, embed_size) , where n_patches is img_height x img_width / patch_size \u00b2. Example image feature config using an MLP-Mixer encoder: name : image_column_name type : image encoder : mlp_mixer patch_size : 16 embed_size : 512 token_size : 2048 channel_dim : 256 num_layers : 8 dropout : 0.0 avg_pool : True preprocessing : height : 64 width : 64 num_channels : 3 Vision Transformer Encoder \u00b6 Encodes images using a Vision Transformer as described in An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale . Vision Transformer divides the image into equal-sized patches, uses a linear transformation to encode each flattened patch, then applies a deep transformer architecture to the sequence of encoded patches. The Vision Transformer Encoder takes the following optional parameters: use_pretrained (default true ): Use pre-trained model weights from Hugging Face. pretrained_model (default google/vit-base-patch16-224 ): The pre-trained model to use. See the model hub for other pretrained vision transformer models. hidden_size (default 768 ): Dimensionality of the encoder layers and the pooling layer. num_hidden_layers (default 12 ): Number of hidden layers in the Transformer encoder. num_attention_heads (default 12 ): Number of attention heads in each attention layer. intermediate_size (default 3072 ): Dimensionality of the intermediate (i.e., feed-forward) layer in the Transformer encoder. hidden_act (default gelu ): Hidden layer activation, one of gelu , relu , selu or gelu_new . hidden_dropout_prob (default 0.1 ): The dropout rate for all fully connected layers in the embeddings, encoder, and pooling. attention_probs_dropout_prob (default 0.1 ): The dropout rate for the attention probabilities. initializer_range (default 768 ): The standard deviation of the truncated_normal_initializer for initializing all weight matrices. layer_norm_eps (default 1e-12 ): The epsilon used by the layer normalization layers. gradient_checkpointing (default false ): patch_size (default 16 ): The image patch size. Each patch is patch_size \u00b2 pixels. Must evenly divide the image width and height. trainable (default true ): Is the encoder trainable. Example image feature config using an MLP-Mixer encoder: name : image_column_name type : image encoder : vit use_pretrained : true preprocessing : height : 128 width : 128 num_channels : 3 Image Output Features and Decoders \u00b6 There are no image decoders at the moment (WIP), so image cannot be used as output features. Image Features Measures \u00b6 As no image decoders are available at the moment, there are also no image measures.","title":"\u2191 Image Features"},{"location":"configuration/features/image_features/#supported-image-formats","text":"The number of channels in the image is determined by the image format. The following table lists the supported image formats and the number of channels. Format Number of channels Grayscale 1 Grayscale with Alpha 2 RGB 3 RGB with Alpha 4","title":"Supported Image Formats"},{"location":"configuration/features/image_features/#image-features-preprocessing","text":"During preprocessing, raw image files are transformed into numpy arrays and saved in the hdf5 format. Note Images passed to an image encoder are expected to have the same size. If images are different sizes, by default they will be resized to the dimensions of the first image in the dataset. Optionally, a resize_method together with a target width and height can be specified in the feature preprocessing parameters, in which case all images will be resized to the specified target size.","title":"Image Features Preprocessing"},{"location":"configuration/features/image_features/#height","text":"Image height in pixels. If set, images will be resized to the specified height using the resize_method parameter. If unspecified, images will be resized to the size of the first image in the dataset. Default: null","title":"height"},{"location":"configuration/features/image_features/#width","text":"Image width in pixels. If set, images will be resized to the specified width using the resize_method parameter. If unspecified, images will be resized to the size of the first image in the dataset. Default: null","title":"width"},{"location":"configuration/features/image_features/#num_channels","text":"Number of channels in the images. If specified, images will be read in the mode specified by the number of channels. If not specified, the number of channels will be inferred from the image format of the first valid image in the dataset. E.g., if num_channels = 1 , any RGB images will be converted to Grayscale. If num_channels = 3 , any images with 1 channel will be converted to RGB by repeating the channel 3 times. Default: null","title":"num_channels"},{"location":"configuration/features/image_features/#resize_method","text":"The method to use for resizing images. Default: crop_or_pad Options: crop_or_pad : If image is larger than the specified dimensions, crops images. If image is smaller, pads images using edge padding interpolate : Uses interpolation to resize images to the specified width and height","title":"resize_method"},{"location":"configuration/features/image_features/#infer_image_num_channels","text":"If true, then the number of channels in the dataset is inferred from a sample of the first image in the dataset. Default: true","title":"infer_image_num_channels"},{"location":"configuration/features/image_features/#infer_image_dimensions","text":"If true, then the height and width of images in the dataset will be inferred from a sample of the first image in the dataset. Each image that doesn't conform to these dimensions will be resized according to resize_method . If set to false , then the height and width of images in the dataset will be specified by the user. This parameter will have no effect if width and height are specified. Default: true","title":"infer_image_dimensions"},{"location":"configuration/features/image_features/#infer_image_max_height","text":"If infer_image_dimensions is set, this is used as the maximum height of the images in the dataset. Default: 256","title":"infer_image_max_height"},{"location":"configuration/features/image_features/#infer_image_max_width","text":"If infer_image_dimensions is set, this is used as the maximum width of the images in the dataset. Default: 256","title":"infer_image_max_width"},{"location":"configuration/features/image_features/#infer_image_sample_size","text":"The sample size used for inferring dimensions of images in infer_image_dimensions . Default: 100","title":"infer_image_sample_size"},{"location":"configuration/features/image_features/#scaling","text":"The scaling strategy for pixel values in the image. Default: pixel_normalization Options: pixel_normalization : Normalizes pixel values to be between 0 and 1 by dividing each pixel value by 255. pixel_standardization : Normalizes pixel values based on the mean and standard deviation of images in ImageNet.","title":"scaling"},{"location":"configuration/features/image_features/#in_memory","text":"Defines whether image dataset will reside in memory during the training process or will be dynamically fetched from disk (useful for large datasets). In the latter case a training batch of input images will be fetched from disk each training iteration. Default: true","title":"in_memory"},{"location":"configuration/features/image_features/#num_processes","text":"Specifies the number of processes to run for preprocessing images. Default: 1 Note Depending on the application, it is preferable not to exceed a size of 256 x 256 as bigger sizes will seldom provide a significant performance advantage. Larger images will considerably slow down training and inference and consume more memory, leading to memory overflows on machines with limited amounts of RAM or OOM (out-of-memory) on GPUs. Example of a preprocessing specification: name : image_feature_name type : image preprocessing : missing_value_strategy : fill_with_const fill_value : 0.5 height : 128 width : 128 num_channels : 3 resize_method : interpolate scaling : pixel_normalization in_memory : true num_processes : 4","title":"num_processes"},{"location":"configuration/features/image_features/#image-input-features-and-encoders","text":"The default encoder is stacked_cnn .","title":"Image Input Features and Encoders"},{"location":"configuration/features/image_features/#convolutional-stack-encoder-stacked_cnn","text":"Stack of 2D convolutional layers with optional normalization, dropout, and downsampling pooling layers, followed by an optional stack of fully connected layers. Convolutional Stack Encoder takes the following optional parameters:","title":"Convolutional Stack Encoder (stacked_cnn)"},{"location":"configuration/features/image_features/#conv_layers","text":"A list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. If a parameter for a layer is not specified in the dictionary, then the default value for the stacked CNN encoder is used. Default: null Parameters for each layer: out_channels : The number of output channels. kernel_size : The size of the convolutional kernel. stride : The stride of the convolutional kernel. padding : The padding of the convolutional kernel. dilation : The dilation of the convolutional kernel. groups : The number of groups for grouped convolution. bias : Whether to add a bias term to the convolution. padding_mode : The padding mode to use for the convolution. norm : The type of normalization to use for the convolution. norm_params : Optional parameters for the normalization. activation : The type of activation to use for the convolution. dropout : The dropout probability to use for the convolution. pool_function : The type of pooling function to use for the convolution. pool_kernel_size : The size of the pooling kernel. pool_stride : The stride of the pooling kernel. pool_padding : The padding of the pooling kernel. pool_dilation : The dilation of the pooling kernel.","title":"conv_layers"},{"location":"configuration/features/image_features/#num_conv_layers","text":"If conv_layers is null , this is the number of stacked convolutional layers. Each layer will use default parameters for the convolutional layer. Default: null Note If both conv_layers and num_conv_layers are null , conv_layers is set to the following default value: conv_layers = [ { kernel_size : 3 , out_channels : 32 , pool_kernel_size : 2 , }, { kernel_size : 3 , out_channels : 64 , pool_kernel_size : 2 , }, ]","title":"num_conv_layers"},{"location":"configuration/features/image_features/#out_channels","text":"Indicates the number of filters, and by consequence the output channels of the 2d convolution. If out_channels is not already specified in conv_layers this is the default out_channels that will be used for each layer. Default: 32","title":"out_channels"},{"location":"configuration/features/image_features/#kernel_size","text":"An integer or pair of integers specifying the kernel size. A single integer specifies a square kernel, while a pair of integers specifies the height and width of the kernel in that order ( [h, w] ). If a kernel_size is not specified in conv_layers this kernel_size that will be used for each layer. Default: 3","title":"kernel_size"},{"location":"configuration/features/image_features/#stride","text":"An integer or pair of integers specifying the stride of the convolution along the height and width. If a stride is not already specified in conv_layers , specifies the default stride of the 2D convolutional kernel that will be used for each layer. Default: 1","title":"stride"},{"location":"configuration/features/image_features/#padding","text":"An int, pair of ints [h, w] , or one of valid , same specifying the padding used for convolution kernels. Default: valid","title":"padding"},{"location":"configuration/features/image_features/#dilation","text":"An int or pair of ints specifying the dilation rate to use for dilated convolution. If dilation is not already specified in conv_layers , specifies the default dilation of the 2D convolutional kernel that will be used for each layer. Default: 1","title":"dilation"},{"location":"configuration/features/image_features/#groups","text":"Groups controls the connectivity between convolution inputs and outputs. When groups = 1 , each output channel depends on every input channel. When groups > 1 , input and output channels are divided into groups separate groups, where each output channel depends only on the inputs in its respective input channel group. in_channels and out_channels must both be divisible by groups . Default: 1","title":"groups"},{"location":"configuration/features/image_features/#conv_bias","text":"If bias not already specified in conv_layers , specifies if the 2D convolutional kernel should have a bias term. Default: true","title":"conv_bias"},{"location":"configuration/features/image_features/#padding_mode","text":"If padding_mode is not already specified in conv_layers , specifies the default padding_mode of the 2D convolutional kernel that will be used for each layer. Default: zeros Choices: zeros , reflect , replicate , circular","title":"padding_mode"},{"location":"configuration/features/image_features/#conv_norm","text":"(default null ): if a norm is not already specified in conv_layers this is the default norm that will be used for each layer. It indicates the normalization applied to the activations and can be null , batch or layer .","title":"conv_norm"},{"location":"configuration/features/image_features/#conv_norm_params","text":"(default null ): parameters used if conv_norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization .","title":"conv_norm_params"},{"location":"configuration/features/image_features/#conv_activation","text":"(default relu ): if an activation is not already specified in conv_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output.","title":"conv_activation"},{"location":"configuration/features/image_features/#conv_dropout","text":"(default 0 ): dropout rate","title":"conv_dropout"},{"location":"configuration/features/image_features/#pool_function","text":"(default max ): max will use max pooling. Any of average , avg or mean will use average pooling.","title":"pool_function"},{"location":"configuration/features/image_features/#pool_kernel_size","text":"(default 2 ): An integer or pair of integers specifying the pooling size. If pool_kernel_size is not specified in conv_layers this is the default value that will be used for each layer.","title":"pool_kernel_size"},{"location":"configuration/features/image_features/#pool_stride","text":"(default null ): An integer or pair of integers specifying the pooling stride, which is the factor by which the pooling layer downsamples the feature map. Defaults to pool_kernel_size .","title":"pool_stride"},{"location":"configuration/features/image_features/#pool_padding","text":"(default 0 ): An integer or pair of ints specifying pooling padding (h, w) .","title":"pool_padding"},{"location":"configuration/features/image_features/#pool_dilation","text":"(default 1 ): An integer or pair of ints specifying pooling dilation rate (h, w) .","title":"pool_dilation"},{"location":"configuration/features/image_features/#fc_layers","text":"(default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead.","title":"fc_layers"},{"location":"configuration/features/image_features/#num_fc_layers","text":"(default 1 ): The number of stacked fully connected layers.","title":"num_fc_layers"},{"location":"configuration/features/image_features/#output_size","text":"(default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer.","title":"output_size"},{"location":"configuration/features/image_features/#fc_use_bias","text":"(default true ): boolean, whether the layer uses a bias vector.","title":"fc_use_bias"},{"location":"configuration/features/image_features/#fc_weights_initializer","text":"(default xavier_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init .","title":"fc_weights_initializer"},{"location":"configuration/features/image_features/#fc_bias_initializer","text":"(default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init .","title":"fc_bias_initializer"},{"location":"configuration/features/image_features/#fc_norm","text":"(default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and can be null , batch or layer .","title":"fc_norm"},{"location":"configuration/features/image_features/#fc_norm_params","text":"(default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization .","title":"fc_norm_params"},{"location":"configuration/features/image_features/#fc_activation","text":"(default relu ): : if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output.","title":"fc_activation"},{"location":"configuration/features/image_features/#fc_dropout","text":"(default 0 ): dropout rate Example image feature config using a convolutional stack encoder: name : image_column_name type : image encoder : stacked_cnn conv_layers : null num_conv_layers : null kernel_size : 3 out_channels : 256 padding : valid conv_use_bias : true conv_norm : batch conv_activation : relu conv_dropout : 0 pool_function : max num_fc_layers : 1 output_size : 256 fc_use_bias : true fc_weights_initializer : xavier_uniform fc_bias_initializer : zeros fc_norm : batch fc_activation : relu fc_dropout : 0 preprocessing : # example pre-processing height : 32 width : 32 num_channels : 1","title":"fc_dropout"},{"location":"configuration/features/image_features/#resnet-encoder","text":"Implements ResNet V2 as described in Identity Mappings in Deep Residual Networks . The ResNet encoder takes the following optional parameters: resnet_size (default 50 ): The ResNet size, one of: 8 , 14 , 18 , 34 , 50 , 101 , 152 , 200 . num_filters (default 16 ): The number of filters, and by consequence the output channels of the 2d convolution. kernel_size (default 3 ): An integer or pair of integers specifying the convolution kernel size. A single integer specifies a square kernel, a pair of integers specifies the height and width of the kernel in that order ( [h, w] ). conv_stride (default 1 ): An integer or pair of integers specifying the stride of the initial convolutional layer. first_pool_kernel_size (default null ): Pool size to be used for the first pooling layer. If none, the first pooling layer is skipped. first_pool_stride (default null ): Stride for first pooling layer. If null , defaults to first_pool_kernel_size . batch_norm_momentum (default 0.9 ): Momentum of the batch norm running statistics. batch_norm_epsilon (default 0.001 ): Epsilon of the batch norm. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 1 ): The number of stacked fully connected layers. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. weights_initializer (default xavier_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Example image input feature config using a ResNet encoder: name : image_column_name type : image encoder : resnet resnet_size : 50 num_filters : 16 kernel_size : 3 conv_stride : 1 batch_norm_momentum : 0.9 batch_norm_epsilon : 0.001 num_fc_layers : 1 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 preprocessing : height : 224 width : 224 num_channels : 3","title":"ResNet Encoder"},{"location":"configuration/features/image_features/#mlp-mixer-encoder","text":"Encodes images using MLP-Mixer, as described in MLP-Mixer: An all-MLP Architecture for Vision . MLP-Mixer divides the image into equal-sized patches, applying fully connected layers to each patch to compute per-patch representations (tokens) and combining the representations with fully-connected mixer layers. The MLP-Mixer Encoder takes the following optional parameters: patch_size (default 16 ): The image patch size. Each patch is patch_size \u00b2 pixels. Must evenly divide the image width and height. embed_size (default 512 ): The patch embedding size, the output size of the mixer if avg_pool is true. token_size (default 2048 ): The per-patch embedding size. channel_dim (default 256 ): Number of channels in hidden layer. num_layers (default 8 ): The depth of the network (the number of Mixer blocks). dropout (default 0 ): Dropout rate. avg_pool (default true ): If true, pools output over patch dimension, outputs a vector of shape (embed_size) . If false, the output tensor is of shape (n_patches, embed_size) , where n_patches is img_height x img_width / patch_size \u00b2. Example image feature config using an MLP-Mixer encoder: name : image_column_name type : image encoder : mlp_mixer patch_size : 16 embed_size : 512 token_size : 2048 channel_dim : 256 num_layers : 8 dropout : 0.0 avg_pool : True preprocessing : height : 64 width : 64 num_channels : 3","title":"MLP-Mixer Encoder"},{"location":"configuration/features/image_features/#vision-transformer-encoder","text":"Encodes images using a Vision Transformer as described in An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale . Vision Transformer divides the image into equal-sized patches, uses a linear transformation to encode each flattened patch, then applies a deep transformer architecture to the sequence of encoded patches. The Vision Transformer Encoder takes the following optional parameters: use_pretrained (default true ): Use pre-trained model weights from Hugging Face. pretrained_model (default google/vit-base-patch16-224 ): The pre-trained model to use. See the model hub for other pretrained vision transformer models. hidden_size (default 768 ): Dimensionality of the encoder layers and the pooling layer. num_hidden_layers (default 12 ): Number of hidden layers in the Transformer encoder. num_attention_heads (default 12 ): Number of attention heads in each attention layer. intermediate_size (default 3072 ): Dimensionality of the intermediate (i.e., feed-forward) layer in the Transformer encoder. hidden_act (default gelu ): Hidden layer activation, one of gelu , relu , selu or gelu_new . hidden_dropout_prob (default 0.1 ): The dropout rate for all fully connected layers in the embeddings, encoder, and pooling. attention_probs_dropout_prob (default 0.1 ): The dropout rate for the attention probabilities. initializer_range (default 768 ): The standard deviation of the truncated_normal_initializer for initializing all weight matrices. layer_norm_eps (default 1e-12 ): The epsilon used by the layer normalization layers. gradient_checkpointing (default false ): patch_size (default 16 ): The image patch size. Each patch is patch_size \u00b2 pixels. Must evenly divide the image width and height. trainable (default true ): Is the encoder trainable. Example image feature config using an MLP-Mixer encoder: name : image_column_name type : image encoder : vit use_pretrained : true preprocessing : height : 128 width : 128 num_channels : 3","title":"Vision Transformer Encoder"},{"location":"configuration/features/image_features/#image-output-features-and-decoders","text":"There are no image decoders at the moment (WIP), so image cannot be used as output features.","title":"Image Output Features and Decoders"},{"location":"configuration/features/image_features/#image-features-measures","text":"As no image decoders are available at the moment, there are also no image measures.","title":"Image Features Measures"},{"location":"configuration/features/input_features/","text":"The input_features section is list of feature definitions. Each feature definition contains two required fields: name and type . YAML Python Dict input_features : - name : Pclass type : category { \"input_features\" : [{ \"name\" : \"Pclass\" , \"type\" : \"category\" }] } name is the name of the feature in the dataset. type is one of the supported data types . Preprocessing \u00b6 Recall Ludwig's butterfly framework. Each input feature can specify its own preprocessing via the preprocessing sub-section. YAML Python Dict input_features : - name : Fare type : number preprocessing : missing_value_strategy : fill_with_mean { \"input_features\" : [ { \"name\" : \"Fare\" , \"type\" : \"number\" , \"preprocessing\" : { \"missing_value_strategy\" : \"fill_with_mean\" } } ] } It's also possible to specify preprocessing rules for all features of a certain type. See type-global preprocessing . Encoders \u00b6 Each input feature can configure a specific encoder to map input feature values into tensors. For instance, a user might want to encode a sequence feature using a transformer or an image feature using a stacked_cnn . Different data types support different encoders. Check the documentation for specific feature types to see what encoders are supported for that type. All the other parameters besides name , type , and preprocessing , will be passed as parameters to the function that build the input feature's encoder, and each encoder can have different parameters. Extensive documentation for all of the encoders that can be used for a certain data type can also be found in each data type's documentation. YAML Python Dict input_features : - name : text type : text encoder : bert preprocessing : tokenizer : space reduce_output : null trainable : true { \"input_features\" : [ { \"name\" : \"text\" , \"type\" : \"text\" , \"encoder\" : \"bert\" , \"level\" : \"word\" , \"preprocessing\" : { \"word_tokenizer\" : \"space\" }, \"reduce_output\" : None , \"trainable\" : True } ] } Encoders map raw feature values into tensors. These are usually vectors in the case of data types without a temporal / sequential aspect, matrices for when there is a temporal / sequential aspect, or higher rank tensors for when there is a spatial or a spatiotemporal aspect to the input data. Different configurations of the same encoder may return a tensor with different rank, for instance a sequential encoder may return a vector of size h that is either the final vector of a sequence or the result of pooling over the sequence length, or it can return a matrix of size l x h where l is the length of the sequence and h is the hidden dimension if you specify the pooling reduce operation ( reduce_output ) to be None . For the sake of simplicity you can imagine the output to be a vector in most of the cases, but there is a reduce_output parameter one can specify to change the default behavior. For first-time users, we recommend starting with the defaults. Tying encoder weights \u00b6 An additional feature that Ludwig provides is the option to have tied weights between different encoders. For instance, if my model takes two sentences as input and return the probability of their entailment, I may want to encode both sentences with the same encoder. This is done by specifying the tied parameter of one feature to be the name of another output feature. For example: YAML Python Dict input_features : - name : sentence1 type : text - name : sentence2 type : text tied : sentence1 { \"input_features\" : [ { \"name\" : \"sentence1\" , \"type\" : \"text\" }, { \"name\" : \"sentence2\" , \"type\" : \"text\" , \"tied\" : \"sentence1\" } ] } Specifying a name of a non-existent input feature will result in an error. Also, in order to be able to have tied weights, all encoder parameters have to be identical between the two input features.","title":"Input Features (\u2191)"},{"location":"configuration/features/input_features/#preprocessing","text":"Recall Ludwig's butterfly framework. Each input feature can specify its own preprocessing via the preprocessing sub-section. YAML Python Dict input_features : - name : Fare type : number preprocessing : missing_value_strategy : fill_with_mean { \"input_features\" : [ { \"name\" : \"Fare\" , \"type\" : \"number\" , \"preprocessing\" : { \"missing_value_strategy\" : \"fill_with_mean\" } } ] } It's also possible to specify preprocessing rules for all features of a certain type. See type-global preprocessing .","title":"Preprocessing"},{"location":"configuration/features/input_features/#encoders","text":"Each input feature can configure a specific encoder to map input feature values into tensors. For instance, a user might want to encode a sequence feature using a transformer or an image feature using a stacked_cnn . Different data types support different encoders. Check the documentation for specific feature types to see what encoders are supported for that type. All the other parameters besides name , type , and preprocessing , will be passed as parameters to the function that build the input feature's encoder, and each encoder can have different parameters. Extensive documentation for all of the encoders that can be used for a certain data type can also be found in each data type's documentation. YAML Python Dict input_features : - name : text type : text encoder : bert preprocessing : tokenizer : space reduce_output : null trainable : true { \"input_features\" : [ { \"name\" : \"text\" , \"type\" : \"text\" , \"encoder\" : \"bert\" , \"level\" : \"word\" , \"preprocessing\" : { \"word_tokenizer\" : \"space\" }, \"reduce_output\" : None , \"trainable\" : True } ] } Encoders map raw feature values into tensors. These are usually vectors in the case of data types without a temporal / sequential aspect, matrices for when there is a temporal / sequential aspect, or higher rank tensors for when there is a spatial or a spatiotemporal aspect to the input data. Different configurations of the same encoder may return a tensor with different rank, for instance a sequential encoder may return a vector of size h that is either the final vector of a sequence or the result of pooling over the sequence length, or it can return a matrix of size l x h where l is the length of the sequence and h is the hidden dimension if you specify the pooling reduce operation ( reduce_output ) to be None . For the sake of simplicity you can imagine the output to be a vector in most of the cases, but there is a reduce_output parameter one can specify to change the default behavior. For first-time users, we recommend starting with the defaults.","title":"Encoders"},{"location":"configuration/features/input_features/#tying-encoder-weights","text":"An additional feature that Ludwig provides is the option to have tied weights between different encoders. For instance, if my model takes two sentences as input and return the probability of their entailment, I may want to encode both sentences with the same encoder. This is done by specifying the tied parameter of one feature to be the name of another output feature. For example: YAML Python Dict input_features : - name : sentence1 type : text - name : sentence2 type : text tied : sentence1 { \"input_features\" : [ { \"name\" : \"sentence1\" , \"type\" : \"text\" }, { \"name\" : \"sentence2\" , \"type\" : \"text\" , \"tied\" : \"sentence1\" } ] } Specifying a name of a non-existent input feature will result in an error. Also, in order to be able to have tied weights, all encoder parameters have to be identical between the two input features.","title":"Tying encoder weights"},{"location":"configuration/features/number_features/","text":"Number Features Preprocessing \u00b6 Number features are directly transformed into a float valued vector of length n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. No additional information about them is available in the JSON metadata file. Parameters available for preprocessing are missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in a number column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default 0 ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . normalization (default null ): technique to be used when normalizing the number feature types. The available options are null , zscore , minmax and log1p . If the value is null no normalization is performed. If the value is zscore , the mean and standard deviation are computed so that values are shifted to have zero mean and 1 standard deviation. If the value is minmax , the minimum is subtracted from values and the result is divided by difference between maximum and minimum. If normalization is log1p the value returned is the natural log of 1 plus the original value. Note: log1p is defined only for positive values. Number Input Features and Encoders \u00b6 Number features have two encoders. One encoder ( passthrough ) simply returns the raw numerical values coming from the input placeholders as outputs. Inputs are of size b while outputs are of size b x 1 where b is the batch size. The other encoder ( dense ) passes the raw numerical values through fully connected layers. In this case the inputs of size b are transformed to size b x h . The available encoder parameters are: norm (default null ): norm to apply after the single neuron. It can be null , batch or layer . tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters. Passthrough Encoder \u00b6 There are no additional parameters for the passthrough encoder. Dense Encoder \u00b6 For the dense encoder these are the available parameters. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_layers (default 1 ): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Example number feature entry in the input features list: name : number_column_name type : number norm : null tied : null encoder : dense num_layers : 1 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 Number Output Features and Decoders \u00b6 Number features can be used when a regression needs to be performed. There is only one decoder available for number features: a (potentially empty) stack of fully connected layers, followed by a projection to a single number. These are the available parameters of a number output feature reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). loss (default {type: mean_squared_error} ): is a dictionary containing a loss type . The available loss types are mean_squared_error and mean_absolute_error . These are the available parameters of a number output feature decoder fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . dropout (default 0 ): dropout rate use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . clip (default null ): If not null it specifies a minimum and maximum value the predictions will be clipped to. The value can be either a list or a tuple of length 2, with the first value representing the minimum and the second the maximum. For instance (-5,5) will make it so that all predictions will be clipped to the [-5,5] interval. Example number feature entry (with default parameters) in the output features list: name : number_column_name type : number reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : mean_squared_error fc_layers : null num_fc_layers : 0 output_size : 256 activation : relu norm : null norm_params : null dropout : 0 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros clip : null Number Features Metrics \u00b6 The metrics that are calculated every epoch and are available for number features are mean_squared_error , mean_absolute_error , root_mean_squared_error , root_mean_squared_percentage_error and the loss itself. You can set either of them as validation_metric in the training section of the configuration if you set the validation_field to be the name of a number feature.","title":"\u21c5 Number Features"},{"location":"configuration/features/number_features/#number-features-preprocessing","text":"Number features are directly transformed into a float valued vector of length n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. No additional information about them is available in the JSON metadata file. Parameters available for preprocessing are missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in a number column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default 0 ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . normalization (default null ): technique to be used when normalizing the number feature types. The available options are null , zscore , minmax and log1p . If the value is null no normalization is performed. If the value is zscore , the mean and standard deviation are computed so that values are shifted to have zero mean and 1 standard deviation. If the value is minmax , the minimum is subtracted from values and the result is divided by difference between maximum and minimum. If normalization is log1p the value returned is the natural log of 1 plus the original value. Note: log1p is defined only for positive values.","title":"Number Features Preprocessing"},{"location":"configuration/features/number_features/#number-input-features-and-encoders","text":"Number features have two encoders. One encoder ( passthrough ) simply returns the raw numerical values coming from the input placeholders as outputs. Inputs are of size b while outputs are of size b x 1 where b is the batch size. The other encoder ( dense ) passes the raw numerical values through fully connected layers. In this case the inputs of size b are transformed to size b x h . The available encoder parameters are: norm (default null ): norm to apply after the single neuron. It can be null , batch or layer . tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.","title":"Number Input Features and Encoders"},{"location":"configuration/features/number_features/#passthrough-encoder","text":"There are no additional parameters for the passthrough encoder.","title":"Passthrough Encoder"},{"location":"configuration/features/number_features/#dense-encoder","text":"For the dense encoder these are the available parameters. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_layers (default 1 ): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Example number feature entry in the input features list: name : number_column_name type : number norm : null tied : null encoder : dense num_layers : 1 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0","title":"Dense Encoder"},{"location":"configuration/features/number_features/#number-output-features-and-decoders","text":"Number features can be used when a regression needs to be performed. There is only one decoder available for number features: a (potentially empty) stack of fully connected layers, followed by a projection to a single number. These are the available parameters of a number output feature reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). loss (default {type: mean_squared_error} ): is a dictionary containing a loss type . The available loss types are mean_squared_error and mean_absolute_error . These are the available parameters of a number output feature decoder fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . dropout (default 0 ): dropout rate use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . clip (default null ): If not null it specifies a minimum and maximum value the predictions will be clipped to. The value can be either a list or a tuple of length 2, with the first value representing the minimum and the second the maximum. For instance (-5,5) will make it so that all predictions will be clipped to the [-5,5] interval. Example number feature entry (with default parameters) in the output features list: name : number_column_name type : number reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : mean_squared_error fc_layers : null num_fc_layers : 0 output_size : 256 activation : relu norm : null norm_params : null dropout : 0 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros clip : null","title":"Number Output Features and Decoders"},{"location":"configuration/features/number_features/#number-features-metrics","text":"The metrics that are calculated every epoch and are available for number features are mean_squared_error , mean_absolute_error , root_mean_squared_error , root_mean_squared_percentage_error and the loss itself. You can set either of them as validation_metric in the training section of the configuration if you set the validation_field to be the name of a number feature.","title":"Number Features Metrics"},{"location":"configuration/features/output_features/","text":"The Ludwig configuration's output_features section has the same structure as input_features , which is a list of feature definitions, each of which contains a name and a type , with optional preprocessing , that users want their model to predict. YAML Python Dict output_features : - name : french type : text { \"output_features\" : [ { \"name\" : \"french\" , \"type\" : \"text\" , } ] } Decoders \u00b6 Recall Ludwig's butterfly framework: Instead of having encoders , output features have decoders . All the other parameters besides name and type will be passed as parameters to the function that builds the output feature's decoder, and each decoder can have different parameters. Extensive documentation for all of the decoders that can be used for a certain data type can be found in each data type's documentation . YAML Python Dict output_features : - name : french type : text decoder : generator cell_type : lstm num_layers : 2 max_sequence_length : 256 { \"output_features\" : [ { \"name\" : \"french\" , \"type\" : \"text\" , \"decoder\" : \"generator\" , \"cell_type\" : \"lstm\" , \"num_layers\" : 2 , \"max_sequence_length\" : 256 } ] } Decoders take the output of the combiner as input, process it further, for instance passing it through fully connected layers, and predict values, which are subsequently used to compute loss and evaluation metrics. Decoders have additional parameters, in particular loss that allows you to specify a different loss to optimize for this specific decoder. For instance, number features support both mean_squared_error and mean_absolute_error as losses. Details about the available decoders and losses alongside with the description of all parameters is provided in datatype-specific documentation. Multi-task Learning \u00b6 In most machine learning tasks you want to predict only one target variable, but in Ludwig users are empowered to specify multiple output features. During training, output features are optimized in a multi-task fashion, using a weighted sum of their losses as a combined loss. Ludwig natively supports multi-task learning. When multiple output features are specified, the loss that is optimized is a weighted sum of the losses of each individual output feature. By default each loss weight is 1 , but this can be changed by specifying a value for the weight parameter in the loss section of each output feature definition. For example, given a category feature A and number feature B , in order to optimize the loss loss_total = 1.5 * loss_A + 0.8 + loss_B the output_feature section of the configuration should look like: YAML Python Dict output_features : - name : A type : category loss : weight : 1.5 - name : A type : number loss : weight : 0.8 { \"output_features\" : [ { \"name\" : \"A\" , \"type\" : \"category\" , \"loss\" : { \"weight\" : 1.5 } }, { \"name\" : \"A\" , \"type\" : \"number\" , \"loss\" : { \"weight\" : 0.8 } } ] } Output Feature Dependencies \u00b6 An additional feature that Ludwig provides is the concept of dependencies between output_features . Sometimes output features have strong causal relationships, and knowing which prediction has been made for one can improve the prediction for the other. For example, if there are two output features: 1) coarse grained category and 2) fine-grained category, knowing the prediction made for coarse grained can productively clarify the possible choices for the fine-grained category. Output feature dependencies are declared in the feature definition. For example: YAML Python Dict output_features : - name : coarse_class type : category num_fc_layers : 2 output_size : 64 - name : fine_class type : category dependencies : - coarse_class num_fc_layers : 1 output_size : 64 { \"output_features\": [ { \"name\": \"coarse_class\", \"type\": \"category\", \"num_fc_layers\": 2, \"output_size\": 64 }, { \"name\": \"fine_class\", \"type\": \"category\", \"dependencies\": [ \"coarse_class\" ], \"num_fc_layers\": 1, \"output_size\": 64 } ] } At model building time Ludwig checks that no cyclic dependency exists. For the downstream feature, Ludwig will concatenate all the final representations before the prediction of any dependent output features to feed as input to the downstream feature's decoder 1 Assuming the input coming from the combiner has hidden dimension h 128, there are two fully connected layers that return a vector with hidden size 64 at the end of the coarse_class decoder (that vector will be used for the final layer before projecting in the output coarse_class space). In the decoder of fine_class , the 64 dimensional vector of coarse_class will be concatenated with the combiner output vector, making a vector of hidden size 192 that will be passed through a fully connected layer and the 64 dimensional output will be used for the final layer before projecting in the output class space of the fine_class . \u21a9","title":"Output Features (\u2193)"},{"location":"configuration/features/output_features/#decoders","text":"Recall Ludwig's butterfly framework: Instead of having encoders , output features have decoders . All the other parameters besides name and type will be passed as parameters to the function that builds the output feature's decoder, and each decoder can have different parameters. Extensive documentation for all of the decoders that can be used for a certain data type can be found in each data type's documentation . YAML Python Dict output_features : - name : french type : text decoder : generator cell_type : lstm num_layers : 2 max_sequence_length : 256 { \"output_features\" : [ { \"name\" : \"french\" , \"type\" : \"text\" , \"decoder\" : \"generator\" , \"cell_type\" : \"lstm\" , \"num_layers\" : 2 , \"max_sequence_length\" : 256 } ] } Decoders take the output of the combiner as input, process it further, for instance passing it through fully connected layers, and predict values, which are subsequently used to compute loss and evaluation metrics. Decoders have additional parameters, in particular loss that allows you to specify a different loss to optimize for this specific decoder. For instance, number features support both mean_squared_error and mean_absolute_error as losses. Details about the available decoders and losses alongside with the description of all parameters is provided in datatype-specific documentation.","title":"Decoders"},{"location":"configuration/features/output_features/#multi-task-learning","text":"In most machine learning tasks you want to predict only one target variable, but in Ludwig users are empowered to specify multiple output features. During training, output features are optimized in a multi-task fashion, using a weighted sum of their losses as a combined loss. Ludwig natively supports multi-task learning. When multiple output features are specified, the loss that is optimized is a weighted sum of the losses of each individual output feature. By default each loss weight is 1 , but this can be changed by specifying a value for the weight parameter in the loss section of each output feature definition. For example, given a category feature A and number feature B , in order to optimize the loss loss_total = 1.5 * loss_A + 0.8 + loss_B the output_feature section of the configuration should look like: YAML Python Dict output_features : - name : A type : category loss : weight : 1.5 - name : A type : number loss : weight : 0.8 { \"output_features\" : [ { \"name\" : \"A\" , \"type\" : \"category\" , \"loss\" : { \"weight\" : 1.5 } }, { \"name\" : \"A\" , \"type\" : \"number\" , \"loss\" : { \"weight\" : 0.8 } } ] }","title":"Multi-task Learning"},{"location":"configuration/features/output_features/#output-feature-dependencies","text":"An additional feature that Ludwig provides is the concept of dependencies between output_features . Sometimes output features have strong causal relationships, and knowing which prediction has been made for one can improve the prediction for the other. For example, if there are two output features: 1) coarse grained category and 2) fine-grained category, knowing the prediction made for coarse grained can productively clarify the possible choices for the fine-grained category. Output feature dependencies are declared in the feature definition. For example: YAML Python Dict output_features : - name : coarse_class type : category num_fc_layers : 2 output_size : 64 - name : fine_class type : category dependencies : - coarse_class num_fc_layers : 1 output_size : 64 { \"output_features\": [ { \"name\": \"coarse_class\", \"type\": \"category\", \"num_fc_layers\": 2, \"output_size\": 64 }, { \"name\": \"fine_class\", \"type\": \"category\", \"dependencies\": [ \"coarse_class\" ], \"num_fc_layers\": 1, \"output_size\": 64 } ] } At model building time Ludwig checks that no cyclic dependency exists. For the downstream feature, Ludwig will concatenate all the final representations before the prediction of any dependent output features to feed as input to the downstream feature's decoder 1 Assuming the input coming from the combiner has hidden dimension h 128, there are two fully connected layers that return a vector with hidden size 64 at the end of the coarse_class decoder (that vector will be used for the final layer before projecting in the output coarse_class space). In the decoder of fine_class , the 64 dimensional vector of coarse_class will be concatenated with the combiner output vector, making a vector of hidden size 192 that will be passed through a fully connected layer and the 64 dimensional output will be used for the final layer before projecting in the output class space of the fine_class . \u21a9","title":"Output Feature Dependencies"},{"location":"configuration/features/sequence_features/","text":"Sequence Features Preprocessing \u00b6 Sequence features are transformed into an integer valued matrix of size n x l (where n is the number of rows and l is the minimum of the length of the longest sequence and a max_sequence_length parameter) and added to HDF5 with a key that reflects the name of column in the dataset. Each sequence in mapped to a list of integers internally. First, a tokenizer converts each sequence to a list of tokens (default tokenization is done by splitting on spaces). Next, a dictionary is constructed which maps each unique token to its frequency in the dataset column. Tokens are ranked by frequency and a sequential integer ID is assigned from the most frequent to the most rare. Ludwig uses <PAD> , <UNK> , <SOS> , and <EOS> special symbols for padding, unknown, start, and end, consistent with common NLP deep learning practices. Special symbols can also be set manually in the preprocessing config. The column name is added to the JSON file, with an associated dictionary containing the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the maximum length of all sequences ( max_sequence_length ) additional preprocessing information (how to fill missing values and what token to use to fill missing values) The parameters available for preprocessing are tokenizer (default space ): defines how to map from the raw string content of the dataset column to a sequence of elements. For the available options refer to the Tokenizers section. vocab_file (default null ) filepath string to a UTF-8 encoded file containing the sequence's vocabulary. On each line the first string until \\t or \\n is considered a word. max_sequence_length (default 256 ): the maximum length of the sequence. Sequences that are longer than this value will be truncated, while sequences that are shorter will be padded. most_common (default 20000 ): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown. padding_symbol (default <PAD> ): the string used as a padding symbol, mapped to the integer ID 0 in the vocabulary. unknown_symbol (default <UNK> ): the string used as the unknown placeholder, mapped to the integer ID 1 in the vocabulary. padding (default right ): the direction of the padding. right and left are available options. lowercase (default false ): If true, converts the string to lowercase before tokenizing. missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in the column. The value should be one of fill_with_const (replaces the missing value with the value specified by the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default <UNK> ): the value to replace the missing values with in case the missing_value_strategy is fill_value . Sequence Input Features and Encoders \u00b6 Sequence features have several encoders and each of them has its own parameters. Inputs are of size b while outputs are of size b x h where b is the batch size and h is the dimensionality of the output of the encoder. In case a representation for each element of the sequence is needed (for example for tagging them, or for using an attention mechanism), one can specify the parameter reduce_output to be null and the output will be a b x s x h tensor where s is the length of the sequence. Some encoders, because of their inner workings, may require additional parameters to be specified in order to obtain one representation for each element of the sequence. For instance the parallel_cnn encoder by default pools and flattens the sequence dimension and then passes the flattened vector through fully connected layers, so in order to obtain the full sequence tensor one has to specify reduce_output: null . Sequence input feature parameters are encoder (default parallel_cnn ): the name of the encoder to use to encode the sequence, one of embed , parallel_cnn , stacked_cnn , stacked_parallel_cnn , rnn , cnnrnn , transformer and passthrough (equivalent to null or None ). tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters. Embed Encoder \u00b6 The embed encoder simply maps each integer in the sequence to an embedding, creating a b x s x h tensor where b is the batch size, s is the length of the sequence and h is the embedding size. The tensor is reduced along the s dimension to obtain a single vector of size h for each element of the batch. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +-----------+ |43| +------+ |Aggregation| |65+--->Emb 65+--->Reduce +--> |23| +------+ |Operation | |4 | |Emb 23| +-----------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the parameters available for the embed encoder representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense , sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. dropout (default 0 ): dropout rate. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (selects the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using an embed encoder: name : sequence_column_name type : sequence encoder : embed representation : dense embedding_size : 256 embeddings_trainable : true embeddings_on_cpu : false dropout : 0 reduce_output : sum Parallel CNN Encoder \u00b6 The parallel cnn encoder is inspired by Yoon Kim's Convolutional Neural Network for Sentence Classification . It works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a number of parallel 1d convolutional layers with different filter size (by default 4 layers with filter size 2, 3, 4 and 5), followed by max pooling and concatenation. This single vector concatenating the outputs of the parallel convolutional layers is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +-------+ +----+ +-->1D Conv+--->Pool+--+ +------+ | |Width 2| +----+ | |Emb 12| | +-------+ | +------+ | | +--+ |Emb 7 | | +-------+ +----+ | |12| +------+ +-->1D Conv+--->Pool+--+ |7 | |Emb 43| | |Width 3| +----+ | +---------+ |43| +------+ | +-------+ | +------+ |Fully | |65+-->Emb 65 +--+ +-->Concat+-->Connected+--> |23| +------+ | +-------+ +----+ | +------+ |Layers | |4 | |Emb 23| +-->1D Conv+--->Pool+--+ +---------+ |1 | +------+ | |Width 4| +----+ | +--+ |Emb 4 | | +-------+ | +------+ | | |Emb 1 | | +-------+ +----+ | +------+ +-->1D Conv+--->Pool+--+ |Width 5| +----+ +-------+ These are the available parameters for a parallel cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of parallel convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}] . num_conv_layers (default null ): if conv_layers is null , this is the number of parallel convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (selects the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a parallel cnn encoder: name : sequence_column_name type : sequence encoder : parallel_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 pool_function : max output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0.0 reduce_output : sum Stacked CNN Encoder \u00b6 The stacked cnn encoder is inspired by Xiang Zhang at all's Character-level Convolutional Networks for Text Classification . It works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of 1d convolutional layers with different filter size (by default 6 layers with filter size 7, 7, 3, 3, 3 and 3), followed by an optional final pool and by a flatten operation. This single flatten vector is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify the pool_size of all your conv_layers to be null and reduce_output: null , while if pool_size has a value different from null and reduce_output: null the returned tensor will be of shape b x s' x h , where s' is width of the output of the last convolutional layer. +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +----------------+ +---------+ |43| +------+ |1D Conv | |Fully | |65+--->Emb 65+--->Layers +--->Connected+--> |23| +------+ |Different Widths| |Layers | |4 | |Emb 23| +----------------+ +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the parameters available for the stack cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}] . num_conv_layers (default null ): if conv_layers is null , this is the number of stacked convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. strides (default 1 ): stride length of the convolution padding (default same ): one of valid or same . dilation_rate (default 1 ): dilation rate to use for dilated convolution pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. pool_strides (default null ): factor to scale down pool_padding (default same ): one of valid or same fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default max ): defines how to reduce the output tensor of the convolutional layers along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a parallel cnn encoder: name : sequence_column_name type : sequence encoder : stacked_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 strides : 1 padding : same dilation_rate : 1 pool_function : max pool_padding : same output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 reduce_output : max Stacked Parallel CNN Encoder \u00b6 The stacked parallel cnn encoder is a combination of the Parallel CNN and the Stacked CNN encoders where each layer of the stack is composed of parallel convolutional layers. It works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of several parallel 1d convolutional layers with different filter size, followed by an optional final pool and by a flatten operation. This single flattened vector is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +-------+ +-------+ +->1D Conv+-+ +->1D Conv+-+ +------+ | |Width 2| | | |Width 2| | |Emb 12| | +-------+ | | +-------+ | +------+ | | | | +--+ |Emb 7 | | +-------+ | | +-------+ | |12| +------+ +->1D Conv+-+ +->1D Conv+-+ |7 | |Emb 43| | |Width 3| | | |Width 3| | +---------+ |43| +------+ | +-------+ | +------+ +---+ | +-------+ | +------+ +----+ |Fully | |65+->Emb 65 +--+ +->Concat+-->...+-+ +->Concat+->Pool+->Connected+--> |23| +------+ | +-------+ | +------+ +---+ | +-------+ | +------+ +----+ |Layers | |4 | |Emb 23| +->1D Conv+-+ +->1D Conv+-+ +---------+ |1 | +------+ | |Width 4| | | |Width 4| | +--+ |Emb 4 | | +-------+ | | +-------+ | +------+ | | | | |Emb 1 | | +-------+ | | +-------+ | +------+ +->1D Conv+-+ +->1D Conv+-+ |Width 5| |Width 5| +-------+ +-------+ These are the available parameters for the stack parallel cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. stacked_layers (default null ): a nested list of lists of dictionaries containing the parameters of the stack of parallel convolutional layers. The length of the list determines the number of stacked parallel convolutional layers, length of the sub-lists determines the number of parallel conv layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both stacked_layers and num_stacked_layers are null , a default list will be assigned to stacked_layers with the value [[{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}]] . num_stacked_layers (default null ): if stacked_layers is null , this is the number of elements in the stack of parallel convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in stacked_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in stacker_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in stacked_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a parallel cnn encoder: name : sequence_column_name type : sequence encoder : stacked_parallel_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 pool_function : max output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 reduce_output : max RNN Encoder \u00b6 The rnn encoder works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of recurrent layers (by default 1 layer), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions. If you want to output the full b x s x h where h is the size of the output of the last rnn layer, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +---------+ |43| +------+ +----------+ |Fully | |65+--->Emb 65+--->RNN Layers+-->Connected+--> |23| +------+ +----------+ |Layers | |4 | |Emb 23| +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the available parameters for the rnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): the number of stacked recurrent layers. state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use. recurrent_activation (default sigmoid ): activation function to use in the recurrent step unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization recurrent_initializer (default orthogonal ): initializer for recurrent matrix weights dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a parallel cnn encoder: name : sequence_column_name type : sequence encoder : rnn representation' : dense embedding_size : 256 embeddings_trainable : true num_layers : 1 state_size : 256 cell_type : rnn bidirectional : false activation : tanh recurrent_activation : sigmoid unit_forget_bias : true recurrent_initializer : orthogonal dropout : 0.0 recurrent_dropout : 0.0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last CNN RNN Encoder \u00b6 The cnnrnn encoder works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of convolutional layers (by default 2), that is followed by a stack of recurrent layers (by default 1), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions. If you want to output the full b x s x h where h is the size of the output of the last rnn layer, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +---------+ |43| +------+ +----------+ +----------+ |Fully | |65+--->Emb 65+-->CNN Layers+-->RNN Layers+-->Connected+--> |23| +------+ +----------+ +----------+ |Layers | |4 | |Emb 23| +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the available parameters of the cnn rnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}] . num_conv_layers (default 1 ): the number of stacked convolutional layers. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. filter_size (default 5 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. strides (default 1 ): stride length of the convolution padding (default same ): one of valid or same . dilation_rate (default 1 ): dilation rate to use for dilated convolution conv_activation (default relu ): activation for the convolution layer conv_dropout (default 0.0 ): dropout rate for the convolution layer pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default 2 ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. pool_strides (default null ): factor to scale down pool_padding (default same ): one of valid or same num_rec_layers (default 1 ): the number of recurrent layers state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use recurrent_activation (default sigmoid ): activation function to use in the recurrent step unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization recurrent_initializer (default orthogonal ): initializer for recurrent matrix weights dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the inputs features list using a cnn rnn encoder: name : sequence_column_name type : sequence encoder : cnnrnn representation : dense embedding_size : 256 embeddings_trainable : true num_conv_layers : 1 num_filters : 256 filter_size : 5 strides : 1 padding : same dilation_rate : 1 conv_activation : relu conv_dropout : 0.0 pool_function : max pool_size : 2 pool_padding : same num_rec_layers : 1 state_size : 256 cell_type : rnn bidirectional : false activation : tanh recurrent_activation : sigmoid unit_forget_bias : true recurrent_initializer : orthogonal dropout : 0.0 recurrent_dropout : 0.0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last Transformer Encoder \u00b6 The transformer encoder implements a stack of transformer blocks, replicating the architecture introduced in the Attention is all you need paper, and adds am optional stack of fully connected layers at the end. +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +-------------+ +---------+ |43| +------+ | | |Fully | |65+---+Emb 65+---> Transformer +--->Connected+--> |23| +------+ | Blocks | |Layers | |4 | |Emb 23| +-------------+ +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): number of transformer blocks. hidden_size (default 256 ): the size of the hidden representation within the transformer block. It is usually the same as the embedding_size , but if the two values are different, a projection layer will be added before the first transformer block. num_heads (default 8 ): number of attention heads in each transformer block. transformer_output_size (default 256 ): Size of the fully connected layer after self attention in the transformer block. This is usually the same as hidden_size and embedding_size . dropout (default 0.1 ): dropout rate for the transformer block fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default 0 ): This is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the inputs features list using a Transformer encoder: name : sequence_column_name type : sequence encoder : transformer representation : dense embedding_size : 256 embeddings_trainable : true num_layers : 1 hidden_size : 256 num_heads : 8 transformer_output_size : 256 dropout : 0.1 num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last Passthrough Encoder \u00b6 The passthrough decoder simply transforms each input value into a float value and adds a dimension to the input tensor, creating a b x s x 1 tensor where b is the batch size and s is the length of the sequence. The tensor is reduced along the s dimension to obtain a single vector of size h for each element of the batch. If you want to output the full b x s x h tensor, you can specify reduce_output: null . This encoder is not really useful for sequence or text features, but may be useful for timeseries features, as it allows for using them without any processing in later stages of the model, like in a sequence combiner for instance. +--+ |12| |7 | +-----------+ |43| +------------+ |Aggregation| |65+--->Cast float32+--->Reduce +--> |23| +------------+ |Operation | |4 | +-----------+ |1 | +--+ These are the parameters available for the passthrough encoder reduce_output (default null ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a passthrough encoder: name : sequence_column_name type : sequence encoder : passthrough reduce_output : null Sequence Output Features and Decoders \u00b6 Sequence output features can be used for either tagging (classifying each element of an input sequence) or generation (generating a sequence by sampling from the model). Ludwig provides two sequence decoders named tagger and generator respectively. The following are the available parameters of a sequence output feature: reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). loss (default {type: softmax_cross_entropy, class_similarities_temperature: 0, class_weights: 1, confidence_penalty: 0, robust_lambda: 0} ): is a dictionary containing a loss type . The only available loss type for sequences is softmax_cross_entropy . For more details on losses and their options, see also Category Output Features and Decoders . Tagger Decoder \u00b6 In the case of tagger the decoder is a (potentially empty) stack of fully connected layers, followed by a projection into a tensor of size b x s x c , where b is the batch size, s is the length of the sequence and c is the number of classes, followed by a softmax_cross_entropy. This decoder requires its input to be shaped as b x s x h , where h is a hidden dimension, which is the output of a sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner. If a b x h input is provided instead, an error will be raised during model building. Combiner Output +---+ +----------+ +-------+ |emb| +---------+ |Projection| |Softmax| +---+ |Fully | +----------+ +-------+ |...+--->Connected+--->... +--->... | +---+ |Layers | +----------+ +-------+ |emb| +---------+ |Projection| |Softmax| +---+ +----------+ +-------+ These are the available parameters of a tagger decoder: fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate attention (default false ): If true , applies a multi-head self attention layer before prediction. attention_embedding_size (default 256 ): the embedding size of the multi-head self attention layer. attention_num_heads (default 8 ): number of attention heads in the multi-head self attention layer. Example sequence feature entry using a tagger decoder (with default parameters) in the output features list: name : sequence_column_name type : sequence decoder : tagger reduce_input : null dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities_temperature : 0 num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 attention : false attention_embedding_size : 256 attention_num_heads : 8 Generator Decoder \u00b6 In the case of generator the decoder is a (potentially empty) stack of fully connected layers, followed by an rnn that generates outputs feeding on its own previous predictions and generates a tensor of size b x s' x c , where b is the batch size, s' is the length of the generated sequence and c is the number of classes, followed by a softmax_cross_entropy. During training teacher forcing is adopted, meaning the list of targets is provided as both inputs and outputs (shifted by 1), while at evaluation time greedy decoding (generating one token at a time and feeding it as input for the next step) is performed by beam search, using a beam of 1 by default. In general a generator expects a b x h shaped input tensor, where h is a hidden dimension. The h vectors are (after an optional stack of fully connected layers) fed into the rnn generator. One exception is when the generator uses attention, as in that case the expected size of the input tensor is b x s x h , which is the output of a sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner. If a b x h input is provided to a generator decoder using an rnn with attention instead, an error will be raised during model building. Output Output 1 +-+ ... +--+ END ^ | ^ | ^ +--------+ +---------+ | | | | | |Combiner| |Fully | +---+--+ | +---+---+ | +---+--+ |Output +--->Connected+---+RNN +--->RNN... +--->RNN | | | |Layers | +---^--+ | +---^---+ | +---^--+ +--------+ +---------+ | | | | | GO +-----+ +-----+ reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). These are the available parameters of a Generator decoder: fc_layers (default null ): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch documentation on batch normalization or for layer see Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . state_size (default 256 ): the size of the state of the rnn. embedding_size (default 256 ): The size of the embeddings of the inputs of the generator. beam_width (default 1 ): sampling from the RNN generator is performed using beam search. By default, with a beam of one, only a greedy sequence using always the most probable next token is generated, but the beam size can be increased. This usually leads to better performance at the expense of more computation and slower generation. tied (default null ): if null the embeddings of the targets are initialized randomly. If tied names an input feature, the embeddings of that input feature will be used as embeddings of the target. The vocabulary_size of that input feature has to be the same as the output feature and it has to have an embedding matrix (binary and number features will not have one, for instance). In this case the embedding_size will be the same as the state_size . This is useful for implementing autoencoders where the encoding and decoding part of the model share parameters. max_sequence_length (default 256 ): The maximum sequence length. Example sequence feature entry using a generator decoder in the output features list: name : sequence_column_name type : sequence decoder : generator reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities_temperature : 0 num_fc_layers : 0 output_size : 256 use_bias : true bias_initializer : zeros weights_initializer : glorot_uniform activation : relu dropout : 0 cell_type : rnn state_size : 256 embedding_size : 256 beam_width : 1 max_sequence_length : 256 Sequence Features Metrics \u00b6 The metrics that are calculated every epoch and are available for sequence features are: sequence_accuracy The rate at which the model predicted the correct sequence. token_accuracy The number of tokens correctly predicted divided by the total number of tokens in all sequences. last_accuracy Accuracy considering only the last element of the sequence. Useful to ensure special end-of-sequence tokens are generated or tagged. edit_distance Levenshtein distance: the minimum number of single-token edits (insertions, deletions or substitutions) required to change predicted sequence to ground truth. perplexity Perplexity is the inverse of the predicted probability of the ground truth sequence, normalized by the number of tokens. The lower the perplexity, the higher the probability of predicting the true sequence. loss The value of the loss function. You can set any of the above as validation_metric in the training section of the configuration if validation_field names a sequence feature.","title":"\u21c5 Sequence Features"},{"location":"configuration/features/sequence_features/#sequence-features-preprocessing","text":"Sequence features are transformed into an integer valued matrix of size n x l (where n is the number of rows and l is the minimum of the length of the longest sequence and a max_sequence_length parameter) and added to HDF5 with a key that reflects the name of column in the dataset. Each sequence in mapped to a list of integers internally. First, a tokenizer converts each sequence to a list of tokens (default tokenization is done by splitting on spaces). Next, a dictionary is constructed which maps each unique token to its frequency in the dataset column. Tokens are ranked by frequency and a sequential integer ID is assigned from the most frequent to the most rare. Ludwig uses <PAD> , <UNK> , <SOS> , and <EOS> special symbols for padding, unknown, start, and end, consistent with common NLP deep learning practices. Special symbols can also be set manually in the preprocessing config. The column name is added to the JSON file, with an associated dictionary containing the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the maximum length of all sequences ( max_sequence_length ) additional preprocessing information (how to fill missing values and what token to use to fill missing values) The parameters available for preprocessing are tokenizer (default space ): defines how to map from the raw string content of the dataset column to a sequence of elements. For the available options refer to the Tokenizers section. vocab_file (default null ) filepath string to a UTF-8 encoded file containing the sequence's vocabulary. On each line the first string until \\t or \\n is considered a word. max_sequence_length (default 256 ): the maximum length of the sequence. Sequences that are longer than this value will be truncated, while sequences that are shorter will be padded. most_common (default 20000 ): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown. padding_symbol (default <PAD> ): the string used as a padding symbol, mapped to the integer ID 0 in the vocabulary. unknown_symbol (default <UNK> ): the string used as the unknown placeholder, mapped to the integer ID 1 in the vocabulary. padding (default right ): the direction of the padding. right and left are available options. lowercase (default false ): If true, converts the string to lowercase before tokenizing. missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in the column. The value should be one of fill_with_const (replaces the missing value with the value specified by the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default <UNK> ): the value to replace the missing values with in case the missing_value_strategy is fill_value .","title":"Sequence Features Preprocessing"},{"location":"configuration/features/sequence_features/#sequence-input-features-and-encoders","text":"Sequence features have several encoders and each of them has its own parameters. Inputs are of size b while outputs are of size b x h where b is the batch size and h is the dimensionality of the output of the encoder. In case a representation for each element of the sequence is needed (for example for tagging them, or for using an attention mechanism), one can specify the parameter reduce_output to be null and the output will be a b x s x h tensor where s is the length of the sequence. Some encoders, because of their inner workings, may require additional parameters to be specified in order to obtain one representation for each element of the sequence. For instance the parallel_cnn encoder by default pools and flattens the sequence dimension and then passes the flattened vector through fully connected layers, so in order to obtain the full sequence tensor one has to specify reduce_output: null . Sequence input feature parameters are encoder (default parallel_cnn ): the name of the encoder to use to encode the sequence, one of embed , parallel_cnn , stacked_cnn , stacked_parallel_cnn , rnn , cnnrnn , transformer and passthrough (equivalent to null or None ). tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.","title":"Sequence Input Features and Encoders"},{"location":"configuration/features/sequence_features/#embed-encoder","text":"The embed encoder simply maps each integer in the sequence to an embedding, creating a b x s x h tensor where b is the batch size, s is the length of the sequence and h is the embedding size. The tensor is reduced along the s dimension to obtain a single vector of size h for each element of the batch. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +-----------+ |43| +------+ |Aggregation| |65+--->Emb 65+--->Reduce +--> |23| +------+ |Operation | |4 | |Emb 23| +-----------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the parameters available for the embed encoder representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense , sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. dropout (default 0 ): dropout rate. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (selects the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using an embed encoder: name : sequence_column_name type : sequence encoder : embed representation : dense embedding_size : 256 embeddings_trainable : true embeddings_on_cpu : false dropout : 0 reduce_output : sum","title":"Embed Encoder"},{"location":"configuration/features/sequence_features/#parallel-cnn-encoder","text":"The parallel cnn encoder is inspired by Yoon Kim's Convolutional Neural Network for Sentence Classification . It works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a number of parallel 1d convolutional layers with different filter size (by default 4 layers with filter size 2, 3, 4 and 5), followed by max pooling and concatenation. This single vector concatenating the outputs of the parallel convolutional layers is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +-------+ +----+ +-->1D Conv+--->Pool+--+ +------+ | |Width 2| +----+ | |Emb 12| | +-------+ | +------+ | | +--+ |Emb 7 | | +-------+ +----+ | |12| +------+ +-->1D Conv+--->Pool+--+ |7 | |Emb 43| | |Width 3| +----+ | +---------+ |43| +------+ | +-------+ | +------+ |Fully | |65+-->Emb 65 +--+ +-->Concat+-->Connected+--> |23| +------+ | +-------+ +----+ | +------+ |Layers | |4 | |Emb 23| +-->1D Conv+--->Pool+--+ +---------+ |1 | +------+ | |Width 4| +----+ | +--+ |Emb 4 | | +-------+ | +------+ | | |Emb 1 | | +-------+ +----+ | +------+ +-->1D Conv+--->Pool+--+ |Width 5| +----+ +-------+ These are the available parameters for a parallel cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of parallel convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}] . num_conv_layers (default null ): if conv_layers is null , this is the number of parallel convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (selects the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a parallel cnn encoder: name : sequence_column_name type : sequence encoder : parallel_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 pool_function : max output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0.0 reduce_output : sum","title":"Parallel CNN Encoder"},{"location":"configuration/features/sequence_features/#stacked-cnn-encoder","text":"The stacked cnn encoder is inspired by Xiang Zhang at all's Character-level Convolutional Networks for Text Classification . It works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of 1d convolutional layers with different filter size (by default 6 layers with filter size 7, 7, 3, 3, 3 and 3), followed by an optional final pool and by a flatten operation. This single flatten vector is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify the pool_size of all your conv_layers to be null and reduce_output: null , while if pool_size has a value different from null and reduce_output: null the returned tensor will be of shape b x s' x h , where s' is width of the output of the last convolutional layer. +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +----------------+ +---------+ |43| +------+ |1D Conv | |Fully | |65+--->Emb 65+--->Layers +--->Connected+--> |23| +------+ |Different Widths| |Layers | |4 | |Emb 23| +----------------+ +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the parameters available for the stack cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}] . num_conv_layers (default null ): if conv_layers is null , this is the number of stacked convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. strides (default 1 ): stride length of the convolution padding (default same ): one of valid or same . dilation_rate (default 1 ): dilation rate to use for dilated convolution pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. pool_strides (default null ): factor to scale down pool_padding (default same ): one of valid or same fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default max ): defines how to reduce the output tensor of the convolutional layers along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a parallel cnn encoder: name : sequence_column_name type : sequence encoder : stacked_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 strides : 1 padding : same dilation_rate : 1 pool_function : max pool_padding : same output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 reduce_output : max","title":"Stacked CNN Encoder"},{"location":"configuration/features/sequence_features/#stacked-parallel-cnn-encoder","text":"The stacked parallel cnn encoder is a combination of the Parallel CNN and the Stacked CNN encoders where each layer of the stack is composed of parallel convolutional layers. It works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of several parallel 1d convolutional layers with different filter size, followed by an optional final pool and by a flatten operation. This single flattened vector is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +-------+ +-------+ +->1D Conv+-+ +->1D Conv+-+ +------+ | |Width 2| | | |Width 2| | |Emb 12| | +-------+ | | +-------+ | +------+ | | | | +--+ |Emb 7 | | +-------+ | | +-------+ | |12| +------+ +->1D Conv+-+ +->1D Conv+-+ |7 | |Emb 43| | |Width 3| | | |Width 3| | +---------+ |43| +------+ | +-------+ | +------+ +---+ | +-------+ | +------+ +----+ |Fully | |65+->Emb 65 +--+ +->Concat+-->...+-+ +->Concat+->Pool+->Connected+--> |23| +------+ | +-------+ | +------+ +---+ | +-------+ | +------+ +----+ |Layers | |4 | |Emb 23| +->1D Conv+-+ +->1D Conv+-+ +---------+ |1 | +------+ | |Width 4| | | |Width 4| | +--+ |Emb 4 | | +-------+ | | +-------+ | +------+ | | | | |Emb 1 | | +-------+ | | +-------+ | +------+ +->1D Conv+-+ +->1D Conv+-+ |Width 5| |Width 5| +-------+ +-------+ These are the available parameters for the stack parallel cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. stacked_layers (default null ): a nested list of lists of dictionaries containing the parameters of the stack of parallel convolutional layers. The length of the list determines the number of stacked parallel convolutional layers, length of the sub-lists determines the number of parallel conv layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both stacked_layers and num_stacked_layers are null , a default list will be assigned to stacked_layers with the value [[{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}]] . num_stacked_layers (default null ): if stacked_layers is null , this is the number of elements in the stack of parallel convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in stacked_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in stacker_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in stacked_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a parallel cnn encoder: name : sequence_column_name type : sequence encoder : stacked_parallel_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 pool_function : max output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 reduce_output : max","title":"Stacked Parallel CNN Encoder"},{"location":"configuration/features/sequence_features/#rnn-encoder","text":"The rnn encoder works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of recurrent layers (by default 1 layer), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions. If you want to output the full b x s x h where h is the size of the output of the last rnn layer, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +---------+ |43| +------+ +----------+ |Fully | |65+--->Emb 65+--->RNN Layers+-->Connected+--> |23| +------+ +----------+ |Layers | |4 | |Emb 23| +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the available parameters for the rnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): the number of stacked recurrent layers. state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use. recurrent_activation (default sigmoid ): activation function to use in the recurrent step unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization recurrent_initializer (default orthogonal ): initializer for recurrent matrix weights dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a parallel cnn encoder: name : sequence_column_name type : sequence encoder : rnn representation' : dense embedding_size : 256 embeddings_trainable : true num_layers : 1 state_size : 256 cell_type : rnn bidirectional : false activation : tanh recurrent_activation : sigmoid unit_forget_bias : true recurrent_initializer : orthogonal dropout : 0.0 recurrent_dropout : 0.0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last","title":"RNN Encoder"},{"location":"configuration/features/sequence_features/#cnn-rnn-encoder","text":"The cnnrnn encoder works by first mapping the input integer sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of convolutional layers (by default 2), that is followed by a stack of recurrent layers (by default 1), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions. If you want to output the full b x s x h where h is the size of the output of the last rnn layer, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +---------+ |43| +------+ +----------+ +----------+ |Fully | |65+--->Emb 65+-->CNN Layers+-->RNN Layers+-->Connected+--> |23| +------+ +----------+ +----------+ |Layers | |4 | |Emb 23| +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the available parameters of the cnn rnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}] . num_conv_layers (default 1 ): the number of stacked convolutional layers. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. filter_size (default 5 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. strides (default 1 ): stride length of the convolution padding (default same ): one of valid or same . dilation_rate (default 1 ): dilation rate to use for dilated convolution conv_activation (default relu ): activation for the convolution layer conv_dropout (default 0.0 ): dropout rate for the convolution layer pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default 2 ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. pool_strides (default null ): factor to scale down pool_padding (default same ): one of valid or same num_rec_layers (default 1 ): the number of recurrent layers state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use recurrent_activation (default sigmoid ): activation function to use in the recurrent step unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization recurrent_initializer (default orthogonal ): initializer for recurrent matrix weights dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the inputs features list using a cnn rnn encoder: name : sequence_column_name type : sequence encoder : cnnrnn representation : dense embedding_size : 256 embeddings_trainable : true num_conv_layers : 1 num_filters : 256 filter_size : 5 strides : 1 padding : same dilation_rate : 1 conv_activation : relu conv_dropout : 0.0 pool_function : max pool_size : 2 pool_padding : same num_rec_layers : 1 state_size : 256 cell_type : rnn bidirectional : false activation : tanh recurrent_activation : sigmoid unit_forget_bias : true recurrent_initializer : orthogonal dropout : 0.0 recurrent_dropout : 0.0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last","title":"CNN RNN Encoder"},{"location":"configuration/features/sequence_features/#transformer-encoder","text":"The transformer encoder implements a stack of transformer blocks, replicating the architecture introduced in the Attention is all you need paper, and adds am optional stack of fully connected layers at the end. +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +-------------+ +---------+ |43| +------+ | | |Fully | |65+---+Emb 65+---> Transformer +--->Connected+--> |23| +------+ | Blocks | |Layers | |4 | |Emb 23| +-------------+ +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): number of transformer blocks. hidden_size (default 256 ): the size of the hidden representation within the transformer block. It is usually the same as the embedding_size , but if the two values are different, a projection layer will be added before the first transformer block. num_heads (default 8 ): number of attention heads in each transformer block. transformer_output_size (default 256 ): Size of the fully connected layer after self attention in the transformer block. This is usually the same as hidden_size and embedding_size . dropout (default 0.1 ): dropout rate for the transformer block fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default 0 ): This is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the inputs features list using a Transformer encoder: name : sequence_column_name type : sequence encoder : transformer representation : dense embedding_size : 256 embeddings_trainable : true num_layers : 1 hidden_size : 256 num_heads : 8 transformer_output_size : 256 dropout : 0.1 num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last","title":"Transformer Encoder"},{"location":"configuration/features/sequence_features/#passthrough-encoder","text":"The passthrough decoder simply transforms each input value into a float value and adds a dimension to the input tensor, creating a b x s x 1 tensor where b is the batch size and s is the length of the sequence. The tensor is reduced along the s dimension to obtain a single vector of size h for each element of the batch. If you want to output the full b x s x h tensor, you can specify reduce_output: null . This encoder is not really useful for sequence or text features, but may be useful for timeseries features, as it allows for using them without any processing in later stages of the model, like in a sequence combiner for instance. +--+ |12| |7 | +-----------+ |43| +------------+ |Aggregation| |65+--->Cast float32+--->Reduce +--> |23| +------------+ |Operation | |4 | +-----------+ |1 | +--+ These are the parameters available for the passthrough encoder reduce_output (default null ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the input features list using a passthrough encoder: name : sequence_column_name type : sequence encoder : passthrough reduce_output : null","title":"Passthrough Encoder"},{"location":"configuration/features/sequence_features/#sequence-output-features-and-decoders","text":"Sequence output features can be used for either tagging (classifying each element of an input sequence) or generation (generating a sequence by sampling from the model). Ludwig provides two sequence decoders named tagger and generator respectively. The following are the available parameters of a sequence output feature: reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). loss (default {type: softmax_cross_entropy, class_similarities_temperature: 0, class_weights: 1, confidence_penalty: 0, robust_lambda: 0} ): is a dictionary containing a loss type . The only available loss type for sequences is softmax_cross_entropy . For more details on losses and their options, see also Category Output Features and Decoders .","title":"Sequence Output Features and Decoders"},{"location":"configuration/features/sequence_features/#tagger-decoder","text":"In the case of tagger the decoder is a (potentially empty) stack of fully connected layers, followed by a projection into a tensor of size b x s x c , where b is the batch size, s is the length of the sequence and c is the number of classes, followed by a softmax_cross_entropy. This decoder requires its input to be shaped as b x s x h , where h is a hidden dimension, which is the output of a sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner. If a b x h input is provided instead, an error will be raised during model building. Combiner Output +---+ +----------+ +-------+ |emb| +---------+ |Projection| |Softmax| +---+ |Fully | +----------+ +-------+ |...+--->Connected+--->... +--->... | +---+ |Layers | +----------+ +-------+ |emb| +---------+ |Projection| |Softmax| +---+ +----------+ +-------+ These are the available parameters of a tagger decoder: fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate attention (default false ): If true , applies a multi-head self attention layer before prediction. attention_embedding_size (default 256 ): the embedding size of the multi-head self attention layer. attention_num_heads (default 8 ): number of attention heads in the multi-head self attention layer. Example sequence feature entry using a tagger decoder (with default parameters) in the output features list: name : sequence_column_name type : sequence decoder : tagger reduce_input : null dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities_temperature : 0 num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 attention : false attention_embedding_size : 256 attention_num_heads : 8","title":"Tagger Decoder"},{"location":"configuration/features/sequence_features/#generator-decoder","text":"In the case of generator the decoder is a (potentially empty) stack of fully connected layers, followed by an rnn that generates outputs feeding on its own previous predictions and generates a tensor of size b x s' x c , where b is the batch size, s' is the length of the generated sequence and c is the number of classes, followed by a softmax_cross_entropy. During training teacher forcing is adopted, meaning the list of targets is provided as both inputs and outputs (shifted by 1), while at evaluation time greedy decoding (generating one token at a time and feeding it as input for the next step) is performed by beam search, using a beam of 1 by default. In general a generator expects a b x h shaped input tensor, where h is a hidden dimension. The h vectors are (after an optional stack of fully connected layers) fed into the rnn generator. One exception is when the generator uses attention, as in that case the expected size of the input tensor is b x s x h , which is the output of a sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner. If a b x h input is provided to a generator decoder using an rnn with attention instead, an error will be raised during model building. Output Output 1 +-+ ... +--+ END ^ | ^ | ^ +--------+ +---------+ | | | | | |Combiner| |Fully | +---+--+ | +---+---+ | +---+--+ |Output +--->Connected+---+RNN +--->RNN... +--->RNN | | | |Layers | +---^--+ | +---^---+ | +---^--+ +--------+ +---------+ | | | | | GO +-----+ +-----+ reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). These are the available parameters of a Generator decoder: fc_layers (default null ): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch documentation on batch normalization or for layer see Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . state_size (default 256 ): the size of the state of the rnn. embedding_size (default 256 ): The size of the embeddings of the inputs of the generator. beam_width (default 1 ): sampling from the RNN generator is performed using beam search. By default, with a beam of one, only a greedy sequence using always the most probable next token is generated, but the beam size can be increased. This usually leads to better performance at the expense of more computation and slower generation. tied (default null ): if null the embeddings of the targets are initialized randomly. If tied names an input feature, the embeddings of that input feature will be used as embeddings of the target. The vocabulary_size of that input feature has to be the same as the output feature and it has to have an embedding matrix (binary and number features will not have one, for instance). In this case the embedding_size will be the same as the state_size . This is useful for implementing autoencoders where the encoding and decoding part of the model share parameters. max_sequence_length (default 256 ): The maximum sequence length. Example sequence feature entry using a generator decoder in the output features list: name : sequence_column_name type : sequence decoder : generator reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities_temperature : 0 num_fc_layers : 0 output_size : 256 use_bias : true bias_initializer : zeros weights_initializer : glorot_uniform activation : relu dropout : 0 cell_type : rnn state_size : 256 embedding_size : 256 beam_width : 1 max_sequence_length : 256","title":"Generator Decoder"},{"location":"configuration/features/sequence_features/#sequence-features-metrics","text":"The metrics that are calculated every epoch and are available for sequence features are: sequence_accuracy The rate at which the model predicted the correct sequence. token_accuracy The number of tokens correctly predicted divided by the total number of tokens in all sequences. last_accuracy Accuracy considering only the last element of the sequence. Useful to ensure special end-of-sequence tokens are generated or tagged. edit_distance Levenshtein distance: the minimum number of single-token edits (insertions, deletions or substitutions) required to change predicted sequence to ground truth. perplexity Perplexity is the inverse of the predicted probability of the ground truth sequence, normalized by the number of tokens. The lower the perplexity, the higher the probability of predicting the true sequence. loss The value of the loss function. You can set any of the above as validation_metric in the training section of the configuration if validation_field names a sequence feature.","title":"Sequence Features Metrics"},{"location":"configuration/features/set_features/","text":"Set Features Preprocessing \u00b6 Set features are expected to be provided as a string of elements separated by whitespace, e.g. \"elem5 elem9 elem6\". The string values are transformed into a binary (int8 actually) valued matrix of size n x l (where n is the number of rows in the dataset and l is the minimum of the size of the biggest set and a max_size parameter) and added to HDF5 with a key that reflects the name of column in the dataset. The way sets are mapped into integers consists in first using a tokenizer to map each input string to a sequence of set elements (by default this is done by splitting on spaces). Next a dictionary is constructed which maps each unique element to its frequency in the dataset column. Elements are ranked by frequency and a sequential integer ID is assigned in ascending order from the most frequent to the most rare. The column name is added to the JSON file, with an associated dictionary containing the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the maximum size of all sets ( max_set_size ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values) The parameters available for preprocessing are tokenizer (default space ): defines how to transform the raw text content of the dataset column to a set of elements. The default value space splits the string on spaces. Common options include: underscore (splits on underscore), comma (splits on comma), json (decodes the string into a set or a list through a JSON parser). For all available options see Tokenizers . missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in a set column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default <UNK> ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . lowercase (default false ): if the string has to be lowercased before being handled by the tokenizer. most_common (default 10000 ): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown. Set Input Features and Encoders \u00b6 Set features have one encoder, the raw binary values coming from the input placeholders are first transformed to sparse integer lists, then they are mapped to either dense or sparse embeddings (one-hot encodings), finally they are reduced on the sequence dimension and returned as an aggregated embedding vector. Inputs are of size b while outputs are of size b x h where b is the batch size and h is the dimensionality of the embeddings. +-+ |0| +-----+ |0| +-+ |emb 2| +-----------+ |1| |2| +-----+ |Aggregation| |0+--->4+---->emb 4+--->Reduce +-> |1| |5| +-----+ |Operation | |1| +-+ |emb 5| +-----------+ |0| +-----+ +-+ The available encoder parameters are representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 50 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of different strings appearing in the training set in the input column (plus 1 for the unknown token placeholder <UNK> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default 1 ): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 10 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): describes the strategy to use to aggregate the embeddings of the items of the set. Available values are: sum , mean or avg , max , concat and null (which does not reduce and returns the full tensor). tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters. Example set feature entry in the input features list: name : set_column_name type : set representation : dense embedding_size : 50 embeddings_trainable : true pretrained_embeddings : null embeddings_on_cpu : false fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0.0 reduce_output : sum tied : null Set Output Features and Decoders \u00b6 Set features can be used when multi-label classification needs to be performed. There is only one decoder available for set features: a (potentially empty) stack of fully connected layers, followed by a projection into a vector of size of the number of available classes, followed by a sigmoid. +--------------+ +---------+ +-----------+ |Combiner | |Fully | |Projection | +-------+ |Output +--->Connected+--->into Output+--->Sigmoid| |Representation| |Layers | |Space | +-------+ +--------------+ +---------+ +-----------+ These are the available parameters of the set output feature reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). loss (default {type: sigmoid_cross_entropy} ): is a dictionary containing a loss type . The only supported loss type for set features is sigmoid_cross_entropy . These are the available parameters of a set output feature decoder fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate threshold (default 0.5 ): The threshold above (greater or equal) which the predicted output of the sigmoid will be mapped to 1. Example set feature entry (with default parameters) in the output features list: name : set_column_name type : set reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : sigmoid_cross_entropy fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0.0 threshold : 0.5 Set Features Metrics \u00b6 The metrics that are calculated every epoch and are available for set features are jaccard (counts the number of elements in the intersection of prediction and label divided by number of elements in the union) and the loss itself. You can set either of them as validation_metric in the training section of the configuration if you set the validation_field to be the name of a set feature.","title":"\u21c5 Set Features"},{"location":"configuration/features/set_features/#set-features-preprocessing","text":"Set features are expected to be provided as a string of elements separated by whitespace, e.g. \"elem5 elem9 elem6\". The string values are transformed into a binary (int8 actually) valued matrix of size n x l (where n is the number of rows in the dataset and l is the minimum of the size of the biggest set and a max_size parameter) and added to HDF5 with a key that reflects the name of column in the dataset. The way sets are mapped into integers consists in first using a tokenizer to map each input string to a sequence of set elements (by default this is done by splitting on spaces). Next a dictionary is constructed which maps each unique element to its frequency in the dataset column. Elements are ranked by frequency and a sequential integer ID is assigned in ascending order from the most frequent to the most rare. The column name is added to the JSON file, with an associated dictionary containing the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the maximum size of all sets ( max_set_size ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values) The parameters available for preprocessing are tokenizer (default space ): defines how to transform the raw text content of the dataset column to a set of elements. The default value space splits the string on spaces. Common options include: underscore (splits on underscore), comma (splits on comma), json (decodes the string into a set or a list through a JSON parser). For all available options see Tokenizers . missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in a set column. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default <UNK> ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . lowercase (default false ): if the string has to be lowercased before being handled by the tokenizer. most_common (default 10000 ): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown.","title":"Set Features Preprocessing"},{"location":"configuration/features/set_features/#set-input-features-and-encoders","text":"Set features have one encoder, the raw binary values coming from the input placeholders are first transformed to sparse integer lists, then they are mapped to either dense or sparse embeddings (one-hot encodings), finally they are reduced on the sequence dimension and returned as an aggregated embedding vector. Inputs are of size b while outputs are of size b x h where b is the batch size and h is the dimensionality of the embeddings. +-+ |0| +-----+ |0| +-+ |emb 2| +-----------+ |1| |2| +-----+ |Aggregation| |0+--->4+---->emb 4+--->Reduce +-> |1| |5| +-----+ |Operation | |1| +-+ |emb 5| +-----------+ |0| +-----+ +-+ The available encoder parameters are representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 50 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of different strings appearing in the training set in the input column (plus 1 for the unknown token placeholder <UNK> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default 1 ): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 10 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): describes the strategy to use to aggregate the embeddings of the items of the set. Available values are: sum , mean or avg , max , concat and null (which does not reduce and returns the full tensor). tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters. Example set feature entry in the input features list: name : set_column_name type : set representation : dense embedding_size : 50 embeddings_trainable : true pretrained_embeddings : null embeddings_on_cpu : false fc_layers : null num_fc_layers : 0 output_size : 10 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0.0 reduce_output : sum tied : null","title":"Set Input Features and Encoders"},{"location":"configuration/features/set_features/#set-output-features-and-decoders","text":"Set features can be used when multi-label classification needs to be performed. There is only one decoder available for set features: a (potentially empty) stack of fully connected layers, followed by a projection into a vector of size of the number of available classes, followed by a sigmoid. +--------------+ +---------+ +-----------+ |Combiner | |Fully | |Projection | +-------+ |Output +--->Connected+--->into Output+--->Sigmoid| |Representation| |Layers | |Space | +-------+ +--------------+ +---------+ +-----------+ These are the available parameters of the set output feature reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). loss (default {type: sigmoid_cross_entropy} ): is a dictionary containing a loss type . The only supported loss type for set features is sigmoid_cross_entropy . These are the available parameters of a set output feature decoder fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate threshold (default 0.5 ): The threshold above (greater or equal) which the predicted output of the sigmoid will be mapped to 1. Example set feature entry (with default parameters) in the output features list: name : set_column_name type : set reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : sigmoid_cross_entropy fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0.0 threshold : 0.5","title":"Set Output Features and Decoders"},{"location":"configuration/features/set_features/#set-features-metrics","text":"The metrics that are calculated every epoch and are available for set features are jaccard (counts the number of elements in the intersection of prediction and label divided by number of elements in the union) and the loss itself. You can set either of them as validation_metric in the training section of the configuration if you set the validation_field to be the name of a set feature.","title":"Set Features Metrics"},{"location":"configuration/features/supported_data_types/","text":"Ludwig supports a variety of data types. A subset can be used as output features. Type Supported Input Feature Supported Output Feature binary \u2705 \u2705 number \u2705 \u2705 category \u2705 \u2705 bag \u2705 \u2705 set \u2705 \u2705 sequence \u2705 \u2705 text \u2705 \u2705 vector \u2705 \u2705 audio \u2705 date \u2705 h3 \u2705 image \u2705 timeseries \u2705","title":"Supported Data Types"},{"location":"configuration/features/text_features/","text":"Text Features Preprocessing \u00b6 Text features are an extension of sequence features . Text inputs are processed by a tokenizer which maps the raw text input into a sequence of tokens. An integer id is assigned to each unique token. Using this mapping, each text string is converted first to a sequence of tokens, and next to a sequence of integers. The list of tokens and their integer representations (vocabulary) is stored in the metadata of the model. In the case of a text output feature, this same mapping is used to post-process predictions to text. The parameters for text preprocessing are as follows: tokenizer (default space_punct ): defines how to map from the raw string content of the dataset column to a sequence of elements. For all available options see Tokenizers . vocab_file (default null ): filepath string to a UTF-8 encoded file containing the sequence's vocabulary. On each line the first string until \\t or \\n is considered a word. max_sequence_length (default 256 ): the maximum length (number of tokens) of the text. Texts that are longer than this value will be truncated, while texts that are shorter will be padded. most_common (default 20000 ): the maximum number of most common tokens in the vocabulary. If the data contains more than this amount, the most infrequent symbols will be treated as unknown. padding_symbol (default <PAD> ): the string used as a padding symbol. This special token is mapped to the integer ID 0 in the vocabulary. unknown_symbol (default <UNK> ): the string used as an unknown placeholder. This special token is mapped to the integer ID 1 in the vocabulary. padding (default right ): the direction of the padding. right and left are available options. lowercase (default false ): If true, converts the string to lowercase before tokenizing. missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in the dataset. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default \"\" ): the value to replace the missing values with in case the missing_value_strategy is fill_value . Configuration example: name : text_column_name type : text preprocessing : tokenizer : space_punct vocab_file : null max_sequence_length : 256 most_common : 20000 padding_symbol : <PAD> unknown_symbol : <UNK> padding : right lowercase : false missing_value_strategy : fill_with_const fill_value : \"\" Note If a text feature's encoder specifies a huggingface model, then the tokenizer for that model will be used automatically. Text Input Features and Encoders \u00b6 Text input feature parameters are encoder (default parallel_cnn ): encoder to use for the input text feature. The available encoders include encoders used for Sequence Features as well as pre-trained text encoders from the huggingface transformers library: albert , auto_transformer , bert , camembert , ctrl , distilbert , electra , flaubert , gpt , gpt2 , longformer , roberta , t5 , mt5 , transformer_xl , xlm , xlmroberta , xlnet . tied (default null ): name of the input feature to tie the weights of the encoder with. Tied must name a feature of the same type with the same encoder parameters. Example: name : text_column_name type : text encoder : bert trainable : true Embed Encoder \u00b6 The embed encoder simply maps each token in the input sequence to an embedding, creating a b x s x h tensor where b is the batch size, s is the length of the sequence and h is the embedding size. The tensor is reduced along the s dimension to obtain a single vector of size h for each element of the batch. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +-----------+ |43| +------+ |Aggregation| |65+--->Emb 65+--->Reduce +--> |23| +------+ |Operation | |4 | |Emb 23| +-----------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the parameters available for the embed encoder representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense , sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. dropout (default 0 ): dropout rate. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (selects the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using an embed encoder: name : text_column_name type : text encoder : embed representation : dense embedding_size : 256 embeddings_trainable : true dropout : 0 reduce_output : sum Parallel CNN Encoder \u00b6 The parallel cnn encoder is inspired by Yoon Kim's Convolutional Neural Network for Sentence Classification . It works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a number of parallel 1d convolutional layers with different filter size (by default 4 layers with filter size 2, 3, 4 and 5), followed by max pooling and concatenation. This single vector concatenating the outputs of the parallel convolutional layers is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +-------+ +----+ +-->1D Conv+--->Pool+--+ +------+ | |Width 2| +----+ | |Emb 12| | +-------+ | +------+ | | +--+ |Emb 7 | | +-------+ +----+ | |12| +------+ +-->1D Conv+--->Pool+--+ |7 | |Emb 43| | |Width 3| +----+ | +---------+ |43| +------+ | +-------+ | +------+ |Fully | |65+-->Emb 65 +--+ +-->Concat+-->Connected+--> |23| +------+ | +-------+ +----+ | +------+ |Layers | |4 | |Emb 23| +-->1D Conv+--->Pool+--+ +---------+ |1 | +------+ | |Width 4| +----+ | +--+ |Emb 4 | | +-------+ | +------+ | | |Emb 1 | | +-------+ +----+ | +------+ +-->1D Conv+--->Pool+--+ |Width 5| +----+ +-------+ These are the available parameters for a parallel cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of parallel convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}] . num_conv_layers (default null ): if conv_layers is null , this is the number of parallel convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (selects the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using a parallel cnn encoder: name : text_column_name type : text encoder : parallel_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 pool_function : max output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0.0 reduce_output : sum Stacked CNN Encoder \u00b6 The stacked cnn encoder is inspired by Xiang Zhang at all's Character-level Convolutional Networks for Text Classification . It works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of 1d convolutional layers with different filter size (by default 6 layers with filter size 7, 7, 3, 3, 3 and 3), followed by an optional final pool and by a flatten operation. This single flatten vector is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify the pool_size of all your conv_layers to be null and reduce_output: null , while if pool_size has a value different from null and reduce_output: null the returned tensor will be of shape b x s' x h , where s' is width of the output of the last convolutional layer. +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +----------------+ +---------+ |43| +------+ |1D Conv | |Fully | |65+--->Emb 65+--->Layers +--->Connected+--> |23| +------+ |Different Widths| |Layers | |4 | |Emb 23| +----------------+ +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the parameters available for the stack cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}] . num_conv_layers (default null ): if conv_layers is null , this is the number of stacked convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. strides (default 1 ): stride length of the convolution padding (default same ): one of valid or same . dilation_rate (default 1 ): dilation rate to use for dilated convolution pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. pool_strides (default null ): factor to scale down pool_padding (default same ): one of valid or same fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default max ): defines how to reduce the output tensor of the convolutional layers along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using a parallel cnn encoder: name : text_column_name type : text encoder : stacked_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 strides : 1 padding : same dilation_rate : 1 pool_function : max pool_padding : same output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 reduce_output : max Stacked Parallel CNN Encoder \u00b6 The stacked parallel cnn encoder is a combination of the Parallel CNN and the Stacked CNN encoders where each layer of the stack is composed of parallel convolutional layers. It works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of several parallel 1d convolutional layers with different filter size, followed by an optional final pool and by a flatten operation. This single flattened vector is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +-------+ +-------+ +->1D Conv+-+ +->1D Conv+-+ +------+ | |Width 2| | | |Width 2| | |Emb 12| | +-------+ | | +-------+ | +------+ | | | | +--+ |Emb 7 | | +-------+ | | +-------+ | |12| +------+ +->1D Conv+-+ +->1D Conv+-+ |7 | |Emb 43| | |Width 3| | | |Width 3| | +---------+ |43| +------+ | +-------+ | +------+ +---+ | +-------+ | +------+ +----+ |Fully | |65+->Emb 65 +--+ +->Concat+-->...+-+ +->Concat+->Pool+->Connected+--> |23| +------+ | +-------+ | +------+ +---+ | +-------+ | +------+ +----+ |Layers | |4 | |Emb 23| +->1D Conv+-+ +->1D Conv+-+ +---------+ |1 | +------+ | |Width 4| | | |Width 4| | +--+ |Emb 4 | | +-------+ | | +-------+ | +------+ | | | | |Emb 1 | | +-------+ | | +-------+ | +------+ +->1D Conv+-+ +->1D Conv+-+ |Width 5| |Width 5| +-------+ +-------+ These are the available parameters for the stack parallel cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. stacked_layers (default null ): a nested list of lists of dictionaries containing the parameters of the stack of parallel convolutional layers. The length of the list determines the number of stacked parallel convolutional layers, length of the sub-lists determines the number of parallel conv layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both stacked_layers and num_stacked_layers are null , a default list will be assigned to stacked_layers with the value [[{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}]] . num_stacked_layers (default null ): if stacked_layers is null , this is the number of elements in the stack of parallel convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in stacked_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in stacker_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in stacked_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using a parallel cnn encoder: name : text_column_name type : text encoder : stacked_parallel_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 pool_function : max output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 reduce_output : max RNN Encoder \u00b6 The rnn encoder works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of recurrent layers (by default 1 layer), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions. If you want to output the full b x s x h where h is the size of the output of the last rnn layer, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +---------+ |43| +------+ +----------+ |Fully | |65+--->Emb 65+--->RNN Layers+-->Connected+--> |23| +------+ +----------+ |Layers | |4 | |Emb 23| +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the available parameters for the rnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): the number of stacked recurrent layers. state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use. recurrent_activation (default sigmoid ): activation function to use in the recurrent step unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization recurrent_initializer (default orthogonal ): initializer for recurrent matrix weights dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using a parallel cnn encoder: name : text_column_name type : text encoder : rnn representation' : dense embedding_size : 256 embeddings_trainable : true num_layers : 1 state_size : 256 cell_type : rnn bidirectional : false activation : tanh recurrent_activation : sigmoid unit_forget_bias : true recurrent_initializer : orthogonal dropout : 0.0 recurrent_dropout : 0.0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last CNN RNN Encoder \u00b6 The cnnrnn encoder works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of convolutional layers (by default 2), that is followed by a stack of recurrent layers (by default 1), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions. If you want to output the full b x s x h where h is the size of the output of the last rnn layer, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +---------+ |43| +------+ +----------+ +----------+ |Fully | |65+--->Emb 65+-->CNN Layers+-->RNN Layers+-->Connected+--> |23| +------+ +----------+ +----------+ |Layers | |4 | |Emb 23| +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the available parameters of the cnn rnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}] . num_conv_layers (default 1 ): the number of stacked convolutional layers. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. filter_size (default 5 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. strides (default 1 ): stride length of the convolution padding (default same ): one of valid or same . dilation_rate (default 1 ): dilation rate to use for dilated convolution conv_activation (default relu ): activation for the convolution layer conv_dropout (default 0.0 ): dropout rate for the convolution layer pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default 2 ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. pool_strides (default null ): factor to scale down pool_padding (default same ): one of valid or same num_rec_layers (default 1 ): the number of recurrent layers state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use recurrent_activation (default sigmoid ): activation function to use in the recurrent step unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization recurrent_initializer (default orthogonal ): initializer for recurrent matrix weights dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the inputs features list using a cnn rnn encoder: name : text_column_name type : text encoder : cnnrnn representation : dense embedding_size : 256 embeddings_trainable : true num_conv_layers : 1 num_filters : 256 filter_size : 5 strides : 1 padding : same dilation_rate : 1 conv_activation : relu conv_dropout : 0.0 pool_function : max pool_size : 2 pool_padding : same num_rec_layers : 1 state_size : 256 cell_type : rnn bidirectional : false activation : tanh recurrent_activation : sigmoid unit_forget_bias : true recurrent_initializer : orthogonal dropout : 0.0 recurrent_dropout : 0.0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last Transformer Encoder \u00b6 The transformer encoder implements a stack of transformer blocks, replicating the architecture introduced in the Attention is all you need paper, and adds am optional stack of fully connected layers at the end. +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +-------------+ +---------+ |43| +------+ | | |Fully | |65+---+Emb 65+---> Transformer +--->Connected+--> |23| +------+ | Blocks | |Layers | |4 | |Emb 23| +-------------+ +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): number of transformer blocks. hidden_size (default 256 ): the size of the hidden representation within the transformer block. It is usually the same as the embedding_size , but if the two values are different, a projection layer will be added before the first transformer block. num_heads (default 8 ): number of attention heads in each transformer block. transformer_output_size (default 256 ): Size of the fully connected layer after self attention in the transformer block. This is usually the same as hidden_size and embedding_size . dropout (default 0.1 ): dropout rate for the transformer block fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default 0 ): This is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the inputs features list using a Transformer encoder: name : text_column_name type : text encoder : transformer representation : dense embedding_size : 256 embeddings_trainable : true num_layers : 1 hidden_size : 256 num_heads : 8 transformer_output_size : 256 dropout : 0.1 num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last Huggingface encoders \u00b6 All huggingface-based text encoders are configured with the following parameters: pretrained_model_name_or_path (default is the huggingface default model path for the specified encoder, i.e. bert-base-uncased for BERT). This can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the Hugging Face documentation . reduce_output (default cls_pooled ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: cls_pooled , sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor). trainable (default false ): if true the weights of the encoder will be trained, otherwise they will be kept frozen. Note Any hyperparameter of any huggingface encoder can be overridden. Check the huggingface documentation for which parameters are used for which models. name : text_column_name type : text encoder : bert trainable : true num_attention_heads : 16 # Instead of 12 ALBERT Encoder \u00b6 The albert encoder loads a pretrained ALBERT (default albert-base-v2 ) model using the Hugging Face transformers package. Albert is similar to BERT, with significantly lower memory usage and somewhat faster training time. AutoTransformer \u00b6 The auto_transformer encoder automatically instantiates the model architecture for the specified pretrained_model_name_or_path . Unlike the other HF encoders, auto_transformer does not provide a default value for pretrained_model_name_or_path , this is its only mandatory parameter. See the Hugging Face AutoModels documentation for more details. BERT Encoder \u00b6 The bert encoder loads a pretrained BERT (default bert-base-uncased ) model using the Hugging Face transformers package. CamemBERT Encoder \u00b6 The camembert encoder loads a pretrained CamemBERT (default jplu/tf-camembert-base ) model using the Hugging Face transformers package. CamemBERT is pre-trained on a large French language web-crawled text corpus. CTRL Encoder \u00b6 The ctrl encoder loads a pretrained CTRL (default ctrl ) model using the Hugging Face transformers package. CTRL is a conditional transformer language model trained to condition on control codes that govern style, content, and task-specific behavior. DistilBERT Encoder \u00b6 The distilbert encoder loads a pretrained DistilBERT (default distilbert-base-uncased ) model using the Hugging Face transformers package. A compressed version of BERT, 60% faster and smaller that BERT. ELECTRA Encoder \u00b6 The electra encoder loads a pretrained ELECTRA model using the Hugging Face transformers package. FlauBERT Encoder \u00b6 The flaubert encoder loads a pretrained FlauBERT (default jplu/tf-flaubert-base-uncased ) model using the Hugging Face transformers package. FlauBERT has an architecture similar to BERT and is pre-trained on a large French language corpus. GPT Encoder \u00b6 The gpt encoder loads a pretrained GPT (default openai-gpt ) model using the Hugging Face transformers package. GPT-2 Encoder \u00b6 The gpt2 encoder loads a pretrained GPT-2 (default gpt2 ) model using the Hugging Face transformers package. Longformer Encoder \u00b6 The longformer encoder loads a pretrained Longformer (default allenai/longformer-base-4096 ) model using the Hugging Face transformers package. Longformer is a good choice for longer text, as it supports sequences up to 4096 tokens long. RoBERTa Encoder \u00b6 The roberta encoder loads a pretrained RoBERTa (default roberta-base ) model using the Hugging Face transformers package. Replication of BERT pretraining which may match or exceed the performance of BERT. Transformer XL Encoder \u00b6 The transformer_xl encoder loads a pretrained Transformer-XL (default transfo-xl-wt103 ) model using the Hugging Face transformers package. Adds novel positional encoding scheme which improves understanding and generation of long-form text up to thousands of tokens. T5 Encoder \u00b6 The t5 encoder loads a pretrained T5 (default t5-small ) model using the Hugging Face transformers package. T5 (Text-to-Text Transfer Transformer) is pre-trained on a huge text dataset crawled from the web and shows good transfer performance on multiple tasks. MT5 Encoder \u00b6 The mt5 encoder loads a pretrained MT5 (default google/mt5-base ) model using the Hugging Face transformers package. MT5 is a multilingual variant of T5 trained on a dataset of 101 languages. XLM Encoder \u00b6 The xlm encoder loads a pretrained XLM (default xlm-mlm-en-2048 ) model using the Hugging Face transformers package. Pre-trained by cross-language modeling. XLM-RoBERTa Encoder \u00b6 The xlmroberta encoder loads a pretrained XLM-RoBERTa (default jplu/tf-xlm-reoberta-base ) model using the Hugging Face transformers package. XLM-RoBERTa is a multi-language model similar to BERT, trained on 100 languages. XLNet Encoder \u00b6 The xlnet encoder loads a pretrained XLNet (default xlnet-base-cased ) model using the Hugging Face transformers package. XLNet outperforms BERT on a variety of benchmarks. Text Output Features and Decoders \u00b6 Text output features are a special case of Sequence Features , so all options of sequence features are available for text features as well. Text output features can be used for either tagging (classifying each token of an input sequence) or text generation (generating text by repeatedly sampling from the model). There are two decoders available for these tasks named tagger and generator respectively. The following are the available parameters of a text output feature: reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). loss (default {type: softmax_cross_entropy, class_similarities_temperature: 0, class_weights: 1, confidence_penalty: 0, robust_lambda: 0} ): is a dictionary containing a loss type . The only available loss type for text features is softmax_cross_entropy . For more details on losses and their options, see also Category Output Features and Decoders . Tagger Decoder \u00b6 In the case of tagger the decoder is a (potentially empty) stack of fully connected layers, followed by a projection into a tensor of size b x s x c , where b is the batch size, s is the length of the sequence and c is the number of classes, followed by a softmax_cross_entropy. This decoder requires its input to be shaped as b x s x h , where h is a hidden dimension, which is the output of a sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner. If a b x h input is provided instead, an error will be raised during model building. Combiner Output +---+ +----------+ +-------+ |emb| +---------+ |Projection| |Softmax| +---+ |Fully | +----------+ +-------+ |...+--->Connected+--->... +--->... | +---+ |Layers | +----------+ +-------+ |emb| +---------+ |Projection| |Softmax| +---+ +----------+ +-------+ These are the available parameters of a tagger decoder: fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate attention (default false ): If true , applies a multi-head self attention layer before prediction. attention_embedding_size (default 256 ): the embedding size of the multi-head self attention layer. attention_num_heads (default 8 ): number of attention heads in the multi-head self attention layer. Example text feature entry using a tagger decoder (with default parameters) in the output features list: name : text_column_name type : text decoder : tagger reduce_input : null dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities_temperature : 0 num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 attention : false attention_embedding_size : 256 attention_num_heads : 8 Generator Decoder \u00b6 In the case of generator the decoder is a (potentially empty) stack of fully connected layers, followed by an RNN that generates outputs feeding on its own previous predictions and generates a tensor of size b x s' x c , where b is the batch size, s' is the length of the generated sequence and c is the number of classes, followed by a softmax_cross_entropy. During training teacher forcing is adopted, meaning the list of targets is provided as both inputs and outputs (shifted by 1), while at evaluation time greedy decoding (generating one token at a time and feeding it as input for the next step) is performed by beam search, using a beam of 1 by default. In general a generator expects a b x h shaped input tensor, where h is a hidden dimension. The h vectors are (after an optional stack of fully connected layers) fed into the rnn generator. One exception is when the generator uses attention, as in that case the expected size of the input tensor is b x s x h , which is the output of a sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner. If a b x h input is provided to a generator decoder using an RNN with attention instead, an error will be raised during model building. Output Output 1 +-+ ... +--+ END ^ | ^ | ^ +--------+ +---------+ | | | | | |Combiner| |Fully | +---+--+ | +---+---+ | +---+--+ |Output +--->Connected+---+RNN +--->RNN... +--->RNN | | | |Layers | +---^--+ | +---^---+ | +---^--+ +--------+ +---------+ | | | | | GO +-----+ +-----+ reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). These are the available parameters of a Generator decoder: fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch documentation on batch normalization or for layer see Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . state_size (default 256 ): the size of the state of the rnn. embedding_size (default 256 ): The size of the embeddings of the inputs of the generator. beam_width (default 1 ): sampling from the RNN generator is performed using beam search. By default, with a beam of one, only a greedy sequence using always the most probable next token is generated, but the beam size can be increased. This usually leads to better performance at the expense of more computation and slower generation. tied (default null ): if null the embeddings of the targets are initialized randomly. If tied names an input feature, the embeddings of that input feature will be used as embeddings of the target. The vocabulary_size of that input feature has to be the same as the output feature and it has to have an embedding matrix (binary and number features will not have one, for instance). In this case the embedding_size will be the same as the state_size . This is useful for implementing autoencoders where the encoding and decoding part of the model share parameters. max_sequence_length (default 256 ): The maximum sequence length. Example text feature entry using a generator decoder in the output features list: name : text_column_name type : text decoder : generator reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities_temperature : 0 num_fc_layers : 0 output_size : 256 use_bias : true bias_initializer : zeros weights_initializer : glorot_uniform activation : relu dropout : 0 cell_type : rnn state_size : 256 embedding_size : 256 beam_width : 1 max_sequence_length : 256 Text Features Metrics \u00b6 The metrics available for text features are the same as for Sequence Features : sequence_accuracy The rate at which the model predicted the correct sequence. token_accuracy The number of tokens correctly predicted divided by the total number of tokens in all sequences. last_accuracy Accuracy considering only the last element of the sequence. Useful to ensure special end-of-sequence tokens are generated or tagged. edit_distance Levenshtein distance: the minimum number of single-token edits (insertions, deletions or substitutions) required to change predicted sequence to ground truth. perplexity Perplexity is the inverse of the predicted probability of the ground truth sequence, normalized by the number of tokens. The lower the perplexity, the higher the probability of predicting the true sequence. loss The value of the loss function. You can set any of the above as validation_metric in the training section of the configuration if validation_field names a sequence feature.","title":"\u21c5 Text Features"},{"location":"configuration/features/text_features/#text-features-preprocessing","text":"Text features are an extension of sequence features . Text inputs are processed by a tokenizer which maps the raw text input into a sequence of tokens. An integer id is assigned to each unique token. Using this mapping, each text string is converted first to a sequence of tokens, and next to a sequence of integers. The list of tokens and their integer representations (vocabulary) is stored in the metadata of the model. In the case of a text output feature, this same mapping is used to post-process predictions to text. The parameters for text preprocessing are as follows: tokenizer (default space_punct ): defines how to map from the raw string content of the dataset column to a sequence of elements. For all available options see Tokenizers . vocab_file (default null ): filepath string to a UTF-8 encoded file containing the sequence's vocabulary. On each line the first string until \\t or \\n is considered a word. max_sequence_length (default 256 ): the maximum length (number of tokens) of the text. Texts that are longer than this value will be truncated, while texts that are shorter will be padded. most_common (default 20000 ): the maximum number of most common tokens in the vocabulary. If the data contains more than this amount, the most infrequent symbols will be treated as unknown. padding_symbol (default <PAD> ): the string used as a padding symbol. This special token is mapped to the integer ID 0 in the vocabulary. unknown_symbol (default <UNK> ): the string used as an unknown placeholder. This special token is mapped to the integer ID 1 in the vocabulary. padding (default right ): the direction of the padding. right and left are available options. lowercase (default false ): If true, converts the string to lowercase before tokenizing. missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value in the dataset. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default \"\" ): the value to replace the missing values with in case the missing_value_strategy is fill_value . Configuration example: name : text_column_name type : text preprocessing : tokenizer : space_punct vocab_file : null max_sequence_length : 256 most_common : 20000 padding_symbol : <PAD> unknown_symbol : <UNK> padding : right lowercase : false missing_value_strategy : fill_with_const fill_value : \"\" Note If a text feature's encoder specifies a huggingface model, then the tokenizer for that model will be used automatically.","title":"Text Features Preprocessing"},{"location":"configuration/features/text_features/#text-input-features-and-encoders","text":"Text input feature parameters are encoder (default parallel_cnn ): encoder to use for the input text feature. The available encoders include encoders used for Sequence Features as well as pre-trained text encoders from the huggingface transformers library: albert , auto_transformer , bert , camembert , ctrl , distilbert , electra , flaubert , gpt , gpt2 , longformer , roberta , t5 , mt5 , transformer_xl , xlm , xlmroberta , xlnet . tied (default null ): name of the input feature to tie the weights of the encoder with. Tied must name a feature of the same type with the same encoder parameters. Example: name : text_column_name type : text encoder : bert trainable : true","title":"Text Input Features and Encoders"},{"location":"configuration/features/text_features/#embed-encoder","text":"The embed encoder simply maps each token in the input sequence to an embedding, creating a b x s x h tensor where b is the batch size, s is the length of the sequence and h is the embedding size. The tensor is reduced along the s dimension to obtain a single vector of size h for each element of the batch. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +-----------+ |43| +------+ |Aggregation| |65+--->Emb 65+--->Reduce +--> |23| +------+ |Operation | |4 | |Emb 23| +-----------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the parameters available for the embed encoder representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense , sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. dropout (default 0 ): dropout rate. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (selects the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using an embed encoder: name : text_column_name type : text encoder : embed representation : dense embedding_size : 256 embeddings_trainable : true dropout : 0 reduce_output : sum","title":"Embed Encoder"},{"location":"configuration/features/text_features/#parallel-cnn-encoder","text":"The parallel cnn encoder is inspired by Yoon Kim's Convolutional Neural Network for Sentence Classification . It works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a number of parallel 1d convolutional layers with different filter size (by default 4 layers with filter size 2, 3, 4 and 5), followed by max pooling and concatenation. This single vector concatenating the outputs of the parallel convolutional layers is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +-------+ +----+ +-->1D Conv+--->Pool+--+ +------+ | |Width 2| +----+ | |Emb 12| | +-------+ | +------+ | | +--+ |Emb 7 | | +-------+ +----+ | |12| +------+ +-->1D Conv+--->Pool+--+ |7 | |Emb 43| | |Width 3| +----+ | +---------+ |43| +------+ | +-------+ | +------+ |Fully | |65+-->Emb 65 +--+ +-->Concat+-->Connected+--> |23| +------+ | +-------+ +----+ | +------+ |Layers | |4 | |Emb 23| +-->1D Conv+--->Pool+--+ +---------+ |1 | +------+ | |Width 4| +----+ | +--+ |Emb 4 | | +-------+ | +------+ | | |Emb 1 | | +-------+ +----+ | +------+ +-->1D Conv+--->Pool+--+ |Width 5| +----+ +-------+ These are the available parameters for a parallel cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): it is the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of parallel convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}] . num_conv_layers (default null ): if conv_layers is null , this is the number of parallel convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (selects the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using a parallel cnn encoder: name : text_column_name type : text encoder : parallel_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 pool_function : max output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0.0 reduce_output : sum","title":"Parallel CNN Encoder"},{"location":"configuration/features/text_features/#stacked-cnn-encoder","text":"The stacked cnn encoder is inspired by Xiang Zhang at all's Character-level Convolutional Networks for Text Classification . It works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of 1d convolutional layers with different filter size (by default 6 layers with filter size 7, 7, 3, 3, 3 and 3), followed by an optional final pool and by a flatten operation. This single flatten vector is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify the pool_size of all your conv_layers to be null and reduce_output: null , while if pool_size has a value different from null and reduce_output: null the returned tensor will be of shape b x s' x h , where s' is width of the output of the last convolutional layer. +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +----------------+ +---------+ |43| +------+ |1D Conv | |Fully | |65+--->Emb 65+--->Layers +--->Connected+--> |23| +------+ |Different Widths| |Layers | |4 | |Emb 23| +----------------+ +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the parameters available for the stack cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}] . num_conv_layers (default null ): if conv_layers is null , this is the number of stacked convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. strides (default 1 ): stride length of the convolution padding (default same ): one of valid or same . dilation_rate (default 1 ): dilation rate to use for dilated convolution pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. pool_strides (default null ): factor to scale down pool_padding (default same ): one of valid or same fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default max ): defines how to reduce the output tensor of the convolutional layers along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using a parallel cnn encoder: name : text_column_name type : text encoder : stacked_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 strides : 1 padding : same dilation_rate : 1 pool_function : max pool_padding : same output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 reduce_output : max","title":"Stacked CNN Encoder"},{"location":"configuration/features/text_features/#stacked-parallel-cnn-encoder","text":"The stacked parallel cnn encoder is a combination of the Parallel CNN and the Stacked CNN encoders where each layer of the stack is composed of parallel convolutional layers. It works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of several parallel 1d convolutional layers with different filter size, followed by an optional final pool and by a flatten operation. This single flattened vector is then passed through a stack of fully connected layers and returned as a b x h tensor where h is the output size of the last fully connected layer. If you want to output the full b x s x h tensor, you can specify reduce_output: null . +-------+ +-------+ +->1D Conv+-+ +->1D Conv+-+ +------+ | |Width 2| | | |Width 2| | |Emb 12| | +-------+ | | +-------+ | +------+ | | | | +--+ |Emb 7 | | +-------+ | | +-------+ | |12| +------+ +->1D Conv+-+ +->1D Conv+-+ |7 | |Emb 43| | |Width 3| | | |Width 3| | +---------+ |43| +------+ | +-------+ | +------+ +---+ | +-------+ | +------+ +----+ |Fully | |65+->Emb 65 +--+ +->Concat+-->...+-+ +->Concat+->Pool+->Connected+--> |23| +------+ | +-------+ | +------+ +---+ | +-------+ | +------+ +----+ |Layers | |4 | |Emb 23| +->1D Conv+-+ +->1D Conv+-+ +---------+ |1 | +------+ | |Width 4| | | |Width 4| | +--+ |Emb 4 | | +-------+ | | +-------+ | +------+ | | | | |Emb 1 | | +-------+ | | +-------+ | +------+ +->1D Conv+-+ +->1D Conv+-+ |Width 5| |Width 5| +-------+ +-------+ These are the available parameters for the stack parallel cnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. stacked_layers (default null ): a nested list of lists of dictionaries containing the parameters of the stack of parallel convolutional layers. The length of the list determines the number of stacked parallel convolutional layers, length of the sub-lists determines the number of parallel conv layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both stacked_layers and num_stacked_layers are null , a default list will be assigned to stacked_layers with the value [[{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}]] . num_stacked_layers (default null ): if stacked_layers is null , this is the number of elements in the stack of parallel convolutional layers. filter_size (default 3 ): if a filter_size is not already specified in stacked_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. num_filters (default 256 ): if a num_filters is not already specified in stacker_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default null ): if a pool_size is not already specified in stacked_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate reduce_output (default sum ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using a parallel cnn encoder: name : text_column_name type : text encoder : stacked_parallel_cnn representation : dense embedding_size : 256 embeddings_trainable : true filter_size : 3 num_filters : 256 pool_function : max output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 reduce_output : max","title":"Stacked Parallel CNN Encoder"},{"location":"configuration/features/text_features/#rnn-encoder","text":"The rnn encoder works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of recurrent layers (by default 1 layer), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions. If you want to output the full b x s x h where h is the size of the output of the last rnn layer, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +---------+ |43| +------+ +----------+ |Fully | |65+--->Emb 65+--->RNN Layers+-->Connected+--> |23| +------+ +----------+ |Layers | |4 | |Emb 23| +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the available parameters for the rnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): the number of stacked recurrent layers. state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use. recurrent_activation (default sigmoid ): activation function to use in the recurrent step unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization recurrent_initializer (default orthogonal ): initializer for recurrent matrix weights dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example text feature entry in the input features list using a parallel cnn encoder: name : text_column_name type : text encoder : rnn representation' : dense embedding_size : 256 embeddings_trainable : true num_layers : 1 state_size : 256 cell_type : rnn bidirectional : false activation : tanh recurrent_activation : sigmoid unit_forget_bias : true recurrent_initializer : orthogonal dropout : 0.0 recurrent_dropout : 0.0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last","title":"RNN Encoder"},{"location":"configuration/features/text_features/#cnn-rnn-encoder","text":"The cnnrnn encoder works by first mapping the input token sequence b x s (where b is the batch size and s is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of convolutional layers (by default 2), that is followed by a stack of recurrent layers (by default 1), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions. If you want to output the full b x s x h where h is the size of the output of the last rnn layer, you can specify reduce_output: null . +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +---------+ |43| +------+ +----------+ +----------+ |Fully | |65+--->Emb 65+-->CNN Layers+-->RNN Layers+-->Connected+--> |23| +------+ +----------+ +----------+ |Layers | |4 | |Emb 23| +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ These are the available parameters of the cnn rnn encoder: representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. conv_layers (default null ): a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , num_filters , filter_size , strides , padding , dilation_rate , use_bias , pool_function , pool_padding , pool_size , pool_strides , bias_initializer , weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both conv_layers and num_conv_layers are null , a default list will be assigned to conv_layers with the value [{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}] . num_conv_layers (default 1 ): the number of stacked convolutional layers. num_filters (default 256 ): if a num_filters is not already specified in conv_layers this is the default num_filters that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution. filter_size (default 5 ): if a filter_size is not already specified in conv_layers this is the default filter_size that will be used for each layer. It indicates how wide is the 1d convolutional filter. strides (default 1 ): stride length of the convolution padding (default same ): one of valid or same . dilation_rate (default 1 ): dilation rate to use for dilated convolution conv_activation (default relu ): activation for the convolution layer conv_dropout (default 0.0 ): dropout rate for the convolution layer pool_function (default max ): pooling function: max will select the maximum value. Any of average , avg or mean will compute the mean value. pool_size (default 2 ): if a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the s sequence dimension after the convolution operation. pool_strides (default null ): factor to scale down pool_padding (default same ): one of valid or same num_rec_layers (default 1 ): the number of recurrent layers state_size (default 256 ): the size of the state of the rnn. cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . bidirectional (default false ): if true two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. activation (default tanh ): activation function to use recurrent_activation (default sigmoid ): activation function to use in the recurrent step unit_forget_bias (default true ): If true , add 1 to the bias of the forget gate at initialization recurrent_initializer (default orthogonal ): initializer for recurrent matrix weights dropout (default 0.0 ): dropout rate recurrent_dropout (default 0.0 ): dropout rate for recurrent state fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default null ): if fc_layers is null , this is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the inputs features list using a cnn rnn encoder: name : text_column_name type : text encoder : cnnrnn representation : dense embedding_size : 256 embeddings_trainable : true num_conv_layers : 1 num_filters : 256 filter_size : 5 strides : 1 padding : same dilation_rate : 1 conv_activation : relu conv_dropout : 0.0 pool_function : max pool_size : 2 pool_padding : same num_rec_layers : 1 state_size : 256 cell_type : rnn bidirectional : false activation : tanh recurrent_activation : sigmoid unit_forget_bias : true recurrent_initializer : orthogonal dropout : 0.0 recurrent_dropout : 0.0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last","title":"CNN RNN Encoder"},{"location":"configuration/features/text_features/#transformer-encoder","text":"The transformer encoder implements a stack of transformer blocks, replicating the architecture introduced in the Attention is all you need paper, and adds am optional stack of fully connected layers at the end. +------+ |Emb 12| +------+ +--+ |Emb 7 | |12| +------+ |7 | |Emb 43| +-------------+ +---------+ |43| +------+ | | |Fully | |65+---+Emb 65+---> Transformer +--->Connected+--> |23| +------+ | Blocks | |Layers | |4 | |Emb 23| +-------------+ +---------+ |1 | +------+ +--+ |Emb 4 | +------+ |Emb 1 | +------+ representation (default dense ): the possible values are dense and sparse . dense means the embeddings are initialized randomly, sparse means they are initialized to be one-hot encodings. embedding_size (default 256 ): the maximum embedding size, the actual size will be min(vocabulary_size, embedding_size) for dense representations and exactly vocabulary_size for the sparse encoding, where vocabulary_size is the number of unique strings appearing in the training set input column plus the number of special tokens ( <UNK> , <PAD> , <SOS> , <EOS> ). embeddings_trainable (default true ): If true embeddings are trained during the training process, if false embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when representation is dense as sparse one-hot encodings are not trainable. pretrained_embeddings (default null ): by default dense embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the GloVe format . When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if representation is dense . embeddings_on_cpu (default false ): by default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. num_layers (default 1 ): number of transformer blocks. hidden_size (default 256 ): the size of the hidden representation within the transformer block. It is usually the same as the embedding_size , but if the two values are different, a projection layer will be added before the first transformer block. num_heads (default 8 ): number of attention heads in each transformer block. transformer_output_size (default 256 ): Size of the fully connected layer after self attention in the transformer block. This is usually the same as hidden_size and embedding_size . dropout (default 0.1 ): dropout rate for the transformer block fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_fc_layers (default 0 ): This is the number of stacked fully connected layers (only applies if reduce_output is not null ). output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . fc_activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. fc_dropout (default 0 ): dropout rate reduce_output (default last ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension) and null (which does not reduce and returns the full tensor). Example sequence feature entry in the inputs features list using a Transformer encoder: name : text_column_name type : text encoder : transformer representation : dense embedding_size : 256 embeddings_trainable : true num_layers : 1 hidden_size : 256 num_heads : 8 transformer_output_size : 256 dropout : 0.1 num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros fc_activation : relu fc_dropout : 0 reduce_output : last","title":"Transformer Encoder"},{"location":"configuration/features/text_features/#huggingface-encoders","text":"All huggingface-based text encoders are configured with the following parameters: pretrained_model_name_or_path (default is the huggingface default model path for the specified encoder, i.e. bert-base-uncased for BERT). This can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the Hugging Face documentation . reduce_output (default cls_pooled ): defines how to reduce the output tensor along the s sequence length dimension if the rank of the tensor is greater than 2. Available values are: cls_pooled , sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension) and null (which does not reduce and returns the full tensor). trainable (default false ): if true the weights of the encoder will be trained, otherwise they will be kept frozen. Note Any hyperparameter of any huggingface encoder can be overridden. Check the huggingface documentation for which parameters are used for which models. name : text_column_name type : text encoder : bert trainable : true num_attention_heads : 16 # Instead of 12","title":"Huggingface encoders"},{"location":"configuration/features/text_features/#albert-encoder","text":"The albert encoder loads a pretrained ALBERT (default albert-base-v2 ) model using the Hugging Face transformers package. Albert is similar to BERT, with significantly lower memory usage and somewhat faster training time.","title":"ALBERT Encoder"},{"location":"configuration/features/text_features/#autotransformer","text":"The auto_transformer encoder automatically instantiates the model architecture for the specified pretrained_model_name_or_path . Unlike the other HF encoders, auto_transformer does not provide a default value for pretrained_model_name_or_path , this is its only mandatory parameter. See the Hugging Face AutoModels documentation for more details.","title":"AutoTransformer"},{"location":"configuration/features/text_features/#bert-encoder","text":"The bert encoder loads a pretrained BERT (default bert-base-uncased ) model using the Hugging Face transformers package.","title":"BERT Encoder"},{"location":"configuration/features/text_features/#camembert-encoder","text":"The camembert encoder loads a pretrained CamemBERT (default jplu/tf-camembert-base ) model using the Hugging Face transformers package. CamemBERT is pre-trained on a large French language web-crawled text corpus.","title":"CamemBERT Encoder"},{"location":"configuration/features/text_features/#ctrl-encoder","text":"The ctrl encoder loads a pretrained CTRL (default ctrl ) model using the Hugging Face transformers package. CTRL is a conditional transformer language model trained to condition on control codes that govern style, content, and task-specific behavior.","title":"CTRL Encoder"},{"location":"configuration/features/text_features/#distilbert-encoder","text":"The distilbert encoder loads a pretrained DistilBERT (default distilbert-base-uncased ) model using the Hugging Face transformers package. A compressed version of BERT, 60% faster and smaller that BERT.","title":"DistilBERT Encoder"},{"location":"configuration/features/text_features/#electra-encoder","text":"The electra encoder loads a pretrained ELECTRA model using the Hugging Face transformers package.","title":"ELECTRA Encoder"},{"location":"configuration/features/text_features/#flaubert-encoder","text":"The flaubert encoder loads a pretrained FlauBERT (default jplu/tf-flaubert-base-uncased ) model using the Hugging Face transformers package. FlauBERT has an architecture similar to BERT and is pre-trained on a large French language corpus.","title":"FlauBERT Encoder"},{"location":"configuration/features/text_features/#gpt-encoder","text":"The gpt encoder loads a pretrained GPT (default openai-gpt ) model using the Hugging Face transformers package.","title":"GPT Encoder"},{"location":"configuration/features/text_features/#gpt-2-encoder","text":"The gpt2 encoder loads a pretrained GPT-2 (default gpt2 ) model using the Hugging Face transformers package.","title":"GPT-2 Encoder"},{"location":"configuration/features/text_features/#longformer-encoder","text":"The longformer encoder loads a pretrained Longformer (default allenai/longformer-base-4096 ) model using the Hugging Face transformers package. Longformer is a good choice for longer text, as it supports sequences up to 4096 tokens long.","title":"Longformer Encoder"},{"location":"configuration/features/text_features/#roberta-encoder","text":"The roberta encoder loads a pretrained RoBERTa (default roberta-base ) model using the Hugging Face transformers package. Replication of BERT pretraining which may match or exceed the performance of BERT.","title":"RoBERTa Encoder"},{"location":"configuration/features/text_features/#transformer-xl-encoder","text":"The transformer_xl encoder loads a pretrained Transformer-XL (default transfo-xl-wt103 ) model using the Hugging Face transformers package. Adds novel positional encoding scheme which improves understanding and generation of long-form text up to thousands of tokens.","title":"Transformer XL Encoder"},{"location":"configuration/features/text_features/#t5-encoder","text":"The t5 encoder loads a pretrained T5 (default t5-small ) model using the Hugging Face transformers package. T5 (Text-to-Text Transfer Transformer) is pre-trained on a huge text dataset crawled from the web and shows good transfer performance on multiple tasks.","title":"T5 Encoder"},{"location":"configuration/features/text_features/#mt5-encoder","text":"The mt5 encoder loads a pretrained MT5 (default google/mt5-base ) model using the Hugging Face transformers package. MT5 is a multilingual variant of T5 trained on a dataset of 101 languages.","title":"MT5 Encoder"},{"location":"configuration/features/text_features/#xlm-encoder","text":"The xlm encoder loads a pretrained XLM (default xlm-mlm-en-2048 ) model using the Hugging Face transformers package. Pre-trained by cross-language modeling.","title":"XLM Encoder"},{"location":"configuration/features/text_features/#xlm-roberta-encoder","text":"The xlmroberta encoder loads a pretrained XLM-RoBERTa (default jplu/tf-xlm-reoberta-base ) model using the Hugging Face transformers package. XLM-RoBERTa is a multi-language model similar to BERT, trained on 100 languages.","title":"XLM-RoBERTa Encoder"},{"location":"configuration/features/text_features/#xlnet-encoder","text":"The xlnet encoder loads a pretrained XLNet (default xlnet-base-cased ) model using the Hugging Face transformers package. XLNet outperforms BERT on a variety of benchmarks.","title":"XLNet Encoder"},{"location":"configuration/features/text_features/#text-output-features-and-decoders","text":"Text output features are a special case of Sequence Features , so all options of sequence features are available for text features as well. Text output features can be used for either tagging (classifying each token of an input sequence) or text generation (generating text by repeatedly sampling from the model). There are two decoders available for these tasks named tagger and generator respectively. The following are the available parameters of a text output feature: reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Feature Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). loss (default {type: softmax_cross_entropy, class_similarities_temperature: 0, class_weights: 1, confidence_penalty: 0, robust_lambda: 0} ): is a dictionary containing a loss type . The only available loss type for text features is softmax_cross_entropy . For more details on losses and their options, see also Category Output Features and Decoders .","title":"Text Output Features and Decoders"},{"location":"configuration/features/text_features/#tagger-decoder","text":"In the case of tagger the decoder is a (potentially empty) stack of fully connected layers, followed by a projection into a tensor of size b x s x c , where b is the batch size, s is the length of the sequence and c is the number of classes, followed by a softmax_cross_entropy. This decoder requires its input to be shaped as b x s x h , where h is a hidden dimension, which is the output of a sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner. If a b x h input is provided instead, an error will be raised during model building. Combiner Output +---+ +----------+ +-------+ |emb| +---------+ |Projection| |Softmax| +---+ |Fully | +----------+ +-------+ |...+--->Connected+--->... +--->... | +---+ |Layers | +----------+ +-------+ |emb| +---------+ |Projection| |Softmax| +---+ +----------+ +-------+ These are the available parameters of a tagger decoder: fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see the Torch documentation on batch normalization or for layer see the Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate attention (default false ): If true , applies a multi-head self attention layer before prediction. attention_embedding_size (default 256 ): the embedding size of the multi-head self attention layer. attention_num_heads (default 8 ): number of attention heads in the multi-head self attention layer. Example text feature entry using a tagger decoder (with default parameters) in the output features list: name : text_column_name type : text decoder : tagger reduce_input : null dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities_temperature : 0 num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu dropout : 0 attention : false attention_embedding_size : 256 attention_num_heads : 8","title":"Tagger Decoder"},{"location":"configuration/features/text_features/#generator-decoder","text":"In the case of generator the decoder is a (potentially empty) stack of fully connected layers, followed by an RNN that generates outputs feeding on its own previous predictions and generates a tensor of size b x s' x c , where b is the batch size, s' is the length of the generated sequence and c is the number of classes, followed by a softmax_cross_entropy. During training teacher forcing is adopted, meaning the list of targets is provided as both inputs and outputs (shifted by 1), while at evaluation time greedy decoding (generating one token at a time and feeding it as input for the next step) is performed by beam search, using a beam of 1 by default. In general a generator expects a b x h shaped input tensor, where h is a hidden dimension. The h vectors are (after an optional stack of fully connected layers) fed into the rnn generator. One exception is when the generator uses attention, as in that case the expected size of the input tensor is b x s x h , which is the output of a sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner. If a b x h input is provided to a generator decoder using an RNN with attention instead, an error will be raised during model building. Output Output 1 +-+ ... +--+ END ^ | ^ | ^ +--------+ +---------+ | | | | | |Combiner| |Fully | +---+--+ | +---+---+ | +---+--+ |Output +--->Connected+---+RNN +--->RNN... +--->RNN | | | |Layers | +---^--+ | +---^---+ | +---^--+ +--------+ +---------+ | | | | | GO +-----+ +-----+ reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the sequence dimension), last (returns the last vector of the sequence dimension). These are the available parameters of a Generator decoder: fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if an output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default glorot_uniform ): initializer for the weight matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . bias_initializer (default zeros ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . Alternatively it is possible to specify a dictionary with a key type that identifies the type of initializer and other keys for its parameters, e.g. {type: normal, mean: 0, stddev: 0} . To know the parameters of each initializer, please refer to torch.nn.init . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates how the output should be normalized and may be one of null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch documentation on batch normalization or for layer see Torch documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate cell_type (default rnn ): the type of recurrent cell to use. Available values are: rnn , lstm , gru . For reference about the differences between the cells please refer to torch.nn Recurrent Layers . state_size (default 256 ): the size of the state of the rnn. embedding_size (default 256 ): The size of the embeddings of the inputs of the generator. beam_width (default 1 ): sampling from the RNN generator is performed using beam search. By default, with a beam of one, only a greedy sequence using always the most probable next token is generated, but the beam size can be increased. This usually leads to better performance at the expense of more computation and slower generation. tied (default null ): if null the embeddings of the targets are initialized randomly. If tied names an input feature, the embeddings of that input feature will be used as embeddings of the target. The vocabulary_size of that input feature has to be the same as the output feature and it has to have an embedding matrix (binary and number features will not have one, for instance). In this case the embedding_size will be the same as the state_size . This is useful for implementing autoencoders where the encoding and decoding part of the model share parameters. max_sequence_length (default 256 ): The maximum sequence length. Example text feature entry using a generator decoder in the output features list: name : text_column_name type : text decoder : generator reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : softmax_cross_entropy confidence_penalty : 0 robust_lambda : 0 class_weights : 1 class_similarities_temperature : 0 num_fc_layers : 0 output_size : 256 use_bias : true bias_initializer : zeros weights_initializer : glorot_uniform activation : relu dropout : 0 cell_type : rnn state_size : 256 embedding_size : 256 beam_width : 1 max_sequence_length : 256","title":"Generator Decoder"},{"location":"configuration/features/text_features/#text-features-metrics","text":"The metrics available for text features are the same as for Sequence Features : sequence_accuracy The rate at which the model predicted the correct sequence. token_accuracy The number of tokens correctly predicted divided by the total number of tokens in all sequences. last_accuracy Accuracy considering only the last element of the sequence. Useful to ensure special end-of-sequence tokens are generated or tagged. edit_distance Levenshtein distance: the minimum number of single-token edits (insertions, deletions or substitutions) required to change predicted sequence to ground truth. perplexity Perplexity is the inverse of the predicted probability of the ground truth sequence, normalized by the number of tokens. The lower the perplexity, the higher the probability of predicting the true sequence. loss The value of the loss function. You can set any of the above as validation_metric in the training section of the configuration if validation_field names a sequence feature.","title":"Text Features Metrics"},{"location":"configuration/features/time_series_features/","text":"Time Series Features Preprocessing \u00b6 Timeseries features are handled as sequence features, with the only difference being that the matrix in the HDF5 preprocessing file uses floats instead of integers. Since data is continuous, the JSON file, which typically stores vocabulary mappings, isn't needed. Time Series Input Features and Encoders \u00b6 Time series encoders are the same as for Sequence Features , with one exception: Time series features don't have an embedding layer at the beginning, so the b x s placeholders (where b is the batch size and s is the sequence length) are directly mapped to a b x s x 1 tensor and then passed to the different sequential encoders. Time Series Output Features and Decoders \u00b6 There are no time series decoders at the moment. If this would unlock an interesting use case for your application, please file a GitHub Issue or ping the Ludwig Slack .","title":"\u2191 Time Series Features"},{"location":"configuration/features/time_series_features/#time-series-features-preprocessing","text":"Timeseries features are handled as sequence features, with the only difference being that the matrix in the HDF5 preprocessing file uses floats instead of integers. Since data is continuous, the JSON file, which typically stores vocabulary mappings, isn't needed.","title":"Time Series Features Preprocessing"},{"location":"configuration/features/time_series_features/#time-series-input-features-and-encoders","text":"Time series encoders are the same as for Sequence Features , with one exception: Time series features don't have an embedding layer at the beginning, so the b x s placeholders (where b is the batch size and s is the sequence length) are directly mapped to a b x s x 1 tensor and then passed to the different sequential encoders.","title":"Time Series Input Features and Encoders"},{"location":"configuration/features/time_series_features/#time-series-output-features-and-decoders","text":"There are no time series decoders at the moment. If this would unlock an interesting use case for your application, please file a GitHub Issue or ping the Ludwig Slack .","title":"Time Series Output Features and Decoders"},{"location":"configuration/features/vector_features/","text":"Vector features enable providing an ordered set of numerical values within a single feature. This is useful for providing pre-trained representations or activations obtained from other models or for providing multivariate inputs and outputs. An interesting use of vector features is the possibility of providing a probability distribution as output for a multiclass classification problem instead of a single correct class like with a category feature. Vector output features can also be useful for distillation and noise-aware losses. Vector Feature Preprocessing \u00b6 The data is expected as whitespace separated numerical values. Example: \"1.0 0.0 1.04 10.49\". All vectors are expected to be of the same size. Preprocessing parameters: vector_size (default null ): size of the vector. If not provided, it will be inferred from the data. missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default \"\" ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const . Vector Feature Encoders \u00b6 The vector feature supports two encoders: dense and passthrough . The available encoder parameters are: tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters. Passthrough Encoder \u00b6 There are no additional parameters for the passthrough encoder. Dense Encoder \u00b6 For vector features, a dense encoder (stack of fully connected layers) can be used to encode the vector. It takes the following parameters: layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 256 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Example vector feature entry in the input features list using an dense encoder: name : vector_column_name type : vector tied : null encoder : dense layers : null num_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0 Vector Feature Decoders \u00b6 name : vector_column_name type : vector reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : sigmoid_cross_entropy fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu clip : null Vector features can be used when multi-class classification needs to be performed with a noise-aware loss or when the task is multivariate regression. There is only one decoder available for vector features: a (potentially empty) stack of fully connected layers, followed by a projection into a tensor of the vector size (optionally followed by a softmax in the case of multi-class classification). +--------------+ +---------+ +-----------+ |Combiner | |Fully | |Projection | +-------+ |Output +--->Connected+--->into Vector+--->Softmax| |Representation| |Layers | |Size | +-------+ +--------------+ +---------+ +-----------+ These are the available parameters of the vector output feature. reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Features Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). softmax (default false ): determines if to apply a softmax at the end of the decoder. It is useful for predicting a vector of values that sum up to 1 and can be interpreted as probabilities. loss (default {type: mean_squared_error} ): is a dictionary containing a loss type . The available loss type are mean_squared_error , mean_absolute_error and softmax_cross_entropy (use it only if softmax is true ). These are the available parameters of a vector output feature decoder. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. clip (default null ): If not null it specifies a minimum and maximum value the predictions will be clipped to. The value can be either a list or a tuple of length 2, with the first value representing the minimum and the second the maximum. For instance (-5,5) will make it so that all predictions will be clipped in the [-5,5] interval. Vector Features Measures \u00b6 The metrics that are calculated every epoch and are available for set features are mean_squared_error , mean_absolute_error , r2 , and the loss itself. You can set any of them as validation_metric in the training section of the configuration if you set the validation_field to be the name of a vector feature.","title":"\u21c5 Vector Features"},{"location":"configuration/features/vector_features/#vector-feature-preprocessing","text":"The data is expected as whitespace separated numerical values. Example: \"1.0 0.0 1.04 10.49\". All vectors are expected to be of the same size. Preprocessing parameters: vector_size (default null ): size of the vector. If not provided, it will be inferred from the data. missing_value_strategy (default fill_with_const ): what strategy to follow when there's a missing value. The value should be one of fill_with_const (replaces the missing value with a specific value specified with the fill_value parameter), fill_with_mode (replaces the missing values with the most frequent value in the column), fill_with_mean (replaces the missing values with the mean of the values in the column), backfill (replaces the missing values with the next valid value). fill_value (default \"\" ): the value to replace the missing values with in case the missing_value_strategy is fill_with_const .","title":"Vector Feature Preprocessing"},{"location":"configuration/features/vector_features/#vector-feature-encoders","text":"The vector feature supports two encoders: dense and passthrough . The available encoder parameters are: tied (default null ): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.","title":"Vector Feature Encoders"},{"location":"configuration/features/vector_features/#passthrough-encoder","text":"There are no additional parameters for the passthrough encoder.","title":"Passthrough Encoder"},{"location":"configuration/features/vector_features/#dense-encoder","text":"For vector features, a dense encoder (stack of fully connected layers) can be used to encode the vector. It takes the following parameters: layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both fc_layers and num_fc_layers are null , a default list will be assigned to fc_layers with the value [{output_size: 512}, {output_size: 256}] (only applies if reduce_output is not null ). num_layers (default 0 ): This is the number of stacked fully connected layers. output_size (default 256 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . norm (default null ): if a norm is not already specified in fc_layers this is the default norm that will be used for each layer. It indicates the norm of the output and it can be null , batch or layer . norm_params (default null ): parameters used if norm is either batch or layer . For information on parameters used with batch see Torch's documentation on batch normalization or for layer see Torch's documentation on layer normalization . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. dropout (default 0 ): dropout rate Example vector feature entry in the input features list using an dense encoder: name : vector_column_name type : vector tied : null encoder : dense layers : null num_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros norm : null norm_params : null activation : relu dropout : 0","title":"Dense Encoder"},{"location":"configuration/features/vector_features/#vector-feature-decoders","text":"name : vector_column_name type : vector reduce_input : sum dependencies : [] reduce_dependencies : sum loss : type : sigmoid_cross_entropy fc_layers : null num_fc_layers : 0 output_size : 256 use_bias : true weights_initializer : glorot_uniform bias_initializer : zeros activation : relu clip : null Vector features can be used when multi-class classification needs to be performed with a noise-aware loss or when the task is multivariate regression. There is only one decoder available for vector features: a (potentially empty) stack of fully connected layers, followed by a projection into a tensor of the vector size (optionally followed by a softmax in the case of multi-class classification). +--------------+ +---------+ +-----------+ |Combiner | |Fully | |Projection | +-------+ |Output +--->Connected+--->into Vector+--->Softmax| |Representation| |Layers | |Size | +-------+ +--------------+ +---------+ +-----------+ These are the available parameters of the vector output feature. reduce_input (default sum ): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). dependencies (default [] ): the output features this one is dependent on. For a detailed explanation refer to Output Features Dependencies . reduce_dependencies (default sum ): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: sum , mean or avg , max , concat (concatenates along the first dimension), last (returns the last vector of the first dimension). softmax (default false ): determines if to apply a softmax at the end of the decoder. It is useful for predicting a vector of values that sum up to 1 and can be interpreted as probabilities. loss (default {type: mean_squared_error} ): is a dictionary containing a loss type . The available loss type are mean_squared_error , mean_absolute_error and softmax_cross_entropy (use it only if softmax is true ). These are the available parameters of a vector output feature decoder. fc_layers (default null ): a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: activation , dropout , norm , norm_params , output_size , use_bias , bias_initializer and weights_initializer . If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead. num_fc_layers (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space. output_size (default 256 ): if a output_size is not already specified in fc_layers this is the default output_size that will be used for each layer. It indicates the size of the output of a fully connected layer. use_bias (default true ): boolean, whether the layer uses a bias vector. weights_initializer (default 'glorot_uniform' ): initializer for the weights matrix. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . bias_initializer (default 'zeros' ): initializer for the bias vector. Options are: constant , identity , zeros , ones , orthogonal , normal , uniform , truncated_normal , variance_scaling , glorot_normal , glorot_uniform , xavier_normal , xavier_uniform , he_normal , he_uniform , lecun_normal , lecun_uniform . activation (default relu ): if an activation is not already specified in fc_layers this is the default activation that will be used for each layer. It indicates the activation function applied to the output. clip (default null ): If not null it specifies a minimum and maximum value the predictions will be clipped to. The value can be either a list or a tuple of length 2, with the first value representing the minimum and the second the maximum. For instance (-5,5) will make it so that all predictions will be clipped in the [-5,5] interval.","title":"Vector Feature Decoders"},{"location":"configuration/features/vector_features/#vector-features-measures","text":"The metrics that are calculated every epoch and are available for set features are mean_squared_error , mean_absolute_error , r2 , and the loss itself. You can set any of them as validation_metric in the training section of the configuration if you set the validation_field to be the name of a vector feature.","title":"Vector Features Measures"},{"location":"developer_guide/","text":"This is the Ludwig Developer Guide. It helps you understanding the structure of the Ludwig codebase and learn how to add modules and contribute to it.","title":"Developer Guide"},{"location":"developer_guide/add_a_combiner/","text":"Combiners are responsible for combining the outputs of one or more input features into a single combined representation, which is usually a vector, but may also be a sequence of vectors or some other higher-dimensional tensor. One or more output features will use this combined representation to generate predictions. Users can specify which combiner to use in the combiner section of the configuration, if a combiner is not specified the concat combiner will be used. Recall the ECD (Encoder, Combiner, Decoder) data flow architecture: all input feature outputs flow into the combiner, and the combiner's output flows into all output features. +-----------+ +-----------+ |Input | | Output | |Feature 1 +-+ +-+ Feature 1 + ---> Prediction 1 +-----------+ | | +-----------+ +-----------+ | +----------+ | +-----------+ |... +---> | Combiner +---> |... + +-----------+ | +----------+ | +-----------+ +-----------+ | | +-----------+ |Input +-+ +-+ Output | |Feature N | | Feature N + ---> Prediction N +-----------+ +-----------+ There is an additional complication to keep in mind: input features may either output vectors, or sequences of vectors. Thus, a combiner may have to handle a mix of input features whose outputs are of different dimensionality. SequenceConcatCombiner , for example, resolves this by requiring that all input sequences be of the same length. It will raise a ValueError exception if they are not. SequenceConcatCombiner tiles non-sequence inputs to the sequence length before concatenation, processing all input features as sequences of the same length. New combiners should make it clear in their doc strings if they support sequence inputs, declare any requirements on sequence length, type, or dimension, and validate their input features. In this guide we'll outline how to extend Ludwig by adding a new combiner, using the transformer combiner as a template. To add a new combiner: Define a dataclass to represent the combiner schema. Create a new combiner class inheriting from ludwig.combiners.Combiner or one of its subclasses. Allocate all layers and state in the __init__ method. Implement your combiner's forward pass in def forward(self, inputs: Dict): . Add tests. Add the new combiner to the combiner registry. 1. Define the combiner's schema \u00b6 The combiner schema is a dataclass (overloaded by the marshmallow_dataclass modue) that must extend BaseCombinerConfig . Its attributes are the configuration parameters of the combiner. All fields should have a type and a default value. The ludwig.schema.utils.py module provides convenient methods for specifying the valid types and ranges of a combiner config. For example, the TransformerCombiner has the following schema: from typing import Optional , List , Dict , Any # Main imports: from marshmallow_dataclass import dataclass from ludwig.schema import utils as schema_utils from ludwig.schema.combiners.base import BaseCombinerConfig @dataclass class TransformerCombinerConfig ( BaseCombinerConfig ): num_layers : int = schema . PositiveInteger ( default = 1 ) hidden_size : int = schema . NonNegativeInteger ( default = 256 ) num_heads : int = schema . NonNegativeInteger ( default = 8 ) transformer_output_size : int = schema . NonNegativeInteger ( default = 256 ) dropout : float = schema . FloatRange ( default = 0.1 , min = 0 , max = 1 ) fc_layers : Optional [ List [ Dict [ str , Any ]]] = schema . DictList () num_fc_layers : int = schema . NonNegativeInteger ( default = 0 ) output_size : int = schema . PositiveInteger ( default = 256 ) use_bias : bool = True weights_initializer : Union [ str , Dict ] = \\ schema . InitializerOrDict ( default = \"xavier_uniform\" ) bias_initializer : Union [ str , Dict ] = \\ schema . InitializerOrDict ( default = \"zeros\" ) norm : Optional [ str ] = schema . StringOptions ([ \"batch\" , \"layer\" ]) norm_params : Optional [ dict ] = schema . Dict () fc_activation : str = \"relu\" fc_dropout : float = schema . FloatRange ( default = 0.0 , min = 0 , max = 1 ) fc_residual : bool = False reduce_output : Optional [ str ] = schema . ReductionOptions ( default = \"mean\" ) This schema should live in its own file inside ludwig/schema/combiners/ . So that it is more convenient to import elsewhere in Ludwig, you may also add it as an import to ludwig/schema/combiners/__init__.py like so: from ludwig.schema.combiners.transformer import TransformerCombinerConfig # noqa: F401 2. Add a new combiner class \u00b6 Source code for combiners lives in ludwig/combiners/ . Add a new python module which declares a new combiner class. For this example, we'll show how to implement a simplified version of transformer combiner which would be defined in transformer_combiner.py . Note At present, all combiners are defined in ludwig/combiners/combiners.py . However, for new combiners we recommend creating a new python module with a name corresponding to the new combiner class. @register_combiner ( name = \"transformer\" ) class TransformerCombiner ( Combiner ): def __init__ ( self , input_features : Dict [ str , InputFeature ] = None , config : TransformerCombinerConfig = None , ** kwargs ): super () . __init__ ( input_features ) self . name = \"TransformerCombiner\" def forward ( self , inputs : Dict , ) -> Dict [ str : torch . Tensor ]: @staticmethod def get_schema_cls (): return TransformerCombinerConfig Implement @staticmethod def get_schema_cls(): and return the class name of your config schema. 3. Implement Constructor \u00b6 The combiner constructor will be initialized with a dictionary of the input features and the combiner config. The constructor must pass the input features to the superclass constructor, set its name property, then create its own layers and state. The input_features dictionary is passed in to the constructor to make information about the number, size, and type of the inputs accessible. This may determine what resources the combiner needs to allocate. For example, the transformer combiner treats its input features as a sequence, where the sequence length is the number of features. We can determine the sequence length here as self.sequence_size = len(self.input_features) . def __init__ ( self , input_features : Dict [ str , InputFeature ] = None , config : TransformerCombinerConfig = None , ** kwargs ): super () . __init__ ( input_features ) self . name = \"TransformerCombiner\" # ... self . sequence_size = len ( self . input_features ) self . transformer_stack = TransformerStack ( input_size = config . hidden_size , sequence_size = self . sequence_size , hidden_size = config . hidden_size , num_heads = config . num_heads , output_size = config . transformer_output_size , num_layers = config . num_layers , dropout = config . dropout , ) # ... 4. Implement forward method \u00b6 The forward method of the combiner should combine the input feature representations into a single output tensor, which will be passed to output feature decoders. Each key in inputs is an input feature name, and the respective value is a dictionary of the input feature's outputs. Each feature output dictionary is guaranteed to contain an encoder_output key, and may contain other outputs depending on the encoder. forward returns a dictionary mapping strings to tensors which must contain a combiner_output key. It may optionally return additional values that might be useful for output feature decoding, loss computation, or explanation. For example, TabNetCombiner returns its sparse attention masks ( attention_masks , and aggregated_attention_masks ) which are useful to see which input features were attended to in each prediction step. For example, the following is a simplified version of TransformerCombiner 's forward method: def forward ( self , inputs : Dict [ str , Dict [ str , torch . Tensor ]] ) -> Dict [ str , torch . Tensor ]: encoder_outputs = [ inputs [ k ][ \"encoder_output\" ] for k in inputs ] # ================ Flatten ================ batch_size = encoder_outputs [ 0 ] . shape [ 0 ] encoder_outputs = [ torch . reshape ( eo , [ batch_size , - 1 ]) for eo in encoder_outputs ] # ================ Project & Concat ================ projected = [ self . projectors [ i ]( eo ) for i , eo in enumerate ( encoder_outputs ) ] hidden = torch . stack ( projected ) hidden = torch . permute ( hidden , ( 1 , 0 , 2 )) # ================ Transformer Layers ================ hidden = self . transformer_stack ( hidden ) # ================ Sequence Reduction ================ if self . reduce_output is not None : hidden = self . reduce_sequence ( hidden ) hidden = self . fc_stack ( hidden ) return_data = { \"combiner_output\" : hidden } return return_data Inputs inputs ( Dict[str, Dict[str, torch.Tensor]] ): A dictionary of input feature outputs, keyed by the input feature names. Each input feature output dictionary is guaranteed to include encoder_output , and may include other key/value pairs depending on the input feature's encoder. Return ( Dict[str, torch.Tensor] ): A dictionary containing the required key combiner_output whose value is the combiner output tensor, and any other optional output key/value pairs. 5. Add new class to the registry \u00b6 Mapping between combiner names in the model config and combiner classes is made by registering the class in the combiner registry. The combiner registry is defined in ludwig/schema/combiners/utils.py . To register your class, add the @register_combiner decorator on the line above its class definition, specifying the name of the combiner: @register_combiner ( name = \"transformer\" ) class TransformerCombiner ( Combiner ): 6. Add tests \u00b6 Add a corresponding unit test module to tests/ludwig/combiners , using the name of your combiner module prefixed by test_ i.e. test_transformer_combiner.py . At a minimum, the unit test should ensure that: The combiner's forward pass succeeds for all feature types it supports. The combiner fails in expected ways when given unsupported input. (Skip this if the combiner supports all input feature types.) The combiner produces output of the correct type and dimensionality given a variety of configs. Use @pytest.mark.parametrize to parameterize your test with different configurations, also test edge cases: @pytest . mark . parametrize ( \"output_size\" , [ 8 , 16 ]) @pytest . mark . parametrize ( \"transformer_output_size\" , [ 4 , 12 ]) def test_transformer_combiner ( encoder_outputs : tuple , transformer_output_size : int , output_size : int ) -> None : encoder_outputs_dict , input_feature_dict = encoder_outputs For examples of combiner tests, see tests/ludwig/combiners/test_combiners.py . For more detail about unit testing in Ludiwg, see also Unit Test Design Guidelines .","title":"Add a Combiner"},{"location":"developer_guide/add_a_combiner/#1-define-the-combiners-schema","text":"The combiner schema is a dataclass (overloaded by the marshmallow_dataclass modue) that must extend BaseCombinerConfig . Its attributes are the configuration parameters of the combiner. All fields should have a type and a default value. The ludwig.schema.utils.py module provides convenient methods for specifying the valid types and ranges of a combiner config. For example, the TransformerCombiner has the following schema: from typing import Optional , List , Dict , Any # Main imports: from marshmallow_dataclass import dataclass from ludwig.schema import utils as schema_utils from ludwig.schema.combiners.base import BaseCombinerConfig @dataclass class TransformerCombinerConfig ( BaseCombinerConfig ): num_layers : int = schema . PositiveInteger ( default = 1 ) hidden_size : int = schema . NonNegativeInteger ( default = 256 ) num_heads : int = schema . NonNegativeInteger ( default = 8 ) transformer_output_size : int = schema . NonNegativeInteger ( default = 256 ) dropout : float = schema . FloatRange ( default = 0.1 , min = 0 , max = 1 ) fc_layers : Optional [ List [ Dict [ str , Any ]]] = schema . DictList () num_fc_layers : int = schema . NonNegativeInteger ( default = 0 ) output_size : int = schema . PositiveInteger ( default = 256 ) use_bias : bool = True weights_initializer : Union [ str , Dict ] = \\ schema . InitializerOrDict ( default = \"xavier_uniform\" ) bias_initializer : Union [ str , Dict ] = \\ schema . InitializerOrDict ( default = \"zeros\" ) norm : Optional [ str ] = schema . StringOptions ([ \"batch\" , \"layer\" ]) norm_params : Optional [ dict ] = schema . Dict () fc_activation : str = \"relu\" fc_dropout : float = schema . FloatRange ( default = 0.0 , min = 0 , max = 1 ) fc_residual : bool = False reduce_output : Optional [ str ] = schema . ReductionOptions ( default = \"mean\" ) This schema should live in its own file inside ludwig/schema/combiners/ . So that it is more convenient to import elsewhere in Ludwig, you may also add it as an import to ludwig/schema/combiners/__init__.py like so: from ludwig.schema.combiners.transformer import TransformerCombinerConfig # noqa: F401","title":"1. Define the combiner's schema"},{"location":"developer_guide/add_a_combiner/#2-add-a-new-combiner-class","text":"Source code for combiners lives in ludwig/combiners/ . Add a new python module which declares a new combiner class. For this example, we'll show how to implement a simplified version of transformer combiner which would be defined in transformer_combiner.py . Note At present, all combiners are defined in ludwig/combiners/combiners.py . However, for new combiners we recommend creating a new python module with a name corresponding to the new combiner class. @register_combiner ( name = \"transformer\" ) class TransformerCombiner ( Combiner ): def __init__ ( self , input_features : Dict [ str , InputFeature ] = None , config : TransformerCombinerConfig = None , ** kwargs ): super () . __init__ ( input_features ) self . name = \"TransformerCombiner\" def forward ( self , inputs : Dict , ) -> Dict [ str : torch . Tensor ]: @staticmethod def get_schema_cls (): return TransformerCombinerConfig Implement @staticmethod def get_schema_cls(): and return the class name of your config schema.","title":"2. Add a new combiner class"},{"location":"developer_guide/add_a_combiner/#3-implement-constructor","text":"The combiner constructor will be initialized with a dictionary of the input features and the combiner config. The constructor must pass the input features to the superclass constructor, set its name property, then create its own layers and state. The input_features dictionary is passed in to the constructor to make information about the number, size, and type of the inputs accessible. This may determine what resources the combiner needs to allocate. For example, the transformer combiner treats its input features as a sequence, where the sequence length is the number of features. We can determine the sequence length here as self.sequence_size = len(self.input_features) . def __init__ ( self , input_features : Dict [ str , InputFeature ] = None , config : TransformerCombinerConfig = None , ** kwargs ): super () . __init__ ( input_features ) self . name = \"TransformerCombiner\" # ... self . sequence_size = len ( self . input_features ) self . transformer_stack = TransformerStack ( input_size = config . hidden_size , sequence_size = self . sequence_size , hidden_size = config . hidden_size , num_heads = config . num_heads , output_size = config . transformer_output_size , num_layers = config . num_layers , dropout = config . dropout , ) # ...","title":"3. Implement Constructor"},{"location":"developer_guide/add_a_combiner/#4-implement-forward-method","text":"The forward method of the combiner should combine the input feature representations into a single output tensor, which will be passed to output feature decoders. Each key in inputs is an input feature name, and the respective value is a dictionary of the input feature's outputs. Each feature output dictionary is guaranteed to contain an encoder_output key, and may contain other outputs depending on the encoder. forward returns a dictionary mapping strings to tensors which must contain a combiner_output key. It may optionally return additional values that might be useful for output feature decoding, loss computation, or explanation. For example, TabNetCombiner returns its sparse attention masks ( attention_masks , and aggregated_attention_masks ) which are useful to see which input features were attended to in each prediction step. For example, the following is a simplified version of TransformerCombiner 's forward method: def forward ( self , inputs : Dict [ str , Dict [ str , torch . Tensor ]] ) -> Dict [ str , torch . Tensor ]: encoder_outputs = [ inputs [ k ][ \"encoder_output\" ] for k in inputs ] # ================ Flatten ================ batch_size = encoder_outputs [ 0 ] . shape [ 0 ] encoder_outputs = [ torch . reshape ( eo , [ batch_size , - 1 ]) for eo in encoder_outputs ] # ================ Project & Concat ================ projected = [ self . projectors [ i ]( eo ) for i , eo in enumerate ( encoder_outputs ) ] hidden = torch . stack ( projected ) hidden = torch . permute ( hidden , ( 1 , 0 , 2 )) # ================ Transformer Layers ================ hidden = self . transformer_stack ( hidden ) # ================ Sequence Reduction ================ if self . reduce_output is not None : hidden = self . reduce_sequence ( hidden ) hidden = self . fc_stack ( hidden ) return_data = { \"combiner_output\" : hidden } return return_data Inputs inputs ( Dict[str, Dict[str, torch.Tensor]] ): A dictionary of input feature outputs, keyed by the input feature names. Each input feature output dictionary is guaranteed to include encoder_output , and may include other key/value pairs depending on the input feature's encoder. Return ( Dict[str, torch.Tensor] ): A dictionary containing the required key combiner_output whose value is the combiner output tensor, and any other optional output key/value pairs.","title":"4. Implement forward method"},{"location":"developer_guide/add_a_combiner/#5-add-new-class-to-the-registry","text":"Mapping between combiner names in the model config and combiner classes is made by registering the class in the combiner registry. The combiner registry is defined in ludwig/schema/combiners/utils.py . To register your class, add the @register_combiner decorator on the line above its class definition, specifying the name of the combiner: @register_combiner ( name = \"transformer\" ) class TransformerCombiner ( Combiner ):","title":"5. Add new class to the registry"},{"location":"developer_guide/add_a_combiner/#6-add-tests","text":"Add a corresponding unit test module to tests/ludwig/combiners , using the name of your combiner module prefixed by test_ i.e. test_transformer_combiner.py . At a minimum, the unit test should ensure that: The combiner's forward pass succeeds for all feature types it supports. The combiner fails in expected ways when given unsupported input. (Skip this if the combiner supports all input feature types.) The combiner produces output of the correct type and dimensionality given a variety of configs. Use @pytest.mark.parametrize to parameterize your test with different configurations, also test edge cases: @pytest . mark . parametrize ( \"output_size\" , [ 8 , 16 ]) @pytest . mark . parametrize ( \"transformer_output_size\" , [ 4 , 12 ]) def test_transformer_combiner ( encoder_outputs : tuple , transformer_output_size : int , output_size : int ) -> None : encoder_outputs_dict , input_feature_dict = encoder_outputs For examples of combiner tests, see tests/ludwig/combiners/test_combiners.py . For more detail about unit testing in Ludiwg, see also Unit Test Design Guidelines .","title":"6. Add tests"},{"location":"developer_guide/add_a_dataset/","text":"The Ludwig Dataset Zoo is a corpus of various datasets from the web conveniently built into Ludwig. Ludwig datasets automate managing credentials for downloading data from sites like Kaggle, merging multiple files into a single dataset, sharing data parsing code, and loading datasets directly into data frames which can be used to train Ludwig models. The Ludwig Datasets API is contained in ludwig/datasets/ . Dataset configs are defined under ludwig/datasets/configs/ . Custom loaders for specific datasets are in ludwig/datasets/loaders/ . Datasets are made available in Ludwig by providing a dataset config .yaml file. For many datasets, creating this YAML file is the only necessary step. 1. Create a new dataset config \u00b6 Create a new .yaml file under ludwig/datasets/configs/ with a name matching the name of the dataset. The config file must have the following required keys: version : The version of the dataset name : The name of the dataset. This is the name which will be imported or passed into get_datasets(datset_name) . description : Human-readable description of the dataset. May contain multi-line text with links. One of download_urls , kaggle_competition , or kaggle_dataset_id . Supported compressed archive and data file types will be inferred automatically from the file extension. For the full set of options, see ludwig.datasets.dataset_config.DatasetConfig . If the options provided by DatasetConfig are sufficient to integrate your dataset, skip ahead to step 3. Test your Dataset. If, however, the dataset requires other processing not provided by the default dataset loader, continue to step 2. 2. Define a dataset loader if needed \u00b6 If the options provided by DatasetConfig do not cover the format of your dataset, or if the dataset requires unique processing before training, you can add python code in a dataset loader. The loader class should inherit from ludwig.datasets.loaders.dataset_loader.DatasetLoader , and its module name should match the name of the dataset. For example, AG News has a dataset loader agnews.AGNewsLoader in ludwig/datasets/loaders/agnews.py . To instruct Ludwig to use your loader, add the loader property to your dataset config: loader : agnews.AGNewsLoader Datasets are processed in four phases: Download - The dataset files are downloaded to the cache. Verify - Hashes of downloaded files are verified. Extract - The dataset files are extracted from an archive (may be a no-op if data is not archived). Transform - The dataset is transformed into a format usable for training and is ready to load. Transform Files (Files -> Files) Load Dataframe (Files -> DataFrame) Transform Dataframe (DataFrame -> DataFrame) Save Processed (DataFrame -> File) For each of these phases, there is a corresponding method in ludwig.datasets.loaders.DatasetLoader which may be overridden to provide custom processing. 3. Test your dataset \u00b6 Create a simple training script and ludwig config to ensure that the Ludwig training API runs with the new dataset. For example: from ludwig.api import LudwigModel from ludwig.datasets import titanic training_set , test_set , _ , = titanic . load ( split = True ) model = LudwigModel ( config = \"model_config.yaml\" , logging_level = logging . INFO ) train_stats , _ , _ = model . train ( training_set = training_set , test_set = test_set , model_name = \"titanic_model\" ) If you have added a custom loader, please also a unit test to ensure that your loader works with future versions. Following the examples below, provide a small sample of the data to the unit test so the test will not need to download the dataset. Examples of unit tests: Titanic unit test MNIST unit test Note for Kaggle Datasets In order to test downloading datasets hosted on Kaggle, please follow these instructions to obtain the necessary API credentials. If the dataset is part of a competition, you will also need to accept the competition terms in the Kaggle web UI. For testing, the Titanic example also illustrates how to use a mock kaggle client in tests. Unit tests should be runnable without credentials or internet connectivity. 4. Add a modeling example \u00b6 Consider sharing an example for how users can train models using your dataset, for example: Titanic training script MNIST training script","title":"Add a Dataset"},{"location":"developer_guide/add_a_dataset/#1-create-a-new-dataset-config","text":"Create a new .yaml file under ludwig/datasets/configs/ with a name matching the name of the dataset. The config file must have the following required keys: version : The version of the dataset name : The name of the dataset. This is the name which will be imported or passed into get_datasets(datset_name) . description : Human-readable description of the dataset. May contain multi-line text with links. One of download_urls , kaggle_competition , or kaggle_dataset_id . Supported compressed archive and data file types will be inferred automatically from the file extension. For the full set of options, see ludwig.datasets.dataset_config.DatasetConfig . If the options provided by DatasetConfig are sufficient to integrate your dataset, skip ahead to step 3. Test your Dataset. If, however, the dataset requires other processing not provided by the default dataset loader, continue to step 2.","title":"1. Create a new dataset config"},{"location":"developer_guide/add_a_dataset/#2-define-a-dataset-loader-if-needed","text":"If the options provided by DatasetConfig do not cover the format of your dataset, or if the dataset requires unique processing before training, you can add python code in a dataset loader. The loader class should inherit from ludwig.datasets.loaders.dataset_loader.DatasetLoader , and its module name should match the name of the dataset. For example, AG News has a dataset loader agnews.AGNewsLoader in ludwig/datasets/loaders/agnews.py . To instruct Ludwig to use your loader, add the loader property to your dataset config: loader : agnews.AGNewsLoader Datasets are processed in four phases: Download - The dataset files are downloaded to the cache. Verify - Hashes of downloaded files are verified. Extract - The dataset files are extracted from an archive (may be a no-op if data is not archived). Transform - The dataset is transformed into a format usable for training and is ready to load. Transform Files (Files -> Files) Load Dataframe (Files -> DataFrame) Transform Dataframe (DataFrame -> DataFrame) Save Processed (DataFrame -> File) For each of these phases, there is a corresponding method in ludwig.datasets.loaders.DatasetLoader which may be overridden to provide custom processing.","title":"2. Define a dataset loader if needed"},{"location":"developer_guide/add_a_dataset/#3-test-your-dataset","text":"Create a simple training script and ludwig config to ensure that the Ludwig training API runs with the new dataset. For example: from ludwig.api import LudwigModel from ludwig.datasets import titanic training_set , test_set , _ , = titanic . load ( split = True ) model = LudwigModel ( config = \"model_config.yaml\" , logging_level = logging . INFO ) train_stats , _ , _ = model . train ( training_set = training_set , test_set = test_set , model_name = \"titanic_model\" ) If you have added a custom loader, please also a unit test to ensure that your loader works with future versions. Following the examples below, provide a small sample of the data to the unit test so the test will not need to download the dataset. Examples of unit tests: Titanic unit test MNIST unit test Note for Kaggle Datasets In order to test downloading datasets hosted on Kaggle, please follow these instructions to obtain the necessary API credentials. If the dataset is part of a competition, you will also need to accept the competition terms in the Kaggle web UI. For testing, the Titanic example also illustrates how to use a mock kaggle client in tests. Unit tests should be runnable without credentials or internet connectivity.","title":"3. Test your dataset"},{"location":"developer_guide/add_a_dataset/#4-add-a-modeling-example","text":"Consider sharing an example for how users can train models using your dataset, for example: Titanic training script MNIST training script","title":"4. Add a modeling example"},{"location":"developer_guide/add_a_decoder/","text":"1. Add a new decoder class \u00b6 Source code for decoders lives under ludwig/decoders/ . Decoders are grouped into modules by their output feature type. For instance, all new sequence decoders should be added to ludwig/decoders/sequence_decoders.py . Note A decoder may support multiple output types, if so it should be defined in the module corresponding to its most generic supported type. If a decoder is generic with respect to output type, add it to ludwig/decoders/generic_decoders.py . To create a new decoder: Define a new decoder class. Inherit from ludwig.decoders.base.Decoder or one of its subclasses. Create all layers and state in the __init__ method, after calling super().__init__() . Implement your decoder's forward pass in def forward(self, combiner_outputs, **kwargs): . Note: Decoder inherits from LudwigModule , which is itself a torch.nn.Module , so all the usual concerns of developing Torch modules apply. All decoder parameters should be provided as keyword arguments to the constructor, and must have a default value. For example the SequenceGeneratorDecoder decoder takes the following list of parameters in its constructor: from ludwig.constants import SEQUENCE , TEXT from ludwig.decoders.base import Decoder from ludwig.decoders.registry import register_decoder @register_decoder ( \"generator\" , [ SEQUENCE , TEXT ]) class SequenceGeneratorDecoder ( Decoder ): def __init__ ( self , vocab_size : int , max_sequence_length : int , cell_type : str = \"gru\" , input_size : int = 256 , reduce_input : str = \"sum\" , num_layers : int = 1 , ** kwargs , ): super () . __init__ () # Initialize any modules, layers, or variable state 2. Implement forward \u00b6 Actual computation of activations takes place inside the forward method of the decoder. All decoders should have the following signature: def forward ( self , combiner_outputs , ** kwargs ): # perform forward pass # combiner_hidden_output = combiner_outputs[HIDDEN] # ... # logits = result of decoder forward pass return { LOGITS : logits } Inputs combiner_outputs (Dict[str, torch.Tensor]): The input tensor, which is the output of a combiner or the combination of combiner and the activations of any dependent output decoders. The dictionary of combiner outputs includes a tensor of shape b x h , where b is the batch size and h is the embedding size, or a sequence of embeddings b x s x h where s is the sequence length. Return (Dict[str, torch.Tensor]): A dictionary of decoder output tensors. Typical decoders will return values for the keys LOGITS , PREDICTION , or both (defined in ludwig.constants ). 3. Add the new decoder class to the corresponding decoder registry \u00b6 Mapping between decoder names in the model definition and decoder classes is made by registering the class in a decoder registry. The decoder registry is defined in ludwig/decoders/registry.py . To register your class, add the @register_decoder decorator on the line above its class definition, specifying the name of the decoder and a list of supported output feature types: @register_decoder ( \"generator\" , [ SEQUENCE , TEXT ]) class SequenceGeneratorDecoder ( Decoder ):","title":"Add a Decoder"},{"location":"developer_guide/add_a_decoder/#1-add-a-new-decoder-class","text":"Source code for decoders lives under ludwig/decoders/ . Decoders are grouped into modules by their output feature type. For instance, all new sequence decoders should be added to ludwig/decoders/sequence_decoders.py . Note A decoder may support multiple output types, if so it should be defined in the module corresponding to its most generic supported type. If a decoder is generic with respect to output type, add it to ludwig/decoders/generic_decoders.py . To create a new decoder: Define a new decoder class. Inherit from ludwig.decoders.base.Decoder or one of its subclasses. Create all layers and state in the __init__ method, after calling super().__init__() . Implement your decoder's forward pass in def forward(self, combiner_outputs, **kwargs): . Note: Decoder inherits from LudwigModule , which is itself a torch.nn.Module , so all the usual concerns of developing Torch modules apply. All decoder parameters should be provided as keyword arguments to the constructor, and must have a default value. For example the SequenceGeneratorDecoder decoder takes the following list of parameters in its constructor: from ludwig.constants import SEQUENCE , TEXT from ludwig.decoders.base import Decoder from ludwig.decoders.registry import register_decoder @register_decoder ( \"generator\" , [ SEQUENCE , TEXT ]) class SequenceGeneratorDecoder ( Decoder ): def __init__ ( self , vocab_size : int , max_sequence_length : int , cell_type : str = \"gru\" , input_size : int = 256 , reduce_input : str = \"sum\" , num_layers : int = 1 , ** kwargs , ): super () . __init__ () # Initialize any modules, layers, or variable state","title":"1. Add a new decoder class"},{"location":"developer_guide/add_a_decoder/#2-implement-forward","text":"Actual computation of activations takes place inside the forward method of the decoder. All decoders should have the following signature: def forward ( self , combiner_outputs , ** kwargs ): # perform forward pass # combiner_hidden_output = combiner_outputs[HIDDEN] # ... # logits = result of decoder forward pass return { LOGITS : logits } Inputs combiner_outputs (Dict[str, torch.Tensor]): The input tensor, which is the output of a combiner or the combination of combiner and the activations of any dependent output decoders. The dictionary of combiner outputs includes a tensor of shape b x h , where b is the batch size and h is the embedding size, or a sequence of embeddings b x s x h where s is the sequence length. Return (Dict[str, torch.Tensor]): A dictionary of decoder output tensors. Typical decoders will return values for the keys LOGITS , PREDICTION , or both (defined in ludwig.constants ).","title":"2. Implement forward"},{"location":"developer_guide/add_a_decoder/#3-add-the-new-decoder-class-to-the-corresponding-decoder-registry","text":"Mapping between decoder names in the model definition and decoder classes is made by registering the class in a decoder registry. The decoder registry is defined in ludwig/decoders/registry.py . To register your class, add the @register_decoder decorator on the line above its class definition, specifying the name of the decoder and a list of supported output feature types: @register_decoder ( \"generator\" , [ SEQUENCE , TEXT ]) class SequenceGeneratorDecoder ( Decoder ):","title":"3. Add the new decoder class to the corresponding decoder registry"},{"location":"developer_guide/add_a_feature_type/","text":"1. Define the new feature type \u00b6 Feature types are defined as constants in ludwig/constants.py . Add the name of the new feature type as a constant: BINARY = \"binary\" CATEGORY = \"category\" ... NEW_FEATURE_TYPE = \"new_feature_type_name\" 2. Add feature classes in a new python module \u00b6 Source code for feature classes lives under ludwig/features/ . Add the implementation of the new feature into a new python module ludwig/feature/<new_name>_feature.py . Input and output feature classes are defined in the same file, for example CategoryInputFeature and CategoryOutputFeature are defined in ludwig/features/category_feature.py . Input features inherit from ludwig.features.base_feature.InputFeature and corresponding mixin feature classes: class CategoryInputFeature ( CategoryFeatureMixin , InputFeature ): Similarly, output features inherit from the ludwig.features.base_feature.OutputFeature and corresponding mixin feature classes: class CategoryOutputFeature ( CategoryFeatureMixin , OutputFeature ): Feature base classes ( InputFeature , OutputFeature ) inherit from LudwigModule which is itself a torch.nn.Module , so all the usual concerns of developing Torch modules apply. Mixin classes provide shared preprocessing/postprocessing state and logic, such as the mapping from categories to indices, which are shared by input and output feature implementations. Mixin classes are not torch modules, and do not need to provide a forward method. class CategoryFeatureMixin ( BaseFeatureMixin ): 3. Implement required methods \u00b6 Input features \u00b6 Constructor \u00b6 Feature parameters are provided in a dictionary of key-value pairs as an argument to the constructor. The feature dictionary should usually be passed to the superclass constructor before initialization: def __init__ ( self , feature : [ str , Any ], encoder_obj = None ): super () . __init__ ( feature ) # Initialize any modules, layers, or variable state Inputs feature : (dict) contains all feature config parameters. encoder_obj : (Encoder, default: None ) is an encoder object of the supported type (category encoder, binary encoder, etc.). Input features typically create their own encoder, encoder_obj is only specified when two input features share the same encoder. forward \u00b6 All input features must implement the forward method with the following signature: def forward ( self , inputs : torch . Tensor ) -> torch . Tensor : # perform forward pass # ... # inputs_encoded = result of encoder forward pass return inputs_encoded Inputs inputs (torch.Tensor): The input tensor. Return (torch.Tensor): Input data encoded by the input feature's encoder. input_shape \u00b6 @property def input_shape ( self ) -> torch . Size : Return (torch.Size): The fully-specified size of the feature's expected input, without batch dimension. Output features \u00b6 Constructor \u00b6 def __init__ ( self , feature : Dict [ str , Any ], output_features : Dict [ str , OutputFeature ]): super () . __init__ ( feature , output_features ) self . overwrite_defaults ( feature ) # Initialize any decoder modules, layers, metrics, loss objects, etc... Inputs feature (dict): contains all feature parameters. output_features (dict[Str, OutputFeature]): Dictionary of other output features, only used if this output feature depends on other outputs. logits \u00b6 Computes feature logits from the combiner output (and any features this feature depends on). def logits ( self , inputs : Dict [ str , torch . Tensor ], ** kwargs ): hidden = inputs [ HIDDEN ] # logits = results of decoder operation return logits Inputs inputs (dict): input dictionary which contains the HIDDEN key, whose value is the output of the combiner. Will contain other input keys if this feature depends on other output features. Return (torch.Tensor): feature logits. create_predict_module \u00b6 Creates and returns a torch.nn.Module that converts raw model outputs (logits) to predictions. This module is required for exporting models to Torchscript. def create_predict_module ( self ) -> PredictModule : Return (PredictModule): A module whose forward method convert feature logits to predictions. output_shape \u00b6 @property def output_shape ( self ) -> torch . Size : Return (torch.Size): The fully-specified size of the feature's output, without batch dimension. Feature Mixins \u00b6 If your new feature can re-use the preprocessing and postprocessing logic of an existing feature type, you do not need to implement a new mixin class. If your new feature does require unique pre or post-processing, add a new subclass of ludwig.features.base_feature.BaseFeatureMixin . Implement all abstract methods of BaseFeatureMixin . 4. Add the new feature classes to the corresponding feature registries \u00b6 Input and output feature registries are defined in ludwig/features/feature_registries.py . Import your new feature classes, and add them to the appropriate registry dictionaries: base_type_registry = { CATEGORY : CategoryFeatureMixin , ... } input_type_registry = { CATEGORY : CategoryInputFeature , ... } output_type_registry = { CATEGORY : CategoryOutputFeature , ... }","title":"Add a Feature Type"},{"location":"developer_guide/add_a_feature_type/#1-define-the-new-feature-type","text":"Feature types are defined as constants in ludwig/constants.py . Add the name of the new feature type as a constant: BINARY = \"binary\" CATEGORY = \"category\" ... NEW_FEATURE_TYPE = \"new_feature_type_name\"","title":"1. Define the new feature type"},{"location":"developer_guide/add_a_feature_type/#2-add-feature-classes-in-a-new-python-module","text":"Source code for feature classes lives under ludwig/features/ . Add the implementation of the new feature into a new python module ludwig/feature/<new_name>_feature.py . Input and output feature classes are defined in the same file, for example CategoryInputFeature and CategoryOutputFeature are defined in ludwig/features/category_feature.py . Input features inherit from ludwig.features.base_feature.InputFeature and corresponding mixin feature classes: class CategoryInputFeature ( CategoryFeatureMixin , InputFeature ): Similarly, output features inherit from the ludwig.features.base_feature.OutputFeature and corresponding mixin feature classes: class CategoryOutputFeature ( CategoryFeatureMixin , OutputFeature ): Feature base classes ( InputFeature , OutputFeature ) inherit from LudwigModule which is itself a torch.nn.Module , so all the usual concerns of developing Torch modules apply. Mixin classes provide shared preprocessing/postprocessing state and logic, such as the mapping from categories to indices, which are shared by input and output feature implementations. Mixin classes are not torch modules, and do not need to provide a forward method. class CategoryFeatureMixin ( BaseFeatureMixin ):","title":"2. Add feature classes in a new python module"},{"location":"developer_guide/add_a_feature_type/#3-implement-required-methods","text":"","title":"3. Implement required methods"},{"location":"developer_guide/add_a_feature_type/#input-features","text":"","title":"Input features"},{"location":"developer_guide/add_a_feature_type/#constructor","text":"Feature parameters are provided in a dictionary of key-value pairs as an argument to the constructor. The feature dictionary should usually be passed to the superclass constructor before initialization: def __init__ ( self , feature : [ str , Any ], encoder_obj = None ): super () . __init__ ( feature ) # Initialize any modules, layers, or variable state Inputs feature : (dict) contains all feature config parameters. encoder_obj : (Encoder, default: None ) is an encoder object of the supported type (category encoder, binary encoder, etc.). Input features typically create their own encoder, encoder_obj is only specified when two input features share the same encoder.","title":"Constructor"},{"location":"developer_guide/add_a_feature_type/#forward","text":"All input features must implement the forward method with the following signature: def forward ( self , inputs : torch . Tensor ) -> torch . Tensor : # perform forward pass # ... # inputs_encoded = result of encoder forward pass return inputs_encoded Inputs inputs (torch.Tensor): The input tensor. Return (torch.Tensor): Input data encoded by the input feature's encoder.","title":"forward"},{"location":"developer_guide/add_a_feature_type/#input_shape","text":"@property def input_shape ( self ) -> torch . Size : Return (torch.Size): The fully-specified size of the feature's expected input, without batch dimension.","title":"input_shape"},{"location":"developer_guide/add_a_feature_type/#output-features","text":"","title":"Output features"},{"location":"developer_guide/add_a_feature_type/#constructor_1","text":"def __init__ ( self , feature : Dict [ str , Any ], output_features : Dict [ str , OutputFeature ]): super () . __init__ ( feature , output_features ) self . overwrite_defaults ( feature ) # Initialize any decoder modules, layers, metrics, loss objects, etc... Inputs feature (dict): contains all feature parameters. output_features (dict[Str, OutputFeature]): Dictionary of other output features, only used if this output feature depends on other outputs.","title":"Constructor"},{"location":"developer_guide/add_a_feature_type/#logits","text":"Computes feature logits from the combiner output (and any features this feature depends on). def logits ( self , inputs : Dict [ str , torch . Tensor ], ** kwargs ): hidden = inputs [ HIDDEN ] # logits = results of decoder operation return logits Inputs inputs (dict): input dictionary which contains the HIDDEN key, whose value is the output of the combiner. Will contain other input keys if this feature depends on other output features. Return (torch.Tensor): feature logits.","title":"logits"},{"location":"developer_guide/add_a_feature_type/#create_predict_module","text":"Creates and returns a torch.nn.Module that converts raw model outputs (logits) to predictions. This module is required for exporting models to Torchscript. def create_predict_module ( self ) -> PredictModule : Return (PredictModule): A module whose forward method convert feature logits to predictions.","title":"create_predict_module"},{"location":"developer_guide/add_a_feature_type/#output_shape","text":"@property def output_shape ( self ) -> torch . Size : Return (torch.Size): The fully-specified size of the feature's output, without batch dimension.","title":"output_shape"},{"location":"developer_guide/add_a_feature_type/#feature-mixins","text":"If your new feature can re-use the preprocessing and postprocessing logic of an existing feature type, you do not need to implement a new mixin class. If your new feature does require unique pre or post-processing, add a new subclass of ludwig.features.base_feature.BaseFeatureMixin . Implement all abstract methods of BaseFeatureMixin .","title":"Feature Mixins"},{"location":"developer_guide/add_a_feature_type/#4-add-the-new-feature-classes-to-the-corresponding-feature-registries","text":"Input and output feature registries are defined in ludwig/features/feature_registries.py . Import your new feature classes, and add them to the appropriate registry dictionaries: base_type_registry = { CATEGORY : CategoryFeatureMixin , ... } input_type_registry = { CATEGORY : CategoryInputFeature , ... } output_type_registry = { CATEGORY : CategoryOutputFeature , ... }","title":"4. Add the new feature classes to the corresponding feature registries"},{"location":"developer_guide/add_a_hyperopt/","text":"The hyperparameter optimization design in Ludwig is based on two abstract interfaces: HyperoptSampler and HyperoptExecutor . See Hyperopt configuration for examples of how the sampler and executor are configured. HyperoptSampler \u00b6 HyperoptSampler dictates how to sample hyperparameters values. The sampler is configured by sampler section of the hyperopt section of the Ludwig configuration. Each hyperparameter that should be sampled is declared in hyperopt.parameters , which also specifies additional constraints that the Sampler should honor. For example: hyperopt : goal : minimize output_feature : combined metric : loss split : validation parameters : trainer.learning_rate : space : linear range : low : 0.001 high : 0.1 steps : 4 text.fc_layers : space : choice categories : - [{ \"output_size\" : 512 }, { \"output_size\" : 256 }] - [{ \"output_size\" : 512 }] - [{ \"output_size\" : 256 }] Here, trainer.learning_rate is sampled in continuously while text.fc_layers is sampled discretely. Note Different HyperoptSampler s are described here . HyperoptExecutor \u00b6 HyperoptExecutor dictates how to execute the hyperparameter optimization, which operates independently of how hyperparameters are actually sampled. A HyperoptExecutor uses a HyperoptSampler to sample hyperparameters values, usually initializes an execution context, like a multithread pool for instance, and executes the hyperparameter optimization according to the sampler. First, a new batch of parameters values is sampled from the HyperoptSampler . Then, sampled parameters values are merged with the seed Ludwig configuration, with the sampled parameters values overriding the seed's. Training is executed and validation losses and metrics are collected. A (sampled_parameters, statistics) pair is provided to the HyperoptSampler.update function to inform the next sample of hyperparameters. The loop is repeated until all the samples are sampled. Finally, HyperoptExecutor.execute returns a list of dictionaries that each contain: the sampled parameters, metric scores, and other training, validation, and test statistics. The returned list is printed and saved to disk, so that it can also be used as input to hyperparameter optimization visualizations . Note Different HyperoptExecutor s are described here Adding a HyperoptSampler \u00b6 1. Add a new sampler class \u00b6 The source code for the base HyperoptSampler class is in ludwig/hyperopt/sampling.py . Classes extending the base class should be defined in this file. __init__ \u00b6 def __init__ ( self , goal : str , parameters : Dict [ str , Any ]): The parameters of the base HyperoptStrategy class constructor are: goal which indicates if to minimize or maximize a metric or a loss of any of the output features on any of the splits which is defined in the hyperopt section parameters which contains all hyperparameters to optimize with their types and ranges / values. Example: goal = \"minimize\" parameters = { \"training.learning_rate\" : { \"type\" : \"float\" , \"low\" : 0.001 , \"high\" : 0.1 , \"steps\" : 4 , \"scale\" : \"linear\" }, \"combiner.num_fc_layers\" : { \"type\" : \"int\" , \"low\" : 2 , \"high\" : 6 , \"steps\" : 3 } } sampler = GridSampler ( goal , parameters ) sample \u00b6 def sample ( self ) -> Dict [ str , Any ]: sample is a method that yields a new sample according to the sampler. It returns a set of parameters names and their values. If finished() returns True , calling sample would return a IndexError . Example returned value: { 'training.learning_rate' : 0.005 , 'combiner.num_fc_layers' : 2 , 'utterance.cell_type' : 'gru' } sample_batch \u00b6 def sample_batch ( self , batch_size : int = 1 ) -> List [ Dict [ str , Any ]]: sample_batch method returns a list of sampled parameters of length equal to or less than batch_size . If finished() returns True , calling sample_batch would return a IndexError . Example returned value: [{ 'training.learning_rate' : 0.005 , 'combiner.num_fc_layers' : 2 , 'utterance.cell_type' : 'gru' }, { 'training.learning_rate' : 0.015 , 'combiner.num_fc_layers' : 3 , 'utterance.cell_type' : 'lstm' }] update \u00b6 def update ( self , sampled_parameters : Dict [ str , Any ], metric_score : float ): update updates the sampler with the results of previous computation. sampled_parameters is a dictionary of sampled parameters. metric_score is the value of the optimization metric obtained for the specified sample. It is not needed for stateless strategies like grid and random, but is needed for stateful strategies like bayesian and evolutionary ones. Example: sampled_parameters = { 'training.learning_rate' : 0.005 , 'combiner.num_fc_layers' : 2 , 'utterance.cell_type' : 'gru' } metric_score = 2.53463 sampler . update ( sampled_parameters , metric_score ) update_batch \u00b6 def update_batch ( self , parameters_metric_tuples : Iterable [ Tuple [ Dict [ str , Any ], float ]] ): update_batch updates the sampler with the results of previous computation in batch. parameters_metric_tuples a list of pairs of sampled parameters and their respective metric value. It is not needed for stateless strategies like grid and random, but is needed for stateful strategies like bayesian and evolutionary ones. Example: sampled_parameters = [ { 'training.learning_rate' : 0.005 , 'combiner.num_fc_layers' : 2 , 'utterance.cell_type' : 'gru' }, { 'training.learning_rate' : 0.015 , 'combiner.num_fc_layers' : 5 , 'utterance.cell_type' : 'lstm' } ] metric_scores = [ 2.53463 , 1.63869 ] sampler . update_batch ( zip ( sampled_parameters , metric_scores )) finished \u00b6 def finished ( self ) -> bool : The finished method return True when all samples have been sampled, return False otherwise. 2. Add the new sampler class to the corresponding sampler registry \u00b6 The sampler_registry contains a mapping between sampler names in the hyperopt section of model definition and HyperoptSampler sub-classes. Add the new sampler to the registry: sampler_registry = { \"random\" : RandomSampler , \"grid\" : GridSampler , ... , \"new_sampler_name\" : NewSamplerClass } Adding a HyperoptExecutor \u00b6 1. Add a new executor class \u00b6 The source code for the base HyperoptExecutor class is in the ludwig/utils/hyperopt_utils.py module. Classes extending the base class should be defined in the module. __init__ \u00b6 def __init__ ( self , hyperopt_sampler : HyperoptSampler , output_feature : str , metric : str , split : str ) The parameters of the base HyperoptExecutor class constructor are hyperopt_sampler is a HyperoptSampler object that will be used to sample hyperparameters values output_feature is a str containing the name of the output feature that we want to optimize the metric or loss of. Available values are combined (default) or the name of any output feature provided in the model definition. combined is a special output feature that allows to optimize for the aggregated loss and metrics of all output features. metric is the metric that we want to optimize for. The default one is loss , but depending on the tye of the feature defined in output_feature , different metrics and losses are available. Check the metrics section of the specific output feature type to figure out what metrics are available to use. split is the split of data that we want to compute our metric on. By default it is the validation split, but you have the flexibility to specify train or test splits. Example: goal = \"minimize\" parameters = { \"training.learning_rate\" : { \"type\" : \"float\" , \"low\" : 0.001 , \"high\" : 0.1 , \"steps\" : 4 , \"scale\" : \"linear\" }, \"combiner.num_fc_layers\" : { \"type\" : \"int\" , \"low\" : 2 , \"high\" : 6 , \"steps\" : 3 } } output_feature = \"combined\" metric = \"loss\" split = \"validation\" grid_sampler = GridSampler ( goal , parameters ) executor = SerialExecutor ( grid_sampler , output_feature , metric , split ) execute \u00b6 def execute ( self , config , dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , experiment_name = \"hyperopt\" , model_name = \"run\" , model_load_path = None , model_resume_path = None , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = False , skip_save_unprocessed_output = False , skip_save_predictions = False , skip_save_eval_stats = False , output_directory = \"results\" , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , use_horovod = None , random_seed = default_random_seed , debug = False , ** kwargs ): The execute method executes the hyperparameter optimization. It can leverage the run_experiment function to obtain training and eval statistics and the self.get_metric_score function to extract the metric score from the eval results according to self.output_feature , self.metric and self.split . 2. Add the new executor class to the corresponding executor registry \u00b6 The executor_registry contains a mapping between executor names in the hyperopt section of model definition and HyperoptExecutor sub-classes. To make a new executor available, add it to the registry: executor_registry = { \"serial\" : SerialExecutor , \"parallel\" : ParallelExecutor , \"fiber\" : FiberExecutor , \"new_executor_name\" : NewExecutorClass }","title":"Add a Hyperopt Algorithm"},{"location":"developer_guide/add_a_hyperopt/#hyperoptsampler","text":"HyperoptSampler dictates how to sample hyperparameters values. The sampler is configured by sampler section of the hyperopt section of the Ludwig configuration. Each hyperparameter that should be sampled is declared in hyperopt.parameters , which also specifies additional constraints that the Sampler should honor. For example: hyperopt : goal : minimize output_feature : combined metric : loss split : validation parameters : trainer.learning_rate : space : linear range : low : 0.001 high : 0.1 steps : 4 text.fc_layers : space : choice categories : - [{ \"output_size\" : 512 }, { \"output_size\" : 256 }] - [{ \"output_size\" : 512 }] - [{ \"output_size\" : 256 }] Here, trainer.learning_rate is sampled in continuously while text.fc_layers is sampled discretely. Note Different HyperoptSampler s are described here .","title":"HyperoptSampler"},{"location":"developer_guide/add_a_hyperopt/#hyperoptexecutor","text":"HyperoptExecutor dictates how to execute the hyperparameter optimization, which operates independently of how hyperparameters are actually sampled. A HyperoptExecutor uses a HyperoptSampler to sample hyperparameters values, usually initializes an execution context, like a multithread pool for instance, and executes the hyperparameter optimization according to the sampler. First, a new batch of parameters values is sampled from the HyperoptSampler . Then, sampled parameters values are merged with the seed Ludwig configuration, with the sampled parameters values overriding the seed's. Training is executed and validation losses and metrics are collected. A (sampled_parameters, statistics) pair is provided to the HyperoptSampler.update function to inform the next sample of hyperparameters. The loop is repeated until all the samples are sampled. Finally, HyperoptExecutor.execute returns a list of dictionaries that each contain: the sampled parameters, metric scores, and other training, validation, and test statistics. The returned list is printed and saved to disk, so that it can also be used as input to hyperparameter optimization visualizations . Note Different HyperoptExecutor s are described here","title":"HyperoptExecutor"},{"location":"developer_guide/add_a_hyperopt/#adding-a-hyperoptsampler","text":"","title":"Adding a HyperoptSampler"},{"location":"developer_guide/add_a_hyperopt/#1-add-a-new-sampler-class","text":"The source code for the base HyperoptSampler class is in ludwig/hyperopt/sampling.py . Classes extending the base class should be defined in this file.","title":"1. Add a new sampler class"},{"location":"developer_guide/add_a_hyperopt/#__init__","text":"def __init__ ( self , goal : str , parameters : Dict [ str , Any ]): The parameters of the base HyperoptStrategy class constructor are: goal which indicates if to minimize or maximize a metric or a loss of any of the output features on any of the splits which is defined in the hyperopt section parameters which contains all hyperparameters to optimize with their types and ranges / values. Example: goal = \"minimize\" parameters = { \"training.learning_rate\" : { \"type\" : \"float\" , \"low\" : 0.001 , \"high\" : 0.1 , \"steps\" : 4 , \"scale\" : \"linear\" }, \"combiner.num_fc_layers\" : { \"type\" : \"int\" , \"low\" : 2 , \"high\" : 6 , \"steps\" : 3 } } sampler = GridSampler ( goal , parameters )","title":"__init__"},{"location":"developer_guide/add_a_hyperopt/#sample","text":"def sample ( self ) -> Dict [ str , Any ]: sample is a method that yields a new sample according to the sampler. It returns a set of parameters names and their values. If finished() returns True , calling sample would return a IndexError . Example returned value: { 'training.learning_rate' : 0.005 , 'combiner.num_fc_layers' : 2 , 'utterance.cell_type' : 'gru' }","title":"sample"},{"location":"developer_guide/add_a_hyperopt/#sample_batch","text":"def sample_batch ( self , batch_size : int = 1 ) -> List [ Dict [ str , Any ]]: sample_batch method returns a list of sampled parameters of length equal to or less than batch_size . If finished() returns True , calling sample_batch would return a IndexError . Example returned value: [{ 'training.learning_rate' : 0.005 , 'combiner.num_fc_layers' : 2 , 'utterance.cell_type' : 'gru' }, { 'training.learning_rate' : 0.015 , 'combiner.num_fc_layers' : 3 , 'utterance.cell_type' : 'lstm' }]","title":"sample_batch"},{"location":"developer_guide/add_a_hyperopt/#update","text":"def update ( self , sampled_parameters : Dict [ str , Any ], metric_score : float ): update updates the sampler with the results of previous computation. sampled_parameters is a dictionary of sampled parameters. metric_score is the value of the optimization metric obtained for the specified sample. It is not needed for stateless strategies like grid and random, but is needed for stateful strategies like bayesian and evolutionary ones. Example: sampled_parameters = { 'training.learning_rate' : 0.005 , 'combiner.num_fc_layers' : 2 , 'utterance.cell_type' : 'gru' } metric_score = 2.53463 sampler . update ( sampled_parameters , metric_score )","title":"update"},{"location":"developer_guide/add_a_hyperopt/#update_batch","text":"def update_batch ( self , parameters_metric_tuples : Iterable [ Tuple [ Dict [ str , Any ], float ]] ): update_batch updates the sampler with the results of previous computation in batch. parameters_metric_tuples a list of pairs of sampled parameters and their respective metric value. It is not needed for stateless strategies like grid and random, but is needed for stateful strategies like bayesian and evolutionary ones. Example: sampled_parameters = [ { 'training.learning_rate' : 0.005 , 'combiner.num_fc_layers' : 2 , 'utterance.cell_type' : 'gru' }, { 'training.learning_rate' : 0.015 , 'combiner.num_fc_layers' : 5 , 'utterance.cell_type' : 'lstm' } ] metric_scores = [ 2.53463 , 1.63869 ] sampler . update_batch ( zip ( sampled_parameters , metric_scores ))","title":"update_batch"},{"location":"developer_guide/add_a_hyperopt/#finished","text":"def finished ( self ) -> bool : The finished method return True when all samples have been sampled, return False otherwise.","title":"finished"},{"location":"developer_guide/add_a_hyperopt/#2-add-the-new-sampler-class-to-the-corresponding-sampler-registry","text":"The sampler_registry contains a mapping between sampler names in the hyperopt section of model definition and HyperoptSampler sub-classes. Add the new sampler to the registry: sampler_registry = { \"random\" : RandomSampler , \"grid\" : GridSampler , ... , \"new_sampler_name\" : NewSamplerClass }","title":"2. Add the new sampler class to the corresponding sampler registry"},{"location":"developer_guide/add_a_hyperopt/#adding-a-hyperoptexecutor","text":"","title":"Adding a HyperoptExecutor"},{"location":"developer_guide/add_a_hyperopt/#1-add-a-new-executor-class","text":"The source code for the base HyperoptExecutor class is in the ludwig/utils/hyperopt_utils.py module. Classes extending the base class should be defined in the module.","title":"1. Add a new executor class"},{"location":"developer_guide/add_a_hyperopt/#__init___1","text":"def __init__ ( self , hyperopt_sampler : HyperoptSampler , output_feature : str , metric : str , split : str ) The parameters of the base HyperoptExecutor class constructor are hyperopt_sampler is a HyperoptSampler object that will be used to sample hyperparameters values output_feature is a str containing the name of the output feature that we want to optimize the metric or loss of. Available values are combined (default) or the name of any output feature provided in the model definition. combined is a special output feature that allows to optimize for the aggregated loss and metrics of all output features. metric is the metric that we want to optimize for. The default one is loss , but depending on the tye of the feature defined in output_feature , different metrics and losses are available. Check the metrics section of the specific output feature type to figure out what metrics are available to use. split is the split of data that we want to compute our metric on. By default it is the validation split, but you have the flexibility to specify train or test splits. Example: goal = \"minimize\" parameters = { \"training.learning_rate\" : { \"type\" : \"float\" , \"low\" : 0.001 , \"high\" : 0.1 , \"steps\" : 4 , \"scale\" : \"linear\" }, \"combiner.num_fc_layers\" : { \"type\" : \"int\" , \"low\" : 2 , \"high\" : 6 , \"steps\" : 3 } } output_feature = \"combined\" metric = \"loss\" split = \"validation\" grid_sampler = GridSampler ( goal , parameters ) executor = SerialExecutor ( grid_sampler , output_feature , metric , split )","title":"__init__"},{"location":"developer_guide/add_a_hyperopt/#execute","text":"def execute ( self , config , dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , experiment_name = \"hyperopt\" , model_name = \"run\" , model_load_path = None , model_resume_path = None , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = False , skip_save_unprocessed_output = False , skip_save_predictions = False , skip_save_eval_stats = False , output_directory = \"results\" , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , use_horovod = None , random_seed = default_random_seed , debug = False , ** kwargs ): The execute method executes the hyperparameter optimization. It can leverage the run_experiment function to obtain training and eval statistics and the self.get_metric_score function to extract the metric score from the eval results according to self.output_feature , self.metric and self.split .","title":"execute"},{"location":"developer_guide/add_a_hyperopt/#2-add-the-new-executor-class-to-the-corresponding-executor-registry","text":"The executor_registry contains a mapping between executor names in the hyperopt section of model definition and HyperoptExecutor sub-classes. To make a new executor available, add it to the registry: executor_registry = { \"serial\" : SerialExecutor , \"parallel\" : ParallelExecutor , \"fiber\" : FiberExecutor , \"new_executor_name\" : NewExecutorClass }","title":"2. Add the new executor class to the corresponding executor registry"},{"location":"developer_guide/add_a_loss_function/","text":"At a high level, a loss function evaluates how well a model predicts a dataset. Loss functions should always output a scalar. Lower loss corresponds to a better fit, thus the objective of training is to minimize the loss. Ludwig losses conform to the torch.nn.Module interface, and are declared in ludwig/modules/loss_modules.py . Before implementing a new loss from scratch, check the documentation of torch.nn loss functions to see if the desired loss is available. Adding a torch loss to Ludwig is simpler than implementing a loss from scratch. Add a torch loss to Ludwig \u00b6 Torch losses whose call signature takes model outputs and targets i.e. loss(model(input), target) can be added to Ludwig easily by declaring a trivial subclass in ludwig/modules/loss_modules.py and registering the loss for one or more output feature types. This example adds MAELoss (mean absolute error loss) to Ludwig: @register_loss ( \"mean_absolute_error\" , [ NUMBER , TIMESERIES , VECTOR ]) class MAELoss ( torch . nn . L1Loss , LogitsInputsMixin ): def __init__ ( self , ** kwargs ): super () . __init__ () The @register_loss decorator registers the loss under the name mean_absolute_error , and indicates it is supported for NUMBER , TIMESERIES , and VECTOR output features. Implement a loss from scratch \u00b6 Implement loss function \u00b6 To implement a new loss function, we recommend first implementing it as a function of logits and labels, plus any other configuration parameters. For this example, lets suppose we have implemented the tempered softmax from \"Robust Bi-Tempered Logistic Loss Based on Bregman Divergences\" . This loss function takes two constant parameters t1 and t2 , which we'd like to allow users to specify in the config. Assuming we have the following function: def tempered_softmax_cross_entropy_loss ( logits : torch . Tensor , labels : torch . Tensor , t1 : float , t2 : float ) -> torch . Tensor : # Computes the loss, returns the result as a torch.Tensor. Define and register module \u00b6 Next, we'll define a module class which computes our loss function, and add it to the loss registry for CATEGORY output features with @register_loss . LogitsInputsMixin tells Ludwig that this loss should be called with the output feature logits , which are the feature decoder outputs before normalization to a probability distribution. @register_loss ( \"tempered_softmax_cross_entropy\" , [ CATEGORY ]) class TemperedSoftmaxCrossEntropy ( torch . nn . Module , LogitsInputsMixin ): Note It is possible to define losses on other outputs besides logits but this is not used in Ludwig today. For example, loss could be computed over probabilities , but it is usually more numerically stable to compute from logits (rather than backpropagating loss through a softmax function). constructor \u00b6 The loss constructor will receive any parameters specified in the config as kwargs. It must provide reasonable defaults for all arguments. def __init__ ( self , t1 : float = 1.0 , t2 : float = 1.0 , ** kwargs ): super () . __init__ () self . t1 = t1 self . t2 = t2 forward \u00b6 The forward method is responsible for computing the loss. Here we'll call the tempered_softmax_cross_entropy_loss after ensuring its inputs are the correct type, and return its output averaged over the batch. def forward ( self , logits : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : labels = target . long () loss = tempered_softmax_cross_entropy_loss ( logits , labels , self . t1 , self . t2 ) return torch . mean ( loss )","title":"Add a Loss Function"},{"location":"developer_guide/add_a_loss_function/#add-a-torch-loss-to-ludwig","text":"Torch losses whose call signature takes model outputs and targets i.e. loss(model(input), target) can be added to Ludwig easily by declaring a trivial subclass in ludwig/modules/loss_modules.py and registering the loss for one or more output feature types. This example adds MAELoss (mean absolute error loss) to Ludwig: @register_loss ( \"mean_absolute_error\" , [ NUMBER , TIMESERIES , VECTOR ]) class MAELoss ( torch . nn . L1Loss , LogitsInputsMixin ): def __init__ ( self , ** kwargs ): super () . __init__ () The @register_loss decorator registers the loss under the name mean_absolute_error , and indicates it is supported for NUMBER , TIMESERIES , and VECTOR output features.","title":"Add a torch loss to Ludwig"},{"location":"developer_guide/add_a_loss_function/#implement-a-loss-from-scratch","text":"","title":"Implement a loss from scratch"},{"location":"developer_guide/add_a_loss_function/#implement-loss-function","text":"To implement a new loss function, we recommend first implementing it as a function of logits and labels, plus any other configuration parameters. For this example, lets suppose we have implemented the tempered softmax from \"Robust Bi-Tempered Logistic Loss Based on Bregman Divergences\" . This loss function takes two constant parameters t1 and t2 , which we'd like to allow users to specify in the config. Assuming we have the following function: def tempered_softmax_cross_entropy_loss ( logits : torch . Tensor , labels : torch . Tensor , t1 : float , t2 : float ) -> torch . Tensor : # Computes the loss, returns the result as a torch.Tensor.","title":"Implement loss function"},{"location":"developer_guide/add_a_loss_function/#define-and-register-module","text":"Next, we'll define a module class which computes our loss function, and add it to the loss registry for CATEGORY output features with @register_loss . LogitsInputsMixin tells Ludwig that this loss should be called with the output feature logits , which are the feature decoder outputs before normalization to a probability distribution. @register_loss ( \"tempered_softmax_cross_entropy\" , [ CATEGORY ]) class TemperedSoftmaxCrossEntropy ( torch . nn . Module , LogitsInputsMixin ): Note It is possible to define losses on other outputs besides logits but this is not used in Ludwig today. For example, loss could be computed over probabilities , but it is usually more numerically stable to compute from logits (rather than backpropagating loss through a softmax function).","title":"Define and register module"},{"location":"developer_guide/add_a_loss_function/#constructor","text":"The loss constructor will receive any parameters specified in the config as kwargs. It must provide reasonable defaults for all arguments. def __init__ ( self , t1 : float = 1.0 , t2 : float = 1.0 , ** kwargs ): super () . __init__ () self . t1 = t1 self . t2 = t2","title":"constructor"},{"location":"developer_guide/add_a_loss_function/#forward","text":"The forward method is responsible for computing the loss. Here we'll call the tempered_softmax_cross_entropy_loss after ensuring its inputs are the correct type, and return its output averaged over the batch. def forward ( self , logits : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : labels = target . long () loss = tempered_softmax_cross_entropy_loss ( logits , labels , self . t1 , self . t2 ) return torch . mean ( loss )","title":"forward"},{"location":"developer_guide/add_a_metric/","text":"Metrics are used to report model performance during training and evaluation, and also serve as optimization objectives for hyperparameter optimization . Concretely, metrics are modules which compute a function of the model's output for each batch and aggregate the function's result over all batches. A common example of a metric is the LossMetric , which computes the average batch loss. Metrics are defined in ludwig/modules/metric_modules.py . Ludwig's metrics are designed to be consistent with torchmetrics and conform to the interface of torchmetrics.Metric . Note Before implementing a new metric from scratch, check the torchmetrics documentation to see if the desired function is available there. Torch metrics can often be added to Ludwig trivially, see RMSEMetric in ludwig/modules/metric_modules.py for example. 1. Add a new metric class \u00b6 For the majority of use cases metrics should be averaged over batches, for this Ludwig provides a MeanMetric class which keeps a running average of its values. The following examples will assume averaging is desired and inherit from MeanMetric . If you need different aggregation behavior replace MeanMetric with LudwigMetric and accumulate the metric values as needed. We'll use TokenAccuracyMetric as an example, which treats each token of a sequence as an independent prediction and computes average accuracy over sequences. First, declare the new metric class in ludwig/modules/metric_modules.py : class TokenAccuracyMetric ( MeanMetric ): 2. Implement required methods \u00b6 get_current_value \u00b6 If using MeanMetric , compute the value of the metric given a batch of feature outputs and target values in get_current_value . def get_current_value ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : # Compute metric over a batch of predictions (preds) and truth values (target). # Aggregate metric over batch. return metric_value Inputs preds (torch.Tensor): A batch of outputs from an output feature which are either predictions, probabilities, or logits depending on the return value of get_inputs . target (torch.Tensor): The batch of true labels for the dataset column corresponding to the metric's output feature. Return (torch.Tensor): The computed metric, in most cases this will be a scalar value. update and reset \u00b6 If not using MeanMetric , implement update and reset instead of get_current_value . def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> None : # Compute metric over a batch of predictions (preds) and truth values (target). # Accumulate metric values or aggregate statistics. Inputs preds (torch.Tensor): A batch of outputs from an output feature which are either predictions, probabilities, or logits depending on the return value of get_inputs . target (torch.Tensor): The batch of true labels for the dataset column corresponding to the metric's output feature. def reset ( self ) -> None : # Reset accumulated values. Note MeanMetric 's update method simply delegates metric computation to get_current_value . def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> None : self . avg . update ( self . get_current_value ( preds , target )) get_objective \u00b6 The return value of get_objective tells Ludwig whether to minimize or maximize this metric in hyperparameter optimization. @classmethod def get_objective ( cls ): return MAXIMIZE Return (str): How this metric should be optimized, one of MINIMIZE or MAXIMIZE. get_inputs \u00b6 Determines which feature output is passed in to this metric's update or get_current_value method. Valid return values are: PREDICTIONS : The predicted values of the output feature. PROBABILITIES : The vector of probabilities. LOGITS : The vector of outputs of the feature decoder's final layer (before the application of any sigmoid or softmax function). @classmethod def get_inputs ( cls ): return PREDICTIONS Return (str): Which output this metric derives its value from, one of PREDICTIONS , PROBABILITIES , or LOGITS . 3. Add the new metric class to the registry \u00b6 Mapping between metric names in the config and metric classes is made by registering the class in a metric registry. The metric registry is defined in ludwig/modules/metric_registry.py . To register your class, add the @register_metric decorator on the line above its class definition, specifying the name of the metric and a list of the supported output feature types: @register_metric ( TOKEN_ACCURACY , [ SEQUENCE , TEXT ]) class TokenAccuracyMetric ( MeanMetric ):","title":"Add a Metric"},{"location":"developer_guide/add_a_metric/#1-add-a-new-metric-class","text":"For the majority of use cases metrics should be averaged over batches, for this Ludwig provides a MeanMetric class which keeps a running average of its values. The following examples will assume averaging is desired and inherit from MeanMetric . If you need different aggregation behavior replace MeanMetric with LudwigMetric and accumulate the metric values as needed. We'll use TokenAccuracyMetric as an example, which treats each token of a sequence as an independent prediction and computes average accuracy over sequences. First, declare the new metric class in ludwig/modules/metric_modules.py : class TokenAccuracyMetric ( MeanMetric ):","title":"1. Add a new metric class"},{"location":"developer_guide/add_a_metric/#2-implement-required-methods","text":"","title":"2. Implement required methods"},{"location":"developer_guide/add_a_metric/#get_current_value","text":"If using MeanMetric , compute the value of the metric given a batch of feature outputs and target values in get_current_value . def get_current_value ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : # Compute metric over a batch of predictions (preds) and truth values (target). # Aggregate metric over batch. return metric_value Inputs preds (torch.Tensor): A batch of outputs from an output feature which are either predictions, probabilities, or logits depending on the return value of get_inputs . target (torch.Tensor): The batch of true labels for the dataset column corresponding to the metric's output feature. Return (torch.Tensor): The computed metric, in most cases this will be a scalar value.","title":"get_current_value"},{"location":"developer_guide/add_a_metric/#update-and-reset","text":"If not using MeanMetric , implement update and reset instead of get_current_value . def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> None : # Compute metric over a batch of predictions (preds) and truth values (target). # Accumulate metric values or aggregate statistics. Inputs preds (torch.Tensor): A batch of outputs from an output feature which are either predictions, probabilities, or logits depending on the return value of get_inputs . target (torch.Tensor): The batch of true labels for the dataset column corresponding to the metric's output feature. def reset ( self ) -> None : # Reset accumulated values. Note MeanMetric 's update method simply delegates metric computation to get_current_value . def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> None : self . avg . update ( self . get_current_value ( preds , target ))","title":"update and reset"},{"location":"developer_guide/add_a_metric/#get_objective","text":"The return value of get_objective tells Ludwig whether to minimize or maximize this metric in hyperparameter optimization. @classmethod def get_objective ( cls ): return MAXIMIZE Return (str): How this metric should be optimized, one of MINIMIZE or MAXIMIZE.","title":"get_objective"},{"location":"developer_guide/add_a_metric/#get_inputs","text":"Determines which feature output is passed in to this metric's update or get_current_value method. Valid return values are: PREDICTIONS : The predicted values of the output feature. PROBABILITIES : The vector of probabilities. LOGITS : The vector of outputs of the feature decoder's final layer (before the application of any sigmoid or softmax function). @classmethod def get_inputs ( cls ): return PREDICTIONS Return (str): Which output this metric derives its value from, one of PREDICTIONS , PROBABILITIES , or LOGITS .","title":"get_inputs"},{"location":"developer_guide/add_a_metric/#3-add-the-new-metric-class-to-the-registry","text":"Mapping between metric names in the config and metric classes is made by registering the class in a metric registry. The metric registry is defined in ludwig/modules/metric_registry.py . To register your class, add the @register_metric decorator on the line above its class definition, specifying the name of the metric and a list of the supported output feature types: @register_metric ( TOKEN_ACCURACY , [ SEQUENCE , TEXT ]) class TokenAccuracyMetric ( MeanMetric ):","title":"3. Add the new metric class to the registry"},{"location":"developer_guide/add_a_pretrained_model/","text":"For text and images, there exist a wide selection of pre-trained models from libraries like huggingface that can be useful to leverage in a Ludwig model, for instance as an encoder. Any pre-trained model implemented as a torch.nn.Module can be used within any LudwigModule , which is itself a torch.nn.Module . For demonstration purposes, we'll walk through how to implement huggingface's pre-trained BERT model as Ludwig text encoder. We recommend reading how to add an encoder as a first step. 1. Import/load the pretrained model \u00b6 Load the pre-trained model in the LudwigModule 's constructor. @register_encoder ( \"bert\" , TEXT ) class BERTEncoder ( Encoder ): fixed_preprocessing_parameters = { \"word_tokenizer\" : \"hf_tokenizer\" , \"pretrained_model_name_or_path\" : \"feature.pretrained_model_name_or_path\" , } default_params = { \"pretrained_model_name_or_path\" : \"bert-base-uncased\" , } def __init__ ( self , max_sequence_length : int , use_pretrained : bool = True , pretrained_model_name_or_path : str = \"bert-base-uncased\" , trainable : bool = True , reduce_output : str = \"cls_pooled\" , vocab_size : int = 30522 , hidden_size : int = 768 , num_hidden_layers : int = 12 , num_attention_heads : int = 12 , intermediate_size : int = 3072 , hidden_act : Union [ str , Callable ] = \"gelu\" , hidden_dropout_prob : float = 0.1 , attention_probs_dropout_prob : float = 0.1 , max_position_embeddings : int = 512 , type_vocab_size : int = 2 , initializer_range : float = 0.02 , layer_norm_eps : float = 1e-12 , pad_token_id : int = 0 , gradient_checkpointing : bool = False , position_embedding_type : str = \"absolute\" , classifier_dropout : float = None , pretrained_kwargs : Dict = None , ** kwargs ): super () . __init__ () try : from transformers import BertConfig , BertModel except ModuleNotFoundError : logger . error ( \"The transformers library is not installed. \" \"To use the huggingface pretrained models as a Ludwig text \" \"encoders, please run pip install ludwig[text].\" ) sys . exit ( - 1 ) if use_pretrained : pretrained_kwargs = pretrained_kwargs or {} self . transformer = BertModel . from_pretrained ( pretrained_model_name_or_path , ** pretrained_kwargs ) else : config = BertConfig ( vocab_size = vocab_size , hidden_size = hidden_size , num_hidden_layers = num_hidden_layers , num_attention_heads = num_attention_heads , intermediate_size = intermediate_size , hidden_act = hidden_act , hidden_dropout_prob = hidden_dropout_prob , attention_probs_dropout_prob = attention_probs_dropout_prob , max_position_embeddings = max_position_embeddings , type_vocab_size = type_vocab_size , initializer_range = initializer_range , layer_norm_eps = layer_norm_eps , pad_token_id = pad_token_id , gradient_checkpointing = gradient_checkpointing , position_embedding_type = position_embedding_type , classifier_dropout = classifier_dropout , ) self . transformer = BertModel ( config ) self . reduce_output = reduce_output if not self . reduce_output == \"cls_pooled\" : self . reduce_sequence = SequenceReducer ( reduce_mode = reduce_output ) if trainable : self . transformer . train () self . transformer . resize_token_embeddings ( vocab_size ) self . max_sequence_length = max_sequence_length 2. Call the pre-trained model in the LudwigModule 's forward pass \u00b6 def forward ( self , inputs : torch . Tensor , mask : Optional [ torch . Tensor ] = None ) -> Dict [ str , torch . Tensor ]: if mask is not None : mask = mask . to ( torch . int32 ) transformer_outputs = self . transformer ( input_ids = inputs , attention_mask = mask , token_type_ids = torch . zeros_like ( inputs ), ) # Optionally reduce output. if self . reduce_output == \"cls_pooled\" : hidden = transformer_outputs [ 1 ] else : hidden = transformer_outputs [ 0 ][:, 1 : - 1 , :] hidden = self . reduce_sequence ( hidden , self . reduce_output ) return { \"encoder_output\" : hidden } 3. Use pre-trained models \u00b6 Once the encoder has been registered, users can use the encoder right away in their Ludwig config. input_features : - name : description type : text encoder : bert trainable : false max_sequence_length : 128 num_attention_heads : 3","title":"Add a Pretrained Model"},{"location":"developer_guide/add_a_pretrained_model/#1-importload-the-pretrained-model","text":"Load the pre-trained model in the LudwigModule 's constructor. @register_encoder ( \"bert\" , TEXT ) class BERTEncoder ( Encoder ): fixed_preprocessing_parameters = { \"word_tokenizer\" : \"hf_tokenizer\" , \"pretrained_model_name_or_path\" : \"feature.pretrained_model_name_or_path\" , } default_params = { \"pretrained_model_name_or_path\" : \"bert-base-uncased\" , } def __init__ ( self , max_sequence_length : int , use_pretrained : bool = True , pretrained_model_name_or_path : str = \"bert-base-uncased\" , trainable : bool = True , reduce_output : str = \"cls_pooled\" , vocab_size : int = 30522 , hidden_size : int = 768 , num_hidden_layers : int = 12 , num_attention_heads : int = 12 , intermediate_size : int = 3072 , hidden_act : Union [ str , Callable ] = \"gelu\" , hidden_dropout_prob : float = 0.1 , attention_probs_dropout_prob : float = 0.1 , max_position_embeddings : int = 512 , type_vocab_size : int = 2 , initializer_range : float = 0.02 , layer_norm_eps : float = 1e-12 , pad_token_id : int = 0 , gradient_checkpointing : bool = False , position_embedding_type : str = \"absolute\" , classifier_dropout : float = None , pretrained_kwargs : Dict = None , ** kwargs ): super () . __init__ () try : from transformers import BertConfig , BertModel except ModuleNotFoundError : logger . error ( \"The transformers library is not installed. \" \"To use the huggingface pretrained models as a Ludwig text \" \"encoders, please run pip install ludwig[text].\" ) sys . exit ( - 1 ) if use_pretrained : pretrained_kwargs = pretrained_kwargs or {} self . transformer = BertModel . from_pretrained ( pretrained_model_name_or_path , ** pretrained_kwargs ) else : config = BertConfig ( vocab_size = vocab_size , hidden_size = hidden_size , num_hidden_layers = num_hidden_layers , num_attention_heads = num_attention_heads , intermediate_size = intermediate_size , hidden_act = hidden_act , hidden_dropout_prob = hidden_dropout_prob , attention_probs_dropout_prob = attention_probs_dropout_prob , max_position_embeddings = max_position_embeddings , type_vocab_size = type_vocab_size , initializer_range = initializer_range , layer_norm_eps = layer_norm_eps , pad_token_id = pad_token_id , gradient_checkpointing = gradient_checkpointing , position_embedding_type = position_embedding_type , classifier_dropout = classifier_dropout , ) self . transformer = BertModel ( config ) self . reduce_output = reduce_output if not self . reduce_output == \"cls_pooled\" : self . reduce_sequence = SequenceReducer ( reduce_mode = reduce_output ) if trainable : self . transformer . train () self . transformer . resize_token_embeddings ( vocab_size ) self . max_sequence_length = max_sequence_length","title":"1. Import/load the pretrained model"},{"location":"developer_guide/add_a_pretrained_model/#2-call-the-pre-trained-model-in-the-ludwigmodules-forward-pass","text":"def forward ( self , inputs : torch . Tensor , mask : Optional [ torch . Tensor ] = None ) -> Dict [ str , torch . Tensor ]: if mask is not None : mask = mask . to ( torch . int32 ) transformer_outputs = self . transformer ( input_ids = inputs , attention_mask = mask , token_type_ids = torch . zeros_like ( inputs ), ) # Optionally reduce output. if self . reduce_output == \"cls_pooled\" : hidden = transformer_outputs [ 1 ] else : hidden = transformer_outputs [ 0 ][:, 1 : - 1 , :] hidden = self . reduce_sequence ( hidden , self . reduce_output ) return { \"encoder_output\" : hidden }","title":"2. Call the pre-trained model in the LudwigModule's forward pass"},{"location":"developer_guide/add_a_pretrained_model/#3-use-pre-trained-models","text":"Once the encoder has been registered, users can use the encoder right away in their Ludwig config. input_features : - name : description type : text encoder : bert trainable : false max_sequence_length : 128 num_attention_heads : 3","title":"3. Use pre-trained models"},{"location":"developer_guide/add_a_tokenizer/","text":"Tokenizers transform a text string into a sequence of tokens. Ludwig will call the tokenizer for each text column it is specified in, for each row of the dataset during preprocessing. It will then collect a list of unique tokens and assign an integer index to each unique token. This ordered list of unique tokens is called the vocabulary , and will be used by encoders to convert tokens to embeddings and by decoders to convert output predictions to tokens. A tokenizer is primarily responsible for splitting a string into a list of tokens, and may optionally perform other processing usually for the purpose of reducing the size of the vocabulary. Some examples of processing tokenizers may perform include: Splitting on a delimiter ex. underscore \"_\" or comma \",\". Removing punctuation characters Removing stop words, for example \"a\", \"an\", \"the\" in English. Lemmatization: Grouping inflected forms of the same word i.e. \"car\", \"cars\", \"car's\", \"cars'\" -> \"car\" A tokenizer, once registered, can be used to preprocess any text input column by specifying its name as the value of tokenizer in the preprocessing config dictionary: input_features : - name : title type : text preprocessing : tokenizer : <NEW_TOKENIZER> Tokenizers are defined in ludwig/utils/tokenizers.py . To add a tokenizer, define a new subclass of BaseTokenizer and add it to the registry. 1. Add a new tokenizer class \u00b6 Tokenizers may define an optional constructor which can receive arguments from the config. Most tokenizers have no config parameters, and do not need a constructor. For an example of a tokenizer which uses a parameter in its constructor, see HFTokenizer . The __call__ method does the actual processing, is called with a single string argument, and is expected to return a list of strings. The tokenizer will be called once for each example in the dataset during preprocessing. Preprocessed token sequences will be cached on disk in .hdf5 files and re-used in training and validation, thus the tokenizer will not be called during training. class NewTokenizer ( BaseTokenizer ): def __init__ ( self , ** kwargs ): super () . __init__ () # Initialize any variables or state def __call__ ( self , text : str ) -> List [ str ]: # tokenized_text = result of tokenizing return tokenized_text 2. Add the tokenizer to the registry \u00b6 Tokenizer names are mapped to their implementations in the tokenizer_registry dictionary at the bottom of ludwig/utils/tokenizers.py . tokenizer_registry = { \"characters\" : CharactersToListTokenizer , \"space\" : SpaceStringToListTokenizer , ... \"new_tokenizer\" : NewTokenizer , # Add your tokenizer as a new entry in the registry.","title":"Add a Tokenizer"},{"location":"developer_guide/add_a_tokenizer/#1-add-a-new-tokenizer-class","text":"Tokenizers may define an optional constructor which can receive arguments from the config. Most tokenizers have no config parameters, and do not need a constructor. For an example of a tokenizer which uses a parameter in its constructor, see HFTokenizer . The __call__ method does the actual processing, is called with a single string argument, and is expected to return a list of strings. The tokenizer will be called once for each example in the dataset during preprocessing. Preprocessed token sequences will be cached on disk in .hdf5 files and re-used in training and validation, thus the tokenizer will not be called during training. class NewTokenizer ( BaseTokenizer ): def __init__ ( self , ** kwargs ): super () . __init__ () # Initialize any variables or state def __call__ ( self , text : str ) -> List [ str ]: # tokenized_text = result of tokenizing return tokenized_text","title":"1. Add a new tokenizer class"},{"location":"developer_guide/add_a_tokenizer/#2-add-the-tokenizer-to-the-registry","text":"Tokenizer names are mapped to their implementations in the tokenizer_registry dictionary at the bottom of ludwig/utils/tokenizers.py . tokenizer_registry = { \"characters\" : CharactersToListTokenizer , \"space\" : SpaceStringToListTokenizer , ... \"new_tokenizer\" : NewTokenizer , # Add your tokenizer as a new entry in the registry.","title":"2. Add the tokenizer to the registry"},{"location":"developer_guide/add_an_encoder/","text":"1. Add a new encoder class \u00b6 Source code for encoders lives under ludwig/encoders/ . Encoders are grouped into modules by their input feature type. For instance, all new sequence encoders should be added to ludwig/encoders/sequence_encoders.py . Note An encoder may support multiple types, if so it should be defined in the module corresponding to its most generic supported type. If an encoder is generic with respect to input type, add it to ludwig/encoders/generic_encoders.py . To create a new encoder: Define a new encoder class. Inherit from ludwig.encoders.base.Encoder or one of its subclasses. Create all layers and state in the __init__ method, after calling super().__init__() . Implement your encoder's forward pass in def forward(self, inputs, mask=None): . Define @property input_shape and @property output_shape . Note: Encoder inherits from LudwigModule , which is itself a torch.nn.Module , so all the usual concerns of developing Torch modules apply. All encoder parameters should be provided as keyword arguments to the constructor, and must have a default value. For example the StackedRNN encoder takes the following list of parameters in its constructor: from ludwig.constants import AUDIO , SEQUENCE , TEXT , TIMESERIES from ludwig.encoders.base import Encoder from ludwig.encoders.registry import register_encoder @register_encoder ( \"rnn\" , [ AUDIO , SEQUENCE , TEXT , TIMESERIES ]) class StackedRNN ( Encoder ): def __init__ ( self , should_embed = True , vocab = None , representation = \"dense\" , embedding_size = 256 , embeddings_trainable = True , pretrained_embeddings = None , embeddings_on_cpu = False , num_layers = 1 , max_sequence_length = None , state_size = 256 , cell_type = \"rnn\" , bidirectional = False , activation = \"tanh\" , recurrent_activation = \"sigmoid\" , unit_forget_bias = True , recurrent_initializer = \"orthogonal\" , dropout = 0.0 , recurrent_dropout = 0.0 , fc_layers = None , num_fc_layers = 0 , output_size = 256 , use_bias = True , weights_initializer = \"xavier_uniform\" , bias_initializer = \"zeros\" , norm = None , norm_params = None , fc_activation = \"relu\" , fc_dropout = 0 , reduce_output = \"last\" , ** kwargs , ): super () . __init__ () # Initialize any modules, layers, or variable state 2. Implement forward , input_shape , and output_shape \u00b6 Actual computation of activations takes place inside the forward method of the encoder. All encoders should have the following signature: def forward ( self , inputs : torch . Tensor , mask : Optional [ torch . Tensor ] = None ): # perform forward pass # ... # output_tensor = result of forward pass return { \"encoder_output\" : output_tensor } Inputs inputs (torch.Tensor): input tensor. mask (torch.Tensor, default: None ): binary tensor indicating which values in inputs should be masked out. Note: mask is not required, and is not implemented for most encoder types. Return (dict): A dictionary containing the key encoder_output whose value is the encoder output tensor. {\"encoder_output\": output_tensor} The input_shape and output_shape properties must return the fully-specified shape of the encoder's expected input and output, without batch dimension: @property def input_shape ( self ) -> torch . Size : return torch . Size ([ self . max_sequence_length ]) @property def output_shape ( self ) -> torch . Size : return self . recurrent_stack . output_shape 3. Add the new encoder class to the encoder registry \u00b6 Mapping between encoder names in the model definition and encoder classes is made by registering the class in an encoder registry. The encoder registry is defined in ludwig/encoders/registry.py . To register your class, add the @register_encoder decorator on the line above its class definition, specifying the name of the encoder and a list of supported input feature types: @register_encoder ( \"rnn\" , [ AUDIO , SEQUENCE , TEXT , TIMESERIES ]) class StackedRNN ( Encoder ):","title":"Add an Encoder"},{"location":"developer_guide/add_an_encoder/#1-add-a-new-encoder-class","text":"Source code for encoders lives under ludwig/encoders/ . Encoders are grouped into modules by their input feature type. For instance, all new sequence encoders should be added to ludwig/encoders/sequence_encoders.py . Note An encoder may support multiple types, if so it should be defined in the module corresponding to its most generic supported type. If an encoder is generic with respect to input type, add it to ludwig/encoders/generic_encoders.py . To create a new encoder: Define a new encoder class. Inherit from ludwig.encoders.base.Encoder or one of its subclasses. Create all layers and state in the __init__ method, after calling super().__init__() . Implement your encoder's forward pass in def forward(self, inputs, mask=None): . Define @property input_shape and @property output_shape . Note: Encoder inherits from LudwigModule , which is itself a torch.nn.Module , so all the usual concerns of developing Torch modules apply. All encoder parameters should be provided as keyword arguments to the constructor, and must have a default value. For example the StackedRNN encoder takes the following list of parameters in its constructor: from ludwig.constants import AUDIO , SEQUENCE , TEXT , TIMESERIES from ludwig.encoders.base import Encoder from ludwig.encoders.registry import register_encoder @register_encoder ( \"rnn\" , [ AUDIO , SEQUENCE , TEXT , TIMESERIES ]) class StackedRNN ( Encoder ): def __init__ ( self , should_embed = True , vocab = None , representation = \"dense\" , embedding_size = 256 , embeddings_trainable = True , pretrained_embeddings = None , embeddings_on_cpu = False , num_layers = 1 , max_sequence_length = None , state_size = 256 , cell_type = \"rnn\" , bidirectional = False , activation = \"tanh\" , recurrent_activation = \"sigmoid\" , unit_forget_bias = True , recurrent_initializer = \"orthogonal\" , dropout = 0.0 , recurrent_dropout = 0.0 , fc_layers = None , num_fc_layers = 0 , output_size = 256 , use_bias = True , weights_initializer = \"xavier_uniform\" , bias_initializer = \"zeros\" , norm = None , norm_params = None , fc_activation = \"relu\" , fc_dropout = 0 , reduce_output = \"last\" , ** kwargs , ): super () . __init__ () # Initialize any modules, layers, or variable state","title":"1. Add a new encoder class"},{"location":"developer_guide/add_an_encoder/#2-implement-forward-input_shape-and-output_shape","text":"Actual computation of activations takes place inside the forward method of the encoder. All encoders should have the following signature: def forward ( self , inputs : torch . Tensor , mask : Optional [ torch . Tensor ] = None ): # perform forward pass # ... # output_tensor = result of forward pass return { \"encoder_output\" : output_tensor } Inputs inputs (torch.Tensor): input tensor. mask (torch.Tensor, default: None ): binary tensor indicating which values in inputs should be masked out. Note: mask is not required, and is not implemented for most encoder types. Return (dict): A dictionary containing the key encoder_output whose value is the encoder output tensor. {\"encoder_output\": output_tensor} The input_shape and output_shape properties must return the fully-specified shape of the encoder's expected input and output, without batch dimension: @property def input_shape ( self ) -> torch . Size : return torch . Size ([ self . max_sequence_length ]) @property def output_shape ( self ) -> torch . Size : return self . recurrent_stack . output_shape","title":"2. Implement forward, input_shape, and output_shape"},{"location":"developer_guide/add_an_encoder/#3-add-the-new-encoder-class-to-the-encoder-registry","text":"Mapping between encoder names in the model definition and encoder classes is made by registering the class in an encoder registry. The encoder registry is defined in ludwig/encoders/registry.py . To register your class, add the @register_encoder decorator on the line above its class definition, specifying the name of the encoder and a list of supported input feature types: @register_encoder ( \"rnn\" , [ AUDIO , SEQUENCE , TEXT , TIMESERIES ]) class StackedRNN ( Encoder ):","title":"3. Add the new encoder class to the encoder registry"},{"location":"developer_guide/add_an_integration/","text":"Ludwig provides an open-ended method of third-party system integration. This makes it easy to integrate other systems or services with Ludwig which can be enabled simply by passing a flag to the command line interface. To contribute an integration, follow these steps: 1. Create a Python file in ludwig/contribs/ \u00b6 The file should have an obvious name associated with the third-party system it integrates with i.e. comet.py , wandb.py . In this example, it is called my_callback.py . 2. Create Callback class \u00b6 Create a new class implementing the ludwig.callbacks.Callback interface. The new class should have a name associated with the third-party system it integrates with, matching its file name. from ludwig.callbacks import Callback class MyCallback ( Callback ): 3. Implement callback methods \u00b6 Ludwig provides the following callbacks which you can implement to add functionality to Ludwig. All the following methods are optional: def on_cmdline ( self , cmd : str , * args : List [ str ]): \"\"\"Called when Ludwig is run on the command line with the callback enabled. :param cmd: The Ludwig subcommand being run, ex. \"train\", \"evaluate\", \"predict\", ... :param args: The full list of command-line arguments (sys.argv). \"\"\" pass def on_preprocess_start ( self , config : Dict [ str , Any ]): \"\"\"Called before preprocessing starts. :param config: The config dictionary. \"\"\" pass def on_preprocess_end ( self , training_set , validation_set , test_set , training_set_metadata : Dict [ str , Any ] ): \"\"\"Called after preprocessing ends. :param training_set: The training set. :type training_set: ludwig.dataset.base.Dataset :param validation_set: The validation set. :type validation_set: ludwig.dataset.base.Dataset :param test_set: The test set. :type test_set: ludwig.dataset.base.Dataset :param training_set_metadata: Values inferred from the training set, including preprocessing settings, vocabularies, feature statistics, etc. Same as training_set_metadata.json. \"\"\" pass def on_hyperopt_init ( self , experiment_name : str ): \"\"\"Called to initialize state before hyperparameter optimization begins. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_preprocessing_start ( self , experiment_name : str ): \"\"\"Called before data preprocessing for hyperparameter optimization begins. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_preprocessing_end ( self , experiment_name : str ): \"\"\"Called after data preprocessing for hyperparameter optimization is completed. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_start ( self , experiment_name : str ): \"\"\"Called before any hyperparameter optimization trials are started. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_end ( self , experiment_name : str ): \"\"\"Called after all hyperparameter optimization trials are completed. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_trial_start ( self , parameters : Dict [ str , Any ]): \"\"\"Called before the start of each hyperparameter optimization trial. :param parameters: The complete dictionary of parameters for this hyperparameter optimization experiment. \"\"\" pass def on_hyperopt_trial_end ( self , parameters : Dict [ str , Any ]): \"\"\"Called after the end of each hyperparameter optimization trial. :param parameters: The complete dictionary of parameters for this hyperparameter optimization experiment. \"\"\" pass def on_train_init ( self , base_config : Dict [ str , Any ], experiment_directory : str , experiment_name : str , model_name : str , output_directory : str , resume : Union [ str , None ], ): \"\"\"Called after preprocessing, but before the creation of the model and trainer objects. :param base_config: The user-specified config, before the insertion of defaults or inferred values. :param experiment_directory: The experiment directory, same as output_directory if no experiment specified. :param experiment_name: The experiment name. :param model_name: The model name. :param output_directory: file path to where training results are stored. :param resume: model directory to resume training from, or None. \"\"\" pass def on_train_start ( self , model , config : Dict [ str , Any ], config_fp : Union [ str , None ], ): \"\"\"Called after creation of trainer, before the start of training. :param model: The ludwig model. :type model: ludwig.utils.torch_utils.LudwigModule :param config: The config dictionary. :param config_fp: The file path to the config, or none if config was passed to stdin. \"\"\" pass def on_train_end ( self , output_directory : str ): \"\"\"Called at the end of training, before the model is saved. :param output_directory: file path to where training results are stored. \"\"\" pass def on_trainer_train_setup ( self , trainer , save_path : str , is_coordinator : bool ): \"\"\"Called in every trainer (distributed or local) before training starts. :param trainer: The trainer instance. :type trainer: trainer: ludwig.models.Trainer :param save_path: The path to the directory model is saved in. :param is_coordinator: Is this trainer the coordinator. \"\"\" pass def on_trainer_train_teardown ( self , trainer , progress_tracker , is_coordinator : bool ): \"\"\"Called in every trainer (distributed or local) after training completes. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param is_coordinator: Is this trainer the coordinator. \"\"\" pass def on_batch_start ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator only before each batch. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_batch_end ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator only after each batch. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_epoch_start ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator only before the start of each epoch. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_epoch_end ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator only after the end of each epoch. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_validation_start ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator before validation starts. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_validation_end ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator after validation is complete. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_test_start ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator before testing starts. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_test_end ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator after testing ends. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_build_metadata_start ( self , df , mode : str ): \"\"\"Called before building metadata for dataset. :param df: The dataset. :type df: pd.DataFrame :param mode: \"prediction\", \"training\", or None. \"\"\" pass def on_build_metadata_end ( self , df , mode ): \"\"\"Called after building dataset metadata. :param df: The dataset. :type df: pd.DataFrame :param mode: \"prediction\", \"training\", or None. \"\"\" pass def on_build_data_start ( self , df , mode ): \"\"\"Called before build_data, which does preprocessing, handling missing values, adding metadata to training_set_metadata. :param df: The dataset. :type df: pd.DataFrame :param mode: \"prediction\", \"training\", or None. \"\"\" pass def on_build_data_end ( self , df , mode ): \"\"\"Called after build_data completes. :param df: The dataset. :type df: pd.DataFrame :param mode: \"prediction\", \"training\", or None. \"\"\" pass def on_evaluation_start ( self ): \"\"\"Called before preprocessing for evaluation.\"\"\" pass def on_evaluation_end ( self ): \"\"\"Called after evaluation is complete.\"\"\" pass def on_visualize_figure ( self , fig ): \"\"\"Called after a visualization is generated. :param fig: The figure. :type fig: matplotlib.figure.Figure \"\"\" pass def prepare_ray_tune ( self , train_fn : Callable , tune_config : Dict [ str , Any ], tune_callbacks : List [ Callable ] ): \"\"\"Configures Ray Tune callback and config. :param train_fn: The function which runs the experiment trial. :param tune_config: The ray tune configuration dictionary. :param tune_callbacks: List of callbacks (not used yet). :returns: Tuple[Callable, Dict] The train_fn and tune_config, which will be passed to ray tune. \"\"\" return train_fn , tune_config @staticmethod def preload (): \"\"\"Will always be called when Ludwig CLI is invoked, preload gives the callback an opportunity to import or create any shared resources. Importing required 3rd-party libraries should be done here i.e. import wandb. preload is guaranteed to be called before any other callback method, and will only be called once per process. \"\"\" pass If you would like to add additional actions not already handled by the above: Add them to the appropriate calling location. Add the associated method to your callback class. Write a docstring, and add it to this documentation page. See existing calls in ludwig/callbacks.py as a pattern to follow. 4. Import the new callback \u00b6 In ludwig/contribs/__init__.py add an import in this pattern, using your module and class names: from my_callback import MyCallback 5. Register a flag for the callback \u00b6 In ludwig/contribs/__init__.py in the contrib_registry[\"classes\"] dictionary, add a key/value pair where the key is the flag which enables the callback and the value is the class: contrib_registry = { ... , \"myflag\" : MyCallback , }","title":"Add an Integration"},{"location":"developer_guide/add_an_integration/#1-create-a-python-file-in-ludwigcontribs","text":"The file should have an obvious name associated with the third-party system it integrates with i.e. comet.py , wandb.py . In this example, it is called my_callback.py .","title":"1. Create a Python file in ludwig/contribs/"},{"location":"developer_guide/add_an_integration/#2-create-callback-class","text":"Create a new class implementing the ludwig.callbacks.Callback interface. The new class should have a name associated with the third-party system it integrates with, matching its file name. from ludwig.callbacks import Callback class MyCallback ( Callback ):","title":"2. Create Callback class"},{"location":"developer_guide/add_an_integration/#3-implement-callback-methods","text":"Ludwig provides the following callbacks which you can implement to add functionality to Ludwig. All the following methods are optional: def on_cmdline ( self , cmd : str , * args : List [ str ]): \"\"\"Called when Ludwig is run on the command line with the callback enabled. :param cmd: The Ludwig subcommand being run, ex. \"train\", \"evaluate\", \"predict\", ... :param args: The full list of command-line arguments (sys.argv). \"\"\" pass def on_preprocess_start ( self , config : Dict [ str , Any ]): \"\"\"Called before preprocessing starts. :param config: The config dictionary. \"\"\" pass def on_preprocess_end ( self , training_set , validation_set , test_set , training_set_metadata : Dict [ str , Any ] ): \"\"\"Called after preprocessing ends. :param training_set: The training set. :type training_set: ludwig.dataset.base.Dataset :param validation_set: The validation set. :type validation_set: ludwig.dataset.base.Dataset :param test_set: The test set. :type test_set: ludwig.dataset.base.Dataset :param training_set_metadata: Values inferred from the training set, including preprocessing settings, vocabularies, feature statistics, etc. Same as training_set_metadata.json. \"\"\" pass def on_hyperopt_init ( self , experiment_name : str ): \"\"\"Called to initialize state before hyperparameter optimization begins. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_preprocessing_start ( self , experiment_name : str ): \"\"\"Called before data preprocessing for hyperparameter optimization begins. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_preprocessing_end ( self , experiment_name : str ): \"\"\"Called after data preprocessing for hyperparameter optimization is completed. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_start ( self , experiment_name : str ): \"\"\"Called before any hyperparameter optimization trials are started. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_end ( self , experiment_name : str ): \"\"\"Called after all hyperparameter optimization trials are completed. :param experiment_name: The name of the current experiment. \"\"\" pass def on_hyperopt_trial_start ( self , parameters : Dict [ str , Any ]): \"\"\"Called before the start of each hyperparameter optimization trial. :param parameters: The complete dictionary of parameters for this hyperparameter optimization experiment. \"\"\" pass def on_hyperopt_trial_end ( self , parameters : Dict [ str , Any ]): \"\"\"Called after the end of each hyperparameter optimization trial. :param parameters: The complete dictionary of parameters for this hyperparameter optimization experiment. \"\"\" pass def on_train_init ( self , base_config : Dict [ str , Any ], experiment_directory : str , experiment_name : str , model_name : str , output_directory : str , resume : Union [ str , None ], ): \"\"\"Called after preprocessing, but before the creation of the model and trainer objects. :param base_config: The user-specified config, before the insertion of defaults or inferred values. :param experiment_directory: The experiment directory, same as output_directory if no experiment specified. :param experiment_name: The experiment name. :param model_name: The model name. :param output_directory: file path to where training results are stored. :param resume: model directory to resume training from, or None. \"\"\" pass def on_train_start ( self , model , config : Dict [ str , Any ], config_fp : Union [ str , None ], ): \"\"\"Called after creation of trainer, before the start of training. :param model: The ludwig model. :type model: ludwig.utils.torch_utils.LudwigModule :param config: The config dictionary. :param config_fp: The file path to the config, or none if config was passed to stdin. \"\"\" pass def on_train_end ( self , output_directory : str ): \"\"\"Called at the end of training, before the model is saved. :param output_directory: file path to where training results are stored. \"\"\" pass def on_trainer_train_setup ( self , trainer , save_path : str , is_coordinator : bool ): \"\"\"Called in every trainer (distributed or local) before training starts. :param trainer: The trainer instance. :type trainer: trainer: ludwig.models.Trainer :param save_path: The path to the directory model is saved in. :param is_coordinator: Is this trainer the coordinator. \"\"\" pass def on_trainer_train_teardown ( self , trainer , progress_tracker , is_coordinator : bool ): \"\"\"Called in every trainer (distributed or local) after training completes. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param is_coordinator: Is this trainer the coordinator. \"\"\" pass def on_batch_start ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator only before each batch. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_batch_end ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator only after each batch. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_epoch_start ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator only before the start of each epoch. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_epoch_end ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator only after the end of each epoch. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_validation_start ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator before validation starts. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_validation_end ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator after validation is complete. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_test_start ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator before testing starts. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_test_end ( self , trainer , progress_tracker , save_path : str ): \"\"\"Called on coordinator after testing ends. :param trainer: The trainer instance. :type trainer: ludwig.models.trainer.Trainer :param progress_tracker: An object which tracks training progress. :type progress_tracker: ludwig.models.trainer.ProgressTracker :param save_path: The path to the directory model is saved in. \"\"\" pass def on_build_metadata_start ( self , df , mode : str ): \"\"\"Called before building metadata for dataset. :param df: The dataset. :type df: pd.DataFrame :param mode: \"prediction\", \"training\", or None. \"\"\" pass def on_build_metadata_end ( self , df , mode ): \"\"\"Called after building dataset metadata. :param df: The dataset. :type df: pd.DataFrame :param mode: \"prediction\", \"training\", or None. \"\"\" pass def on_build_data_start ( self , df , mode ): \"\"\"Called before build_data, which does preprocessing, handling missing values, adding metadata to training_set_metadata. :param df: The dataset. :type df: pd.DataFrame :param mode: \"prediction\", \"training\", or None. \"\"\" pass def on_build_data_end ( self , df , mode ): \"\"\"Called after build_data completes. :param df: The dataset. :type df: pd.DataFrame :param mode: \"prediction\", \"training\", or None. \"\"\" pass def on_evaluation_start ( self ): \"\"\"Called before preprocessing for evaluation.\"\"\" pass def on_evaluation_end ( self ): \"\"\"Called after evaluation is complete.\"\"\" pass def on_visualize_figure ( self , fig ): \"\"\"Called after a visualization is generated. :param fig: The figure. :type fig: matplotlib.figure.Figure \"\"\" pass def prepare_ray_tune ( self , train_fn : Callable , tune_config : Dict [ str , Any ], tune_callbacks : List [ Callable ] ): \"\"\"Configures Ray Tune callback and config. :param train_fn: The function which runs the experiment trial. :param tune_config: The ray tune configuration dictionary. :param tune_callbacks: List of callbacks (not used yet). :returns: Tuple[Callable, Dict] The train_fn and tune_config, which will be passed to ray tune. \"\"\" return train_fn , tune_config @staticmethod def preload (): \"\"\"Will always be called when Ludwig CLI is invoked, preload gives the callback an opportunity to import or create any shared resources. Importing required 3rd-party libraries should be done here i.e. import wandb. preload is guaranteed to be called before any other callback method, and will only be called once per process. \"\"\" pass If you would like to add additional actions not already handled by the above: Add them to the appropriate calling location. Add the associated method to your callback class. Write a docstring, and add it to this documentation page. See existing calls in ludwig/callbacks.py as a pattern to follow.","title":"3. Implement callback methods"},{"location":"developer_guide/add_an_integration/#4-import-the-new-callback","text":"In ludwig/contribs/__init__.py add an import in this pattern, using your module and class names: from my_callback import MyCallback","title":"4. Import the new callback"},{"location":"developer_guide/add_an_integration/#5-register-a-flag-for-the-callback","text":"In ludwig/contribs/__init__.py in the contrib_registry[\"classes\"] dictionary, add a key/value pair where the key is the flag which enables the callback and the value is the class: contrib_registry = { ... , \"myflag\" : MyCallback , }","title":"5. Register a flag for the callback"},{"location":"developer_guide/codebase_structure/","text":"\u251c\u2500\u2500 docker - Ludwig Docker images \u251c\u2500\u2500 examples - Configs demonstrating Ludwig on various tasks \u251c\u2500\u2500 ludwig - Ludwig library source code \u2502 \u251c\u2500\u2500 automl - Configurations, defaults, and utilities for AutoML \u2502 \u251c\u2500\u2500 backend - Execution backends (local, horovod, ray) \u2502 \u251c\u2500\u2500 combiners \u2502 \u251c\u2500\u2500 contribs - 3rd-party integrations (MLFlow, WandB, Comet) \u2502 \u251c\u2500\u2500 data - Data loading, pre/postprocessing, sampling \u2502 \u251c\u2500\u2500 datasets - Datasets provided by the ludwig.datasets API \u2502 \u251c\u2500\u2500 decoders - Output feature decoders \u2502 \u251c\u2500\u2500 encoders - Input feature encoders \u2502 \u251c\u2500\u2500 features - Implementations of feature types \u2502 \u251c\u2500\u2500 hyperopt \u2502 \u251c\u2500\u2500 models - Implementations of ECD, trainer, predictor. \u2502 \u251c\u2500\u2500 modules - Torch modules including layers, metrics, and losses \u2502 \u251c\u2500\u2500 utils \u2502 \u251c\u2500\u2500 api.py - Entry point for python API. Declares LudwigModel. \u2502 \u2514\u2500\u2500 cli.py - ludwig command-line tool \u2514\u2500\u2500 tests \u251c\u2500\u2500 integration_tests - End-to-end tests of Ludwig workflows \u2514\u2500\u2500 ludwig - Unit tests. Subdirectories match ludwig/ structure The codebase is organized in a modular, datatype / feature centric way. Adding a feature for a new datatype can be done with minimal edits to existing code: Add a module implementing the new feature Import it in the appropriate registry file i.e. ludwig/features/feature_registries.py Add the new module to the intended registries i.e. input_type_registry All datatype-specific logic lives in the corresponding feature module, all of which are under ludwig/features/ . Features \u00b6 Feature classes provide raw data preprocessing logic specific to each data type in datatype mixin classes, i.e. BinaryFeatureMixin , NumberFeatureMixin , CategoryFeatureMixin . Feature mixins contain data preprocessing functions to obtain feature metadata ( get_feature_meta , one-time dataset-wide operations to collect things like min, max, average, vocabulary, etc.) and to transform raw data into tensors using the previously calculated metadata ( add_feature_data , which usually work on a dataset row basis). Output features also contain datatype-specific logic to compute data postprocessing, to transform model predictions back into data space, and output metrics such as loss, accuracy, etc... Model Architectures \u00b6 Encoders and decoders are modularized as well (they are under ludwig/encoders/ and ludwig/decoders/ respectively) so that they can be used by multiple features. For example sequence encoders are shared by text, sequence, and timeseries features. Various model architecture components which can be reused are also split into dedicated modules (i.e. convolutional modules, fully connected layers, attention, etc...) which are available in ludwig/modules/ . Training and Inference \u00b6 The training logic resides in ludwig/models/trainer.py which initializes a training session, feeds the data, and executes the training loop. Prediction logic including batch prediction and evaluation resides in ludwig/models/predictor.py . Ludwig CLI \u00b6 The command line interface is managed by the ludwig/cli.py script, which imports the other scripts in the ludwig/ top-level directory which perform various sub-commands (experiment, evaluate, export, visualize, etc...). The programmatic interface (which is also used by the CLI commands) is available in the ludwig/api.py . Testing \u00b6 All test code is in the tests/ directory. The tests/integration_tests/ subdirectory contains test cases which aim to provide end-to-end test coverage of all workflows provided by Ludwig. The tests/ludwig/ directory contains unit tests, organized in a subdirectory tree parallel to the ludwig/ source tree. For more details on testing, see Style Guidelines and Tests . Misc \u00b6 Hyperparameter optimization logic is implemented in the scripts in the ludwig/hyperopt/ package. The ludwig/utils/ package contains various utilities used by all other packages. Finally the ludwig/contrib/ packages contains user contributed code that integrates with external libraries.","title":"Codebase Structure"},{"location":"developer_guide/codebase_structure/#features","text":"Feature classes provide raw data preprocessing logic specific to each data type in datatype mixin classes, i.e. BinaryFeatureMixin , NumberFeatureMixin , CategoryFeatureMixin . Feature mixins contain data preprocessing functions to obtain feature metadata ( get_feature_meta , one-time dataset-wide operations to collect things like min, max, average, vocabulary, etc.) and to transform raw data into tensors using the previously calculated metadata ( add_feature_data , which usually work on a dataset row basis). Output features also contain datatype-specific logic to compute data postprocessing, to transform model predictions back into data space, and output metrics such as loss, accuracy, etc...","title":"Features"},{"location":"developer_guide/codebase_structure/#model-architectures","text":"Encoders and decoders are modularized as well (they are under ludwig/encoders/ and ludwig/decoders/ respectively) so that they can be used by multiple features. For example sequence encoders are shared by text, sequence, and timeseries features. Various model architecture components which can be reused are also split into dedicated modules (i.e. convolutional modules, fully connected layers, attention, etc...) which are available in ludwig/modules/ .","title":"Model Architectures"},{"location":"developer_guide/codebase_structure/#training-and-inference","text":"The training logic resides in ludwig/models/trainer.py which initializes a training session, feeds the data, and executes the training loop. Prediction logic including batch prediction and evaluation resides in ludwig/models/predictor.py .","title":"Training and Inference"},{"location":"developer_guide/codebase_structure/#ludwig-cli","text":"The command line interface is managed by the ludwig/cli.py script, which imports the other scripts in the ludwig/ top-level directory which perform various sub-commands (experiment, evaluate, export, visualize, etc...). The programmatic interface (which is also used by the CLI commands) is available in the ludwig/api.py .","title":"Ludwig CLI"},{"location":"developer_guide/codebase_structure/#testing","text":"All test code is in the tests/ directory. The tests/integration_tests/ subdirectory contains test cases which aim to provide end-to-end test coverage of all workflows provided by Ludwig. The tests/ludwig/ directory contains unit tests, organized in a subdirectory tree parallel to the ludwig/ source tree. For more details on testing, see Style Guidelines and Tests .","title":"Testing"},{"location":"developer_guide/codebase_structure/#misc","text":"Hyperparameter optimization logic is implemented in the scripts in the ludwig/hyperopt/ package. The ludwig/utils/ package contains various utilities used by all other packages. Finally the ludwig/contrib/ packages contains user contributed code that integrates with external libraries.","title":"Misc"},{"location":"developer_guide/contributing/","text":"Contributing \u00b6 Everybody is welcome to contribute, and we value everybody\u2019s contribution. Code is thus not the only way to help the community. Answering questions, helping others, reaching out and improving the documentation are immensely valuable contributions as well. It also helps us if you spread the word: reference the library in blog posts on the awesome projects it made possible, shout out on Twitter every time it has helped you, or simply star the repo to say \"thank you\". Check out the official ludwig docs to get oriented around the codebase, and join the community! Open Issues \u00b6 Issues are listed at: https://github.com/ludwig-ai/ludwig/issues If you would like to work on any of them, make sure it is not already assigned to someone else. You can self-assign it by commenting on the Issue page with one of the keywords: #take or #self-assign . Work on your self-assigned issue and eventually create a Pull Request. Creating Pull Requests \u00b6 Fork the repository by clicking on the \"Fork\" button on the repository's page. This creates a copy of the code under your GitHub user account. Clone your fork to your local disk, and add the base repository as a remote: git clone git@github.com:<your Github handle>/ludwig.git cd ludwig git remote add upstream https://github.com/ludwig-ai/ludwig.git Create a new branch to hold your development changes: git checkout -b a-descriptive-name-for-my-changes Do not work on the master branch. Set up a development environment by running the following command in a virtual environment: pip install -e . pip install pre-commit pre-commit install Develop features on your branch. Format your code by running pre-commits so that your newly added files look nice: pre-commit run Pre-commits also run automatically when committing. Once you're happy with your changes, make a commit to record your changes locally: git add . git commit It is a good idea to sync your copy of the code with the original repository regularly. This way you can quickly account for changes: git fetch upstream git rebase upstream/master Push the changes to your account using: git push -u origin a-descriptive-name-for-my-changes Once you are satisfied, go the webpage of your fork on GitHub. Click on \"Pull request\" to send your contribution to the project maintainers for review. Other tips \u00b6 Add unit tests for any new code you write. Make sure tests pass. See the Developer Guide for more details. Attribution \u00b6 This contributing guideline is adapted from huggingface , available at https://github.com/huggingface/datasets/blob/master/CONTRIBUTING.md . Code of Conduct \u00b6 Please be mindful of and adhere to the Linux Foundation's Code of Conduct when contributing to Ludwig.","title":"How to Contribute"},{"location":"developer_guide/contributing/#contributing","text":"Everybody is welcome to contribute, and we value everybody\u2019s contribution. Code is thus not the only way to help the community. Answering questions, helping others, reaching out and improving the documentation are immensely valuable contributions as well. It also helps us if you spread the word: reference the library in blog posts on the awesome projects it made possible, shout out on Twitter every time it has helped you, or simply star the repo to say \"thank you\". Check out the official ludwig docs to get oriented around the codebase, and join the community!","title":"Contributing"},{"location":"developer_guide/contributing/#open-issues","text":"Issues are listed at: https://github.com/ludwig-ai/ludwig/issues If you would like to work on any of them, make sure it is not already assigned to someone else. You can self-assign it by commenting on the Issue page with one of the keywords: #take or #self-assign . Work on your self-assigned issue and eventually create a Pull Request.","title":"Open Issues"},{"location":"developer_guide/contributing/#creating-pull-requests","text":"Fork the repository by clicking on the \"Fork\" button on the repository's page. This creates a copy of the code under your GitHub user account. Clone your fork to your local disk, and add the base repository as a remote: git clone git@github.com:<your Github handle>/ludwig.git cd ludwig git remote add upstream https://github.com/ludwig-ai/ludwig.git Create a new branch to hold your development changes: git checkout -b a-descriptive-name-for-my-changes Do not work on the master branch. Set up a development environment by running the following command in a virtual environment: pip install -e . pip install pre-commit pre-commit install Develop features on your branch. Format your code by running pre-commits so that your newly added files look nice: pre-commit run Pre-commits also run automatically when committing. Once you're happy with your changes, make a commit to record your changes locally: git add . git commit It is a good idea to sync your copy of the code with the original repository regularly. This way you can quickly account for changes: git fetch upstream git rebase upstream/master Push the changes to your account using: git push -u origin a-descriptive-name-for-my-changes Once you are satisfied, go the webpage of your fork on GitHub. Click on \"Pull request\" to send your contribution to the project maintainers for review.","title":"Creating Pull Requests"},{"location":"developer_guide/contributing/#other-tips","text":"Add unit tests for any new code you write. Make sure tests pass. See the Developer Guide for more details.","title":"Other tips"},{"location":"developer_guide/contributing/#attribution","text":"This contributing guideline is adapted from huggingface , available at https://github.com/huggingface/datasets/blob/master/CONTRIBUTING.md .","title":"Attribution"},{"location":"developer_guide/contributing/#code-of-conduct","text":"Please be mindful of and adhere to the Linux Foundation's Code of Conduct when contributing to Ludwig.","title":"Code of Conduct"},{"location":"developer_guide/release_process/","text":"Standard release process \u00b6 1. Determine the version name \u00b6 Note Version names always begin with v . Examples of version names: \"vX.Y\" # Release major version X (starts at 0), minor version Y (starts at 1). \"vX.Y.Z\" # Release major version X (starts at 0), minor version Y (starts at 1), patch Z (starts at 1). \"vX.YrcZ\" # Release candidate Z, without a period. (starts at 1) \"vX.Y.dev\" # Developer version, with a period. Inspiration: Python pre-releases . PEP0440 pre-releases . 2. Update Ludwig versions in code \u00b6 Create a new branch off of a target_release_branch, e.g. master or release-X.Y . git checkout <TARGET_RELEASE_BRANCH> git checkout -b ludwig_release git push --set-upstream origin ludwig_release Update the versions referenced in globals and setup. Reference PR . git commit -m \"Update ludwig version to vX.YrcZ.\" git push Create a PR with the change requesting a merge from ludwig_release to the target branch. Get approval from a Ludwig maintainer . Merge PR (with squashing). 3. Tag the latest commit, and push the tag \u00b6 After merging the PR from step 2, the latest commit on the target_release_branch should be the PR that upgrades ludwig versions in code. Pull the change from head. git checkout <TARGET_RELEASE_BRANCH> git pull Add a tag to the commit locally: git tag -a vX.YrcZ -m \"Ludwig vX.YrcZ\" Push tags to the repo. git push --follow-tags 4. In Github, go to releases and \"Draft a new release\" \u00b6 Loom walk-through . Release candidates don't need release notes. Full releases should have detailed release notes. All releases should include a full list of changes (Github supports generating this automatically). Do not upload assets manually. These will be created automatically by Github. For release candidates, check \"pre-release\". 5. Click publish \u00b6 When the release notes are ready, click Publish release on Github. Ludwig's CI will automatically update PyPI. 6. Update Ludwig docs \u00b6 Check that the Ludwig PyPi has been updated with the newest version. Go to the ludwig-docs repo and update the auto-generated docs there. > cd ludwig-docs > git pull > git checkout -b update_docs > pip install ludwig --upgrade > python code_doc_autogen.py If there are any changes, commit them. > git commit -m \"Update auto-generated docs.\" > git push --set-upstream origin update_docs Create a PR. 7. For major releases, create an release-X.Y branch \u00b6 > git checkout master > git checkout -b release-X.Y > git push --set-upstream origin release-X.Y All subsequent minor releases on top of this major version will be based from this branch. 8. Spread the word \u00b6 Announce the release on Slack. Ludwig X.Y.Z Released Features: Improvements to <CONTENT>. See <LINK>release notes<LINK> for complete details. Docs: https://ludwig.ai/latest/ If it's a major version release, consider other forms of publicization like coordinating sharing the release on other social media, or writing a blog post. Cherrypicking bugfix commits from master to stable release branches \u00b6 1. Gather a list of commit hashes that should be cherrypicked \u00b6 You can use either the full hashes from git log or partial hashes from the Github PR UI, i.e. 2. Cherry pick each commit in a cherrypick-X.Y branch \u00b6 git checkout release-X.Y git checkout -b cherrypick-X.Y git cherry-pick <commit_1> # One commit at a time. git cherry-pick <commit_2> <commit_3> <commit_4> ... # Or multiple commits all at once. Ensure that all cherry-picks have been correctly applied. Note Empty cherry-picks could mean that that commit already exists. 3. Create a PR with the cherry-pick changes, merging into release-X.Y \u00b6 Push the cherrypick branch. git push --set-upstream origin cherrypick-X.Y Create a PR with the change requesting a merge from cherrypick-X.Y to release-X.Y . Get approval from a Ludwig maintainer . Merge PR without squashing. Continue with the standard release process . Appendix \u00b6 Oops, more PRs were merged after the version bump \u00b6 If there were some last minute PRs merged after the version bump, reorder the commits to make the version bump be the last commit that gets tagged before the release. Reordering Commits in Git Oops, I tagged the wrong commit, and pushed it to github already \u00b6 git tag -d <tagname> # delete the old tag locally git push origin :refs/tags/<tagname> # delete the old tag remotely git tag <tagname> <commitId> # make a new tag locally git push origin <tagname> # push the new local tag to the remote","title":"Release Process"},{"location":"developer_guide/release_process/#standard-release-process","text":"","title":"Standard release process"},{"location":"developer_guide/release_process/#1-determine-the-version-name","text":"Note Version names always begin with v . Examples of version names: \"vX.Y\" # Release major version X (starts at 0), minor version Y (starts at 1). \"vX.Y.Z\" # Release major version X (starts at 0), minor version Y (starts at 1), patch Z (starts at 1). \"vX.YrcZ\" # Release candidate Z, without a period. (starts at 1) \"vX.Y.dev\" # Developer version, with a period. Inspiration: Python pre-releases . PEP0440 pre-releases .","title":"1. Determine the version name"},{"location":"developer_guide/release_process/#2-update-ludwig-versions-in-code","text":"Create a new branch off of a target_release_branch, e.g. master or release-X.Y . git checkout <TARGET_RELEASE_BRANCH> git checkout -b ludwig_release git push --set-upstream origin ludwig_release Update the versions referenced in globals and setup. Reference PR . git commit -m \"Update ludwig version to vX.YrcZ.\" git push Create a PR with the change requesting a merge from ludwig_release to the target branch. Get approval from a Ludwig maintainer . Merge PR (with squashing).","title":"2. Update Ludwig versions in code"},{"location":"developer_guide/release_process/#3-tag-the-latest-commit-and-push-the-tag","text":"After merging the PR from step 2, the latest commit on the target_release_branch should be the PR that upgrades ludwig versions in code. Pull the change from head. git checkout <TARGET_RELEASE_BRANCH> git pull Add a tag to the commit locally: git tag -a vX.YrcZ -m \"Ludwig vX.YrcZ\" Push tags to the repo. git push --follow-tags","title":"3. Tag the latest commit, and push the tag"},{"location":"developer_guide/release_process/#4-in-github-go-to-releases-and-draft-a-new-release","text":"Loom walk-through . Release candidates don't need release notes. Full releases should have detailed release notes. All releases should include a full list of changes (Github supports generating this automatically). Do not upload assets manually. These will be created automatically by Github. For release candidates, check \"pre-release\".","title":"4. In Github, go to releases and \"Draft a new release\""},{"location":"developer_guide/release_process/#5-click-publish","text":"When the release notes are ready, click Publish release on Github. Ludwig's CI will automatically update PyPI.","title":"5. Click publish"},{"location":"developer_guide/release_process/#6-update-ludwig-docs","text":"Check that the Ludwig PyPi has been updated with the newest version. Go to the ludwig-docs repo and update the auto-generated docs there. > cd ludwig-docs > git pull > git checkout -b update_docs > pip install ludwig --upgrade > python code_doc_autogen.py If there are any changes, commit them. > git commit -m \"Update auto-generated docs.\" > git push --set-upstream origin update_docs Create a PR.","title":"6. Update Ludwig docs"},{"location":"developer_guide/release_process/#7-for-major-releases-create-an-release-xy-branch","text":"> git checkout master > git checkout -b release-X.Y > git push --set-upstream origin release-X.Y All subsequent minor releases on top of this major version will be based from this branch.","title":"7. For major releases, create an release-X.Y branch"},{"location":"developer_guide/release_process/#8-spread-the-word","text":"Announce the release on Slack. Ludwig X.Y.Z Released Features: Improvements to <CONTENT>. See <LINK>release notes<LINK> for complete details. Docs: https://ludwig.ai/latest/ If it's a major version release, consider other forms of publicization like coordinating sharing the release on other social media, or writing a blog post.","title":"8. Spread the word"},{"location":"developer_guide/release_process/#cherrypicking-bugfix-commits-from-master-to-stable-release-branches","text":"","title":"Cherrypicking bugfix commits from master to stable release branches"},{"location":"developer_guide/release_process/#1-gather-a-list-of-commit-hashes-that-should-be-cherrypicked","text":"You can use either the full hashes from git log or partial hashes from the Github PR UI, i.e.","title":"1. Gather a list of commit hashes that should be cherrypicked"},{"location":"developer_guide/release_process/#2-cherry-pick-each-commit-in-a-cherrypick-xy-branch","text":"git checkout release-X.Y git checkout -b cherrypick-X.Y git cherry-pick <commit_1> # One commit at a time. git cherry-pick <commit_2> <commit_3> <commit_4> ... # Or multiple commits all at once. Ensure that all cherry-picks have been correctly applied. Note Empty cherry-picks could mean that that commit already exists.","title":"2. Cherry pick each commit in a cherrypick-X.Y branch"},{"location":"developer_guide/release_process/#3-create-a-pr-with-the-cherry-pick-changes-merging-into-release-xy","text":"Push the cherrypick branch. git push --set-upstream origin cherrypick-X.Y Create a PR with the change requesting a merge from cherrypick-X.Y to release-X.Y . Get approval from a Ludwig maintainer . Merge PR without squashing. Continue with the standard release process .","title":"3. Create a PR with the cherry-pick changes, merging into release-X.Y"},{"location":"developer_guide/release_process/#appendix","text":"","title":"Appendix"},{"location":"developer_guide/release_process/#oops-more-prs-were-merged-after-the-version-bump","text":"If there were some last minute PRs merged after the version bump, reorder the commits to make the version bump be the last commit that gets tagged before the release. Reordering Commits in Git","title":"Oops, more PRs were merged after the version bump"},{"location":"developer_guide/release_process/#oops-i-tagged-the-wrong-commit-and-pushed-it-to-github-already","text":"git tag -d <tagname> # delete the old tag locally git push origin :refs/tags/<tagname> # delete the old tag remotely git tag <tagname> <commitId> # make a new tag locally git push origin <tagname> # push the new local tag to the remote","title":"Oops, I tagged the wrong commit, and pushed it to github already"},{"location":"developer_guide/run_tests_on_gpu_using_ray/","text":"As part of Ludwig's GitHub actions PR checks, all Ludwig tests must pass with and without GPU availability. To debug a specific test on GPU, it may be useful to run Ludwig GPU tests using Ray. Setup \u00b6 1. Set up an AWS AMI with a GPU \u00b6 Reach out to your AWS account administrator, or set up an account for yourself . 2. Test if you have the AWS CLI \u00b6 aws s3 ls If not, install it from here . 3. Set up AWS keys \u00b6 AWS Credentials [you will need to set this up for Ray to authenticate you] How to create AWS Access Key ID Once created, download your access key so you can refer to it. Run aws configure to configure your AWS CLI with your access credentials Configuration and credential file settings - AWS Command Line Interface (optional) Get an AWS PEM file Not needed for unit tests on GPU, which never spins up new nodes, but it will be needed if you ever want to enable Ray to launch new nodes. Amazon EC2 key pairs and Linux instances - Amazon Elastic Compute Cloud 4. Get Ray \u00b6 Install ray locally: pip install -U \"ray[default]\" boto3 5. Set up a Ray Config \u00b6 vim $HOME /.clusters/cluster.yaml Copy the sample ray config below and edit all the <...> values to match your local dev environment. cluster_name : <$USER>-ludwig-ray-g4dn max_workers : 3 docker : image : \"ludwigai/ludwig-ray-gpu:master\" container_name : \"ray_container\" pull_before_run : True run_options : # Extra options to pass into \"docker run\" - --ulimit nofile=65536:65536 provider : type : aws region : <us-east-2> availability_zone : <us-east-2a> available_node_types : ray.head.default : resources : {} node_config : InstanceType : g4dn.4xlarge ImageId : latest_dlami BlockDeviceMappings : - DeviceName : /dev/sda1 Ebs : VolumeSize : 100 ray.worker.default : min_workers : 0 max_workers : 0 resources : {} node_config : InstanceType : g4dn.4xlarge ImageId : latest_dlami head_node_type : ray.head.default file_mounts : { /home/ubuntu/ludwig/ : </Users/$USER/ludwig> , # Ludwig Repo. /home/ray/.aws : </Users/$USER/.aws> , # AWS credentials. } rsync_exclude : - \"**/.git\" - \"**/.git/**\" rsync_filter : - \".gitignore\" setup_commands : - pip uninstall -y ludwig && pip install -e /home/ubuntu/ludwig/. - pip install s3fs==2021.10.0 aiobotocore==1.4.2 boto3==1.17.106 - pip install pandas==1.1.4 - pip install hydra-core --upgrade head_start_ray_commands : - ray stop --force - ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml worker_start_ray_commands : - ray stop --force - ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076 Set an environment variable mapping to the location (can be relative) of your cluster config: export CLUSTER = \" $HOME /.clusters/cluster.yaml\" Developer Workflow \u00b6 (once) Launch the ray cluster \u00b6 export CLUSTER=\"$HOME/cluster_g4dn.yaml\" export CLUSTER_CPU=\"$HOME/cluster_cpu.yaml\" ray up $CLUSTER Make local changes \u00b6 Run tests locally. pytest tests/... Rsync your local changes to the ray GPU cluster \u00b6 ray rsync_up $CLUSTER -A '/Users/$USER/ludwig/' '/home/ubuntu/ludwig' ray rsync_up $CLUSTER_CPU -A '/Users/$USER/ludwig/' '/home/ubuntu/ludwig' Warning The trailing backslash / is important! Run tests on the GPU cluster from the Ray-mounted ludwig directory \u00b6 ray exec $CLUSTER \"cd /home/ubuntu/ludwig && pytest tests/\" You can also connect directly to a terminal on the cluster head: ray attach $CLUSTER","title":"Run Tests on GPU Using Ray"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#setup","text":"","title":"Setup"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#1-set-up-an-aws-ami-with-a-gpu","text":"Reach out to your AWS account administrator, or set up an account for yourself .","title":"1. Set up an AWS AMI with a GPU"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#2-test-if-you-have-the-aws-cli","text":"aws s3 ls If not, install it from here .","title":"2. Test if you have the AWS CLI"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#3-set-up-aws-keys","text":"AWS Credentials [you will need to set this up for Ray to authenticate you] How to create AWS Access Key ID Once created, download your access key so you can refer to it. Run aws configure to configure your AWS CLI with your access credentials Configuration and credential file settings - AWS Command Line Interface (optional) Get an AWS PEM file Not needed for unit tests on GPU, which never spins up new nodes, but it will be needed if you ever want to enable Ray to launch new nodes. Amazon EC2 key pairs and Linux instances - Amazon Elastic Compute Cloud","title":"3. Set up AWS keys"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#4-get-ray","text":"Install ray locally: pip install -U \"ray[default]\" boto3","title":"4. Get Ray"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#5-set-up-a-ray-config","text":"vim $HOME /.clusters/cluster.yaml Copy the sample ray config below and edit all the <...> values to match your local dev environment. cluster_name : <$USER>-ludwig-ray-g4dn max_workers : 3 docker : image : \"ludwigai/ludwig-ray-gpu:master\" container_name : \"ray_container\" pull_before_run : True run_options : # Extra options to pass into \"docker run\" - --ulimit nofile=65536:65536 provider : type : aws region : <us-east-2> availability_zone : <us-east-2a> available_node_types : ray.head.default : resources : {} node_config : InstanceType : g4dn.4xlarge ImageId : latest_dlami BlockDeviceMappings : - DeviceName : /dev/sda1 Ebs : VolumeSize : 100 ray.worker.default : min_workers : 0 max_workers : 0 resources : {} node_config : InstanceType : g4dn.4xlarge ImageId : latest_dlami head_node_type : ray.head.default file_mounts : { /home/ubuntu/ludwig/ : </Users/$USER/ludwig> , # Ludwig Repo. /home/ray/.aws : </Users/$USER/.aws> , # AWS credentials. } rsync_exclude : - \"**/.git\" - \"**/.git/**\" rsync_filter : - \".gitignore\" setup_commands : - pip uninstall -y ludwig && pip install -e /home/ubuntu/ludwig/. - pip install s3fs==2021.10.0 aiobotocore==1.4.2 boto3==1.17.106 - pip install pandas==1.1.4 - pip install hydra-core --upgrade head_start_ray_commands : - ray stop --force - ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml worker_start_ray_commands : - ray stop --force - ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076 Set an environment variable mapping to the location (can be relative) of your cluster config: export CLUSTER = \" $HOME /.clusters/cluster.yaml\"","title":"5. Set up a Ray Config"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#developer-workflow","text":"","title":"Developer Workflow"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#once-launch-the-ray-cluster","text":"export CLUSTER=\"$HOME/cluster_g4dn.yaml\" export CLUSTER_CPU=\"$HOME/cluster_cpu.yaml\" ray up $CLUSTER","title":"(once) Launch the ray cluster"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#make-local-changes","text":"Run tests locally. pytest tests/...","title":"Make local changes"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#rsync-your-local-changes-to-the-ray-gpu-cluster","text":"ray rsync_up $CLUSTER -A '/Users/$USER/ludwig/' '/home/ubuntu/ludwig' ray rsync_up $CLUSTER_CPU -A '/Users/$USER/ludwig/' '/home/ubuntu/ludwig' Warning The trailing backslash / is important!","title":"Rsync your local changes to the ray GPU cluster"},{"location":"developer_guide/run_tests_on_gpu_using_ray/#run-tests-on-the-gpu-cluster-from-the-ray-mounted-ludwig-directory","text":"ray exec $CLUSTER \"cd /home/ubuntu/ludwig && pytest tests/\" You can also connect directly to a terminal on the cluster head: ray attach $CLUSTER","title":"Run tests on the GPU cluster from the Ray-mounted ludwig directory"},{"location":"developer_guide/style_guidelines_and_tests/","text":"Coding Style Guidelines \u00b6 We expect contributions to mimic existing patterns in the codebase and demonstrate good practices: the code should be concise, readable, PEP8-compliant , and limit each line to 120 characters. See codebase structure for guidelines on where new modules should be added. pre-commit.ci \u00b6 The Ludwig repository integrates with pre-commit.ci , which enforces basic code style guidelines and automatically fixes minor style issues by adding a commit to pull requests. So, check the results of pre-commit.ci after creating a new pull request. There may be automatic fixes to pull, or issues which require manual editing to fix. To run pre-commit on local branches, you can install pre-commit locally with pip: # Installs pre-commit tool pip install pre-commit # Adds pre-commit hooks to local clone of git repository. pre-commit install # Runs pre-commit on all files pre-commit run --all-files # To disable, simply uninstall pre-commit from the local clone. pre-commit uninstall Docstrings \u00b6 All new files, classes, and methods should have a docstring. Docstrings should give a concise description of the method and describe the meaning for each parameter, as well as any possible return value. Type hints should also be used in the function signature wherever possible, and should use the most specific type accepted by the method. Example: def load_processed_dataset ( self , split ) -> Union [ pd . DataFrame , Tuple [ pd . DataFrame , pd . DataFrame , pd . DataFrame ]]: \"\"\"Loads the processed Parquet into a dataframe. :param split: Splits along 'split' column if present. :returns: The preprocessed dataset, or a tuple of (train, validation, test). \"\"\" Functions with no arguments or return value may have a isingle-line docstring, ie: @pytest . fixture () def csv_filename (): \"\"\"Yields a csv filename for holding temporary data.\"\"\" Tests \u00b6 Ludwig uses two types of tests: unit tests and integration tests. Unit tests test a single module, and should individually be very fast. Integration tests run an end-to-end test of a single Ludwig functionality, like hyperopt or visualization. Ludwig tests are organized in the following directories: \u251c\u2500\u2500 ludwig - Ludwig library source code \u2514\u2500\u2500 tests \u251c\u2500\u2500 integration_tests - End-to-end tests of Ludwig workflows \u2514\u2500\u2500 ludwig - Unit tests. Subdirectories match ludwig/ structure We are using pytest as our testing framework. For more information, see the pytest docs . Note Ludwig's test coverage is a work in progress, and many modules do not have proper test coverage yet. Contributions which get us closer to the goal of 100% test coverage will be welcomed! Checklist \u00b6 Before running tests, make sure: Your python environment is properly setup to run Ludwig. All required dependencies for testing are installed: pip install ludwig[test] You have write access on the machine. Some tests require saving temporary files to disk. Running tests \u00b6 To run all tests, execute python -m pytest from the ludwig root directory. Note that you don't need to have ludwig module installed. Running tests from the ludwig source root is useful for development as the test will import ludwig modules directly from the source tree. To run all unit tests (will take a few minutes): python -m pytest tests/ludwig/ Run a single test module: python -m pytest tests/ludwig/decoders/test_sequence_decoder.py To run a single test case of a module, you can use -k to specify the test case name: python -m pytest tests/integration_tests/test_experiment.py \\ -k \"test_visual_question_answering\" Another useful tool for debugging is the -vs flag, which runs the test with eager stdout. This prints log messages to the console in real time. Also, individual test cases can be specified with the module::test_case pattern instead of -k : python -m pytest \\ tests/integration_tests/test_api.py::test_api_training_determinism -vs","title":"Style Guidelines and Tests"},{"location":"developer_guide/style_guidelines_and_tests/#coding-style-guidelines","text":"We expect contributions to mimic existing patterns in the codebase and demonstrate good practices: the code should be concise, readable, PEP8-compliant , and limit each line to 120 characters. See codebase structure for guidelines on where new modules should be added.","title":"Coding Style Guidelines"},{"location":"developer_guide/style_guidelines_and_tests/#pre-commitci","text":"The Ludwig repository integrates with pre-commit.ci , which enforces basic code style guidelines and automatically fixes minor style issues by adding a commit to pull requests. So, check the results of pre-commit.ci after creating a new pull request. There may be automatic fixes to pull, or issues which require manual editing to fix. To run pre-commit on local branches, you can install pre-commit locally with pip: # Installs pre-commit tool pip install pre-commit # Adds pre-commit hooks to local clone of git repository. pre-commit install # Runs pre-commit on all files pre-commit run --all-files # To disable, simply uninstall pre-commit from the local clone. pre-commit uninstall","title":"pre-commit.ci"},{"location":"developer_guide/style_guidelines_and_tests/#docstrings","text":"All new files, classes, and methods should have a docstring. Docstrings should give a concise description of the method and describe the meaning for each parameter, as well as any possible return value. Type hints should also be used in the function signature wherever possible, and should use the most specific type accepted by the method. Example: def load_processed_dataset ( self , split ) -> Union [ pd . DataFrame , Tuple [ pd . DataFrame , pd . DataFrame , pd . DataFrame ]]: \"\"\"Loads the processed Parquet into a dataframe. :param split: Splits along 'split' column if present. :returns: The preprocessed dataset, or a tuple of (train, validation, test). \"\"\" Functions with no arguments or return value may have a isingle-line docstring, ie: @pytest . fixture () def csv_filename (): \"\"\"Yields a csv filename for holding temporary data.\"\"\"","title":"Docstrings"},{"location":"developer_guide/style_guidelines_and_tests/#tests","text":"Ludwig uses two types of tests: unit tests and integration tests. Unit tests test a single module, and should individually be very fast. Integration tests run an end-to-end test of a single Ludwig functionality, like hyperopt or visualization. Ludwig tests are organized in the following directories: \u251c\u2500\u2500 ludwig - Ludwig library source code \u2514\u2500\u2500 tests \u251c\u2500\u2500 integration_tests - End-to-end tests of Ludwig workflows \u2514\u2500\u2500 ludwig - Unit tests. Subdirectories match ludwig/ structure We are using pytest as our testing framework. For more information, see the pytest docs . Note Ludwig's test coverage is a work in progress, and many modules do not have proper test coverage yet. Contributions which get us closer to the goal of 100% test coverage will be welcomed!","title":"Tests"},{"location":"developer_guide/style_guidelines_and_tests/#checklist","text":"Before running tests, make sure: Your python environment is properly setup to run Ludwig. All required dependencies for testing are installed: pip install ludwig[test] You have write access on the machine. Some tests require saving temporary files to disk.","title":"Checklist"},{"location":"developer_guide/style_guidelines_and_tests/#running-tests","text":"To run all tests, execute python -m pytest from the ludwig root directory. Note that you don't need to have ludwig module installed. Running tests from the ludwig source root is useful for development as the test will import ludwig modules directly from the source tree. To run all unit tests (will take a few minutes): python -m pytest tests/ludwig/ Run a single test module: python -m pytest tests/ludwig/decoders/test_sequence_decoder.py To run a single test case of a module, you can use -k to specify the test case name: python -m pytest tests/integration_tests/test_experiment.py \\ -k \"test_visual_question_answering\" Another useful tool for debugging is the -vs flag, which runs the test with eager stdout. This prints log messages to the console in real time. Also, individual test cases can be specified with the module::test_case pattern instead of -k : python -m pytest \\ tests/integration_tests/test_api.py::test_api_training_determinism -vs","title":"Running tests"},{"location":"developer_guide/unit_test_design_guidelines/","text":"General Guidelines \u00b6 Create a unit test for every module \u00b6 Unit tests are in tests/ludwig/ which parallels the ludwig/ source tree. Every source file in ludwig/ with testable functionality should have a corresponding unit test file in test/ludwig/ , with a filename corresponding to the source file, prefixed by test_ . Examples: Module Test ludwig/data/dataset_synthesizer.py tests/ludwig/data/test_dataset_synthesizer.py ludwig/features/audio_feature.py tests/ludwig/features/test_audio_feature.py ludwig/modules/convolutional_modules.py tests/ludwig/modules/test_convolutional_modules.py Note At the time of writing, not all modules in Ludwig have proper unit tests or match the guidelines here. These guidelines are the goals we aspire to, and we believe incremental improvement is better than demanding perfection. Testing of Ludwig is a work in progress, any changes that get us closer to the goal of 100% test coverage are welcomed! What should be tested \u00b6 Unit tests should generally test every function or method a module exports, with some exceptions. A good rule is that if a function or method fulfills a requirement and will be called from outside the module, it should have a test. Test the common cases . This will provide a notification when something breaks. Test the edge cases of complex methods if you think they might have errors. Test failure cases If a method must fail, ex. when input out of range, ensure it does. Bugs When you find a bug, write a test case to cover it before fixing it. Parameterize tests \u00b6 Use @pytest.mark.parameterize to test combinations of parameters that drive through all code paths, to ensure correct behavior of the function under a variety of situations. # test combinations of parameters to exercise all code paths @pytest . mark . parameterize ( 'num_total_blocks, num_shared_blocks' , [( 4 , 2 ), ( 6 , 4 ), ( 3 , 1 )] ) @pytest . mark . parameterize ( 'virtual_batch_size' , [ None , 7 ]) @pytest . mark . parameterize ( 'size' , [ 4 , 12 ]) @pytest . mark . parameterize ( 'input_size' , [ 2 , 6 ]) def test_feature_transformer ( input_size : int , size : int , virtual_batch_size : Optional [ int ], num_total_blocks : int , num_shared_blocks : int ) -> None : feature_transformer = FeatureTransformer ( input_size , size , bn_virtual_bs = virtual_batch_size , num_total_blocks = num_total_blocks , num_shared_blocks = num_shared_blocks ) Test edge cases \u00b6 Test edge cases when possible. For example, if a method takes multiple inputs: test with an empty input, a single input, and a large number of inputs. @pytest . mark . parametrize ( \"virtual_batch_size\" , [ None , 7 , 64 ]) # Test with no virtual batch norm, odd size, or large. @pytest . mark . parametrize ( \"input_size\" , [ 1 , 8 , 256 ]) # Test with single input feature or many inputs. Tensor Type and Shape \u00b6 At minimum, tests related to tensors should confirm no errors are raised when processing tensor(s) and that resulting tensors are of correct shape and type. This provides minimal assurance that the function is operating as expected. # pass input features through combiner combiner_output = combiner ( input_features ) # check for required attributes in the generated output assert hasattr ( combiner , 'input_dtype' ) assert hasattr ( combiner , 'output_shape' ) # check for correct data type assert isinstance ( combiner_output , dict ) # required key present assert 'combiner_output' in combiner_output # check for correct output shape assert ( combiner_output [ 'combiner_output' ] . shape == ( batch_size , * combiner . output_shape )) Trainable Modules \u00b6 When testing a trainable module (layer, encoder, decoder, combiner or model), make sure that all the variables / weights get updates after one training step. This will ensure that the computation graph does not contain dangling nodes. This catches subtle issues which don\u2019t manifest as crashes, which are not caught by looking at the loss scores or by training the model to convergence (albeit to a usually bad loss), For more details see how to unit test machine learning code . Add type checking based on torch input and outputs. Ensure all module outputs have the expected torch datatype, dimensionality, and tensor shape. For trainable modules, we recommend adding at least one overfitting test . Ensure that a small ECD model containing the module is able to overfit on a small dataset. Ensures that models are able to converge on reasonable targets and catches any unscoped issues that are not captured by shape, type, or weight update tests. Best practices \u00b6 There's lots of great advice on the web for writing good tests. Here are a few highlights from Microsoft's recommendations that we ascribe to: Characteristics of a good unit test Arranging unit tests Write minimally passing tests Avoid logic in tests Avoid multiple acts What not to test \u00b6 It isn't necessary to test every function, a good rule is that if a function or method fulfills a requirement and will be called from outside the module, it should have a test. Things that don't need unit tests: Constructors or properties. Test them only if they contain validations. Configurations like constants, readonly fields, configs, etc. Facades or wrappers around other frameworks or libraries. Private methods Implementation Guidelines \u00b6 Use pytest.mark.parameterize \u00b6 Automates setup for test cases. Be careful to only test case parameter values which are meaningfully different, as the total number of tests cases grows combinatorially. @pytest . mark . parameterize ( 'enc_should_embed' , [ True , False ]) @pytest . mark . parameterize ( 'enc_reduce_output' , [ None , 'sum' ]) @pytest . mark . parameterize ( 'enc_norm' , [ None , 'batch' , 'layer' ]) @pytest . mark . parameterize ( 'enc_num_layers' , [ 1 , 2 ]) @pytest . mark . parameterize ( 'enc_dropout' , [ 0 , 0.2 ]) @pytest . mark . parameterize ( 'enc_cell_type' , [ 'rnn' , 'gru' , 'lstm' ]) @pytest . mark . parameterize ( 'enc_encoder' , ENCODERS + [ 'passthrough' ]) def test_sequence_encoders ( enc_encoder : str , enc_cell_type : str , enc_dropout : float , enc_num_layers : int , enc_norm : Union [ None , str ], enc_reduce_output : Union [ None , str ], enc_should_embed : bool , input_sequence : torch . Tensor ): Use temp_path or tmpdir for generated data \u00b6 Use temporary directories for any generated data. PyTest provides fixtures for temporary directories, which are guaranteed unique for each test run and will be cleaned up automatically. We recommend using tmpdir , which provides a py.path.local object which is compatible with os.path methods. If you are using pathlib , PyTest also provides tmp_path , which is a pathlib.Path . For more details, see Temporary directories and files in the PyTest docs. Example: @pytest . mark . parametrize ( \"skip_save_processed_input\" , [ True , False ]) @pytest . mark . parametrize ( \"in_memory\" , [ True , False ]) @pytest . mark . parametrize ( \"image_source\" , [ \"file\" , \"tensor\" ]) @pytest . mark . parametrize ( \"num_channels\" , [ 1 , 3 ]) def test_basic_image_feature ( num_channels , image_source , in_memory , skip_save_processed_input , tmpdir ): # Image Inputs image_dest_folder = os . path . join ( tmpdir , \"generated_images\" ) Consolidate tests which require setup \u00b6 For example, multiple tests may rely on the same training/test data sets which take time to load. If multiple tests rely on the same common resources, group these tests into a single module and use appropriately scoped @pytest.fixture to reduce overhead of repeatedly performing setup. Examples of reusable test fixtures can be found in tests/conftest.py . This module contains reusable @pytest.fixtures that have applicability across many tests. Deterministic tests \u00b6 Wherever possible, every test run with the same parameters should produce the same result. When using a random number generator, always specify a seed. A test will be difficult to debug if it produces different output on different runs. import torch RANDOM_SEED = 1919 # setup synthetic tensor, ensure reproducibility by setting seed torch . manual_seed ( RANDOM_SEED ) input_tensor = torch . randn ([ BATCH_SIZE , input_size ], dtype = torch . float32 )","title":"Unit Test Design Guidelines"},{"location":"developer_guide/unit_test_design_guidelines/#general-guidelines","text":"","title":"General Guidelines"},{"location":"developer_guide/unit_test_design_guidelines/#create-a-unit-test-for-every-module","text":"Unit tests are in tests/ludwig/ which parallels the ludwig/ source tree. Every source file in ludwig/ with testable functionality should have a corresponding unit test file in test/ludwig/ , with a filename corresponding to the source file, prefixed by test_ . Examples: Module Test ludwig/data/dataset_synthesizer.py tests/ludwig/data/test_dataset_synthesizer.py ludwig/features/audio_feature.py tests/ludwig/features/test_audio_feature.py ludwig/modules/convolutional_modules.py tests/ludwig/modules/test_convolutional_modules.py Note At the time of writing, not all modules in Ludwig have proper unit tests or match the guidelines here. These guidelines are the goals we aspire to, and we believe incremental improvement is better than demanding perfection. Testing of Ludwig is a work in progress, any changes that get us closer to the goal of 100% test coverage are welcomed!","title":"Create a unit test for every module"},{"location":"developer_guide/unit_test_design_guidelines/#what-should-be-tested","text":"Unit tests should generally test every function or method a module exports, with some exceptions. A good rule is that if a function or method fulfills a requirement and will be called from outside the module, it should have a test. Test the common cases . This will provide a notification when something breaks. Test the edge cases of complex methods if you think they might have errors. Test failure cases If a method must fail, ex. when input out of range, ensure it does. Bugs When you find a bug, write a test case to cover it before fixing it.","title":"What should be tested"},{"location":"developer_guide/unit_test_design_guidelines/#parameterize-tests","text":"Use @pytest.mark.parameterize to test combinations of parameters that drive through all code paths, to ensure correct behavior of the function under a variety of situations. # test combinations of parameters to exercise all code paths @pytest . mark . parameterize ( 'num_total_blocks, num_shared_blocks' , [( 4 , 2 ), ( 6 , 4 ), ( 3 , 1 )] ) @pytest . mark . parameterize ( 'virtual_batch_size' , [ None , 7 ]) @pytest . mark . parameterize ( 'size' , [ 4 , 12 ]) @pytest . mark . parameterize ( 'input_size' , [ 2 , 6 ]) def test_feature_transformer ( input_size : int , size : int , virtual_batch_size : Optional [ int ], num_total_blocks : int , num_shared_blocks : int ) -> None : feature_transformer = FeatureTransformer ( input_size , size , bn_virtual_bs = virtual_batch_size , num_total_blocks = num_total_blocks , num_shared_blocks = num_shared_blocks )","title":"Parameterize tests"},{"location":"developer_guide/unit_test_design_guidelines/#test-edge-cases","text":"Test edge cases when possible. For example, if a method takes multiple inputs: test with an empty input, a single input, and a large number of inputs. @pytest . mark . parametrize ( \"virtual_batch_size\" , [ None , 7 , 64 ]) # Test with no virtual batch norm, odd size, or large. @pytest . mark . parametrize ( \"input_size\" , [ 1 , 8 , 256 ]) # Test with single input feature or many inputs.","title":"Test edge cases"},{"location":"developer_guide/unit_test_design_guidelines/#tensor-type-and-shape","text":"At minimum, tests related to tensors should confirm no errors are raised when processing tensor(s) and that resulting tensors are of correct shape and type. This provides minimal assurance that the function is operating as expected. # pass input features through combiner combiner_output = combiner ( input_features ) # check for required attributes in the generated output assert hasattr ( combiner , 'input_dtype' ) assert hasattr ( combiner , 'output_shape' ) # check for correct data type assert isinstance ( combiner_output , dict ) # required key present assert 'combiner_output' in combiner_output # check for correct output shape assert ( combiner_output [ 'combiner_output' ] . shape == ( batch_size , * combiner . output_shape ))","title":"Tensor Type and Shape"},{"location":"developer_guide/unit_test_design_guidelines/#trainable-modules","text":"When testing a trainable module (layer, encoder, decoder, combiner or model), make sure that all the variables / weights get updates after one training step. This will ensure that the computation graph does not contain dangling nodes. This catches subtle issues which don\u2019t manifest as crashes, which are not caught by looking at the loss scores or by training the model to convergence (albeit to a usually bad loss), For more details see how to unit test machine learning code . Add type checking based on torch input and outputs. Ensure all module outputs have the expected torch datatype, dimensionality, and tensor shape. For trainable modules, we recommend adding at least one overfitting test . Ensure that a small ECD model containing the module is able to overfit on a small dataset. Ensures that models are able to converge on reasonable targets and catches any unscoped issues that are not captured by shape, type, or weight update tests.","title":"Trainable Modules"},{"location":"developer_guide/unit_test_design_guidelines/#best-practices","text":"There's lots of great advice on the web for writing good tests. Here are a few highlights from Microsoft's recommendations that we ascribe to: Characteristics of a good unit test Arranging unit tests Write minimally passing tests Avoid logic in tests Avoid multiple acts","title":"Best practices"},{"location":"developer_guide/unit_test_design_guidelines/#what-not-to-test","text":"It isn't necessary to test every function, a good rule is that if a function or method fulfills a requirement and will be called from outside the module, it should have a test. Things that don't need unit tests: Constructors or properties. Test them only if they contain validations. Configurations like constants, readonly fields, configs, etc. Facades or wrappers around other frameworks or libraries. Private methods","title":"What not to test"},{"location":"developer_guide/unit_test_design_guidelines/#implementation-guidelines","text":"","title":"Implementation Guidelines"},{"location":"developer_guide/unit_test_design_guidelines/#use-pytestmarkparameterize","text":"Automates setup for test cases. Be careful to only test case parameter values which are meaningfully different, as the total number of tests cases grows combinatorially. @pytest . mark . parameterize ( 'enc_should_embed' , [ True , False ]) @pytest . mark . parameterize ( 'enc_reduce_output' , [ None , 'sum' ]) @pytest . mark . parameterize ( 'enc_norm' , [ None , 'batch' , 'layer' ]) @pytest . mark . parameterize ( 'enc_num_layers' , [ 1 , 2 ]) @pytest . mark . parameterize ( 'enc_dropout' , [ 0 , 0.2 ]) @pytest . mark . parameterize ( 'enc_cell_type' , [ 'rnn' , 'gru' , 'lstm' ]) @pytest . mark . parameterize ( 'enc_encoder' , ENCODERS + [ 'passthrough' ]) def test_sequence_encoders ( enc_encoder : str , enc_cell_type : str , enc_dropout : float , enc_num_layers : int , enc_norm : Union [ None , str ], enc_reduce_output : Union [ None , str ], enc_should_embed : bool , input_sequence : torch . Tensor ):","title":"Use pytest.mark.parameterize"},{"location":"developer_guide/unit_test_design_guidelines/#use-temp_path-or-tmpdir-for-generated-data","text":"Use temporary directories for any generated data. PyTest provides fixtures for temporary directories, which are guaranteed unique for each test run and will be cleaned up automatically. We recommend using tmpdir , which provides a py.path.local object which is compatible with os.path methods. If you are using pathlib , PyTest also provides tmp_path , which is a pathlib.Path . For more details, see Temporary directories and files in the PyTest docs. Example: @pytest . mark . parametrize ( \"skip_save_processed_input\" , [ True , False ]) @pytest . mark . parametrize ( \"in_memory\" , [ True , False ]) @pytest . mark . parametrize ( \"image_source\" , [ \"file\" , \"tensor\" ]) @pytest . mark . parametrize ( \"num_channels\" , [ 1 , 3 ]) def test_basic_image_feature ( num_channels , image_source , in_memory , skip_save_processed_input , tmpdir ): # Image Inputs image_dest_folder = os . path . join ( tmpdir , \"generated_images\" )","title":"Use temp_path or tmpdir for generated data"},{"location":"developer_guide/unit_test_design_guidelines/#consolidate-tests-which-require-setup","text":"For example, multiple tests may rely on the same training/test data sets which take time to load. If multiple tests rely on the same common resources, group these tests into a single module and use appropriately scoped @pytest.fixture to reduce overhead of repeatedly performing setup. Examples of reusable test fixtures can be found in tests/conftest.py . This module contains reusable @pytest.fixtures that have applicability across many tests.","title":"Consolidate tests which require setup"},{"location":"developer_guide/unit_test_design_guidelines/#deterministic-tests","text":"Wherever possible, every test run with the same parameters should produce the same result. When using a random number generator, always specify a seed. A test will be difficult to debug if it produces different output on different runs. import torch RANDOM_SEED = 1919 # setup synthetic tensor, ensure reproducibility by setting seed torch . manual_seed ( RANDOM_SEED ) input_tensor = torch . randn ([ BATCH_SIZE , input_size ], dtype = torch . float32 )","title":"Deterministic tests"},{"location":"examples/","text":"This section contains several examples of how to build models with Ludwig for a variety of tasks. For each task we show an example dataset and a sample model definition that can be used to train a model from that data. Write-ups in the Tutorials section show both Ludwig's command line interface and Python API. For these tutorials, there are ready-to-run notebooks that work in Google's Colab Service . The notebooks provide the user a starting point for learning about Ludwig capabilities. The Example Use Cases section illustrate how Ludwig can be applied to a variety of machine learning tasks, such as, natural language understanding, timeseries forcasting, multi-label classification to name just a few. In addition to the examples here, on the Ludwig medium publication you can find a three part tutorial on Sentiment Analysis with Ludwig: Part I (Training models from scratch) Part II (Finetuning pretrained models) Part III (Hyperparameter Optimization)","title":"Examples"},{"location":"examples/adult_census_income/","text":"This is a complete example of training a model for binary classification. These interactive notebooks follow the steps of this example: Ludwig CLI: Ludwig Python API: Download the Adult Census Income dataset \u00b6 Adult Census Income is an extract of 1994 Census data for predicting whether a person's income exceeds $50K per year. The data set consists of over 49K records with 14 attributes with missing data. ludwig datasets download adult_census_income This command will create a dataset adult_census_income.csv in the current directory. The columns in the dataset are column description age numeric variable, age of person workclass categorical variable, Type of empolyment fnlwgt numeric variable, no defintion education categorical variable, education level education-num nmeric variable, no definition marital-status categorical variable, marital status occupation categorical variable, occupation relationship categorical variable, Relationship to household race categorical variable, race sex categorical variable, gender capital-gain numeric variable, no definition capital-loss numeric variable, no definition hours-per-week numeric variable, hours worked per week native-country categorical variable, Country of origin income binary variable, \" <=50K\" or \" >50K\" split numeric variable, indicating data split training(0), test(2) Train \u00b6 The Ludwig configuration file describes the machine learning task. There is a vast array of options to control the learning process. This example only covers a small fraction of the options. Only the options used in this example are described. Please refer to the Configuration Section for all the details. First 'preprocessing' section defines the gloabl preprocessing options. All numeric features are z-scored normalized, i.e., mean centered and scaled by the standard deviation. Numeric missing values are filled in with the mean of non-missing values. The input_features section describes each of the predictor variables, i.e., the column name and type of input variable: number or category The 'combiner' section defines how the input features are combined to be passed to the output decoder. This example uses the concat combiner , which simply concatenates the output of the input feature encoders. The combined data is passed through a three layer fully connected network of 128 cells in each layer with dropout regularization. Next the output_features are defined. In this example, there is one response variable called income . This is a binary feature with two possible values: \" <=50K\" or \" >50K\". Because thes values are not conventional binary values, i.e., \"True\" and \"False\", a feature specific preprocessing option is specified to indicate which string (\" >50K\") is interpreted as \"True\". A four layer fully connected decoder of 32 cells in each layer is specified for this output feature. The last section in this configuration file describes options for how the the trainer will operate. In this example the trainer will process the training data for 10 epochs. The optimizer type is \"adam\". cli python preprocessing : number : normalization : zscore missing_value_strategy : fill_with_mean input_features : - name : age type : number - name : workclass type : category - name : fnlwgt type : number - name : education type : category - name : education-num type : number - name : marital-status type : category - name : occupation type : category - name : relationship type : category - name : race type : category - name : sex type : category - name : capital-gain type : number - name : capital-loss type : number - name : hours-per-week type : number - name : native-country type : category combiner : type : concat num_fc_layers : 3 output_size : 128 dropout : 0.2 output_features : - name : income type : binary preprocessing : fallback_true_label : \" >50K\" num_fc_layers : 4 output_size : 32 trainer : epochs : 10 optimizer : type : adam LudwigModel # create Ludwig configuration dictionary # define model configuration config = { 'combiner' : { 'dropout' : 0.2 , 'num_fc_layers' : 3 , 'output_size' : 128 , 'type' : 'concat' }, 'input_features' : [{ 'name' : 'age' , 'type' : 'number' }, { 'name' : 'workclass' , 'type' : 'category' }, { 'name' : 'fnlwgt' , 'type' : 'number' }, { 'name' : 'education' , 'type' : 'category' }, { 'name' : 'education-num' , 'type' : 'number' }, { 'name' : 'marital-status' , 'type' : 'category' }, { 'name' : 'occupation' , 'type' : 'category' }, { 'name' : 'relationship' , 'type' : 'category' }, { 'name' : 'race' , 'type' : 'category' }, { 'name' : 'sex' , 'type' : 'category' }, { 'name' : 'capital-gain' , 'type' : 'number' }, { 'name' : 'capital-loss' , 'type' : 'number' }, { 'name' : 'hours-per-week' , 'type' : 'number' }, { 'name' : 'native-country' , 'type' : 'category' }], 'output_features' : [{ 'name' : 'income' , 'num_fc_layers' : 4 , 'output_size' : 32 , 'preprocessing' : { 'fallback_true_label' : ' >50K' }, 'loss' : { 'type' : 'binary_weighted_cross_entropy' }, 'type' : 'binary' }], 'preprocessing' : { 'number' : { 'missing_value_strategy' : 'fill_with_mean' , 'normalization' : 'zscore' }}, 'trainer' : { 'epochs' : 10 , 'optimizer' : { 'type' : 'adam' }}} # instantiate Ludwig model object model = LudwigModel ( config = config , logging_level = logging . INFO ) Train the model. cli python ludwig train command ludwig train \\ --dataset adult_census_income.csv \\ --config config.yaml train() method # Trains the model. This cell might take a few minutes. train_stats , preprocessed_data , output_directory = model . train ( training_set = train_df , test_set = test_df ) Evaluate \u00b6 cli python ludwig evaluate command ludwig evaluate --model_path results/experiment_run/model \\ --dataset evaluation_dataset.csv \\ --output_directory test_results evaluate() method # Generates predictions and performance statistics for the test set. test_stats , predictions , output_directory = model . evaluate ( eval_df , collect_predictions = True , collect_overall_stats = True , skip_save_eval_stats = False , skip_save_predictions = False , output_directory = \"test_results\" , return_type = \"dict\" ) Visualize Metrics \u00b6 ROC Curve \u00b6 cli python ludwig visualize roc_curves command !ludwig visualize --visualization roc_curves \\ --ground_truth evaluation_dataset.csv \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --probabilities test_results/predictions.parquet \\ --output_feature_name income \\ --output_directory visualizations \\ --model_names \"Adult Census Income Model\" \\ --file_format png visualize.roc_curves() function from ludwig.visualize import roc_curves roc_curves ( [ predictions [ 'income' ][ 'probabilities' ]], eval_df [ 'income' ], preprocessed_data [ - 1 ], 'income' , '1' , model_names = [ \"Adult Census Income\" ], output_directory = 'visualization' , file_format = 'png' ) Binary Threshold Metrics \u00b6 cli python ludwig visualize binary_threshole_vs_metric command ludwig visualize --visualization binary_threshold_vs_metric \\ --ground_truth evaluation_dataset.csv \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --probabilities test_results/predictions.parquet \\ --output_feature_name income \\ --positive_label 1 \\ --output_directory visualizations \\ --model_names \"Adult Census Income Model\" \\ --metrics accuracy precision recall f1 \\ --file_format png visualize.binary_threshold_vs_metric() function from ludwig.visualize import binary_threshold_vs_metric binary_threshold_vs_metric ( [ predictions [ \"income\" ][ \"probabilities\" ]], eval_df [ \"income\" ], preprocessed_data [ - 1 ], \"income\" , [ \"accuracy\" , \"precision\" , \"recall\" , \"f1\" ], 1 , model_names = [ \"Adult Census Income\" ], output_directory = \"visualization\" , file_format = \"png\" , ) Accuracy Metric \u00b6 Precision Metric \u00b6 Recall Metric \u00b6 F1 Metric \u00b6 Predictions \u00b6 cli python ludwig predict command ludwig predict --model_path results/experiment_run/model \\ --dataset evaluation_dataset.csv \\ --output_directory predictions predict() method predictions , prediction_results = model . predict ( dataset = eval_df , skip_save_predictions = False , output_directory = \"predictions_results\" ) Sample predictions","title":"Tabular Data Classification"},{"location":"examples/adult_census_income/#download-the-adult-census-income-dataset","text":"Adult Census Income is an extract of 1994 Census data for predicting whether a person's income exceeds $50K per year. The data set consists of over 49K records with 14 attributes with missing data. ludwig datasets download adult_census_income This command will create a dataset adult_census_income.csv in the current directory. The columns in the dataset are column description age numeric variable, age of person workclass categorical variable, Type of empolyment fnlwgt numeric variable, no defintion education categorical variable, education level education-num nmeric variable, no definition marital-status categorical variable, marital status occupation categorical variable, occupation relationship categorical variable, Relationship to household race categorical variable, race sex categorical variable, gender capital-gain numeric variable, no definition capital-loss numeric variable, no definition hours-per-week numeric variable, hours worked per week native-country categorical variable, Country of origin income binary variable, \" <=50K\" or \" >50K\" split numeric variable, indicating data split training(0), test(2)","title":"Download the Adult Census Income dataset"},{"location":"examples/adult_census_income/#train","text":"The Ludwig configuration file describes the machine learning task. There is a vast array of options to control the learning process. This example only covers a small fraction of the options. Only the options used in this example are described. Please refer to the Configuration Section for all the details. First 'preprocessing' section defines the gloabl preprocessing options. All numeric features are z-scored normalized, i.e., mean centered and scaled by the standard deviation. Numeric missing values are filled in with the mean of non-missing values. The input_features section describes each of the predictor variables, i.e., the column name and type of input variable: number or category The 'combiner' section defines how the input features are combined to be passed to the output decoder. This example uses the concat combiner , which simply concatenates the output of the input feature encoders. The combined data is passed through a three layer fully connected network of 128 cells in each layer with dropout regularization. Next the output_features are defined. In this example, there is one response variable called income . This is a binary feature with two possible values: \" <=50K\" or \" >50K\". Because thes values are not conventional binary values, i.e., \"True\" and \"False\", a feature specific preprocessing option is specified to indicate which string (\" >50K\") is interpreted as \"True\". A four layer fully connected decoder of 32 cells in each layer is specified for this output feature. The last section in this configuration file describes options for how the the trainer will operate. In this example the trainer will process the training data for 10 epochs. The optimizer type is \"adam\". cli python preprocessing : number : normalization : zscore missing_value_strategy : fill_with_mean input_features : - name : age type : number - name : workclass type : category - name : fnlwgt type : number - name : education type : category - name : education-num type : number - name : marital-status type : category - name : occupation type : category - name : relationship type : category - name : race type : category - name : sex type : category - name : capital-gain type : number - name : capital-loss type : number - name : hours-per-week type : number - name : native-country type : category combiner : type : concat num_fc_layers : 3 output_size : 128 dropout : 0.2 output_features : - name : income type : binary preprocessing : fallback_true_label : \" >50K\" num_fc_layers : 4 output_size : 32 trainer : epochs : 10 optimizer : type : adam LudwigModel # create Ludwig configuration dictionary # define model configuration config = { 'combiner' : { 'dropout' : 0.2 , 'num_fc_layers' : 3 , 'output_size' : 128 , 'type' : 'concat' }, 'input_features' : [{ 'name' : 'age' , 'type' : 'number' }, { 'name' : 'workclass' , 'type' : 'category' }, { 'name' : 'fnlwgt' , 'type' : 'number' }, { 'name' : 'education' , 'type' : 'category' }, { 'name' : 'education-num' , 'type' : 'number' }, { 'name' : 'marital-status' , 'type' : 'category' }, { 'name' : 'occupation' , 'type' : 'category' }, { 'name' : 'relationship' , 'type' : 'category' }, { 'name' : 'race' , 'type' : 'category' }, { 'name' : 'sex' , 'type' : 'category' }, { 'name' : 'capital-gain' , 'type' : 'number' }, { 'name' : 'capital-loss' , 'type' : 'number' }, { 'name' : 'hours-per-week' , 'type' : 'number' }, { 'name' : 'native-country' , 'type' : 'category' }], 'output_features' : [{ 'name' : 'income' , 'num_fc_layers' : 4 , 'output_size' : 32 , 'preprocessing' : { 'fallback_true_label' : ' >50K' }, 'loss' : { 'type' : 'binary_weighted_cross_entropy' }, 'type' : 'binary' }], 'preprocessing' : { 'number' : { 'missing_value_strategy' : 'fill_with_mean' , 'normalization' : 'zscore' }}, 'trainer' : { 'epochs' : 10 , 'optimizer' : { 'type' : 'adam' }}} # instantiate Ludwig model object model = LudwigModel ( config = config , logging_level = logging . INFO ) Train the model. cli python ludwig train command ludwig train \\ --dataset adult_census_income.csv \\ --config config.yaml train() method # Trains the model. This cell might take a few minutes. train_stats , preprocessed_data , output_directory = model . train ( training_set = train_df , test_set = test_df )","title":"Train"},{"location":"examples/adult_census_income/#evaluate","text":"cli python ludwig evaluate command ludwig evaluate --model_path results/experiment_run/model \\ --dataset evaluation_dataset.csv \\ --output_directory test_results evaluate() method # Generates predictions and performance statistics for the test set. test_stats , predictions , output_directory = model . evaluate ( eval_df , collect_predictions = True , collect_overall_stats = True , skip_save_eval_stats = False , skip_save_predictions = False , output_directory = \"test_results\" , return_type = \"dict\" )","title":"Evaluate"},{"location":"examples/adult_census_income/#visualize-metrics","text":"","title":"Visualize Metrics"},{"location":"examples/adult_census_income/#roc-curve","text":"cli python ludwig visualize roc_curves command !ludwig visualize --visualization roc_curves \\ --ground_truth evaluation_dataset.csv \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --probabilities test_results/predictions.parquet \\ --output_feature_name income \\ --output_directory visualizations \\ --model_names \"Adult Census Income Model\" \\ --file_format png visualize.roc_curves() function from ludwig.visualize import roc_curves roc_curves ( [ predictions [ 'income' ][ 'probabilities' ]], eval_df [ 'income' ], preprocessed_data [ - 1 ], 'income' , '1' , model_names = [ \"Adult Census Income\" ], output_directory = 'visualization' , file_format = 'png' )","title":"ROC Curve"},{"location":"examples/adult_census_income/#binary-threshold-metrics","text":"cli python ludwig visualize binary_threshole_vs_metric command ludwig visualize --visualization binary_threshold_vs_metric \\ --ground_truth evaluation_dataset.csv \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --probabilities test_results/predictions.parquet \\ --output_feature_name income \\ --positive_label 1 \\ --output_directory visualizations \\ --model_names \"Adult Census Income Model\" \\ --metrics accuracy precision recall f1 \\ --file_format png visualize.binary_threshold_vs_metric() function from ludwig.visualize import binary_threshold_vs_metric binary_threshold_vs_metric ( [ predictions [ \"income\" ][ \"probabilities\" ]], eval_df [ \"income\" ], preprocessed_data [ - 1 ], \"income\" , [ \"accuracy\" , \"precision\" , \"recall\" , \"f1\" ], 1 , model_names = [ \"Adult Census Income\" ], output_directory = \"visualization\" , file_format = \"png\" , )","title":"Binary Threshold Metrics"},{"location":"examples/adult_census_income/#accuracy-metric","text":"","title":"Accuracy Metric"},{"location":"examples/adult_census_income/#precision-metric","text":"","title":"Precision Metric"},{"location":"examples/adult_census_income/#recall-metric","text":"","title":"Recall Metric"},{"location":"examples/adult_census_income/#f1-metric","text":"","title":"F1 Metric"},{"location":"examples/adult_census_income/#predictions","text":"cli python ludwig predict command ludwig predict --model_path results/experiment_run/model \\ --dataset evaluation_dataset.csv \\ --output_directory predictions predict() method predictions , prediction_results = model . predict ( dataset = eval_df , skip_save_predictions = False , output_directory = \"predictions_results\" ) Sample predictions","title":"Predictions"},{"location":"examples/forecasting/","text":"While direct timeseries prediction is a work in progress Ludwig can ingest timeseries input feature data and make number predictions. Below is an example of a model trained to forecast timeseries at five different horizons. timeseries_data y1 y2 y3 y4 y5 15.07 14.89 14.45 ... 16.92 16.67 16.48 17.00 17.02 14.89 14.45 14.30 ... 16.67 16.48 17.00 17.02 16.48 14.45 14.3 14.94 ... 16.48 17.00 17.02 16.48 15.82 ludwig experiment \\ --dataset timeseries_data.csv \\ --config config.yaml With config.yaml : input_features : - name : timeseries_data type : timeseries output_features : - name : y1 type : number - name : y2 type : number - name : y3 type : number - name : y4 type : number - name : y5 type : number","title":"Timeseries forecasting"},{"location":"examples/fraud/","text":"transaction_id card_id customer_id customer_zipcode merchant_id merchant_name merchant_category merchant_zipcode merchant_country transaction_amount authorization_response_code atm_network_xid cvv_2_response_xflg fraud_label 469483 9003 1085 23039 893 Wright Group 7917 91323 GB 1962 C C N 0 926515 9009 1001 32218 1011 Mums Kitchen 5813 10001 US 1643 C D M 1 730021 9064 1174 9165 916 Keller 7582 38332 DE 1184 D B M 0 ludwig experiment \\ --dataset transactions.csv \\ --config config.yaml With config.yaml : input_features : - name : customer_id type : category - name : card_id type : category - name : merchant_id type : category - name : merchant_category type : category - name : merchant_zipcode type : category - name : transaction_amount type : number - name : authorization_response_code type : category - name : atm_network_xid type : category - name : cvv_2_response_xflg type : category combiner : type : concat num_fc_layers : 1 output_size : 48 output_features : - name : fraud_label type : binary","title":"Fraud Detection"},{"location":"examples/fuel_efficiency/","text":"This example replicates the Keras example at https://www.tensorflow.org/tutorials/keras/basic_regression to predict the miles per gallon of a car given its characteristics in the Auto MPG dataset. MPG Cylinders Displacement Horsepower Weight Acceleration ModelYear Origin 18.0 8 307.0 130.0 3504.0 12.0 70 1 15.0 8 350.0 165.0 3693.0 11.5 70 1 18.0 8 318.0 150.0 3436.0 11.0 70 1 16.0 8 304.0 150.0 3433.0 12.0 70 1 ludwig experiment \\ --dataset auto_mpg.csv \\ --config config.yaml With config.yaml : training : batch_size : 32 epochs : 1000 early_stop : 50 learning_rate : 0.001 optimizer : type : rmsprop input_features : - name : Cylinders type : number - name : Displacement type : number - name : Horsepower type : number - name : Weight type : number - name : Acceleration type : number - name : ModelYear type : number - name : Origin type : category output_features : - name : MPG type : number optimizer : type : mean_squared_error num_fc_layers : 2 output_size : 64","title":"Simple Regression - Fuel Efficiency Prediction"},{"location":"examples/hyperopt/","text":"This is a complete example of Ludwig's hyperparameter optimization capability. These interactive notebooks follow the steps of this example: Ludwig CLI: Ludwig Python API: Download the Adult Census Income dataset \u00b6 Adult Census Income is an extract of 1994 Census data for predicting whether a person's income exceeds $50K per year. The data set consists of over 49K records with 14 attributes with missing data. ludwig datasets download adult_census_income This command will create a dataset adult_census_income.csv in the current directory. The columns in the dataset are column description age numeric variable, age of person workclass categorical variable, Type of empolyment fnlwgt numeric variable, no defintion education categorical variable, education level education-num nmeric variable, no definition marital-status categorical variable, marital status occupation categorical variable, occupation relationship categorical variable, Relationship to household race categorical variable, race sex categorical variable, gender capital-gain numeric variable, no definition capital-loss numeric variable, no definition hours-per-week numeric variable, hours worked per week native-country categorical variable, Country of origin income binary variable, \" <=50K\" or \" >50K\" split numeric variable, indicating data split training(0), test(2) Setup for hyperparameter optimization run \u00b6 Hyperparameter optimization is defined with the hyperopt section of the Ludwig configuration specification . cli python ludwig hyperopt preprocessing : ... input_features : ... combiner : ... output_features : ... trainer : ... # hyperopt specification hyperopt : # specify parameters for the Ray Tune to executor to run the hyperparameter optimization executor : ... # specify Ray Tune search algorithm to use search_alg : ... # hyperparameter search space for the optimization parameters : ... # minimize or maximize the metric score goal : ... # metric score to optimize metric : ... # name of the output feature output_feature : ... # define model configuration config = { 'combiner' : ... , 'input_features' : ... , 'output_features' : ... , 'preprocessing' : ... , 'trainer' : ... , # hyperopt specification 'hyperopt' : { # specify parameters for the Ray Tune to executor to run the hyperparameter optimization 'executor' : { 'type' : 'ray' , ... }, # specify Ray Tune search algorithm to use 'search_alg' : { ... }, # hyperparameter search space for the optimization 'parameters' : { ... }, # minimize or maximize the metric score 'goal' : ... , # metric score to optimize 'metric' : ... , # name of the output feature 'output_feature' : ... , } } Hyperparameter Search Space Specification \u00b6 For this example, we want to determine the effect of Ludwig's Trainer's learning_rate and num_fc_layers of the income output feature on model's roc_auc metric. To do this we will use two different hyperparameter optimization approaches: Random Search and Grid Search. Random Search \u00b6 cli python hyperopt : executor : num_samples : 16 goal : maximize metric : roc_auc output_feature : income parameters : income.num_fc_layers : space : randint lower : 2 upper : 9 trainer.learning_rate : space : loguniform lower : 0.001 upper : 0.1 search_alg : type : variant_generator random_state : 1919 'hyperopt' : { 'executor' : { 'num_samples' : 16 , }, 'goal' : 'maximize' , 'metric' : 'roc_auc' , 'output_feature' : 'income' , 'parameters' : { 'income.num_fc_layers' : { 'space' : 'randint' , 'lower' : 2 , 'upper' : 9 }, 'trainer.learning_rate' : { 'space' : 'loguniform' , 'lower' : 0.001 , 'upper' : 0.1 } }, 'search_alg' : { 'type' : 'variant_generator' , 'random_state' : 1919 , } }, Grid Search \u00b6 cli python hyperopt : executor : num_samples : 1 goal : maximize metric : roc_auc output_feature : income parameters : income.num_fc_layers : space : grid_search values : [ 2 , 4 , 6 , 8 ] trainer.learning_rate : space : grid_search values : [ 0.001 , 0.003 , 0.007 , 0.01 ] search_alg : type : variant_generator random_state : 1919 'hyperopt' : { 'executor' : { 'num_samples' : 1 ,}, 'goal' : 'maximize' , 'metric' : 'roc_auc' , 'output_feature' : 'income' , 'parameters' : { 'income.num_fc_layers' : { 'space' : 'grid_search' , 'values' : [ 2 , 4 , 6 , 8 ]}, 'trainer.learning_rate' : { 'space' : 'grid_search' , 'values' : [ 0.001 , 0.003 , 0.007 , 0.01 ]}}, 'search_alg' : { 'type' : 'variant_generator' , 'random_state' : 1919 , } }, Run Hyperparameter Optimization \u00b6 Here are example commands/function call to run Ludwig's hyperparameter optimization capability. cli python ludwig hyperopt command ludwig hyperopt --dataset adult_census_income.csv \\ --config config.yaml \\ --output_directory results \\ --hyperopt_log_verbosity 1 hyperopt() method hyperopt_results = hyperopt ( config , dataset = adult_census_df , output_directory = \"results\" , hyperopt_log_verbosity = 1 ) Visualize Hyperparameter Optimization Results \u00b6 cli python ludwig visualize hyperopt_report command ludwig visualize hyperopt_hiplot command # generate visualizations on hyperparameter effects on the metric ludwig visualize --visualization hyperopt_report \\ --hyperopt_stats_path results/hyperopt_statistics.json \\ --output_directory visualizations \\ --file_format png # generate hyperopt hiplot parallel coordinate visualization ludwig visualize --visualization hyperopt_hiplot \\ --hyperopt_stats_path results/hyperopt_statistics.json \\ --output_directory visualizations visualize.hyperopt_report() function visualize.hyperopt_hiplot() function hyperopt_report ( \"./rs_output/hyperopt_statistics.json\" ) hyperopt_hiplot ( \"./rs_output/hyperopt_statistics.json\" , output_directory = \"visualizations\" ) hyperopt_report \u00b6 hyperopt_hiplot \u00b6","title":"Hyperparameter Optimization"},{"location":"examples/hyperopt/#download-the-adult-census-income-dataset","text":"Adult Census Income is an extract of 1994 Census data for predicting whether a person's income exceeds $50K per year. The data set consists of over 49K records with 14 attributes with missing data. ludwig datasets download adult_census_income This command will create a dataset adult_census_income.csv in the current directory. The columns in the dataset are column description age numeric variable, age of person workclass categorical variable, Type of empolyment fnlwgt numeric variable, no defintion education categorical variable, education level education-num nmeric variable, no definition marital-status categorical variable, marital status occupation categorical variable, occupation relationship categorical variable, Relationship to household race categorical variable, race sex categorical variable, gender capital-gain numeric variable, no definition capital-loss numeric variable, no definition hours-per-week numeric variable, hours worked per week native-country categorical variable, Country of origin income binary variable, \" <=50K\" or \" >50K\" split numeric variable, indicating data split training(0), test(2)","title":"Download the Adult Census Income dataset"},{"location":"examples/hyperopt/#setup-for-hyperparameter-optimization-run","text":"Hyperparameter optimization is defined with the hyperopt section of the Ludwig configuration specification . cli python ludwig hyperopt preprocessing : ... input_features : ... combiner : ... output_features : ... trainer : ... # hyperopt specification hyperopt : # specify parameters for the Ray Tune to executor to run the hyperparameter optimization executor : ... # specify Ray Tune search algorithm to use search_alg : ... # hyperparameter search space for the optimization parameters : ... # minimize or maximize the metric score goal : ... # metric score to optimize metric : ... # name of the output feature output_feature : ... # define model configuration config = { 'combiner' : ... , 'input_features' : ... , 'output_features' : ... , 'preprocessing' : ... , 'trainer' : ... , # hyperopt specification 'hyperopt' : { # specify parameters for the Ray Tune to executor to run the hyperparameter optimization 'executor' : { 'type' : 'ray' , ... }, # specify Ray Tune search algorithm to use 'search_alg' : { ... }, # hyperparameter search space for the optimization 'parameters' : { ... }, # minimize or maximize the metric score 'goal' : ... , # metric score to optimize 'metric' : ... , # name of the output feature 'output_feature' : ... , } }","title":"Setup for hyperparameter optimization run"},{"location":"examples/hyperopt/#hyperparameter-search-space-specification","text":"For this example, we want to determine the effect of Ludwig's Trainer's learning_rate and num_fc_layers of the income output feature on model's roc_auc metric. To do this we will use two different hyperparameter optimization approaches: Random Search and Grid Search.","title":"Hyperparameter Search Space Specification"},{"location":"examples/hyperopt/#random-search","text":"cli python hyperopt : executor : num_samples : 16 goal : maximize metric : roc_auc output_feature : income parameters : income.num_fc_layers : space : randint lower : 2 upper : 9 trainer.learning_rate : space : loguniform lower : 0.001 upper : 0.1 search_alg : type : variant_generator random_state : 1919 'hyperopt' : { 'executor' : { 'num_samples' : 16 , }, 'goal' : 'maximize' , 'metric' : 'roc_auc' , 'output_feature' : 'income' , 'parameters' : { 'income.num_fc_layers' : { 'space' : 'randint' , 'lower' : 2 , 'upper' : 9 }, 'trainer.learning_rate' : { 'space' : 'loguniform' , 'lower' : 0.001 , 'upper' : 0.1 } }, 'search_alg' : { 'type' : 'variant_generator' , 'random_state' : 1919 , } },","title":"Random Search"},{"location":"examples/hyperopt/#grid-search","text":"cli python hyperopt : executor : num_samples : 1 goal : maximize metric : roc_auc output_feature : income parameters : income.num_fc_layers : space : grid_search values : [ 2 , 4 , 6 , 8 ] trainer.learning_rate : space : grid_search values : [ 0.001 , 0.003 , 0.007 , 0.01 ] search_alg : type : variant_generator random_state : 1919 'hyperopt' : { 'executor' : { 'num_samples' : 1 ,}, 'goal' : 'maximize' , 'metric' : 'roc_auc' , 'output_feature' : 'income' , 'parameters' : { 'income.num_fc_layers' : { 'space' : 'grid_search' , 'values' : [ 2 , 4 , 6 , 8 ]}, 'trainer.learning_rate' : { 'space' : 'grid_search' , 'values' : [ 0.001 , 0.003 , 0.007 , 0.01 ]}}, 'search_alg' : { 'type' : 'variant_generator' , 'random_state' : 1919 , } },","title":"Grid Search"},{"location":"examples/hyperopt/#run-hyperparameter-optimization","text":"Here are example commands/function call to run Ludwig's hyperparameter optimization capability. cli python ludwig hyperopt command ludwig hyperopt --dataset adult_census_income.csv \\ --config config.yaml \\ --output_directory results \\ --hyperopt_log_verbosity 1 hyperopt() method hyperopt_results = hyperopt ( config , dataset = adult_census_df , output_directory = \"results\" , hyperopt_log_verbosity = 1 )","title":"Run Hyperparameter Optimization"},{"location":"examples/hyperopt/#visualize-hyperparameter-optimization-results","text":"cli python ludwig visualize hyperopt_report command ludwig visualize hyperopt_hiplot command # generate visualizations on hyperparameter effects on the metric ludwig visualize --visualization hyperopt_report \\ --hyperopt_stats_path results/hyperopt_statistics.json \\ --output_directory visualizations \\ --file_format png # generate hyperopt hiplot parallel coordinate visualization ludwig visualize --visualization hyperopt_hiplot \\ --hyperopt_stats_path results/hyperopt_statistics.json \\ --output_directory visualizations visualize.hyperopt_report() function visualize.hyperopt_hiplot() function hyperopt_report ( \"./rs_output/hyperopt_statistics.json\" ) hyperopt_hiplot ( \"./rs_output/hyperopt_statistics.json\" , output_directory = \"visualizations\" )","title":"Visualize Hyperparameter Optimization Results"},{"location":"examples/hyperopt/#hyperopt_report","text":"","title":"hyperopt_report"},{"location":"examples/hyperopt/#hyperopt_hiplot","text":"","title":"hyperopt_hiplot"},{"location":"examples/machine_translation/","text":"english italian Hello! How are you doing? Ciao, come stai? I got promoted today Oggi sono stato promosso! Not doing well today Oggi non mi sento bene ludwig experiment \\ --dataset translation.csv \\ --config config.yaml With config.yaml : input_features : - name : english type : text encoder : rnn cell_type : lstm reduce_output : null preprocessing : tokenizer : english_tokenize output_features : - name : italian type : text decoder : generator cell_type : lstm attention : bahdanau reduce_input : null loss : type : softmax_cross_entropy preprocessing : tokenizer : italian_tokenize training : batch_size : 96","title":"Machine Translation"},{"location":"examples/mnist/","text":"This is a complete example of training an image classification model on the MNIST handwritten digit dataset. These interactive notebooks follow the steps of this example: Ludwig CLI: Ludwig Python API: Download the MNIST dataset \u00b6 MNIST is a collection of gray-scale images of handwritten digits. This collection is made up of 60,000 images for training and 10,000 images for testing model performance. Each image is 28 X 28 pixels in gray-scale. cli python ludwig datasets download mnist This command will create a dataset mnist_dataset.csv in the current directory. In addition, there will be directories training/ and testing/ containing the images. The columns in the dataset are column description image_path file path string for the image label single digit 0 to 9 indicating what digit is shown in the image split integer value indicating a training example (0) or test example (2) from ludwig.datasets import mnist # Loads the dataset as a pandas.DataFrame train_df , test_df , _ = mnist . load ( split = True ) This will create two pandas DataFrames. train_df contains file path information to the 60K training images. test_df has same information for the 10K test images. column description image_path file path string for the image label single digit 0 to 9 indicating what digit is shown in the image Sample of images with label . Train \u00b6 The Ludwig configuration file describes the machine learning task. This example only uses a small subset of the options provided by Ludwig. Please refer to the Configuration Section for all the details. First it defines the input_features . For the image feature, the configuration specifies the type of neural network architecture to encode the image. In this example the encoder is a two layer Stacked Convolutional Neural Network followed by a fully connected layer with dropout regularization. Next the output_features are defined. In this case, there is only one output feature called label . This is a categorical feature that indicates the digit the image represents, 0, 1, 2, ..., 9. The last section in this configuration file describes options for how the the trainer will operate. In this example the trainer will process the training data for 5 epochs. cli python # config.yaml input_features : - name : image_path type : image encoder : stacked_cnn conv_layers : - num_filters : 32 filter_size : 3 pool_size : 2 pool_stride : 2 - num_filters : 64 filter_size : 3 pool_size : 2 pool_stride : 2 dropout : 0.4 fc_layers : - output_size : 128 dropout : 0.4 output_features : - name : label type : category trainer : epochs : 5 LudwigModel # create Ludwig configuration dictionary config = { 'input_features' : [ { 'name' : 'image_path' , 'type' : 'image' , 'preprocessing' : { 'num_processes' : 4 }, 'encoder' : 'stacked_cnn' , 'conv_layers' : [ { 'num_filters' : 32 , 'filter_size' : 3 , 'pool_size' : 2 , 'pool_stride' : 2 }, { 'num_filters' : 64 , 'filter_size' : 3 , 'pool_size' : 2 , 'pool_stride' : 2 , 'dropout' : 0.4 } ], 'fc_layers' : [{ 'output_size' : 128 , 'dropout' : 0.4 }] } ], 'output_features' : [{ 'name' : 'label' , 'type' : 'category' }], 'trainer' : { 'epochs' : 5 } } # Constructs Ludwig model from config dictionary model = LudwigModel ( config , logging_level = logging . INFO ) Train the model. cli python ludwig train command ludwig train \\ --dataset mnist_dataset.csv \\ --config config.yaml train() method # Trains the model. This cell might take a few minutes. train_stats , preprocessed_data , output_directory = model . train ( dataset = train_df ) Evaluate \u00b6 Evaluate the trained model. cli python ludwig evaluate command ludwig evaluate --model_path results/experiment_run/model \\ --dataset mnist_dataset.csv \\ --split test \\ --output_directory test_results evaluate() method # Generates predictions and performance statistics for the test set. test_stats , predictions , output_directory = model . evaluate ( test_df , collect_predictions = True , collect_overall_stats = True ) Visualize Metrics \u00b6 Display Confusion Matrix and Class Entropy plots. cli python ludwig visualize confusion_matrix command ludwig visualize --visualization confusion_matrix \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --test_statistics test_results/test_statistics.json \\ --output_directory visualizations \\ --file_format png visualize.confusion_matrix() function # Visualizes confusion matrix, which gives an overview of classifier performance # for each class. from ludwig.visualize import confusion_matrix confusion_matrix ( [ test_stats ], model . training_set_metadata , 'label' , top_n_classes = [ 5 ], model_names = [ '' ], normalize = True , ) Display Learning Curves plots. cli python ludwig visualize learning_curves command ludwig visualize --visualization learning_curves \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --training_statistics results/experiment_run/training_statistics.json \\ --file_format png \\ --output_directory visualizations visualize.learning_curves() function # Visualizes learning curves, which show how performance metrics changed over # time during training. from ludwig.visualize import learning_curves learning_curves ( train_stats , output_feature_name = 'label' ) Predictions \u00b6 Generate predictions from test dataset. cli python ludwig predict command ludwig predict --model_path results/experiment_run/model \\ --dataset mnist_dataset.csv \\ --split test \\ --output_directory predictions predict() method predictions , output_directory = model . predict ( test_df ) Sample test images displaying true(\"label\") and predicted(\"pred\") labels.","title":"Image Classification"},{"location":"examples/mnist/#download-the-mnist-dataset","text":"MNIST is a collection of gray-scale images of handwritten digits. This collection is made up of 60,000 images for training and 10,000 images for testing model performance. Each image is 28 X 28 pixels in gray-scale. cli python ludwig datasets download mnist This command will create a dataset mnist_dataset.csv in the current directory. In addition, there will be directories training/ and testing/ containing the images. The columns in the dataset are column description image_path file path string for the image label single digit 0 to 9 indicating what digit is shown in the image split integer value indicating a training example (0) or test example (2) from ludwig.datasets import mnist # Loads the dataset as a pandas.DataFrame train_df , test_df , _ = mnist . load ( split = True ) This will create two pandas DataFrames. train_df contains file path information to the 60K training images. test_df has same information for the 10K test images. column description image_path file path string for the image label single digit 0 to 9 indicating what digit is shown in the image Sample of images with label .","title":"Download the MNIST dataset"},{"location":"examples/mnist/#train","text":"The Ludwig configuration file describes the machine learning task. This example only uses a small subset of the options provided by Ludwig. Please refer to the Configuration Section for all the details. First it defines the input_features . For the image feature, the configuration specifies the type of neural network architecture to encode the image. In this example the encoder is a two layer Stacked Convolutional Neural Network followed by a fully connected layer with dropout regularization. Next the output_features are defined. In this case, there is only one output feature called label . This is a categorical feature that indicates the digit the image represents, 0, 1, 2, ..., 9. The last section in this configuration file describes options for how the the trainer will operate. In this example the trainer will process the training data for 5 epochs. cli python # config.yaml input_features : - name : image_path type : image encoder : stacked_cnn conv_layers : - num_filters : 32 filter_size : 3 pool_size : 2 pool_stride : 2 - num_filters : 64 filter_size : 3 pool_size : 2 pool_stride : 2 dropout : 0.4 fc_layers : - output_size : 128 dropout : 0.4 output_features : - name : label type : category trainer : epochs : 5 LudwigModel # create Ludwig configuration dictionary config = { 'input_features' : [ { 'name' : 'image_path' , 'type' : 'image' , 'preprocessing' : { 'num_processes' : 4 }, 'encoder' : 'stacked_cnn' , 'conv_layers' : [ { 'num_filters' : 32 , 'filter_size' : 3 , 'pool_size' : 2 , 'pool_stride' : 2 }, { 'num_filters' : 64 , 'filter_size' : 3 , 'pool_size' : 2 , 'pool_stride' : 2 , 'dropout' : 0.4 } ], 'fc_layers' : [{ 'output_size' : 128 , 'dropout' : 0.4 }] } ], 'output_features' : [{ 'name' : 'label' , 'type' : 'category' }], 'trainer' : { 'epochs' : 5 } } # Constructs Ludwig model from config dictionary model = LudwigModel ( config , logging_level = logging . INFO ) Train the model. cli python ludwig train command ludwig train \\ --dataset mnist_dataset.csv \\ --config config.yaml train() method # Trains the model. This cell might take a few minutes. train_stats , preprocessed_data , output_directory = model . train ( dataset = train_df )","title":"Train"},{"location":"examples/mnist/#evaluate","text":"Evaluate the trained model. cli python ludwig evaluate command ludwig evaluate --model_path results/experiment_run/model \\ --dataset mnist_dataset.csv \\ --split test \\ --output_directory test_results evaluate() method # Generates predictions and performance statistics for the test set. test_stats , predictions , output_directory = model . evaluate ( test_df , collect_predictions = True , collect_overall_stats = True )","title":"Evaluate"},{"location":"examples/mnist/#visualize-metrics","text":"Display Confusion Matrix and Class Entropy plots. cli python ludwig visualize confusion_matrix command ludwig visualize --visualization confusion_matrix \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --test_statistics test_results/test_statistics.json \\ --output_directory visualizations \\ --file_format png visualize.confusion_matrix() function # Visualizes confusion matrix, which gives an overview of classifier performance # for each class. from ludwig.visualize import confusion_matrix confusion_matrix ( [ test_stats ], model . training_set_metadata , 'label' , top_n_classes = [ 5 ], model_names = [ '' ], normalize = True , ) Display Learning Curves plots. cli python ludwig visualize learning_curves command ludwig visualize --visualization learning_curves \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --training_statistics results/experiment_run/training_statistics.json \\ --file_format png \\ --output_directory visualizations visualize.learning_curves() function # Visualizes learning curves, which show how performance metrics changed over # time during training. from ludwig.visualize import learning_curves learning_curves ( train_stats , output_feature_name = 'label' )","title":"Visualize Metrics"},{"location":"examples/mnist/#predictions","text":"Generate predictions from test dataset. cli python ludwig predict command ludwig predict --model_path results/experiment_run/model \\ --dataset mnist_dataset.csv \\ --split test \\ --output_directory predictions predict() method predictions , output_directory = model . predict ( test_df ) Sample test images displaying true(\"label\") and predicted(\"pred\") labels.","title":"Predictions"},{"location":"examples/movie_ratings/","text":"year duration nominations categories rating 1921 3240 0 comedy drama 8.4 1925 5700 1 adventure comedy 8.3 1927 9180 4 drama comedy scifi 8.4 ludwig experiment \\ --dataset movie_ratings.csv \\ --config config.yaml With config.yaml : input_features : - name : year type : number - name : duration type : number - name : nominations type : number - name : categories type : set output_features : - name : rating type : number","title":"Movie rating prediction"},{"location":"examples/multi_label/","text":"image_path tags images/image_000001.jpg car man images/image_000002.jpg happy dog tie images/image_000003.jpg boat water ludwig experiment \\ --dataset image_data.csv \\ --config config.yaml With config.yaml : input_features : - name : image_path type : image encoder : stacked_cnn output_features : - name : tags type : set","title":"Multi-label classification"},{"location":"examples/multi_task/","text":"This example is inspired by the classic paper Natural Language Processing (Almost) from Scratch by Collobert et al.. sentence chunks part_of_speech named_entities San Francisco is very foggy B-NP I-NP B-VP B-ADJP I-ADJP NNP NNP VBZ RB JJ B-Loc I-Loc O O O My dog likes eating sausage B-NP I-NP B-VP B-VP B-NP PRP NN VBZ VBG NN O O O O O Brutus Killed Julius Caesar B-NP B-VP B-NP I-NP NNP VBD NNP NNP B-Per O B-Per I-Per ludwig experiment \\ --dataset nl_data.csv \\ --config config.yaml With config.yaml : input_features : - name : sentence type : sequence encoder : rnn cell : lstm bidirectional : true reduce_output : null output_features : - name : chunks type : sequence decoder : tagger - name : part_of_speech type : sequence decoder : tagger - name : named_entities type : sequence decoder : tagger","title":"Multi-Task Learning"},{"location":"examples/multimodal_classification/","text":"This example shows how to build a multimodal classifier with Ludwig. If you'd like to run this example interactively in Colab, open one of these notebooks and try it out: Ludwig CLI: Ludwig Python API: Note: you will need your Kaggle API token We'll be using the twitter human-bots dataset, originally uploaded to Kaggle by David Mart\u00edn Guti\u00e9rrez . The dataset is composed of 37438 rows each corresponding to a Twitter user account. Each row contains 20 feature columns collected via the Twitter API. These features contain multiple data modalities, including the account description and the profile image. The target column account_type has two unique values: bot or human . 25013 user accounts were annotated as human accounts, the remaining 12425 are bots. This dataset contains 20 columns, but we'll only use these 16 (15 input + 1 target): column type description default_profile binary Does the account have a default profile default_profile_image binary Does the account have a default profile image description text User account description favorites_count number Total number of favorited tweets followers_count number Total number of followers friends_count number Total number of friends geo_enabled binary Does the account has the geographic location enabled lang category Language of the account location category Location of the account profile_background_image_path image Profile background image path profile_image_path image Profile image path statuses_count number Total number of tweets verified binary Has the account been verified average_tweets_per_day number Average tweets posted per day account_age_days number Account age measured in days account_type binary \"human\" or \"bot\", true if the account is a bot Kaggle API Token (kaggle.json) \u00b6 To download datasets using the Kaggle CLI, you'll need a Kaggle API Token. If you already have one, it should be installed at ~/.kaggle/kaggle.json . Run this command in a shell, and copy the output: cat ~/.kaggle/kaggle.json If you don't have a kaggle.json file: Sign in to Kaggle . If you don't already have an account, create one. Go to \"Account\", and click the \"Create New API Token\" button. This should start the download. Following the Kaggle instructions, copy your kaggle.json from its download location to a directory called .kaggle in your home directory. If you want to run this example in either of the example Colab notebooks, open kaggle.json and copy its contents to the clipboard. The kaggle.json file should look similar to: { \"username\" : \"your_user_name\" , \"key\" : \"_______________________________\" } Download Dataset \u00b6 Downloads the dataset and creates twitter_human_bots_dataset.csv in the current directory. # Downloads the dataset to the current working directory kaggle datasets download danieltreiman/twitter-human-bots-dataset # Unzips the downloaded dataset, creates twitter_human_bots_dataset.csv unzip -q -o twitter-human-bots-dataset.zip Train \u00b6 Define ludwig config \u00b6 The Ludwig config declares the machine learning task: which columns to use, their datatypes, and which columns to predict. Note There are only 20 unique background images, so we've declared profile_background_image_path as a category instead of an image. Image encoders need a large number of unique images to perform well and will quickly overfit given such a small sample. cli python With config.yaml : input_features : - name : default_profile type : binary - name : default_profile_image type : binary - name : description type : text - name : favourites_count type : number - name : followers_count type : number - name : friends_count type : number - name : geo_enabled type : binary - name : lang type : category - name : location type : category - name : profile_background_image_path type : category - name : profile_image_path type : image - name : statuses_count type : number - name : verified type : binary - name : average_tweets_per_day type : number - name : account_age_days type : number output_features : - name : account_type type : binary With config defined in a python dict: config = { \"input_features\" : [ { \"name\" : \"default_profile\" , \"type\" : \"binary\" , }, { \"name\" : \"default_profile_image\" , \"type\" : \"binary\" , }, { \"name\" : \"description\" , \"type\" : \"text\" , }, { \"name\" : \"favourites_count\" , \"type\" : \"number\" , }, { \"name\" : \"followers_count\" , \"type\" : \"number\" , }, { \"name\" : \"friends_count\" , \"type\" : \"number\" , }, { \"name\" : \"geo_enabled\" , \"type\" : \"binary\" , }, { \"name\" : \"lang\" , \"type\" : \"category\" , }, { \"name\" : \"location\" , \"type\" : \"category\" , }, { \"name\" : \"profile_background_image_path\" , \"type\" : \"category\" , }, { \"name\" : \"profile_image_path\" , \"type\" : \"image\" , }, { \"name\" : \"statuses_count\" , \"type\" : \"number\" , }, { \"name\" : \"verified\" , \"type\" : \"binary\" , }, { \"name\" : \"average_tweets_per_day\" , \"type\" : \"number\" , }, { \"name\" : \"account_age_days\" , \"type\" : \"number\" , }, ], \"output_features\" : [ { \"name\" : \"account_type\" , \"type\" : \"binary\" , } ] } Create and train a model \u00b6 cli python ludwig train --dataset twitter_human_bots_dataset.csv -c config.yaml import pandas as pd # Reads the dataset from CSV file. dataset_df = pd . read_csv ( \"twitter_human_bots_dataset.csv\" ) # Constructs Ludwig model from config dictionary model = LudwigModel ( config , logging_level = logging . INFO ) # Trains the model. This cell might take a few minutes. train_stats , preprocessed_data , output_directory = model . train ( dataset = dataset_df ) Evaluate \u00b6 Generates predictions and performance statistics for the test set. cli python ludwig evaluate \\ --model_path results/experiment_run/model \\ --dataset twitter_human_bots_dataset.csv \\ --split test \\ --output_directory test_results # Generates predictions and performance statistics for the test set. test_stats , predictions , output_directory = model . evaluate ( dataset_df [ dataset_df . split == 1 ], collect_predictions = True , collect_overall_stats = True ) Visualize Metrics \u00b6 Visualizes confusion matrix, which gives an overview of classifier performance for each class. cli python ludwig visualize \\ --visualization confusion_matrix \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --test_statistics test_results/test_statistics.json \\ --output_directory visualizations \\ --file_format png from ludwig.visualize import confusion_matrix confusion_matrix ( [ test_stats ], model . training_set_metadata , 'account_type' , top_n_classes = [ 2 ], model_names = [ '' ], normalize = True , ) Confusion Matrix Class Entropy Visualizes learning curves, which show how performance metrics changed over time during training. cli python ludwig visualize \\ --visualization learning_curves \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --training_statistics results/experiment_run/training_statistics.json \\ --file_format png \\ --output_directory visualizations # Visualizes learning curves, which show how performance metrics changed over time during training. from ludwig.visualize import learning_curves learning_curves ( train_stats , output_feature_name = 'account_type' ) Losses Metrics","title":"Multimodal Classification"},{"location":"examples/multimodal_classification/#kaggle-api-token-kagglejson","text":"To download datasets using the Kaggle CLI, you'll need a Kaggle API Token. If you already have one, it should be installed at ~/.kaggle/kaggle.json . Run this command in a shell, and copy the output: cat ~/.kaggle/kaggle.json If you don't have a kaggle.json file: Sign in to Kaggle . If you don't already have an account, create one. Go to \"Account\", and click the \"Create New API Token\" button. This should start the download. Following the Kaggle instructions, copy your kaggle.json from its download location to a directory called .kaggle in your home directory. If you want to run this example in either of the example Colab notebooks, open kaggle.json and copy its contents to the clipboard. The kaggle.json file should look similar to: { \"username\" : \"your_user_name\" , \"key\" : \"_______________________________\" }","title":"Kaggle API Token (kaggle.json)"},{"location":"examples/multimodal_classification/#download-dataset","text":"Downloads the dataset and creates twitter_human_bots_dataset.csv in the current directory. # Downloads the dataset to the current working directory kaggle datasets download danieltreiman/twitter-human-bots-dataset # Unzips the downloaded dataset, creates twitter_human_bots_dataset.csv unzip -q -o twitter-human-bots-dataset.zip","title":"Download Dataset"},{"location":"examples/multimodal_classification/#train","text":"","title":"Train"},{"location":"examples/multimodal_classification/#define-ludwig-config","text":"The Ludwig config declares the machine learning task: which columns to use, their datatypes, and which columns to predict. Note There are only 20 unique background images, so we've declared profile_background_image_path as a category instead of an image. Image encoders need a large number of unique images to perform well and will quickly overfit given such a small sample. cli python With config.yaml : input_features : - name : default_profile type : binary - name : default_profile_image type : binary - name : description type : text - name : favourites_count type : number - name : followers_count type : number - name : friends_count type : number - name : geo_enabled type : binary - name : lang type : category - name : location type : category - name : profile_background_image_path type : category - name : profile_image_path type : image - name : statuses_count type : number - name : verified type : binary - name : average_tweets_per_day type : number - name : account_age_days type : number output_features : - name : account_type type : binary With config defined in a python dict: config = { \"input_features\" : [ { \"name\" : \"default_profile\" , \"type\" : \"binary\" , }, { \"name\" : \"default_profile_image\" , \"type\" : \"binary\" , }, { \"name\" : \"description\" , \"type\" : \"text\" , }, { \"name\" : \"favourites_count\" , \"type\" : \"number\" , }, { \"name\" : \"followers_count\" , \"type\" : \"number\" , }, { \"name\" : \"friends_count\" , \"type\" : \"number\" , }, { \"name\" : \"geo_enabled\" , \"type\" : \"binary\" , }, { \"name\" : \"lang\" , \"type\" : \"category\" , }, { \"name\" : \"location\" , \"type\" : \"category\" , }, { \"name\" : \"profile_background_image_path\" , \"type\" : \"category\" , }, { \"name\" : \"profile_image_path\" , \"type\" : \"image\" , }, { \"name\" : \"statuses_count\" , \"type\" : \"number\" , }, { \"name\" : \"verified\" , \"type\" : \"binary\" , }, { \"name\" : \"average_tweets_per_day\" , \"type\" : \"number\" , }, { \"name\" : \"account_age_days\" , \"type\" : \"number\" , }, ], \"output_features\" : [ { \"name\" : \"account_type\" , \"type\" : \"binary\" , } ] }","title":"Define ludwig config"},{"location":"examples/multimodal_classification/#create-and-train-a-model","text":"cli python ludwig train --dataset twitter_human_bots_dataset.csv -c config.yaml import pandas as pd # Reads the dataset from CSV file. dataset_df = pd . read_csv ( \"twitter_human_bots_dataset.csv\" ) # Constructs Ludwig model from config dictionary model = LudwigModel ( config , logging_level = logging . INFO ) # Trains the model. This cell might take a few minutes. train_stats , preprocessed_data , output_directory = model . train ( dataset = dataset_df )","title":"Create and train a model"},{"location":"examples/multimodal_classification/#evaluate","text":"Generates predictions and performance statistics for the test set. cli python ludwig evaluate \\ --model_path results/experiment_run/model \\ --dataset twitter_human_bots_dataset.csv \\ --split test \\ --output_directory test_results # Generates predictions and performance statistics for the test set. test_stats , predictions , output_directory = model . evaluate ( dataset_df [ dataset_df . split == 1 ], collect_predictions = True , collect_overall_stats = True )","title":"Evaluate"},{"location":"examples/multimodal_classification/#visualize-metrics","text":"Visualizes confusion matrix, which gives an overview of classifier performance for each class. cli python ludwig visualize \\ --visualization confusion_matrix \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --test_statistics test_results/test_statistics.json \\ --output_directory visualizations \\ --file_format png from ludwig.visualize import confusion_matrix confusion_matrix ( [ test_stats ], model . training_set_metadata , 'account_type' , top_n_classes = [ 2 ], model_names = [ '' ], normalize = True , ) Confusion Matrix Class Entropy Visualizes learning curves, which show how performance metrics changed over time during training. cli python ludwig visualize \\ --visualization learning_curves \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --training_statistics results/experiment_run/training_statistics.json \\ --file_format png \\ --output_directory visualizations # Visualizes learning curves, which show how performance metrics changed over time during training. from ludwig.visualize import learning_curves learning_curves ( train_stats , output_feature_name = 'account_type' ) Losses Metrics","title":"Visualize Metrics"},{"location":"examples/ner_tagging/","text":"utterance tag Blade Runner is a 1982 neo-noir science fiction film directed by Ridley Scott Movie Movie O O Date O O O O O O Person Person Harrison Ford and Rutger Hauer starred in it Person Person O Person person O O O Philip Dick 's novel Do Androids Dream of Electric Sheep ? was published in 1968 Person Person O O Book Book Book Book Book Book Book O O O Date ludwig experiment \\ --dataset sequence_tags.csv \\ --config config.yaml With config.yaml : input_features : - name : utterance type : text encoder : rnn cell_type : lstm reduce_output : null preprocessing : tokenizer : space output_features : - name : tag type : sequence decoder : tagger","title":"Named Entity Recognition Tagging"},{"location":"examples/nlu/","text":"utterance intent slots I want a pizza order_food O O O B-Food_type Book a flight to Boston book_flight O O O O B-City Book a flight at 7pm to London book_flight O O O O B-Departure_time O B-City ludwig experiment \\ --dataset nlu.csv \\ --config config.yaml With config.yaml : input_features : - name : utterance type : text encoder : rnn cell_type : lstm bidirectional : true num_layers : 2 reduce_output : null preprocessing : tokenizer : space output_features : - name : intent type : category reduce_input : sum num_fc_layers : 1 output_size : 64 - name : slots type : sequence decoder : tagger","title":"Natural Language Understanding"},{"location":"examples/oneshot/","text":"This example can be considered a simple baseline for one-shot learning on the Omniglot dataset. The task is, given two images of two handwritten characters, recognize if they are two instances of the same character or not. image_path_1 image_path_2 similarity balinese/character01/0108_13.png balinese/character01/0108_18.png 1 balinese/character01/0108_13.png balinese/character08/0115_12.png 0 balinese/character01/0108_04.png balinese/character01/0108_08.png 1 balinese/character01/0108_11.png balinese/character05/0112_02.png 0 ludwig experiment \\ --dataset balinese_characters.csv \\ --config config.yaml With config.yaml : input_features : - name : image_path_1 type : image encoder : stacked_cnn preprocessing : width : 28 height : 28 resize_image : true - name : image_path_2 type : image encoder : stacked_cnn preprocessing : width : 28 height : 28 resize_image : true tied : image_path_1 combiner : type : concat num_fc_layers : 2 output_size : 256 output_features : - name : similarity type : binary","title":"One-shot Learning with Siamese Networks"},{"location":"examples/sentiment_analysis/","text":"review sentiment The movie was fantastic! positive Great acting and cinematography positive The acting was terrible! negative ludwig experiment \\ --dataset sentiment.csv \\ --config config.yaml With config.yaml : input_features : - name : review type : text encoder : parallel_cnn output_features : - name : sentiment type : category","title":"Sentiment Analysis"},{"location":"examples/seq2seq/","text":"user1 user2 Hello! How are you doing? Doing well, thanks! I got promoted today Congratulations! Not doing well today I\u2019m sorry, can I do something to help you? ludwig experiment \\ --dataset chitchat.csv \\ --config config.yaml With config.yaml : input_features : - name : user1 type : text encoder : rnn cell_type : lstm reduce_output : null output_features : - name : user2 type : text decoder : generator cell_type : lstm attention : bahdanau loss : type : softmax_cross_entropy training : batch_size : 96","title":"Chit-Chat Dialogue Modeling through Sequence2Sequence"},{"location":"examples/speaker_verification/","text":"This example describes how to use Ludwig for a simple speaker verification task. We assume to have the following data with label 0 corresponding to an audio file of an unauthorized voice and label 1 corresponding to an audio file of an authorized voice. The sample data looks as follows: audio_path label audiodata/audio_000001.wav 0 audiodata/audio_000002.wav 0 audiodata/audio_000003.wav 1 audiodata/audio_000004.wav 1 ludwig experiment \\ --dataset speaker_verification.csv \\ --config config.yaml With config.yaml : input_features : - name : audio_path type : audio preprocessing : audio_file_length_limit_in_s : 7.0 audio_feature : type : stft window_length_in_s : 0.04 window_shift_in_s : 0.02 encoder : cnnrnn output_features : - name : label type : binary","title":"Speaker Verification"},{"location":"examples/speech_recognition/","text":"This is a complete example of training an spoken digit speech recognition model on the \"MNIST dataset of speech recognition\". Download the free spoken digit dataset \u00b6 git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git mkdir speech_recog_digit_data cp -r free-spoken-digit-dataset/recordings speech_recog_digit_data cd speech_recog_digit_data Create an CSV dataset \u00b6 echo \"audio_path\",\"label\" >> \"spoken_digit.csv\" cd \"recordings\" ls | while read -r file_name; do audio_path=$(readlink -m \"${file_name}\") label=$(echo ${file_name} | cut -c1) echo \"${audio_path},${label}\" >> \"../spoken_digit.csv\" done cd \"../\" Now you should have spoken_digit.csv containing 2000 examples having the following format audio_path label .../speech_recog_digit_data/recordings/0_jackson_0.wav 0 .../speech_recog_digit_data/recordings/0_jackson_10.wav 0 .../speech_recog_digit_data/recordings/0_jackson_11.wav 0 ... ... .../speech_recog_digit_data/recordings/1_jackson_0.wav 1 Train a model \u00b6 From the directory where you have virtual environment with ludwig installed: ludwig experiment \\ --dataset <PATH_TO_SPOKEN_DIGIT_CSV> \\ --config config_file.yaml With config.yaml : input_features : - name : audio_path type : audio encoder : stacked_cnn preprocessing : audio_feature : type : fbank window_length_in_s : 0.025 window_shift_in_s : 0.01 num_filter_bands : 80 audio_file_length_limit_in_s : 1.0 norm : per_file reduce_output : concat conv_layers : - num_filters : 16 filter_size : 6 pool_size : 4 pool_stride : 4 dropout : 0.4 - num_filters : 32 filter_size : 3 pool_size : 2 pool_stride : 2 dropout : 0.4 fc_layers : - output_size : 64 dropout : 0.4 output_features : - name : label type : category training : early_stop : 10","title":"Spoken Digit Speech Recognition"},{"location":"examples/speech_recognition/#download-the-free-spoken-digit-dataset","text":"git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git mkdir speech_recog_digit_data cp -r free-spoken-digit-dataset/recordings speech_recog_digit_data cd speech_recog_digit_data","title":"Download the free spoken digit dataset"},{"location":"examples/speech_recognition/#create-an-csv-dataset","text":"echo \"audio_path\",\"label\" >> \"spoken_digit.csv\" cd \"recordings\" ls | while read -r file_name; do audio_path=$(readlink -m \"${file_name}\") label=$(echo ${file_name} | cut -c1) echo \"${audio_path},${label}\" >> \"../spoken_digit.csv\" done cd \"../\" Now you should have spoken_digit.csv containing 2000 examples having the following format audio_path label .../speech_recog_digit_data/recordings/0_jackson_0.wav 0 .../speech_recog_digit_data/recordings/0_jackson_10.wav 0 .../speech_recog_digit_data/recordings/0_jackson_11.wav 0 ... ... .../speech_recog_digit_data/recordings/1_jackson_0.wav 1","title":"Create an CSV dataset"},{"location":"examples/speech_recognition/#train-a-model","text":"From the directory where you have virtual environment with ludwig installed: ludwig experiment \\ --dataset <PATH_TO_SPOKEN_DIGIT_CSV> \\ --config config_file.yaml With config.yaml : input_features : - name : audio_path type : audio encoder : stacked_cnn preprocessing : audio_feature : type : fbank window_length_in_s : 0.025 window_shift_in_s : 0.01 num_filter_bands : 80 audio_file_length_limit_in_s : 1.0 norm : per_file reduce_output : concat conv_layers : - num_filters : 16 filter_size : 6 pool_size : 4 pool_stride : 4 dropout : 0.4 - num_filters : 32 filter_size : 3 pool_size : 2 pool_stride : 2 dropout : 0.4 fc_layers : - output_size : 64 dropout : 0.4 output_features : - name : label type : category training : early_stop : 10","title":"Train a model"},{"location":"examples/text_classification/","text":"This example shows how to build a text classifier with Ludwig. These interactive notebooks follow the steps of this example: Ludwig CLI: Ludwig Python API: We'll be using AG's news topic classification dataset, a common benchmark dataset for text classification. This dataset is a subset of the full AG news dataset, constructed by choosing the four largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 with 7,600 total testing samples. The original split does not include a validation set, so we've labeled the first 5% of each training set class as the validation set. This dataset contains four columns: column description class_index An integer from 1 to 4: \"world\", \"sports\", \"business\", \"sci_tech\" respectively class A string, one of \"world\", \"sports\", \"business\", \"sci_tech\" title Title of the news article description Description of the news article Ludwig also provides several other text classification benchmark datasets which can be used, including: Amazon Reviews BBC News IMDB Yelp Reviews Download Dataset \u00b6 cli python Downloads the dataset and write to agnews.csv in the current directory. ludwig datasets download agnews Downloads the AG news dataset into a pandas dataframe. from ludwig.datasets import agnews # Loads the dataset as a pandas.DataFrame train_df , test_df , _ = agnews . load () The dataset contains the above four columns plus an additional split column which is one of 0: train, 1: test, 2: validation. Sample (description text omitted for space): class_index,title,description,split,class 3,Carlyle Looks Toward Commercial Aerospace (Reuters),...,0,business 3,Oil and Economy Cloud Stocks' Outlook (Reuters),...,0,business 3,Iraq Halts Oil Exports from Main Southern Pipeline (Reuters),...,0,business Train \u00b6 Define ludwig config \u00b6 The Ludwig config declares the machine learning task. It tells Ludwig what to predict, what columns to use as input, and optionally specifies the model type and hyperparameters. Here, for simplicity, we'll try to predict class from title . cli python With config.yaml : input_features : - name : title type : text encoder : parallel_cnn output_features : - name : class type : category trainer : epochs : 3 With config defined in a python dict: config = { \"input_features\" : [ { \"name\" : \"title\" , # The name of the input column \"type\" : \"text\" , # Data type of the input column \"encoder\" : \"parallel_cnn\" , # The model architecture we should use for # encoding this column } ], \"output_features\" : [ { \"name\" : \"class\" , \"type\" : \"category\" , } ], \"trainer\" : { \"epochs\" : 3 , # We'll train for three epochs. Training longer might give # better performance. } } Create and train a model \u00b6 cli python ludwig train --dataset agnews.csv -c config.yaml # Constructs Ludwig model from config dictionary model = LudwigModel ( config , logging_level = logging . INFO ) # Trains the model. This cell might take a few minutes. train_stats , preprocessed_data , output_directory = model . train ( dataset = train_df ) Evaluate \u00b6 Generates predictions and performance statistics for the test set. cli python ludwig evaluate \\ --model_path results/experiment_run/model \\ --dataset agnews.csv \\ --split test \\ --output_directory test_results # Generates predictions and performance statistics for the test set. test_stats , predictions , output_directory = model . evaluate ( test_df , collect_predictions = True , collect_overall_stats = True ) Visualize Metrics \u00b6 Visualizes confusion matrix, which gives an overview of classifier performance for each class. cli python ludwig visualize \\ --visualization confusion_matrix \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --test_statistics test_results/test_statistics.json \\ --output_directory visualizations \\ --file_format png from ludwig.visualize import confusion_matrix confusion_matrix ( [ test_stats ], model . training_set_metadata , 'class' , top_n_classes = [ 5 ], model_names = [ '' ], normalize = True , ) Confusion Matrix Class Entropy Visualizes learning curves, which show how performance metrics changed over time during training. cli python ludwig visualize \\ --visualization learning_curves \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --training_statistics results/experiment_run/training_statistics.json \\ --file_format png \\ --output_directory visualizations # Visualizes learning curves, which show how performance metrics changed over # time during training. from ludwig.visualize import learning_curves learning_curves ( train_stats , output_feature_name = 'class' ) Losses Metrics Make Predictions on New Data \u00b6 Lastly we'll show how to generate predictions for new data. The following are some recent news headlines. Feel free to edit or add your own strings to text_to_predict to see how the newly trained model classifies them. cli python With text_to_predict.csv : title Google may spur cloud cybersecurity M&A with $5.4B Mandiant buy Europe struggles to meet mounting needs of Ukraine's fleeing millions How the pandemic housing market spurred buyer's remorse across America ludwig predict \\ --model_path results/experiment_run/model \\ --dataset text_to_predict.csv \\ --output_directory predictions text_to_predict = pd . DataFrame ({ \"title\" : [ \"Google may spur cloud cybersecurity M&A with $5.4B Mandiant buy\" , \"Europe struggles to meet mounting needs of Ukraine's fleeing millions\" , \"How the pandemic housing market spurred buyer's remorse across America\" , ] }) predictions , output_directory = model . predict ( text_to_predict ) This command will write predictions to output_directory . Predictions outputs are written in multiple formats including csv and parquet. For instance, predictions/predictions.parquet contains the predicted classes for each example as well as the psuedo-probabilities for each class: class_predictions class_probabilities class_probability class_probabilities_<UNK> class_probabilities_sci_tech class_probabilities_sports class_probabilities_world class_probabilities_business sci_tech [1.9864278277825775e-10, ... 0.954650 1.986428e-10 0.954650 0.000033 0.002563 0.042754 world [8.458710176739714e-09, ... 0.995293 8.458710e-09 0.002305 0.000379 0.995293 0.002022 business [3.710099008458201e-06, ... 0.490741 3.710099e-06 0.447916 0.000815 0.060523 0.490741","title":"Text Classification"},{"location":"examples/text_classification/#download-dataset","text":"cli python Downloads the dataset and write to agnews.csv in the current directory. ludwig datasets download agnews Downloads the AG news dataset into a pandas dataframe. from ludwig.datasets import agnews # Loads the dataset as a pandas.DataFrame train_df , test_df , _ = agnews . load () The dataset contains the above four columns plus an additional split column which is one of 0: train, 1: test, 2: validation. Sample (description text omitted for space): class_index,title,description,split,class 3,Carlyle Looks Toward Commercial Aerospace (Reuters),...,0,business 3,Oil and Economy Cloud Stocks' Outlook (Reuters),...,0,business 3,Iraq Halts Oil Exports from Main Southern Pipeline (Reuters),...,0,business","title":"Download Dataset"},{"location":"examples/text_classification/#train","text":"","title":"Train"},{"location":"examples/text_classification/#define-ludwig-config","text":"The Ludwig config declares the machine learning task. It tells Ludwig what to predict, what columns to use as input, and optionally specifies the model type and hyperparameters. Here, for simplicity, we'll try to predict class from title . cli python With config.yaml : input_features : - name : title type : text encoder : parallel_cnn output_features : - name : class type : category trainer : epochs : 3 With config defined in a python dict: config = { \"input_features\" : [ { \"name\" : \"title\" , # The name of the input column \"type\" : \"text\" , # Data type of the input column \"encoder\" : \"parallel_cnn\" , # The model architecture we should use for # encoding this column } ], \"output_features\" : [ { \"name\" : \"class\" , \"type\" : \"category\" , } ], \"trainer\" : { \"epochs\" : 3 , # We'll train for three epochs. Training longer might give # better performance. } }","title":"Define ludwig config"},{"location":"examples/text_classification/#create-and-train-a-model","text":"cli python ludwig train --dataset agnews.csv -c config.yaml # Constructs Ludwig model from config dictionary model = LudwigModel ( config , logging_level = logging . INFO ) # Trains the model. This cell might take a few minutes. train_stats , preprocessed_data , output_directory = model . train ( dataset = train_df )","title":"Create and train a model"},{"location":"examples/text_classification/#evaluate","text":"Generates predictions and performance statistics for the test set. cli python ludwig evaluate \\ --model_path results/experiment_run/model \\ --dataset agnews.csv \\ --split test \\ --output_directory test_results # Generates predictions and performance statistics for the test set. test_stats , predictions , output_directory = model . evaluate ( test_df , collect_predictions = True , collect_overall_stats = True )","title":"Evaluate"},{"location":"examples/text_classification/#visualize-metrics","text":"Visualizes confusion matrix, which gives an overview of classifier performance for each class. cli python ludwig visualize \\ --visualization confusion_matrix \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --test_statistics test_results/test_statistics.json \\ --output_directory visualizations \\ --file_format png from ludwig.visualize import confusion_matrix confusion_matrix ( [ test_stats ], model . training_set_metadata , 'class' , top_n_classes = [ 5 ], model_names = [ '' ], normalize = True , ) Confusion Matrix Class Entropy Visualizes learning curves, which show how performance metrics changed over time during training. cli python ludwig visualize \\ --visualization learning_curves \\ --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\ --training_statistics results/experiment_run/training_statistics.json \\ --file_format png \\ --output_directory visualizations # Visualizes learning curves, which show how performance metrics changed over # time during training. from ludwig.visualize import learning_curves learning_curves ( train_stats , output_feature_name = 'class' ) Losses Metrics","title":"Visualize Metrics"},{"location":"examples/text_classification/#make-predictions-on-new-data","text":"Lastly we'll show how to generate predictions for new data. The following are some recent news headlines. Feel free to edit or add your own strings to text_to_predict to see how the newly trained model classifies them. cli python With text_to_predict.csv : title Google may spur cloud cybersecurity M&A with $5.4B Mandiant buy Europe struggles to meet mounting needs of Ukraine's fleeing millions How the pandemic housing market spurred buyer's remorse across America ludwig predict \\ --model_path results/experiment_run/model \\ --dataset text_to_predict.csv \\ --output_directory predictions text_to_predict = pd . DataFrame ({ \"title\" : [ \"Google may spur cloud cybersecurity M&A with $5.4B Mandiant buy\" , \"Europe struggles to meet mounting needs of Ukraine's fleeing millions\" , \"How the pandemic housing market spurred buyer's remorse across America\" , ] }) predictions , output_directory = model . predict ( text_to_predict ) This command will write predictions to output_directory . Predictions outputs are written in multiple formats including csv and parquet. For instance, predictions/predictions.parquet contains the predicted classes for each example as well as the psuedo-probabilities for each class: class_predictions class_probabilities class_probability class_probabilities_<UNK> class_probabilities_sci_tech class_probabilities_sports class_probabilities_world class_probabilities_business sci_tech [1.9864278277825775e-10, ... 0.954650 1.986428e-10 0.954650 0.000033 0.002563 0.042754 world [8.458710176739714e-09, ... 0.995293 8.458710e-09 0.002305 0.000379 0.995293 0.002022 business [3.710099008458201e-06, ... 0.490741 3.710099e-06 0.447916 0.000815 0.060523 0.490741","title":"Make Predictions on New Data"},{"location":"examples/titanic/","text":"This example describes how to use Ludwig to train a model for the kaggle competition , on predicting a passenger's probability of surviving the Titanic disaster. Here's a sample of the data: Pclass Sex Age SibSp Parch Fare Survived Embarked 3 male 22 1 0 7.2500 0 S 1 female 38 1 0 71.2833 1 C 3 female 26 0 0 7.9250 0 S 3 male 35 0 0 8.0500 0 S The full data and the column descriptions can be found here . After downloading the data, to train a model on this dataset using Ludwig, ludwig experiment \\ --dataset <PATH_TO_TITANIC_CSV> \\ --config config.yaml With config.yaml : input_features : - name : Pclass type : category - name : Sex type : category - name : Age type : number preprocessing : missing_value_strategy : fill_with_mean - name : SibSp type : number - name : Parch type : number - name : Fare type : number preprocessing : missing_value_strategy : fill_with_mean - name : Embarked type : category output_features : - name : Survived type : binary Better results can be obtained with morerefined feature transformations and preprocessing, but this example has the only aim to show how this type do tasks and data can be used in Ludwig.","title":"Binary Classification (Titanic)"},{"location":"examples/visual_qa/","text":"image_path question answer imdata/image_000001.jpg Is there snow on the mountains? yes imdata/image_000002.jpg What color are the wheels blue imdata/image_000003.jpg What kind of utensil is in the glass bowl knife ludwig experiment \\ --dataset vqa.csv \\ --config config.yaml With config.yaml : input_features : - name : image_path type : image encoder : stacked_cnn - name : question type : text encoder : parallel_cnn output_features : - name : answer type : text decoder : generator cell_type : lstm loss : type : softmax_cross_entropy","title":"Visual Question Answering"},{"location":"examples/weather/","text":"This example illustrates univariate timeseries forecasting using historical temperature data for Los Angeles. Dowload and unpack historical hourly weather data available on Kaggle https://www.kaggle.com/selfishgene/historical-hourly-weather-data Run the following python script to prepare the training dataset: import pandas as pd from ludwig.utils.data_utils import add_sequence_feature_column df = pd.read_csv( '<PATH_TO_FILE>/temperature.csv', usecols=['Los Angeles'] ).rename( columns={\"Los Angeles\": \"temperature\"} ).fillna(method='backfill').fillna(method='ffill') # normalize df.temperature = ((df.temperature-df.temperature.mean()) / df.temperature.std()) train_size = int(0.6 * len(df)) vali_size = int(0.2 * len(df)) # train, validation, test split df['split'] = 0 df.loc[ ( (df.index.values >= train_size) & (df.index.values < train_size + vali_size) ), ('split') ] = 1 df.loc[ df.index.values >= train_size + vali_size, ('split') ] = 2 # prepare timeseries input feature colum # (here we are using 20 preceding values to predict the target) add_sequence_feature_column(df, 'temperature', 20) df.to_csv('<PATH_TO_FILE>/temperature_la.csv') ludwig experiment \\ --dataset <PATH_TO_FILE>/temperature_la.csv \\ --config config.yaml With config.yaml : input_features : - name : temperature_feature type : timeseries encoder : rnn embedding_size : 32 state_size : 32 output_features : - name : temperature type : number","title":"Timeseries forecasting (Weather)"},{"location":"getting_started/","text":"Welcome to Ludwig's Getting Started Guide. This will go through a full workflow using the Rotten Tomatoes dataset, a CSV file with variety of feature types and a binary target: Installation Dataset preparation Training Prediction and evaluation Hyperparameter optimization Serving Distributed training on Ray","title":"Getting Started"},{"location":"getting_started/docker/","text":"You can also run Ludwig using the docker images available on dockerhub . These images come with a full set of pre-requiste packages to support the capabilities of Ludwig Repositories \u00b6 The following repositories each contain a version of Ludwig with full features built from the master branch. ludwigai/ludwig Ludwig packaged with PyTorch ludwigai/ludwig-gpu Ludwig packaged with gpu-enabled version of PyTorch ludwigai/ludwig-ray Ludwig packaged with PyTorch and nightly build of ray-project/ray ludwigai/ludwig-ray-gpu Ludwig packaged with gpu-enabled versions of PyTorch and nightly build of ray-project/ray Image Tags \u00b6 The following are the image tags that can be used when pulling and running the docker images. master - built from Ludwig's master branch nightly - nightly build of Ludwig's software. sha-<commit point> - version of Ludwig software at designated git sha1 7-character commit point. Running Containers \u00b6 Here are some examples of using the ludwigai/ludwig:master image to: run the ludwig cli command or run Python program containing Ludwig api or view Ludwig results with Tensorboard For purposes of the examples assume this host directory structure /top/level/directory/path/ data/ train.csv src/ config.yaml ludwig_api_program.py Run Ludwig CLI \u00b6 # set shell variable to parent directory parent_path = /top/level/directory/path # invoke docker run command to execute the ludwig cli # map host directory ${parent_path}/data to container /data directory # map host directory ${parent_path}/src to container /src directory docker run -v ${ parent_path } /data:/data \\ -v ${ parent_path } /src:/src \\ ludwigai/ludwig:master \\ experiment --config /src/config.yaml \\ --dataset /data/train.csv \\ --output_directory /src/results Experiment results can be found in host directory /top/level/directory/path/src/results Run Python program using Ludwig APIs \u00b6 # set shell variable to parent directory parent_path = /top/level/directory/path # invoke docker run command to execute Python interpreter # map host directory ${parent_path}/data to container /data directory # map host directory ${parent_path}/src to container /src directory # set current working directory to container /src directory # change default entrypoint from ludwig to python docker run -v ${ parent_path } /data:/data \\ -v ${ parent_path } /src:/src \\ -w /src \\ --entrypoint python \\ ludwigai/ludwig:master /src/ludwig_api_program.py Ludwig results can be found in host directory /top/level/directory/path/src/results","title":"Ludwig with Docker"},{"location":"getting_started/docker/#repositories","text":"The following repositories each contain a version of Ludwig with full features built from the master branch. ludwigai/ludwig Ludwig packaged with PyTorch ludwigai/ludwig-gpu Ludwig packaged with gpu-enabled version of PyTorch ludwigai/ludwig-ray Ludwig packaged with PyTorch and nightly build of ray-project/ray ludwigai/ludwig-ray-gpu Ludwig packaged with gpu-enabled versions of PyTorch and nightly build of ray-project/ray","title":"Repositories"},{"location":"getting_started/docker/#image-tags","text":"The following are the image tags that can be used when pulling and running the docker images. master - built from Ludwig's master branch nightly - nightly build of Ludwig's software. sha-<commit point> - version of Ludwig software at designated git sha1 7-character commit point.","title":"Image Tags"},{"location":"getting_started/docker/#running-containers","text":"Here are some examples of using the ludwigai/ludwig:master image to: run the ludwig cli command or run Python program containing Ludwig api or view Ludwig results with Tensorboard For purposes of the examples assume this host directory structure /top/level/directory/path/ data/ train.csv src/ config.yaml ludwig_api_program.py","title":"Running Containers"},{"location":"getting_started/docker/#run-ludwig-cli","text":"# set shell variable to parent directory parent_path = /top/level/directory/path # invoke docker run command to execute the ludwig cli # map host directory ${parent_path}/data to container /data directory # map host directory ${parent_path}/src to container /src directory docker run -v ${ parent_path } /data:/data \\ -v ${ parent_path } /src:/src \\ ludwigai/ludwig:master \\ experiment --config /src/config.yaml \\ --dataset /data/train.csv \\ --output_directory /src/results Experiment results can be found in host directory /top/level/directory/path/src/results","title":"Run Ludwig CLI"},{"location":"getting_started/docker/#run-python-program-using-ludwig-apis","text":"# set shell variable to parent directory parent_path = /top/level/directory/path # invoke docker run command to execute Python interpreter # map host directory ${parent_path}/data to container /data directory # map host directory ${parent_path}/src to container /src directory # set current working directory to container /src directory # change default entrypoint from ludwig to python docker run -v ${ parent_path } /data:/data \\ -v ${ parent_path } /src:/src \\ -w /src \\ --entrypoint python \\ ludwigai/ludwig:master /src/ludwig_api_program.py Ludwig results can be found in host directory /top/level/directory/path/src/results","title":"Run Python program using Ludwig APIs"},{"location":"getting_started/evaluate/","text":"After the model has been trained, it can be used to predict the target output features on new data. We've created a small test dataset containing input features for 10 movie reviews that we can use for testing. Download the test dataset here . Let's make some predictions on the test dataset! CLI Python Docker CLI ludwig predict --model_path results/experiment_run/model --dataset rotten_tomatoes_test.csv # This step can be skipped if you are working in a notebook, and you can simply # re-use the model created in the training section. model = LudwigModel . load ( 'results/experiment_run/model' ) predictions , _ = model . predict ( dataset = 'rotten_tomatoes_test.csv' ) predictions . head () docker run -t -i --mount type = bind,source ={ absolute/path/to/rotten_tomatoes_data } ,target = /rotten_tomatoes_data ludwigai/ludwig predict --model_path /rotten_tomatoes_data/results/experiment_run/model --dataset /rotten_tomatoes_data/rotten_tomatoes.csv Running this command will return model predictions. Your results should look something like this: Index recommended_probabilities recommended_predictions recommended_probabilities_False recommended_probabilities_True recommended_probability 0 [0.09741002321243286, 0.9025899767875671] True 0.097410 0.902590 0.902590 1 [0.6842662990093231, 0.3157337009906769] False 0.684266 0.315734 0.684266 2 [0.026504933834075928, 0.973495066165 9241] True 0.026505 0.973495 0.973495 3 [0.022977590560913086, 0.9770224094390869] True 0.022978 0.977022 0.977022 4 [0.9472369104623795, 0.052763089537620544] False 0.947237 0.052763 0.947237 A handy ludwig experiment CLI command is also available. This one command performs training and then prediction using the checkpoint with the best validation metric. In addition to predictions, Ludwig also computes a suite of evaluation metrics, depending on the output feature's type. The exact metrics that are computed for each output feature type can be found here . Note Non-loss evaluation metrics, like accuracy, require ground truth values of the target outputs. CLI Python Docker CLI ludwig evaluate --dataset path/to/data.csv --model_path /path/to/model eval_stats , _ , _ = model . evaluate ( dataset = 'rotten_tomatoes_test.csv' ) cp rotten_tomatoes_test.csv ./rotten_tomatoes_data docker run -t -i --mount type = bind,source ={ absolute/path/to/rotten_tomatoes_data } ,target = /rotten_tomatoes_data ludwigai/ludwig evaluate --dataset /rotten_tomatoes_data/rotten_tomatoes_test.csv --model_path /rotten_tomatoes_data/results/experiment_run/model Evaluation performance can be visualized using ludwig visualize . This enables us to visualize metrics like for omparing performances and predictions across different models. For instance, if you have two models which you want to compare evaluation statistics for, you could use the following commands: CLI Python Docker CLI ludwig visualize --visualization compare_performance --test_statistics path/to/test_statistics_model_1.json path/to/test_statistics_model_2.json from ludwig.visualize import compare_performance compare_performance ([ eval_stats_model_1 , eval_stats_model_2 ]) docker run -t -i --mount type = bind,source ={ absolute/path/to/rotten_tomatoes_data } ,target = /rotten_tomatoes_data ludwigai/ludwig visualize --visualization compare_performance --test_statistics /rotten_tomatoes_data/path/to/test_statistics_model_1.json /rotten_tomatoes_data/path/to/test_statistics_model_2.json This will return a bar plot comparing the performance of each model on different metrics like the example below.","title":"Prediction and Evaluation"},{"location":"getting_started/hyperopt/","text":"After training our first model and using it to predict new data with reasonable accuracy, how can we make the model better? Ludwig can perform hyperparameter optimization by simply adding hyperopt to the Ludwig config. rotten_tomatoes.yaml input_features : - name : genres type : set - name : content_rating type : category - name : top_critic type : binary - name : runtime type : number - name : review_content type : text encoder : embed output_features : - name : recommended type : binary hyperopt : goal : maximize output_feature : recommended metric : accuracy split : validation parameters : training.learning_rate : space : loguniform lower : 0.0001 upper : 0.1 training.optimizer.type : space : choice categories : [ sgd , adam , adagrad ] review_content.embedding_size : space : choice categories : [ 128 , 256 ] search_alg : type : variant_generator executor : num_samples : 10 In this example we have specified a basic hyperopt config with the following specifications: We have set the goal to maximize the accuracy metric on the validation split The parameters we are optimizing are the learning rate , the optimizer type , and the embedding_size of text representation to use. When optimizing learning rate we are randomly selecting values on a log scale between 0.0001 and 0.1. When optimizing the optimizer type , we randomly select the optimizer from sgd , adam , and adagrad optimizers. When optimizing the embedding_size of text representation we randomly chose between 128 or 256. We set hyperopt executor to use Ray Tune's variant_generator search algorithm and generates 10 random hyperparameter combinations from the search space we defined. The execution will locally run trials in parallel. Ludwig supports advanced hyperparameter sampling algorithms like Bayesian optimization and genetical algorithms. See this guide for details. The hyperparameter optimization strategy is run using the ludwig hyperopt command: CLI Python Docker CLI ludwig hyperopt --config rotten_tomatoes.yaml --dataset rotten_tomatoes.csv from ludwig.hyperopt.run import hyperopt import pandas df = pandas . read_csv ( 'rotten_tomatoes.csv' ) results = hyperopt ( config = 'rotten_tomatoes.yaml' , dataset = df ) docker run -t -i --mount type = bind,source ={ absolute/path/to/rotten_tomatoes_data } ,target = /rotten_tomatoes_data ludwigai/ludwig hyperopt --config /rotten_tomatoes_data/rotten_tomatoes.yaml --dataset /rotten_tomatoes_data/rotten_tomatoes.csv Every parameter within the config can be tuned using hyperopt. Refer to the full hyperopt guide to learn more.","title":"Hyperopt"},{"location":"getting_started/installation/","text":"Ludwig is a declarative deep learning framework that allows users to train, evaluate, and deploy models without the need to write code. Being declarative means you only need to tell Ludwig what columns in your data are input and output features, and Ludwig will figure out how to train the best model. For users familiar with Python, we recommend installing with pip within an isolated virtual environment . If not, you can use our pre-built docker images. Advanced users can also install Ludwig from git . For large or long-running workloads, Ludwig can be run remotely in the cloud or on a private compute cluster using Ray . Python (with Pip) recommended \u00b6 pip install ludwig This will install Ludwig's basic requirements for modeling with binary, category, number, text, image, and audio features. The requirements for additional functionality are separated out so that users are able to install only the ones they actually need: ludwig[serve] for serving dependencies. ludwig[viz] for visualization dependencies. ludwig[hyperopt] for hyperparameter optimization dependencies. ludwig[distributed] for distributed training on Ray using Dask and Horovod . The full set of dependencies can be installed with: pip install 'ludwig[full]' GPU support \u00b6 If your machine has a GPU to accelerate the training process, make sure you install a GPU-enabled version of PyTorch before installing Ludwig: pip install torch -f https://download.pytorch.org/whl/cu113/torch_stable.html The example above will install the latest version of PyTorch with CUDA 11.3. See the official PyTorch docs for more details on installing the right version of PyTorch for your environment. Docker \u00b6 The Ludwig team publishes official Docker images that come with the full set of dependencies pre-installed. You can pull the latest images (for the most recent official Ludwig release) by running: docker pull ludwigai/ludwig:latest The ludwig command line tool is provided as the entrypoint for all commands. GPU support \u00b6 If your machine has a GPU to accelerate the training process, pull the official Ludwig image with GPU support: docker pull ludwigai/ludwig-gpu:latest Git \u00b6 For developers who wish to build the source code from the GitHub repository, first clone the repo locally: git clone git@github.com:ludwig-ai/ludwig.git Install the required dependencies: pip install -e '.[test]' The test extra will pull in all Ludwig dependencies in addition to test dependencies.","title":"Installation"},{"location":"getting_started/installation/#with-pip","text":"pip install ludwig This will install Ludwig's basic requirements for modeling with binary, category, number, text, image, and audio features. The requirements for additional functionality are separated out so that users are able to install only the ones they actually need: ludwig[serve] for serving dependencies. ludwig[viz] for visualization dependencies. ludwig[hyperopt] for hyperparameter optimization dependencies. ludwig[distributed] for distributed training on Ray using Dask and Horovod . The full set of dependencies can be installed with: pip install 'ludwig[full]'","title":"Python (with Pip) recommended"},{"location":"getting_started/installation/#gpu-support","text":"If your machine has a GPU to accelerate the training process, make sure you install a GPU-enabled version of PyTorch before installing Ludwig: pip install torch -f https://download.pytorch.org/whl/cu113/torch_stable.html The example above will install the latest version of PyTorch with CUDA 11.3. See the official PyTorch docs for more details on installing the right version of PyTorch for your environment.","title":"GPU support"},{"location":"getting_started/installation/#with-docker","text":"The Ludwig team publishes official Docker images that come with the full set of dependencies pre-installed. You can pull the latest images (for the most recent official Ludwig release) by running: docker pull ludwigai/ludwig:latest The ludwig command line tool is provided as the entrypoint for all commands.","title":"Docker"},{"location":"getting_started/installation/#gpu-support_1","text":"If your machine has a GPU to accelerate the training process, pull the official Ludwig image with GPU support: docker pull ludwigai/ludwig-gpu:latest","title":"GPU support"},{"location":"getting_started/installation/#with-git","text":"For developers who wish to build the source code from the GitHub repository, first clone the repo locally: git clone git@github.com:ludwig-ai/ludwig.git Install the required dependencies: pip install -e '.[test]' The test extra will pull in all Ludwig dependencies in addition to test dependencies.","title":"Git"},{"location":"getting_started/prepare_data/","text":"Ludwig can train on any table-like dataset, meaning that every feature has its own column and every example its own row . In this example, we'll use this Rotten Tomatoes dataset, a CSV file with variety of feature types and a binary target. Download the data locally here . Let's take a look at the first 5 rows to see how the data is arranged: CLI Python head -n 5 rotten_tomatoes.csv import pandas as pd df = pd . read_csv ( 'rotten_tomatoes.csv' ) df . head () Your results should look a little something like this: movie_title content_rating genres runtime top_critic review_content recommended Deliver Us from Evil R Action & Adventure, Horror 117.0 TRUE Director Scott Derrickson and his co-writer, Paul Harris Boardman, deliver a routine procedural with unremarkable frights. 0 Barbara PG-13 Art House & International, Drama 105.0 FALSE Somehow, in this stirring narrative, Barbara manages to keep hold of her principles, and her humanity and courage, and battles to save a dissident teenage girl whose life the Communists are trying to destroy. 1 Horrible Bosses R Comedy 98.0 FALSE These bosses cannot justify either murder or lasting comic memories, fatally compromising a farce that could have been great but ends up merely mediocre. 0 Money Monster R Drama 98.0 FALSE A satire about television that feels like it was made by the kind of people who claim they don't even watch TV. 0 Battle Royale NR Action & Adventure, Art House & International, Drama, Mystery & Suspense 114.0 FALSE Battle Royale is The Hunger Games not diluted for young audiences. 1","title":"Dataset preparation"},{"location":"getting_started/ray/","text":"Ludwig has strong support for Ray , a framework for distributed computing that makes it easy to scale up code that runs on your local machine to execute in parallel across a cluster of machines. Let's spin up a ray cluster, so we can try out distributed training and hyperparameter tuning in parallel. Make sure you have access to an AWS EC2 node provider. First install the Ray Cluster Launcher: pip install ray Next let's make a configuration file named cluster.yaml for the Ray Cluster: cluster.yaml cluster_name : ludwig-ray-gpu-nightly min_workers : 4 max_workers : 4 docker : image : \"ludwigai/ludwig-ray-gpu:nightly\" container_name : \"ray_container\" head_node : InstanceType : c5.2xlarge ImageId : latest_dlami worker_nodes : InstanceType : g4dn.xlarge ImageId : latest_dlami Finally, you can spin up the cluster with the following command: ray up cluster.yaml In order to run a distributed training job, make sure you have your dataset stored in an S3 bucket, and run this command: ray submit cluster.yaml ludwig train --config rotten_tomatoes.yaml --dataset s3://mybucket/rotten_tomatoes.csv You can also run a distributed hyperopt job with this command: ray submit cluster.yaml ludwig hyperopt --config rotten_tomatoes.yaml --dataset s3://mybucket/rotten_tomatoes.csv For more information on using Ray with Ludwig, refer to the ray configuration guide .","title":"Distributed training on Ray"},{"location":"getting_started/serve/","text":"Model pipelines trained with Ludwig can be served by spawning a Rest API using the FastAPI library. Let's serve the model we just created. CLI Docker CLI ludwig serve --model_path ./results/experiment_run/model docker run -t -i --mount type = bind,source ={ absolute/path/to/rotten_tomatoes_data } ,target = /rotten_tomatoes_data ludwigai/ludwig serve --model_path /rotten_tomatoes_data/results/experiment_run/model Now that our server is up and running, you can make a POST request on the endpoint to get predictions back: curl http://0.0.0.0:8000/predict -X POST -F \"movie_title=Friends With Money\" -F \"content_rating=R\" -F \"genres=Art House & International, Comedy, Drama\" -F \"runtime=88.0\" -F \"top_critic=TRUE\" -F \"review_content=The cast is terrific, the movie isn't.\" Since the output feature is a binary type feature, the output from the POST call will look something like this: { \"review_content_predictions\": false, \"review_content_probabilities_False\": 0.76, \"review_content_probabilities_True\": 0.24, \"review_content_probability\": 0.76 } Note Users can also send POST requests to the /batch_predict endpoint to run inference on multiple examples at once. Read more about ludwig serve to learn more about ludwig deployments.","title":"Serving"},{"location":"getting_started/train/","text":"To train a model with Ludwig, we first need to create a Ludwig configuration . The config specifies input features, output features, preprocessing, model architecture, training loop, hyperparameter search, and backend infrastructure -- everything that's needed to build, train, and evaluate a model. At a minimum, the config must specify the model's input and output features. For now, let's use a basic config that just specifies the inputs and output and leaves the rest to Ludwig: rotten_tomatoes.yaml input_features : - name : genres type : set preprocessing : tokenizer : comma - name : content_rating type : category - name : top_critic type : binary - name : runtime type : number - name : review_content type : text encoder : embed output_features : - name : recommended type : binary This config file tells Ludwig that we want to train a model that uses the following input features : The genres associated with the movie will be used as a set feature The movie's content rating will be used as a category feature Whether the review was done by a top critic or not will be used as a binary feature The movie's runtime will be used as a number feature The review content will be used as text feature This config file also tells Ludwig that we want our model to have the following output features : The recommendation of whether to watch the movie or not will be output as a binary feature Once you've created the rotten_tomatoes.yaml file with the contents above, you're ready to train your first model: CLI Python Docker CLI ludwig train --config rotten_tomatoes.yaml --dataset rotten_tomatoes.csv from ludwig.api import LudwigModel import pandas df = pandas . read_csv ( 'rotten_tomatoes.csv' ) model = LudwigModel ( config = 'rotten_tomatoes.yaml' ) results = model . train ( dataset = df ) mkdir rotten_tomatoes_data mv rotten_tomatoes.yaml ./rotten_tomatoes_data mv rotten_tomatoes.csv ./rotten_tomatoes_data docker run -t -i --mount type = bind,source ={ absolute/path/to/rotten_tomatoes_data } ,target = /rotten_tomatoes_data ludwigai/ludwig train --config /rotten_tomatoes_data/rotten_tomatoes.yaml --dataset /rotten_tomatoes_data/rotten_tomatoes.csv --output_directory /rotten_tomatoes_data Note In this example, we encoded the text feature with an embed encoder, which assigns an embedding for each word and sums them. Ludwig provides many options for tokenizing and embedding text like with CNNs, RNNs, Transformers, and pretrained models such as BERT or GPT-2 (provided through huggingface ). Using a different text encoder is simple as changing encoder option in the config from embed to bert . Give it a try! input_features : - name : genres type : set preprocessing : tokenizer : comma - name : content_rating type : category - name : top_critic type : binary - name : runtime type : number - name : review_content type : text encoder : bert output_features : - name : recommended type : binary Ludwig is very flexible. Users can configure just about any parameter in their models including training parameters, preprocessing parameters, and more, directly from the configuration. Check out the config documentation for the full list of parameters available in the configuration.","title":"Training"},{"location":"user_guide/","text":"Welcome to the Ludwig User Guide! Here, you can read about What Ludwig is , How Ludwig works , and various features that Ludwig supports like AutoML , Hyperparameter optimization , Distributed Training , Serving , Visualization , the Dataset Zoo , and more, with code snippets and examples scattered throughout. For a new-user-friendly guide, check out Getting Started . For comprehensive documentation about what parameters are available in the Ludwig configuration, what they do, and how to use them, check out Configuration . For complete end-to-end examples, check out the Examples . Happy reading!","title":"User Guide"},{"location":"user_guide/automl/","text":"Ludwig AutoML takes a dataset, the target column, and a time budget, and returns a trained Ludwig model. Ludwig AutoML is currently experimental and is focused on tabular datasets. A blog describing its development, evaluation, and use is here . Ludwig AutoML infers the types of the input and output features, chooses the model architecture, and launches a Ray Tune Async HyperBand search job across a set of hyperparameters and ranges, limited by the specified time budget. It returns the set of models produced by the trials in the search sorted from best to worst, along with a hyperparameter search report, which can be inspected manually or post-processed by various Ludwig visualization tools. Users can audit and interact with Ludwig AutoML in various ways, described below. auto_train \u00b6 The basic API for Ludwig AutoML is auto_train . A simple example of its invocation can be found here . import logging import pprint from ludwig.automl import auto_train from ludwig.datasets import mushroom_edibility from ludwig.utils.dataset_utils import get_repeatable_train_val_test_split mushroom_df = mushroom_edibility . load () mushroom_edibility_df = get_repeatable_train_val_test_split ( mushroom_df , 'class' , random_seed = 42 ) auto_train_results = auto_train ( dataset = mushroom_edibility_df , target = 'class' , time_limit_s = 7200 , tune_for_memory = False , user_config = { 'preprocessing' : { 'split' : { 'column' : 'split' , 'type' : 'fixed' }}}, ) pprint . pprint ( auto_train_results ) create_auto_config \u00b6 The Ludwig AutoML create_auto_config API outputs auto_train \u2019s hyperparameter search configuration without running the search. This API is useful for examining AutoML's chosen input and output feature types, model architecture, and hyperparameters and ranges. A simple example of its invocation: import logging import pprint from ludwig.automl import create_auto_config from ludwig.datasets import mushroom_edibility from ludwig.utils.dataset_utils import get_repeatable_train_val_test_split mushroom_df = mushroom_edibility . load () mushroom_edibility_df = get_repeatable_train_val_test_split ( mushroom_df , 'class' , random_seed = 42 ) auto_config = create_auto_config ( dataset = mushroom_edibility_df , target = 'class' , time_limit_s = 7200 , tune_for_memory = False , user_config = { 'preprocessing' : { 'split' : { 'column' : 'split' , 'type' : 'fixed' }}}, ) pprint . pprint ( auto_config ) Source The API is also useful for manual refinement of the AutoML-generated search; the output of this API can be edited and then directly used as the input configuration for a Ludwig hyperparameter search job. Overriding auto configs with user_config \u00b6 The user_config parameter can be provided to the auto_train or create_auto_config APIs to override specified parts of the configuration produced. For example, we can specify that the TripType output feature for the Walmart Recruiting dataset specifies be set to type category , to override the Ludwig AutoML type detection system\u2019s characterization of the feature as a number feature. import logging import pprint from ludwig.automl import auto_train from ludwig.datasets import walmart_recruiting from ludwig.utils.dataset_utils import get_repeatable_train_val_test_split walmart_df = walmart_recruiting . load () walmart_recruiting_df = get_repeatable_train_val_test_split ( walmart_df , 'TripType' , random_seed = 42 ) auto_train_results = auto_train ( dataset = walmart_recruiting_df , target = 'TripType' , time_limit_s = 3600 , tune_for_memory = False , user_config = { 'output_features' : [{ 'column' : 'TripType' , 'name' : 'TripType' , 'type' : 'category' }], 'preprocessing' : { 'split' : { 'column' : 'split' , 'type' : 'fixed' }}}, ) pprint . pprint ( auto_train_results ) Source We can also specify that the hyperparameter search job optimize for maximum accuracy of the specified output feature rather than minimal loss of all combined output features, which is the default. import logging import pprint from ludwig.automl import auto_train from ludwig.datasets import mushroom_edibility from ludwig.utils.dataset_utils import get_repeatable_train_val_test_split mushroom_df = mushroom_edibility . load () mushroom_edibility_df = get_repeatable_train_val_test_split ( mushroom_df , 'class' , random_seed = 42 ) auto_train_results = auto_train ( dataset = mushroom_edibility_df , target = 'class' , time_limit_s = 3600 , tune_for_memory = False , user_config = { 'hyperopt' : { 'goal' : 'maximize' , 'metric' : 'accuracy' , 'output_feature' : 'class' }, 'preprocessing' : { 'split' : { 'column' : 'split' , 'type' : 'fixed' }}}, ) pprint . pprint ( auto_train_results ) Source","title":"AutoML"},{"location":"user_guide/automl/#auto_train","text":"The basic API for Ludwig AutoML is auto_train . A simple example of its invocation can be found here . import logging import pprint from ludwig.automl import auto_train from ludwig.datasets import mushroom_edibility from ludwig.utils.dataset_utils import get_repeatable_train_val_test_split mushroom_df = mushroom_edibility . load () mushroom_edibility_df = get_repeatable_train_val_test_split ( mushroom_df , 'class' , random_seed = 42 ) auto_train_results = auto_train ( dataset = mushroom_edibility_df , target = 'class' , time_limit_s = 7200 , tune_for_memory = False , user_config = { 'preprocessing' : { 'split' : { 'column' : 'split' , 'type' : 'fixed' }}}, ) pprint . pprint ( auto_train_results )","title":"auto_train"},{"location":"user_guide/automl/#create_auto_config","text":"The Ludwig AutoML create_auto_config API outputs auto_train \u2019s hyperparameter search configuration without running the search. This API is useful for examining AutoML's chosen input and output feature types, model architecture, and hyperparameters and ranges. A simple example of its invocation: import logging import pprint from ludwig.automl import create_auto_config from ludwig.datasets import mushroom_edibility from ludwig.utils.dataset_utils import get_repeatable_train_val_test_split mushroom_df = mushroom_edibility . load () mushroom_edibility_df = get_repeatable_train_val_test_split ( mushroom_df , 'class' , random_seed = 42 ) auto_config = create_auto_config ( dataset = mushroom_edibility_df , target = 'class' , time_limit_s = 7200 , tune_for_memory = False , user_config = { 'preprocessing' : { 'split' : { 'column' : 'split' , 'type' : 'fixed' }}}, ) pprint . pprint ( auto_config ) Source The API is also useful for manual refinement of the AutoML-generated search; the output of this API can be edited and then directly used as the input configuration for a Ludwig hyperparameter search job.","title":"create_auto_config"},{"location":"user_guide/automl/#overriding-auto-configs-with-user_config","text":"The user_config parameter can be provided to the auto_train or create_auto_config APIs to override specified parts of the configuration produced. For example, we can specify that the TripType output feature for the Walmart Recruiting dataset specifies be set to type category , to override the Ludwig AutoML type detection system\u2019s characterization of the feature as a number feature. import logging import pprint from ludwig.automl import auto_train from ludwig.datasets import walmart_recruiting from ludwig.utils.dataset_utils import get_repeatable_train_val_test_split walmart_df = walmart_recruiting . load () walmart_recruiting_df = get_repeatable_train_val_test_split ( walmart_df , 'TripType' , random_seed = 42 ) auto_train_results = auto_train ( dataset = walmart_recruiting_df , target = 'TripType' , time_limit_s = 3600 , tune_for_memory = False , user_config = { 'output_features' : [{ 'column' : 'TripType' , 'name' : 'TripType' , 'type' : 'category' }], 'preprocessing' : { 'split' : { 'column' : 'split' , 'type' : 'fixed' }}}, ) pprint . pprint ( auto_train_results ) Source We can also specify that the hyperparameter search job optimize for maximum accuracy of the specified output feature rather than minimal loss of all combined output features, which is the default. import logging import pprint from ludwig.automl import auto_train from ludwig.datasets import mushroom_edibility from ludwig.utils.dataset_utils import get_repeatable_train_val_test_split mushroom_df = mushroom_edibility . load () mushroom_edibility_df = get_repeatable_train_val_test_split ( mushroom_df , 'class' , random_seed = 42 ) auto_train_results = auto_train ( dataset = mushroom_edibility_df , target = 'class' , time_limit_s = 3600 , tune_for_memory = False , user_config = { 'hyperopt' : { 'goal' : 'maximize' , 'metric' : 'accuracy' , 'output_feature' : 'class' }, 'preprocessing' : { 'split' : { 'column' : 'split' , 'type' : 'fixed' }}}, ) pprint . pprint ( auto_train_results ) Source","title":"Overriding auto configs with user_config"},{"location":"user_guide/command_line_interface/","text":"Commands \u00b6 Ludwig provides several functions through its command line interface. Mode Description train Trains a model predict Predicts using a pretrained model evaluate Evaluate a pretrained model's performance experiment Runs a full experiment training a model and evaluating it hyperopt Perform hyperparameter optimization serve Serves a pretrained model visualize Visualizes experiment results init_config Initialize a user config from a dataset and targets render_config Renders the fully populated config with all defaults set collect_summary Prints names of weights and layers activations to use with other collect commands collect_weights Collects tensors containing a pretrained model weights collect_activations Collects tensors for each datapoint using a pretrained model export_torchscript Exports Ludwig models to Torchscript export_neuropod Exports Ludwig models to Neuropod export_mlflow Exports Ludwig models to MLflow preprocess Preprocess data and saves it into HDF5 and JSON format synthesize_dataset Creates synthetic data for testing purposes These are described in detail below. train \u00b6 Train a model from your data. ludwig train [ options ] or with: python -m ludwig.train [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig train [options] This script trains a model optional arguments: -h, --help show this help message and exit --output_directory OUTPUT_DIRECTORY directory that contains the results --experiment_name EXPERIMENT_NAME experiment name --model_name MODEL_NAME name for the model --dataset DATASET input data file path. If it has a split column, it will be used for splitting (0: train, 1: validation, 2: test), otherwise the dataset will be randomly split --training_set TRAINING_SET input train data file path --validation_set VALIDATION_SET input validation data file path --test_set TEST_SET input test data file path --training_set_metadata TRAINING_SET_METADATA input metadata JSON file path. An intermediate preprocessed containing the mappings of the input file created the first time a file is used, in the same directory with the same name and a .json extension --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -sspi, --skip_save_processed_input skips saving intermediate HDF5 and JSON files -c CONFIG, --config CONFIG Path to the YAML file containing the model configuration -cs CONFIG_STR, --config_str CONFIG_STRING JSON or YAML serialized string of the model configuration. Ignores --config -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH path of a pretrained model to load as initialization -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH path of the model directory to resume training of -sstd, --skip_save_training_description disables saving the description JSON file -ssts, --skip_save_training_statistics disables saving training statistics JSON file -ssm, --skip_save_model disables saving weights each time the model improves. By default Ludwig saves weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance can a model get with a set of hyperparameters, use this parameter to skip it -ssp, --skip_save_progress disables saving weights after each epoch. By default ludwig saves weights after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will save twice as much space, use this parameter to skip it -ssl, --skip_save_log disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed -rs RANDOM_SEED, --random_seed RANDOM_SEED a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling -g GPUS [GPUS ...], --gpus GPUS [GPUS ...] list of gpus to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun When Ludwig trains a model it creates two intermediate files, one HDF5 and one JSON. The HDF5 file contains the data mapped to numpy ndarrays, while the JSON file contains the mappings from the values in the tensors to their original labels. For instance, for a categorical feature with 3 possible values, the HDF5 file will contain integers from 0 to 3 (with 0 being a <UNK> category), while the JSON file will contain a idx2str list containing all tokens ( [<UNK>, label_1, label_2, label_3] ), a str2idx dictionary ( {\"<UNK>\": 0, \"label_1\": 1, \"label_2\": 2, \"label_3\": 3} ) and a str2freq dictionary ( {\"<UNK>\": 0, \"label_1\": 93, \"label_2\": 55, \"label_3\": 24} ). The reason to have those intermediate files is two-fold: on one hand, if you are going to train your model again Ludwig will try to load them instead of recomputing all tensors, which saves a considerable amount of time, and on the other hand when you want to use your model to predict, data has to be mapped to tensors in exactly the same way it was mapped during training, so you'll be required to load the JSON metadata file in the predict command. The first time you provide a UTF-8 encoded dataset ( --dataset ), the HDF5 and JSON files are created, from the second time on Ludwig will load them instead of the dataset even if you specify the dataset (it looks in the same directory for files names in the same way but with a different extension), finally you can directly specify the HDF5 and JSON files. As the mapping from raw data to tensors depends on the type of feature that you specify in your configuration, if you change type (for instance from sequence to text ) you also have to redo the preprocessing, which is achieved by deleting the HDF5 and JSON files. Alternatively you can skip saving the HDF5 and JSON files specifying --skip_save_processed_input . Splitting between train, validation and test set can be done in several ways. This allows for a few possible input data scenarios: one single UTF-8 encoded dataset file is provided ( -dataset ). In this case if the dataset contains a split column with values 0 for training, 1 for validation and 2 for test, this split will be used. If you want to ignore the split column and perform a random split, use a force_split argument in the configuration. In the case when there is no split column, a random 70-20-10 split will be performed. You can set the percentages and specify if you want stratified sampling in the configuration preprocessing section. you can provide separate UTF-8 encoded training, validation and test sets ( --training_set , --validation_set , --test_set ). the HDF5 and JSON file indications specified in the case of a single dataset file apply also in the multiple files case, with the only difference that you need to specify only one JSON file ( --train_set_metadata_json ). The validation set is optional, but if absent the training will continue until the end of the training epochs, while when there's a validation set the default behavior is to perform early stopping after the validation measure does not improve for a certain amount of epochs. The test set is optional too. Other optional arguments are --output_directory , --experiment_name and --model name . By default the output directory is ./results . That directory will contain a directory named [experiment_name]_[model_name]_0 if model name and experiment name are specified. If the same combination of experiment and model name is used again, the integer at the end of the name will be increased. If neither of them is specified the directory will be named run_0 . The directory will contain description.json - a file containing a description of the training process with all the information to reproduce it. training_statistics.json - a file containing records of all measures and losses for each epoch. model - a directory containing model hyperparameters, weights, checkpoints and logs (for TensorBoard). The configuration can be provided either as a string ( --config_str ) or as YAML file ( --config ). Details on how to write your configuration are provided in the Configuration section. During training Ludwig saves two sets of weights for the model, one that is the weights at the end of the epoch where the best performance on the validation measure was achieved and one that is the weights at the end of the latest epoch. The reason for keeping the second set is to be able to resume training in case the training process gets interrupted somehow. To resume training using the latest weights and the whole history of progress so far you have to specify the --model_resume_path argument. You can avoid saving the latest weights and the overall progress so far by using the argument --skip_save_progress , but you will not be able to resume it afterwards. Another available option is to load a previously trained model as an initialization for a new training process. In this case Ludwig will start a new training process, without knowing any progress of the previous model, no training statistics, nor the number of epochs the model has been trained on so far. It's not resuming training, just initializing training with a previously trained model with the same configuration, and it is accomplished through the --model_load_path argument. You can specify a random seed to be used by the python environment, python random package, numpy and Torch with the --random_seed argument. This is useful for reproducibility. Be aware that due to asynchronicity in the Torch's GPU execution, when training on GPU results may not be reproducible. You can manage which GPUs on your machine are used with the --gpus argument, which accepts a string identical to the format of CUDA_VISIBLE_DEVICES environment variable, namely a list of integers separated by comma. You can also specify the maximum amount of GPU memory which will be allocated per device with --gpu_memory_limit . By default all of memory is allocated. If less than all of memory is allocated, Torch will need more GPU memory it will try to increase this amount. If parameter --backend is set, will use the given backend for distributed processing (Horovod or Ray). Finally the --logging_level argument lets you set the amount of logging that you want to see during training. Example: ludwig train --dataset reuters-allcats.csv --config \"{input_features: [{name: text, type: text, encoder: parallel_cnn}], output_features: [{name: class, type: category}]}\" predict \u00b6 This command lets you use a previously trained model to predict on new data. You can call it with: ludwig predict [ options ] or with: python -m ludwig.predict [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig predict [options] This script loads a pretrained model and uses it to predict optional arguments: -h, --help show this help message and exit --dataset DATASET input data file path --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -s {training,validation,test,full}, --split {training,validation,test,full} the split to test the model on -m MODEL_PATH, --model_path MODEL_PATH model to load -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory that contains the results -ssuo, --skip_save_unprocessed_output skips saving intermediate NPY output files -sstp, --skip_save_predictions skips saving predictions CSV files -bs BATCH_SIZE, --batch_size BATCH_SIZE size of batches -g GPUS, --gpus GPUS list of gpu to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use The same distinction between UTF-8 encoded dataset files and HDF5 / JSON files explained in the train section also applies here. In either case, the JSON metadata file obtained during training is needed in order to map the new data into tensors. If the new data contains a split column, you can specify which split to use to calculate the predictions with the --split argument. By default it's full which means all the splits will be used. A model to load is needed, and you can specify its path with the --model_path argument. If you trained a model previously and got the results in, for instance, ./results/experiment_run_0 , you have to specify ./results/experiment_run_0/model for using it to predict. You can specify an output directory with the argument --output-directory , by default it will be ./result_0 , with increasing numbers if a directory with the same name is present. The directory will contain a prediction CSV file and a probability CSV file for each output feature, together with raw NPY files containing raw tensors. You can specify not to save the raw NPY output files with the argument skip_save_unprocessed_output . A specific batch size for speeding up the prediction can be specified using the argument --batch_size . Finally the --logging_level , --debug , --gpus , --gpu_memory_limit and --disable_parallel_threads related arguments behave exactly like described in the train command section. Example: ludwig predict --dataset reuters-allcats.csv --model_path results/experiment_run_0/model/ evaluate \u00b6 This command lets you use a previously trained model to predict on new data and evaluate the performance of the prediction compared to ground truth. You can call it with: ludwig evaluate [ options ] or with: python -m ludwig.evaluate [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig evaluate [options] This script loads a pretrained model and evaluates its performance by comparing its predictions with ground truth. optional arguments: -h, --help show this help message and exit --dataset DATASET input data file path --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -s {training,validation,test,full}, --split {training,validation,test,full} the split to test the model on -m MODEL_PATH, --model_path MODEL_PATH model to load -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory that contains the results -ssuo, --skip_save_unprocessed_output skips saving intermediate NPY output files -sses, --skip_save_eval_stats skips saving intermediate JSON eval statistics -scp, --skip_collect_predictions skips collecting predictions -scos, --skip_collect_overall_stats skips collecting overall stats -bs BATCH_SIZE, --batch_size BATCH_SIZE size of batches -g GPUS, --gpus GPUS list of gpu to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use All parameters are the same of predict and the behavior is the same. The only difference isthat evaluate requires the dataset to contain also columns with the same name of output features. This is needed because evaluate compares the predictions produced by the model with the ground truth and will save all those statistics in a test_statistics.json file in the result directory. Note that the data must contain columns for each output feature with ground truth output values in order to compute the performance statistics. If you receive an error regarding a missing output feature column in your data, it means that the data does not contain the columns for each output feature to use as ground truth. Example: ludwig evaluate --dataset reuters-allcats.csv --model_path results/experiment_run_0/model/ experiment \u00b6 This command combines training and evaluation into a single handy command. You can request a k-fold cross validation run by specifying the --k_fold parameter. You can call it with: ludwig experiment [ options ] or with: python -m ludwig.experiment [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig experiment [options] This script trains and evaluates a model optional arguments: -h, --help show this help message and exit --output_directory OUTPUT_DIRECTORY directory that contains the results --experiment_name EXPERIMENT_NAME experiment name --model_name MODEL_NAME name for the model --dataset DATASET input data file path. If it has a split column, it will be used for splitting (0: train, 1: validation, 2: test), otherwise the dataset will be randomly split --training_set TRAINING_SET input train data file path --validation_set VALIDATION_SET input validation data file path --test_set TEST_SET input test data file path --training_set_metadata TRAINING_SET_METADATA input metadata JSON file path. An intermediate preprocessed containing the mappings of the input file created the first time a file is used, in the same directory with the same name and a .json extension --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -es {training,validation,test,full}, --eval_split {training,validation,test,full} the split to evaluate the model on -sspi, --skip_save_processed_input skips saving intermediate HDF5 and JSON files -ssuo, --skip_save_unprocessed_output skips saving intermediate NPY output files -kf K_FOLD, --k_fold K_FOLD number of folds for a k-fold cross validation run -skfsi, --skip_save_k_fold_split_indices disables saving indices generated to split training data set for the k-fold cross validation run, but if it is not needed turning it off can slightly increase the overall speed -c CONFIG, --config CONFIG Path to the YAML file containing the model configuration -cs CONFIG_STR, --config_str CONFIG_STRING JSON or YAML serialized string of the model configuration. Ignores --config -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH path of a pretrained model to load as initialization -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH path of the model directory to resume training of -sstd, --skip_save_training_description disables saving the description JSON file -ssts, --skip_save_training_statistics disables saving training statistics JSON file -sstp, --skip_save_predictions skips saving test predictions CSV files -sstes, --skip_save_eval_stats skips saving eval statistics JSON file -ssm, --skip_save_model disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming if you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it,but the model will not be loadable later on -ssp, --skip_save_progress disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on -ssl, --skip_save_log disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed -rs RANDOM_SEED, --random_seed RANDOM_SEED a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling -g GPUS [GPUS ...], --gpus GPUS [GPUS ...] list of GPUs to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use The parameters combine parameters from both train and test so refer to those sections for an in depth explanation. The output directory will contain the outputs both commands produce. Example: ludwig experiment --dataset reuters-allcats.csv --config \"{input_features: [{name: text, type: text, encoder: parallel_cnn}], output_features: [{name: class, type: category}]}\" hyperopt \u00b6 This command lets you perform an hyperparameter search with a given sampler and parameters. You can call it with: ludwig hyperopt [ options ] or with: python -m ludwig.hyperopt [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig hyperopt [ options ] This script searches for optimal Hyperparameters optional arguments: -h, --help show this help message and exit -sshs, --skip_save_hyperopt_statistics skips saving hyperopt statistics file --output_directory OUTPUT_DIRECTORY directory that contains the results --experiment_name EXPERIMENT_NAME experiment name --model_name MODEL_NAME name for the model --dataset DATASET input data file path. If it has a split column, it will be used for splitting ( 0 : train, 1 : validation, 2 : test ) , otherwise the dataset will be randomly split --training_set TRAINING_SET input train data file path --validation_set VALIDATION_SET input validation data file path --test_set TEST_SET input test data file path --training_set_metadata TRAINING_SET_METADATA input metadata JSON file path. An intermediate preprocessed file containing the mappings of the input file created the first time a file is used, in the same directory with the same name and a .json extension --data_format { auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv } format of the input data -sspi, --skip_save_processed_input skips saving intermediate HDF5 and JSON files -c CONFIG, --config CONFIG Path to the YAML file containing the model configuration -cs CONFIG_STR, --config_str CONFIG_STRING JSON or YAML serialized string of the model configuration. Ignores --config -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH path of a pretrained model to load as initialization -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH path of the model directory to resume training of -sstd, --skip_save_training_description disables saving the description JSON file -ssts, --skip_save_training_statistics disables saving training statistics JSON file -ssm, --skip_save_model disables saving weights each time the model improves. By default Ludwig saves weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance can a model get with a set of hyperparameters, use this parameter to skip it -ssp, --skip_save_progress disables saving weights after each epoch. By default ludwig saves weights after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will save twice as much space, use this parameter to skip it -ssl, --skip_save_log disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed -rs RANDOM_SEED, --random_seed RANDOM_SEED a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling -g GPUS [ GPUS ... ] , --gpus GPUS [ GPUS ... ] list of gpus to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l { critical,error,warning,info,debug,notset } , --logging_level { critical,error,warning,info,debug,notset } the level of logging to use The parameters combine parameters from both train and test so refer to those sections for an in depth explanation. The output directory will contain a hyperopt_statistics.json file that summarizes the results obtained. In order to perform an hyperparameter optimization, the hyperopt section needs to be provided within the configuration. In the hyperopt section you will be able to define what metric to optimize, what parameters, what sampler to use to optimize them and how to execute the optimization. For details on the hyperopt section see the detailed description in the Hyperparameter Optimization section. serve \u00b6 This command lets you load a pre-trained model and serve it on an http server. You can call it with: ludwig serve [ options ] or with python -m ludwig.serve [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig serve [options] This script serves a pretrained model optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use -p PORT, --port PORT port for server (default: 8000) -H HOST, --host HOST host for server (default: 0.0.0.0) The most important argument is --model_path where you have to specify the path of the model to load. Once running, you can make a POST request on the /predict endpoint to run inference on the form data submitted. Note ludwig serve will automatically use GPUs for serving, if avaiable to the machine-local torch environment. Example curl \u00b6 File curl http://0.0.0.0:8000/predict -X POST -F 'image_path=@path_to_image/example.png' Text curl http://0.0.0.0:8000/predict -X POST -F 'english_text=words to be translated' Both Text and File curl http://0.0.0.0:8000/predict -X POST -F 'text=mixed together with' -F 'image=@path_to_image/example.png' Batch prediction You can also make a POST request on the /batch_predict endpoint to run inference on multiple samples at once. Requests must be submitted as form data, with one of fields being dataset : a JSON encoded string representation of the data to be predicted. The dataset JSON string is expected to be in the Pandas \"split\" format to reduce payload size. This format divides the dataset into three parts: columns: List[str] index (optional): List[Union[str, int]] data: List[List[object]] Additional form fields can be used to provide file resources like images that are referenced within the dataset. Batch prediction example: curl http://0.0.0.0:8000/batch_predict -X POST -F 'dataset={\"columns\": [\"a\", \"b\"], \"data\": [[1, 2], [3, 4]]}' visualize \u00b6 This command lets you visualize training and prediction statistics, alongside with comparing different models performances and predictions. You can call it with: ludwig visualize [ options ] or with: python -m ludwig.visualize [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig visualize [options] This script analyzes results and shows some nice plots. optional arguments: -h, --help show this help message and exit -g GROUND_TRUTH, --ground_truth GROUND_TRUTH ground truth file -gm GROUND_TRUTH_METADATA, --ground_truth_metadata GROUND_TRUTH_METADATA input metadata JSON file -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory where to save plots.If not specified, plots will be displayed in a window -ff {pdf,png}, --file_format {pdf,png} file format of output plots -v {binary_threshold_vs_metric,calibration_1_vs_all,calibration_multiclass,compare_classifiers_multiclass_multimetric,compare_classifiers_performance_changing_k,compare_classifiers_performance_from_pred,compare_classifiers_performance_from_prob,compare_classifiers_performance_subset,compare_classifiers_predictions,compare_classifiers_predictions_distribution,compare_performance,confidence_thresholding,confidence_thresholding_2thresholds_2d,confidence_thresholding_2thresholds_3d,confidence_thresholding_data_vs_acc,confidence_thresholding_data_vs_acc_subset,confidence_thresholding_data_vs_acc_subset_per_class,confusion_matrix,frequency_vs_f1,hyperopt_hiplot,hyperopt_report,learning_curves,roc_curves,roc_curves_from_test_statistics}, --visualization {binary_threshold_vs_metric,calibration_1_vs_all,calibration_multiclass,compare_classifiers_multiclass_multimetric,compare_classifiers_performance_changing_k,compare_classifiers_performance_from_pred,compare_classifiers_performance_from_prob,compare_classifiers_performance_subset,compare_classifiers_predictions,compare_classifiers_predictions_distribution,compare_performance,confidence_thresholding,confidence_thresholding_2thresholds_2d,confidence_thresholding_2thresholds_3d,confidence_thresholding_data_vs_acc,confidence_thresholding_data_vs_acc_subset,confidence_thresholding_data_vs_acc_subset_per_class,confusion_matrix,frequency_vs_f1,hyperopt_hiplot,hyperopt_report,learning_curves,roc_curves,roc_curves_from_test_statistics} type of visualization -f OUTPUT_FEATURE_NAME, --output_feature_name OUTPUT_FEATURE_NAME name of the output feature to visualize -gts GROUND_TRUTH_SPLIT, --ground_truth_split GROUND_TRUTH_SPLIT ground truth split - 0:train, 1:validation, 2:test split -tf THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...], --threshold_output_feature_names THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...] names of output features for 2d threshold -pred PREDICTIONS [PREDICTIONS ...], --predictions PREDICTIONS [PREDICTIONS ...] predictions files -prob PROBABILITIES [PROBABILITIES ...], --probabilities PROBABILITIES [PROBABILITIES ...] probabilities files -trs TRAINING_STATISTICS [TRAINING_STATISTICS ...], --training_statistics TRAINING_STATISTICS [TRAINING_STATISTICS ...] training stats files -tes TEST_STATISTICS [TEST_STATISTICS ...], --test_statistics TEST_STATISTICS [TEST_STATISTICS ...] test stats files -hs HYPEROPT_STATS_PATH, --hyperopt_stats_path HYPEROPT_STATS_PATH hyperopt stats file -mn MODEL_NAMES [MODEL_NAMES ...], --model_names MODEL_NAMES [MODEL_NAMES ...] names of the models to use as labels -tn TOP_N_CLASSES [TOP_N_CLASSES ...], --top_n_classes TOP_N_CLASSES [TOP_N_CLASSES ...] number of classes to plot -k TOP_K, --top_k TOP_K number of elements in the ranklist to consider -ll LABELS_LIMIT, --labels_limit LABELS_LIMIT maximum numbers of labels. If labels in dataset are higher than this number, \"rare\" label -ss {ground_truth,predictions}, --subset {ground_truth,predictions} type of subset filtering -n, --normalize normalize rows in confusion matrix -m METRICS [METRICS ...], --metrics METRICS [METRICS ...] metrics to display in threshold_vs_metric -pl POSITIVE_LABEL, --positive_label POSITIVE_LABEL label of the positive class for the roc curve -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use As the --visualization parameters suggests, there is a vast number of visualizations readily available. Each of them requires a different subset of this command's arguments, so they will be described one by one in the Visualizations section. init_config \u00b6 Initialize a user config from a dataset and targets. usage: ludwig init_config [options] This script initializes a valid config from a dataset. optional arguments: -h, --help show this help message and exit -d DATASET, --dataset DATASET input data file path -t TARGET, --target TARGET target(s) to predict as output features of the model --time_limit_s TIME_LIMIT_S time limit to train the model in seconds when using hyperopt --tune_for_memory TUNE_FOR_MEMORY refine hyperopt search space based on available host / GPU memory --hyperopt HYPEROPT include automl hyperopt config --random_seed RANDOM_SEED seed for random number generators used in hyperopt to improve repeatability --use_reference_config USE_REFERENCE_CONFIG refine hyperopt search space by setting first search point from stored reference model config -o OUTPUT, --output OUTPUT output initialized YAML config path render_config \u00b6 Renders the fully populated config with all defaults set. usage: ludwig render_config [options] This script renders the full config from a user config. optional arguments: -h, --help show this help message and exit -o OUTPUT, --output OUTPUT output rendered YAML config path collect_summary \u00b6 This command loads a pretrained model and prints names of weights and layers activations to use with collect_weights or collect_activations . ludwig collect_summary [ options ] or with: python -m ludwig.collect names [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig collect_summary [options] This script loads a pretrained model and print names of weights and layer activations. optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use collect_weights \u00b6 This command lets you load a pre-trained model and collect the tensors with a specific name in order to save them in a NPY format. This may be useful in order to visualize the learned weights (for instance collecting embedding matrices) and for some post-hoc analyses. You can call it with: ludwig collect_weights [ options ] or with: python -m ludwig.collect weights [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig collect_weights [options] This script loads a pretrained model and uses it collect weights. optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -t TENSORS [TENSORS ...], --tensors TENSORS [TENSORS ...] tensors to collect -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory that contains the results -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use The three most important arguments are --model_path where you have to specify the path of the model to load, --tensors that lets you specify a list of tensor names in the Torch graph that contain the weights you want to collect, and finally --output_directory that lets you specify where the NPY files (one for each tensor name specified) will be saved. In order to figure out the names of the tensors containing the weights you want to collect, use the collect_summary command. collect_activations \u00b6 This command lets you load a pre-trained model and input data and collects the values of activations contained in tensors with a specific name in order to save them in a NPY format. This may be useful in order to visualize the activations (for instance collecting the last layer's activations as embeddings representations of the input datapoint) and for some post-hoc analyses. You can call it with: ludwig collect_activations [ options ] or with: python -m ludwig.collect activations [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig collect_activations [options] This script loads a pretrained model and uses it collect tensors for each datapoint in the dataset. optional arguments: -h, --help show this help message and exit --dataset DATASET filepath for input dataset --data_format DATA_FORMAT format of the dataset. Valid values are auto, csv, excel, feature, fwf, hdf5, html, tables, json, json, jsonl, parquet, pickle, sas, spss, stata, tsv -s {training,validation,test,full}, --split {training,validation,test,full} the split to test the model on -m MODEL_PATH, --model_path MODEL_PATH model to load -lyr LAYER [LAYER ..], --layers LAYER [LAYER ..] layers to collect -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory that contains the results -bs BATCH_SIZE, --batch_size BATCH_SIZE size of batches -g GPUS, --gpus GPUS list of gpu to use -gml GPU_MEMORY, --gpu_memory_limit GPU_MEMORY maximum memory in MB of gpu memory to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use The data related and runtime related arguments (GPUs, batch size, etc.) are the same as the ones used in predict , you can refer to that section for an explanation. The collect-specific arguments, --model_path , --tensors and --output_directory , are the same used in collect_weights , you can refer to that section for an explanation. export_torchscript \u00b6 Exports a pre-trained model to Torch's torchscript format. ludwig export_torchscript [ options ] or with: python -m ludwig.export torchscript [ options ] These are the available arguments: usage: ludwig export_torchscript [options] This script loads a pretrained model and uses it collect weights. optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -od OUTPUT_PATH, --output_path OUTPUT_PATH path where to save the export model -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use export_neuropod \u00b6 A Ludwig model can be exported as a Neuropod , a mechanism that allows it to be executed in a framework agnostic way. In order to export a Ludwig model as a Neuropod, first make sure the neuropod package is installed in your environment together with the appropriate backend (only use Python 3.7+), then run the following command: ludwig export_neuropod [ options ] or with: python -m ludwig.export neuropod [ options ] These are the available arguments: usage: ludwig export_neuropod [options] This script loads a pretrained model and uses it collect weights. optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -mn MODEL_NAME, --model_name MODEL_NAME model name -od OUTPUT_PATH, --output_path OUTPUT_PATH path where to save the export model -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use This functionality has been tested with neuropod==0.2.0 . export_mlflow \u00b6 A Ludwig model can be exported as an mlflow.pyfunc model, which allows it to be executed in a framework agnostic way. There are two ways to export a Ludwig model to MLflow: Convert a saved model directory on disk to the MLflow format on disk. Register a saved model directory on disk or in an existing MLflow experiment to an MLflow model registry. For the first approach, you only need to provide the location of the saved Ludwig model locally and the location where the model should be written to on local disk: ludwig export_mlflow --model_path /saved/ludwig/model --output_path /exported/mlflow/model For the second, you will need to provide a registered model name used by the model registry: ludwig export_mlflow --model_path /saved/ludwig/model --output_path relative/model/path --registered_model_name my_ludwig_model preprocess \u00b6 Preprocess data and saves it into HDF5 and JSON format. The preprocessed files can be then used for performing training, prediction and evaluation. The advantage is that, being the data already preprocessed, if multiple models have to be trained on the same data, the preprocessed files act as a cache to avoid performing preprocessing multiple times. ludwig preprocess [options] or with: python -m ludwig.preprocess [options] These are the available arguments: usage: ludwig preprocess [options] This script preprocess a dataset optional arguments: -h, --help show this help message and exit --dataset DATASET input data file path. If it has a split column, it will be used for splitting (0: train, 1: validation, 2: test), otherwise the dataset will be randomly split --training_set TRAINING_SET input train data file path --validation_set VALIDATION_SET input validation data file path --test_set TEST_SET input test data file path --training_set_metadata TRAINING_SET_METADATA input metadata JSON file path. An intermediate preprocessed containing the mappings of the input file created the first time a file is used, in the same directory with the same name and a .json extension --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -pc PREPROCESSING_CONFIG, --preprocessing_config PREPROCESSING_CONFIG preprocessing config. Uses the same format of config, but ignores encoder specific parameters, decoder specific parameters, combiner and training parameters -pcf PREPROCESSING_CONFIG_FILE, --preprocessing_config_file PREPROCESSING_CONFIG_FILE YAML file describing the preprocessing. Ignores --preprocessing_config.Uses the same format of config, but ignores encoder specific parameters, decoder specific parameters, combiner and training parameters -rs RANDOM_SEED, --random_seed RANDOM_SEED a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use synthesize_dataset \u00b6 Creates synthetic data for testing purposes depending on the feature list parameters provided in YAML format. ludwig synthesize_dataset [options] or with: python -m ludwig.data.dataset_synthesizer [options] These are the available arguments: usage: ludwig synthesize_dataset [options] This script generates a synthetic dataset. optional arguments: -h, --help show this help message and exit -od OUTPUT_PATH, --output_path OUTPUT_PATH output CSV file path -d DATASET_SIZE, --dataset_size DATASET_SIZE size of the dataset -f FEATURES, --features FEATURES list of features to generate in YAML format. Provide a list containing one dictionary for each feature, each dictionary must include a name, a type and can include some generation parameters depending on the type Process finished with exit code 0 Example: ludwig synthesize_dataset --features = \"[ \\ {name: text, type: text}, \\ {name: category, type: category}, \\ {name: number, type: number}, \\ {name: binary, type: binary}, \\ {name: set, type: set}, \\ {name: bag, type: bag}, \\ {name: sequence, type: sequence}, \\ {name: timeseries, type: timeseries}, \\ {name: date, type: date}, \\ {name: h3, type: h3}, \\ {name: vector, type: vector}, \\ {name: image, type: image} \\ ]\" --dataset_size = 10 --output_path = synthetic_dataset.csv The available parameters depend on the feature type. binary prob (float, default: 0.5 ): probability of generating true . cycle (boolean, default: false ): cycle through values instead of sampling. number min (float, default: 0 ): minimum value of the range of values to generate. max (float, default: 1 ): maximum value of the range of values to generate. category vocab_size (int, default: 10 ): size of the vocabulary to sample from. cycle (boolean, default: false ): cycle through values instead of sampling. sequence vocab_size (int, default: 10 ): size of the vocabulary to sample from. max_len (int, default: 10 ): maximum length of the generated sequence. min_len (int, default: null ): if null all sequences will be of size max_len . If a value is provided, the length will be randomly determined between min_len and max_len . set vocab_size (int, default: 10 ): size of the vocabulary to sample from. max_len (int, default: 10 ): maximum length of the generated set. bag vocab_size (int, default: 10 ): size of the vocabulary to sample from. max_len (int, default: 10 ): maximum length of the generated set. text vocab_size (int, default: 10 ): size of the vocabulary to sample from. max_len (int, default: 10 ): maximum length of the generated sequence, lengths will be randomly sampled between max_len - 20% and max_len . timeseries max_len (int, default: 10 ): maximum length of the generated sequence. min (float, default: 0 ): minimum value of the range of values to generate. max (float, default: 1 ): maximum value of the range of values to generate. audio destination_folder (str): folder where the generated audio files will be saved. preprocessing: {audio_file_length_limit_in_s} (int, default: 1 ): length of the generated audio in seconds. image destination_folder (str): folder where the generated image files will be saved. preprocessing: {height} (int, default: 28 ): height of the generated image in pixels. preprocessing: {width} (int, default: 28 ): width of the generated image in pixels. preprocessing: {num_channels} (int, default: 1 ): number of channels of the generated images. Valid values are 1 , 3 , 4 . preprocessing: {infer_image_dimensions} (boolean, default: true ): whether to transform differently-sized images to the same width/height dimensions. Target dimensions are inferred by taking the average dimensions of the first infer_image_sample_size images, then applying infer_image_max_height and infer_image_max_width . This parameter has no effect if explicit width and height are specified. preprocessing: {infer_image_sample_size} (int, default 100 ): sample size of infer_image_dimensions . preprocessing: {infer_image_max_height} (int, default 256 ): maximum height of an image transformed using infer_image_dimensions . preprocessing: {infer_image_max_width} (int, default 256 ): maximum width of an image transformed using infer_image_dimensions . date No parameters. h3 No parameters. vector vector_size (int, default: 10 ): size of the vectors to generate.","title":"Command Line Interface"},{"location":"user_guide/command_line_interface/#commands","text":"Ludwig provides several functions through its command line interface. Mode Description train Trains a model predict Predicts using a pretrained model evaluate Evaluate a pretrained model's performance experiment Runs a full experiment training a model and evaluating it hyperopt Perform hyperparameter optimization serve Serves a pretrained model visualize Visualizes experiment results init_config Initialize a user config from a dataset and targets render_config Renders the fully populated config with all defaults set collect_summary Prints names of weights and layers activations to use with other collect commands collect_weights Collects tensors containing a pretrained model weights collect_activations Collects tensors for each datapoint using a pretrained model export_torchscript Exports Ludwig models to Torchscript export_neuropod Exports Ludwig models to Neuropod export_mlflow Exports Ludwig models to MLflow preprocess Preprocess data and saves it into HDF5 and JSON format synthesize_dataset Creates synthetic data for testing purposes These are described in detail below.","title":"Commands"},{"location":"user_guide/command_line_interface/#train","text":"Train a model from your data. ludwig train [ options ] or with: python -m ludwig.train [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig train [options] This script trains a model optional arguments: -h, --help show this help message and exit --output_directory OUTPUT_DIRECTORY directory that contains the results --experiment_name EXPERIMENT_NAME experiment name --model_name MODEL_NAME name for the model --dataset DATASET input data file path. If it has a split column, it will be used for splitting (0: train, 1: validation, 2: test), otherwise the dataset will be randomly split --training_set TRAINING_SET input train data file path --validation_set VALIDATION_SET input validation data file path --test_set TEST_SET input test data file path --training_set_metadata TRAINING_SET_METADATA input metadata JSON file path. An intermediate preprocessed containing the mappings of the input file created the first time a file is used, in the same directory with the same name and a .json extension --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -sspi, --skip_save_processed_input skips saving intermediate HDF5 and JSON files -c CONFIG, --config CONFIG Path to the YAML file containing the model configuration -cs CONFIG_STR, --config_str CONFIG_STRING JSON or YAML serialized string of the model configuration. Ignores --config -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH path of a pretrained model to load as initialization -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH path of the model directory to resume training of -sstd, --skip_save_training_description disables saving the description JSON file -ssts, --skip_save_training_statistics disables saving training statistics JSON file -ssm, --skip_save_model disables saving weights each time the model improves. By default Ludwig saves weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance can a model get with a set of hyperparameters, use this parameter to skip it -ssp, --skip_save_progress disables saving weights after each epoch. By default ludwig saves weights after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will save twice as much space, use this parameter to skip it -ssl, --skip_save_log disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed -rs RANDOM_SEED, --random_seed RANDOM_SEED a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling -g GPUS [GPUS ...], --gpus GPUS [GPUS ...] list of gpus to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun When Ludwig trains a model it creates two intermediate files, one HDF5 and one JSON. The HDF5 file contains the data mapped to numpy ndarrays, while the JSON file contains the mappings from the values in the tensors to their original labels. For instance, for a categorical feature with 3 possible values, the HDF5 file will contain integers from 0 to 3 (with 0 being a <UNK> category), while the JSON file will contain a idx2str list containing all tokens ( [<UNK>, label_1, label_2, label_3] ), a str2idx dictionary ( {\"<UNK>\": 0, \"label_1\": 1, \"label_2\": 2, \"label_3\": 3} ) and a str2freq dictionary ( {\"<UNK>\": 0, \"label_1\": 93, \"label_2\": 55, \"label_3\": 24} ). The reason to have those intermediate files is two-fold: on one hand, if you are going to train your model again Ludwig will try to load them instead of recomputing all tensors, which saves a considerable amount of time, and on the other hand when you want to use your model to predict, data has to be mapped to tensors in exactly the same way it was mapped during training, so you'll be required to load the JSON metadata file in the predict command. The first time you provide a UTF-8 encoded dataset ( --dataset ), the HDF5 and JSON files are created, from the second time on Ludwig will load them instead of the dataset even if you specify the dataset (it looks in the same directory for files names in the same way but with a different extension), finally you can directly specify the HDF5 and JSON files. As the mapping from raw data to tensors depends on the type of feature that you specify in your configuration, if you change type (for instance from sequence to text ) you also have to redo the preprocessing, which is achieved by deleting the HDF5 and JSON files. Alternatively you can skip saving the HDF5 and JSON files specifying --skip_save_processed_input . Splitting between train, validation and test set can be done in several ways. This allows for a few possible input data scenarios: one single UTF-8 encoded dataset file is provided ( -dataset ). In this case if the dataset contains a split column with values 0 for training, 1 for validation and 2 for test, this split will be used. If you want to ignore the split column and perform a random split, use a force_split argument in the configuration. In the case when there is no split column, a random 70-20-10 split will be performed. You can set the percentages and specify if you want stratified sampling in the configuration preprocessing section. you can provide separate UTF-8 encoded training, validation and test sets ( --training_set , --validation_set , --test_set ). the HDF5 and JSON file indications specified in the case of a single dataset file apply also in the multiple files case, with the only difference that you need to specify only one JSON file ( --train_set_metadata_json ). The validation set is optional, but if absent the training will continue until the end of the training epochs, while when there's a validation set the default behavior is to perform early stopping after the validation measure does not improve for a certain amount of epochs. The test set is optional too. Other optional arguments are --output_directory , --experiment_name and --model name . By default the output directory is ./results . That directory will contain a directory named [experiment_name]_[model_name]_0 if model name and experiment name are specified. If the same combination of experiment and model name is used again, the integer at the end of the name will be increased. If neither of them is specified the directory will be named run_0 . The directory will contain description.json - a file containing a description of the training process with all the information to reproduce it. training_statistics.json - a file containing records of all measures and losses for each epoch. model - a directory containing model hyperparameters, weights, checkpoints and logs (for TensorBoard). The configuration can be provided either as a string ( --config_str ) or as YAML file ( --config ). Details on how to write your configuration are provided in the Configuration section. During training Ludwig saves two sets of weights for the model, one that is the weights at the end of the epoch where the best performance on the validation measure was achieved and one that is the weights at the end of the latest epoch. The reason for keeping the second set is to be able to resume training in case the training process gets interrupted somehow. To resume training using the latest weights and the whole history of progress so far you have to specify the --model_resume_path argument. You can avoid saving the latest weights and the overall progress so far by using the argument --skip_save_progress , but you will not be able to resume it afterwards. Another available option is to load a previously trained model as an initialization for a new training process. In this case Ludwig will start a new training process, without knowing any progress of the previous model, no training statistics, nor the number of epochs the model has been trained on so far. It's not resuming training, just initializing training with a previously trained model with the same configuration, and it is accomplished through the --model_load_path argument. You can specify a random seed to be used by the python environment, python random package, numpy and Torch with the --random_seed argument. This is useful for reproducibility. Be aware that due to asynchronicity in the Torch's GPU execution, when training on GPU results may not be reproducible. You can manage which GPUs on your machine are used with the --gpus argument, which accepts a string identical to the format of CUDA_VISIBLE_DEVICES environment variable, namely a list of integers separated by comma. You can also specify the maximum amount of GPU memory which will be allocated per device with --gpu_memory_limit . By default all of memory is allocated. If less than all of memory is allocated, Torch will need more GPU memory it will try to increase this amount. If parameter --backend is set, will use the given backend for distributed processing (Horovod or Ray). Finally the --logging_level argument lets you set the amount of logging that you want to see during training. Example: ludwig train --dataset reuters-allcats.csv --config \"{input_features: [{name: text, type: text, encoder: parallel_cnn}], output_features: [{name: class, type: category}]}\"","title":"train"},{"location":"user_guide/command_line_interface/#predict","text":"This command lets you use a previously trained model to predict on new data. You can call it with: ludwig predict [ options ] or with: python -m ludwig.predict [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig predict [options] This script loads a pretrained model and uses it to predict optional arguments: -h, --help show this help message and exit --dataset DATASET input data file path --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -s {training,validation,test,full}, --split {training,validation,test,full} the split to test the model on -m MODEL_PATH, --model_path MODEL_PATH model to load -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory that contains the results -ssuo, --skip_save_unprocessed_output skips saving intermediate NPY output files -sstp, --skip_save_predictions skips saving predictions CSV files -bs BATCH_SIZE, --batch_size BATCH_SIZE size of batches -g GPUS, --gpus GPUS list of gpu to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use The same distinction between UTF-8 encoded dataset files and HDF5 / JSON files explained in the train section also applies here. In either case, the JSON metadata file obtained during training is needed in order to map the new data into tensors. If the new data contains a split column, you can specify which split to use to calculate the predictions with the --split argument. By default it's full which means all the splits will be used. A model to load is needed, and you can specify its path with the --model_path argument. If you trained a model previously and got the results in, for instance, ./results/experiment_run_0 , you have to specify ./results/experiment_run_0/model for using it to predict. You can specify an output directory with the argument --output-directory , by default it will be ./result_0 , with increasing numbers if a directory with the same name is present. The directory will contain a prediction CSV file and a probability CSV file for each output feature, together with raw NPY files containing raw tensors. You can specify not to save the raw NPY output files with the argument skip_save_unprocessed_output . A specific batch size for speeding up the prediction can be specified using the argument --batch_size . Finally the --logging_level , --debug , --gpus , --gpu_memory_limit and --disable_parallel_threads related arguments behave exactly like described in the train command section. Example: ludwig predict --dataset reuters-allcats.csv --model_path results/experiment_run_0/model/","title":"predict"},{"location":"user_guide/command_line_interface/#evaluate","text":"This command lets you use a previously trained model to predict on new data and evaluate the performance of the prediction compared to ground truth. You can call it with: ludwig evaluate [ options ] or with: python -m ludwig.evaluate [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig evaluate [options] This script loads a pretrained model and evaluates its performance by comparing its predictions with ground truth. optional arguments: -h, --help show this help message and exit --dataset DATASET input data file path --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -s {training,validation,test,full}, --split {training,validation,test,full} the split to test the model on -m MODEL_PATH, --model_path MODEL_PATH model to load -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory that contains the results -ssuo, --skip_save_unprocessed_output skips saving intermediate NPY output files -sses, --skip_save_eval_stats skips saving intermediate JSON eval statistics -scp, --skip_collect_predictions skips collecting predictions -scos, --skip_collect_overall_stats skips collecting overall stats -bs BATCH_SIZE, --batch_size BATCH_SIZE size of batches -g GPUS, --gpus GPUS list of gpu to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use All parameters are the same of predict and the behavior is the same. The only difference isthat evaluate requires the dataset to contain also columns with the same name of output features. This is needed because evaluate compares the predictions produced by the model with the ground truth and will save all those statistics in a test_statistics.json file in the result directory. Note that the data must contain columns for each output feature with ground truth output values in order to compute the performance statistics. If you receive an error regarding a missing output feature column in your data, it means that the data does not contain the columns for each output feature to use as ground truth. Example: ludwig evaluate --dataset reuters-allcats.csv --model_path results/experiment_run_0/model/","title":"evaluate"},{"location":"user_guide/command_line_interface/#experiment","text":"This command combines training and evaluation into a single handy command. You can request a k-fold cross validation run by specifying the --k_fold parameter. You can call it with: ludwig experiment [ options ] or with: python -m ludwig.experiment [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig experiment [options] This script trains and evaluates a model optional arguments: -h, --help show this help message and exit --output_directory OUTPUT_DIRECTORY directory that contains the results --experiment_name EXPERIMENT_NAME experiment name --model_name MODEL_NAME name for the model --dataset DATASET input data file path. If it has a split column, it will be used for splitting (0: train, 1: validation, 2: test), otherwise the dataset will be randomly split --training_set TRAINING_SET input train data file path --validation_set VALIDATION_SET input validation data file path --test_set TEST_SET input test data file path --training_set_metadata TRAINING_SET_METADATA input metadata JSON file path. An intermediate preprocessed containing the mappings of the input file created the first time a file is used, in the same directory with the same name and a .json extension --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -es {training,validation,test,full}, --eval_split {training,validation,test,full} the split to evaluate the model on -sspi, --skip_save_processed_input skips saving intermediate HDF5 and JSON files -ssuo, --skip_save_unprocessed_output skips saving intermediate NPY output files -kf K_FOLD, --k_fold K_FOLD number of folds for a k-fold cross validation run -skfsi, --skip_save_k_fold_split_indices disables saving indices generated to split training data set for the k-fold cross validation run, but if it is not needed turning it off can slightly increase the overall speed -c CONFIG, --config CONFIG Path to the YAML file containing the model configuration -cs CONFIG_STR, --config_str CONFIG_STRING JSON or YAML serialized string of the model configuration. Ignores --config -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH path of a pretrained model to load as initialization -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH path of the model directory to resume training of -sstd, --skip_save_training_description disables saving the description JSON file -ssts, --skip_save_training_statistics disables saving training statistics JSON file -sstp, --skip_save_predictions skips saving test predictions CSV files -sstes, --skip_save_eval_stats skips saving eval statistics JSON file -ssm, --skip_save_model disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming if you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it,but the model will not be loadable later on -ssp, --skip_save_progress disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on -ssl, --skip_save_log disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed -rs RANDOM_SEED, --random_seed RANDOM_SEED a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling -g GPUS [GPUS ...], --gpus GPUS [GPUS ...] list of GPUs to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use The parameters combine parameters from both train and test so refer to those sections for an in depth explanation. The output directory will contain the outputs both commands produce. Example: ludwig experiment --dataset reuters-allcats.csv --config \"{input_features: [{name: text, type: text, encoder: parallel_cnn}], output_features: [{name: class, type: category}]}\"","title":"experiment"},{"location":"user_guide/command_line_interface/#hyperopt","text":"This command lets you perform an hyperparameter search with a given sampler and parameters. You can call it with: ludwig hyperopt [ options ] or with: python -m ludwig.hyperopt [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig hyperopt [ options ] This script searches for optimal Hyperparameters optional arguments: -h, --help show this help message and exit -sshs, --skip_save_hyperopt_statistics skips saving hyperopt statistics file --output_directory OUTPUT_DIRECTORY directory that contains the results --experiment_name EXPERIMENT_NAME experiment name --model_name MODEL_NAME name for the model --dataset DATASET input data file path. If it has a split column, it will be used for splitting ( 0 : train, 1 : validation, 2 : test ) , otherwise the dataset will be randomly split --training_set TRAINING_SET input train data file path --validation_set VALIDATION_SET input validation data file path --test_set TEST_SET input test data file path --training_set_metadata TRAINING_SET_METADATA input metadata JSON file path. An intermediate preprocessed file containing the mappings of the input file created the first time a file is used, in the same directory with the same name and a .json extension --data_format { auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv } format of the input data -sspi, --skip_save_processed_input skips saving intermediate HDF5 and JSON files -c CONFIG, --config CONFIG Path to the YAML file containing the model configuration -cs CONFIG_STR, --config_str CONFIG_STRING JSON or YAML serialized string of the model configuration. Ignores --config -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH path of a pretrained model to load as initialization -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH path of the model directory to resume training of -sstd, --skip_save_training_description disables saving the description JSON file -ssts, --skip_save_training_statistics disables saving training statistics JSON file -ssm, --skip_save_model disables saving weights each time the model improves. By default Ludwig saves weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance can a model get with a set of hyperparameters, use this parameter to skip it -ssp, --skip_save_progress disables saving weights after each epoch. By default ludwig saves weights after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will save twice as much space, use this parameter to skip it -ssl, --skip_save_log disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed -rs RANDOM_SEED, --random_seed RANDOM_SEED a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling -g GPUS [ GPUS ... ] , --gpus GPUS [ GPUS ... ] list of gpus to use -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT maximum memory in MB to allocate per GPU device -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l { critical,error,warning,info,debug,notset } , --logging_level { critical,error,warning,info,debug,notset } the level of logging to use The parameters combine parameters from both train and test so refer to those sections for an in depth explanation. The output directory will contain a hyperopt_statistics.json file that summarizes the results obtained. In order to perform an hyperparameter optimization, the hyperopt section needs to be provided within the configuration. In the hyperopt section you will be able to define what metric to optimize, what parameters, what sampler to use to optimize them and how to execute the optimization. For details on the hyperopt section see the detailed description in the Hyperparameter Optimization section.","title":"hyperopt"},{"location":"user_guide/command_line_interface/#serve","text":"This command lets you load a pre-trained model and serve it on an http server. You can call it with: ludwig serve [ options ] or with python -m ludwig.serve [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig serve [options] This script serves a pretrained model optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use -p PORT, --port PORT port for server (default: 8000) -H HOST, --host HOST host for server (default: 0.0.0.0) The most important argument is --model_path where you have to specify the path of the model to load. Once running, you can make a POST request on the /predict endpoint to run inference on the form data submitted. Note ludwig serve will automatically use GPUs for serving, if avaiable to the machine-local torch environment.","title":"serve"},{"location":"user_guide/command_line_interface/#example-curl","text":"File curl http://0.0.0.0:8000/predict -X POST -F 'image_path=@path_to_image/example.png' Text curl http://0.0.0.0:8000/predict -X POST -F 'english_text=words to be translated' Both Text and File curl http://0.0.0.0:8000/predict -X POST -F 'text=mixed together with' -F 'image=@path_to_image/example.png' Batch prediction You can also make a POST request on the /batch_predict endpoint to run inference on multiple samples at once. Requests must be submitted as form data, with one of fields being dataset : a JSON encoded string representation of the data to be predicted. The dataset JSON string is expected to be in the Pandas \"split\" format to reduce payload size. This format divides the dataset into three parts: columns: List[str] index (optional): List[Union[str, int]] data: List[List[object]] Additional form fields can be used to provide file resources like images that are referenced within the dataset. Batch prediction example: curl http://0.0.0.0:8000/batch_predict -X POST -F 'dataset={\"columns\": [\"a\", \"b\"], \"data\": [[1, 2], [3, 4]]}'","title":"Example curl"},{"location":"user_guide/command_line_interface/#visualize","text":"This command lets you visualize training and prediction statistics, alongside with comparing different models performances and predictions. You can call it with: ludwig visualize [ options ] or with: python -m ludwig.visualize [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig visualize [options] This script analyzes results and shows some nice plots. optional arguments: -h, --help show this help message and exit -g GROUND_TRUTH, --ground_truth GROUND_TRUTH ground truth file -gm GROUND_TRUTH_METADATA, --ground_truth_metadata GROUND_TRUTH_METADATA input metadata JSON file -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory where to save plots.If not specified, plots will be displayed in a window -ff {pdf,png}, --file_format {pdf,png} file format of output plots -v {binary_threshold_vs_metric,calibration_1_vs_all,calibration_multiclass,compare_classifiers_multiclass_multimetric,compare_classifiers_performance_changing_k,compare_classifiers_performance_from_pred,compare_classifiers_performance_from_prob,compare_classifiers_performance_subset,compare_classifiers_predictions,compare_classifiers_predictions_distribution,compare_performance,confidence_thresholding,confidence_thresholding_2thresholds_2d,confidence_thresholding_2thresholds_3d,confidence_thresholding_data_vs_acc,confidence_thresholding_data_vs_acc_subset,confidence_thresholding_data_vs_acc_subset_per_class,confusion_matrix,frequency_vs_f1,hyperopt_hiplot,hyperopt_report,learning_curves,roc_curves,roc_curves_from_test_statistics}, --visualization {binary_threshold_vs_metric,calibration_1_vs_all,calibration_multiclass,compare_classifiers_multiclass_multimetric,compare_classifiers_performance_changing_k,compare_classifiers_performance_from_pred,compare_classifiers_performance_from_prob,compare_classifiers_performance_subset,compare_classifiers_predictions,compare_classifiers_predictions_distribution,compare_performance,confidence_thresholding,confidence_thresholding_2thresholds_2d,confidence_thresholding_2thresholds_3d,confidence_thresholding_data_vs_acc,confidence_thresholding_data_vs_acc_subset,confidence_thresholding_data_vs_acc_subset_per_class,confusion_matrix,frequency_vs_f1,hyperopt_hiplot,hyperopt_report,learning_curves,roc_curves,roc_curves_from_test_statistics} type of visualization -f OUTPUT_FEATURE_NAME, --output_feature_name OUTPUT_FEATURE_NAME name of the output feature to visualize -gts GROUND_TRUTH_SPLIT, --ground_truth_split GROUND_TRUTH_SPLIT ground truth split - 0:train, 1:validation, 2:test split -tf THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...], --threshold_output_feature_names THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...] names of output features for 2d threshold -pred PREDICTIONS [PREDICTIONS ...], --predictions PREDICTIONS [PREDICTIONS ...] predictions files -prob PROBABILITIES [PROBABILITIES ...], --probabilities PROBABILITIES [PROBABILITIES ...] probabilities files -trs TRAINING_STATISTICS [TRAINING_STATISTICS ...], --training_statistics TRAINING_STATISTICS [TRAINING_STATISTICS ...] training stats files -tes TEST_STATISTICS [TEST_STATISTICS ...], --test_statistics TEST_STATISTICS [TEST_STATISTICS ...] test stats files -hs HYPEROPT_STATS_PATH, --hyperopt_stats_path HYPEROPT_STATS_PATH hyperopt stats file -mn MODEL_NAMES [MODEL_NAMES ...], --model_names MODEL_NAMES [MODEL_NAMES ...] names of the models to use as labels -tn TOP_N_CLASSES [TOP_N_CLASSES ...], --top_n_classes TOP_N_CLASSES [TOP_N_CLASSES ...] number of classes to plot -k TOP_K, --top_k TOP_K number of elements in the ranklist to consider -ll LABELS_LIMIT, --labels_limit LABELS_LIMIT maximum numbers of labels. If labels in dataset are higher than this number, \"rare\" label -ss {ground_truth,predictions}, --subset {ground_truth,predictions} type of subset filtering -n, --normalize normalize rows in confusion matrix -m METRICS [METRICS ...], --metrics METRICS [METRICS ...] metrics to display in threshold_vs_metric -pl POSITIVE_LABEL, --positive_label POSITIVE_LABEL label of the positive class for the roc curve -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use As the --visualization parameters suggests, there is a vast number of visualizations readily available. Each of them requires a different subset of this command's arguments, so they will be described one by one in the Visualizations section.","title":"visualize"},{"location":"user_guide/command_line_interface/#init_config","text":"Initialize a user config from a dataset and targets. usage: ludwig init_config [options] This script initializes a valid config from a dataset. optional arguments: -h, --help show this help message and exit -d DATASET, --dataset DATASET input data file path -t TARGET, --target TARGET target(s) to predict as output features of the model --time_limit_s TIME_LIMIT_S time limit to train the model in seconds when using hyperopt --tune_for_memory TUNE_FOR_MEMORY refine hyperopt search space based on available host / GPU memory --hyperopt HYPEROPT include automl hyperopt config --random_seed RANDOM_SEED seed for random number generators used in hyperopt to improve repeatability --use_reference_config USE_REFERENCE_CONFIG refine hyperopt search space by setting first search point from stored reference model config -o OUTPUT, --output OUTPUT output initialized YAML config path","title":"init_config"},{"location":"user_guide/command_line_interface/#render_config","text":"Renders the fully populated config with all defaults set. usage: ludwig render_config [options] This script renders the full config from a user config. optional arguments: -h, --help show this help message and exit -o OUTPUT, --output OUTPUT output rendered YAML config path","title":"render_config"},{"location":"user_guide/command_line_interface/#collect_summary","text":"This command loads a pretrained model and prints names of weights and layers activations to use with collect_weights or collect_activations . ludwig collect_summary [ options ] or with: python -m ludwig.collect names [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig collect_summary [options] This script loads a pretrained model and print names of weights and layer activations. optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use","title":"collect_summary"},{"location":"user_guide/command_line_interface/#collect_weights","text":"This command lets you load a pre-trained model and collect the tensors with a specific name in order to save them in a NPY format. This may be useful in order to visualize the learned weights (for instance collecting embedding matrices) and for some post-hoc analyses. You can call it with: ludwig collect_weights [ options ] or with: python -m ludwig.collect weights [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig collect_weights [options] This script loads a pretrained model and uses it collect weights. optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -t TENSORS [TENSORS ...], --tensors TENSORS [TENSORS ...] tensors to collect -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory that contains the results -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use The three most important arguments are --model_path where you have to specify the path of the model to load, --tensors that lets you specify a list of tensor names in the Torch graph that contain the weights you want to collect, and finally --output_directory that lets you specify where the NPY files (one for each tensor name specified) will be saved. In order to figure out the names of the tensors containing the weights you want to collect, use the collect_summary command.","title":"collect_weights"},{"location":"user_guide/command_line_interface/#collect_activations","text":"This command lets you load a pre-trained model and input data and collects the values of activations contained in tensors with a specific name in order to save them in a NPY format. This may be useful in order to visualize the activations (for instance collecting the last layer's activations as embeddings representations of the input datapoint) and for some post-hoc analyses. You can call it with: ludwig collect_activations [ options ] or with: python -m ludwig.collect activations [ options ] from within Ludwig's main directory. These are the available arguments: usage: ludwig collect_activations [options] This script loads a pretrained model and uses it collect tensors for each datapoint in the dataset. optional arguments: -h, --help show this help message and exit --dataset DATASET filepath for input dataset --data_format DATA_FORMAT format of the dataset. Valid values are auto, csv, excel, feature, fwf, hdf5, html, tables, json, json, jsonl, parquet, pickle, sas, spss, stata, tsv -s {training,validation,test,full}, --split {training,validation,test,full} the split to test the model on -m MODEL_PATH, --model_path MODEL_PATH model to load -lyr LAYER [LAYER ..], --layers LAYER [LAYER ..] layers to collect -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY directory that contains the results -bs BATCH_SIZE, --batch_size BATCH_SIZE size of batches -g GPUS, --gpus GPUS list of gpu to use -gml GPU_MEMORY, --gpu_memory_limit GPU_MEMORY maximum memory in MB of gpu memory to allocate per GPU device -dpt, --disable_parallel_threads disable Torch from using multithreading for reproducibility -b BACKEND, --backend BACKEND specifies backend to use for parallel / distributed execution, defaults to local execution or Horovod if called using horovodrun -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use The data related and runtime related arguments (GPUs, batch size, etc.) are the same as the ones used in predict , you can refer to that section for an explanation. The collect-specific arguments, --model_path , --tensors and --output_directory , are the same used in collect_weights , you can refer to that section for an explanation.","title":"collect_activations"},{"location":"user_guide/command_line_interface/#export_torchscript","text":"Exports a pre-trained model to Torch's torchscript format. ludwig export_torchscript [ options ] or with: python -m ludwig.export torchscript [ options ] These are the available arguments: usage: ludwig export_torchscript [options] This script loads a pretrained model and uses it collect weights. optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -od OUTPUT_PATH, --output_path OUTPUT_PATH path where to save the export model -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use","title":"export_torchscript"},{"location":"user_guide/command_line_interface/#export_neuropod","text":"A Ludwig model can be exported as a Neuropod , a mechanism that allows it to be executed in a framework agnostic way. In order to export a Ludwig model as a Neuropod, first make sure the neuropod package is installed in your environment together with the appropriate backend (only use Python 3.7+), then run the following command: ludwig export_neuropod [ options ] or with: python -m ludwig.export neuropod [ options ] These are the available arguments: usage: ludwig export_neuropod [options] This script loads a pretrained model and uses it collect weights. optional arguments: -h, --help show this help message and exit -m MODEL_PATH, --model_path MODEL_PATH model to load -mn MODEL_NAME, --model_name MODEL_NAME model name -od OUTPUT_PATH, --output_path OUTPUT_PATH path where to save the export model -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use This functionality has been tested with neuropod==0.2.0 .","title":"export_neuropod"},{"location":"user_guide/command_line_interface/#export_mlflow","text":"A Ludwig model can be exported as an mlflow.pyfunc model, which allows it to be executed in a framework agnostic way. There are two ways to export a Ludwig model to MLflow: Convert a saved model directory on disk to the MLflow format on disk. Register a saved model directory on disk or in an existing MLflow experiment to an MLflow model registry. For the first approach, you only need to provide the location of the saved Ludwig model locally and the location where the model should be written to on local disk: ludwig export_mlflow --model_path /saved/ludwig/model --output_path /exported/mlflow/model For the second, you will need to provide a registered model name used by the model registry: ludwig export_mlflow --model_path /saved/ludwig/model --output_path relative/model/path --registered_model_name my_ludwig_model","title":"export_mlflow"},{"location":"user_guide/command_line_interface/#preprocess","text":"Preprocess data and saves it into HDF5 and JSON format. The preprocessed files can be then used for performing training, prediction and evaluation. The advantage is that, being the data already preprocessed, if multiple models have to be trained on the same data, the preprocessed files act as a cache to avoid performing preprocessing multiple times. ludwig preprocess [options] or with: python -m ludwig.preprocess [options] These are the available arguments: usage: ludwig preprocess [options] This script preprocess a dataset optional arguments: -h, --help show this help message and exit --dataset DATASET input data file path. If it has a split column, it will be used for splitting (0: train, 1: validation, 2: test), otherwise the dataset will be randomly split --training_set TRAINING_SET input train data file path --validation_set VALIDATION_SET input validation data file path --test_set TEST_SET input test data file path --training_set_metadata TRAINING_SET_METADATA input metadata JSON file path. An intermediate preprocessed containing the mappings of the input file created the first time a file is used, in the same directory with the same name and a .json extension --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv} format of the input data -pc PREPROCESSING_CONFIG, --preprocessing_config PREPROCESSING_CONFIG preprocessing config. Uses the same format of config, but ignores encoder specific parameters, decoder specific parameters, combiner and training parameters -pcf PREPROCESSING_CONFIG_FILE, --preprocessing_config_file PREPROCESSING_CONFIG_FILE YAML file describing the preprocessing. Ignores --preprocessing_config.Uses the same format of config, but ignores encoder specific parameters, decoder specific parameters, combiner and training parameters -rs RANDOM_SEED, --random_seed RANDOM_SEED a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling -dbg, --debug enables debugging mode -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset} the level of logging to use","title":"preprocess"},{"location":"user_guide/command_line_interface/#synthesize_dataset","text":"Creates synthetic data for testing purposes depending on the feature list parameters provided in YAML format. ludwig synthesize_dataset [options] or with: python -m ludwig.data.dataset_synthesizer [options] These are the available arguments: usage: ludwig synthesize_dataset [options] This script generates a synthetic dataset. optional arguments: -h, --help show this help message and exit -od OUTPUT_PATH, --output_path OUTPUT_PATH output CSV file path -d DATASET_SIZE, --dataset_size DATASET_SIZE size of the dataset -f FEATURES, --features FEATURES list of features to generate in YAML format. Provide a list containing one dictionary for each feature, each dictionary must include a name, a type and can include some generation parameters depending on the type Process finished with exit code 0 Example: ludwig synthesize_dataset --features = \"[ \\ {name: text, type: text}, \\ {name: category, type: category}, \\ {name: number, type: number}, \\ {name: binary, type: binary}, \\ {name: set, type: set}, \\ {name: bag, type: bag}, \\ {name: sequence, type: sequence}, \\ {name: timeseries, type: timeseries}, \\ {name: date, type: date}, \\ {name: h3, type: h3}, \\ {name: vector, type: vector}, \\ {name: image, type: image} \\ ]\" --dataset_size = 10 --output_path = synthetic_dataset.csv The available parameters depend on the feature type. binary prob (float, default: 0.5 ): probability of generating true . cycle (boolean, default: false ): cycle through values instead of sampling. number min (float, default: 0 ): minimum value of the range of values to generate. max (float, default: 1 ): maximum value of the range of values to generate. category vocab_size (int, default: 10 ): size of the vocabulary to sample from. cycle (boolean, default: false ): cycle through values instead of sampling. sequence vocab_size (int, default: 10 ): size of the vocabulary to sample from. max_len (int, default: 10 ): maximum length of the generated sequence. min_len (int, default: null ): if null all sequences will be of size max_len . If a value is provided, the length will be randomly determined between min_len and max_len . set vocab_size (int, default: 10 ): size of the vocabulary to sample from. max_len (int, default: 10 ): maximum length of the generated set. bag vocab_size (int, default: 10 ): size of the vocabulary to sample from. max_len (int, default: 10 ): maximum length of the generated set. text vocab_size (int, default: 10 ): size of the vocabulary to sample from. max_len (int, default: 10 ): maximum length of the generated sequence, lengths will be randomly sampled between max_len - 20% and max_len . timeseries max_len (int, default: 10 ): maximum length of the generated sequence. min (float, default: 0 ): minimum value of the range of values to generate. max (float, default: 1 ): maximum value of the range of values to generate. audio destination_folder (str): folder where the generated audio files will be saved. preprocessing: {audio_file_length_limit_in_s} (int, default: 1 ): length of the generated audio in seconds. image destination_folder (str): folder where the generated image files will be saved. preprocessing: {height} (int, default: 28 ): height of the generated image in pixels. preprocessing: {width} (int, default: 28 ): width of the generated image in pixels. preprocessing: {num_channels} (int, default: 1 ): number of channels of the generated images. Valid values are 1 , 3 , 4 . preprocessing: {infer_image_dimensions} (boolean, default: true ): whether to transform differently-sized images to the same width/height dimensions. Target dimensions are inferred by taking the average dimensions of the first infer_image_sample_size images, then applying infer_image_max_height and infer_image_max_width . This parameter has no effect if explicit width and height are specified. preprocessing: {infer_image_sample_size} (int, default 100 ): sample size of infer_image_dimensions . preprocessing: {infer_image_max_height} (int, default 256 ): maximum height of an image transformed using infer_image_dimensions . preprocessing: {infer_image_max_width} (int, default 256 ): maximum width of an image transformed using infer_image_dimensions . date No parameters. h3 No parameters. vector vector_size (int, default: 10 ): size of the vectors to generate.","title":"synthesize_dataset"},{"location":"user_guide/distributed_training/","text":"For large datasets, training on a single machine storing the entire dataset in memory can be prohibitively expensive. As such, Ludwig supports using distributing the preprocessing, training, and prediction steps across multiple machines and GPUs to operate on separate partitions of the data in parallel. Ludwig supports two different distributed execution backends : Ray and Horovod / MPI . In most cases, we recommend using Ray (supporting both distributed data processing and distributed training at once), but native Horovod execution is also supported, particularly for users accustomed to running with MPI. Ray \u00b6 Ray is a framework for distributed computing that makes it easy to scale up code that runs on your local machine to execute in parallel across a cluster. Ludwig has native integration with Ray for both hyperparameter search and distributed training. Running with Ray has several advantages over local execution: Ray enables you to provision a cluster of machines in a single command through its cluster launcher . Horovod on Ray allows you to do distributed training without needing to configure MPI in your environment. Dask on Ray allows you to process large datasets that don't fit in memory on a single machine. Ray Tune allows you to easily run distributed hyperparameter search across many machines in parallel. Ray provides easy access to high performance instances like high memory or GPU machines in the cloud. All of this comes for free without changing a single line of code in Ludwig. When Ludwig detects that you're running within a Ray cluster, the Ray backend will be enabled automatically. You can also enable the Ray backend explicitly either through the command line: ludwig train ... --backend ray Or in the Ludwig config: backend : type : ray data_format : parquet engine : type : dask Running Ludwig with Ray \u00b6 To use the Ray with Ludwig, you will need to have a running Ray cluster. The simplest way to start a Ray cluster is to use the Ray cluster launcher , which can be installed locally with pip : pip install ray Starting a Ray cluster requires that you have access to a cloud instance provider like AWS EC2 or Kubernetes. Here's an example of a partial Ray cluster configuration YAML file you can use to create your Ludwig Ray cluster: cluster_name : ludwig-ray-gpu-nightly min_workers : 4 max_workers : 4 docker : image : \"ludwigai/ludwig-ray-gpu:nightly\" container_name : \"ray_container\" head_node : InstanceType : c5.2xlarge ImageId : latest_dlami worker_nodes : InstanceType : g4dn.xlarge ImageId : latest_dlami This configuration runs on AWS EC2 instances, with a CPU head node and 4 GPU (Nvidia T4) worker nodes. Every worker runs within a Docker image that provides Ludwig and its dependencies, including Ray, Dask, Horovod, etc. You can use one of these pre-built Docker images as the parent image for your cluster. Ludwig provides both CPU and GPU images ready for use with Ray. Once your Ray cluster is configured, you can start the cluster and submit your existing ludwig commands or Python files to Ray for distributed execution: ray up cluster.yaml ray submit cluster.yaml \\ ludwig train --config config.yaml --dataset s3://mybucket/dataset.parquet Horovod / MPI \u00b6 You can distribute the training and prediction of your models using Horovod , which supports training on a single machine with multiple GPUs as well as on multiple machines with multiple GPUs. In order to use distributed training you have to install Horovod as detailed in Horovod's installation instructions . If you wish to use MPI , be sure to install OpenMPI or another implementation before installing Horovod: pip install horovod mpi4py Horovod works, in practice, by increasing the batch size and distributing a part of each batch to a different node and collecting the gradients from all the nodes in a smart and scalable way. It also adjusts the learning rate to balance the increase in the batch size. The advantage is that training speed scales almost linearly with the number of nodes. experiment , train and predict commands accept a --backend=horovod argument that instructs the model building, training and prediction phases to be conducted using Horovod in a distributed way. A horovodrun command specifying which machines and / or GPUs to use, together with a few more parameters, must be provided before the call to Ludwig's command. For example, to train a Ludwig model on a local machine with four GPUs one you can run: horovodrun -np 4 \\ ludwig train ...other Ludwig parameters... To train on four remote machines with four GPUs each you can run: horovodrun -np 16 \\ -H server1:4,server2:4,server3:4,server4:4 \\ ludwig train ...other Ludwig parameters... The same applies to experiment , predict and test . More details on Horovod installation and run parameters can be found in Horovod's documentation .","title":"Distributed Training"},{"location":"user_guide/distributed_training/#ray","text":"Ray is a framework for distributed computing that makes it easy to scale up code that runs on your local machine to execute in parallel across a cluster. Ludwig has native integration with Ray for both hyperparameter search and distributed training. Running with Ray has several advantages over local execution: Ray enables you to provision a cluster of machines in a single command through its cluster launcher . Horovod on Ray allows you to do distributed training without needing to configure MPI in your environment. Dask on Ray allows you to process large datasets that don't fit in memory on a single machine. Ray Tune allows you to easily run distributed hyperparameter search across many machines in parallel. Ray provides easy access to high performance instances like high memory or GPU machines in the cloud. All of this comes for free without changing a single line of code in Ludwig. When Ludwig detects that you're running within a Ray cluster, the Ray backend will be enabled automatically. You can also enable the Ray backend explicitly either through the command line: ludwig train ... --backend ray Or in the Ludwig config: backend : type : ray data_format : parquet engine : type : dask","title":"Ray"},{"location":"user_guide/distributed_training/#running-ludwig-with-ray","text":"To use the Ray with Ludwig, you will need to have a running Ray cluster. The simplest way to start a Ray cluster is to use the Ray cluster launcher , which can be installed locally with pip : pip install ray Starting a Ray cluster requires that you have access to a cloud instance provider like AWS EC2 or Kubernetes. Here's an example of a partial Ray cluster configuration YAML file you can use to create your Ludwig Ray cluster: cluster_name : ludwig-ray-gpu-nightly min_workers : 4 max_workers : 4 docker : image : \"ludwigai/ludwig-ray-gpu:nightly\" container_name : \"ray_container\" head_node : InstanceType : c5.2xlarge ImageId : latest_dlami worker_nodes : InstanceType : g4dn.xlarge ImageId : latest_dlami This configuration runs on AWS EC2 instances, with a CPU head node and 4 GPU (Nvidia T4) worker nodes. Every worker runs within a Docker image that provides Ludwig and its dependencies, including Ray, Dask, Horovod, etc. You can use one of these pre-built Docker images as the parent image for your cluster. Ludwig provides both CPU and GPU images ready for use with Ray. Once your Ray cluster is configured, you can start the cluster and submit your existing ludwig commands or Python files to Ray for distributed execution: ray up cluster.yaml ray submit cluster.yaml \\ ludwig train --config config.yaml --dataset s3://mybucket/dataset.parquet","title":"Running Ludwig with Ray"},{"location":"user_guide/distributed_training/#horovod-mpi","text":"You can distribute the training and prediction of your models using Horovod , which supports training on a single machine with multiple GPUs as well as on multiple machines with multiple GPUs. In order to use distributed training you have to install Horovod as detailed in Horovod's installation instructions . If you wish to use MPI , be sure to install OpenMPI or another implementation before installing Horovod: pip install horovod mpi4py Horovod works, in practice, by increasing the batch size and distributing a part of each batch to a different node and collecting the gradients from all the nodes in a smart and scalable way. It also adjusts the learning rate to balance the increase in the batch size. The advantage is that training speed scales almost linearly with the number of nodes. experiment , train and predict commands accept a --backend=horovod argument that instructs the model building, training and prediction phases to be conducted using Horovod in a distributed way. A horovodrun command specifying which machines and / or GPUs to use, together with a few more parameters, must be provided before the call to Ludwig's command. For example, to train a Ludwig model on a local machine with four GPUs one you can run: horovodrun -np 4 \\ ludwig train ...other Ludwig parameters... To train on four remote machines with four GPUs each you can run: horovodrun -np 16 \\ -H server1:4,server2:4,server3:4,server4:4 \\ ludwig train ...other Ludwig parameters... The same applies to experiment , predict and test . More details on Horovod installation and run parameters can be found in Horovod's documentation .","title":"Horovod / MPI"},{"location":"user_guide/how_ludwig_works/","text":"Configuration \u00b6 Ludwig provides an expressive declarative configuration system for how users construct their ML pipeline, like data preprocessing, model architecting, backend infrastructure, the training loop, hyperparameter optimization, and more. input_features : - name : title type : text encoder : rnn cell : lstm num_layers : 2 state_size : 128 preprocessing : tokenizer : space_punct - name : author type : category embedding_size : 128 preprocessing : most_common : 10000 - name : description type : text encoder : bert - name : cover type : image encoder : resnet num_layers : 18 output_features : - name : genre type : set - name : price type : number preprocessing : normalization : zscore trainer : epochs : 50 batch_size : 256 optimizer : type : adam beat1 : 0.9 learning_rate : 0.001 backend : type : local cache_format : parquet hyperopt : metric : f1 sampler : random parameters : title.num_layers : lower : 1 upper : 5 training.learning_rate : values : [ 0.01 , 0.003 , 0.001 ] See Ludwig configurations for an in-depth reference. Data type abstractions \u00b6 Every feature in Ludwig is described by a specific data type. Each data type maps to a specific set of modules that handle preprocessing, encoding, decoding, and post-processing for that type. Vice versa, every module (preprocessor, encoder, decoder) is registered to a specific set of data types that the module supports. Binary Number Category Bag Set Sequence Text Vector Audio Date H3 Image Timeseries Read more about Ludwig's supported feature types . ECD Architecture \u00b6 Ludwig\u2019s core modeling architecture is referred to as ECD (encoder-combiner-decoder). Multiple input features are encoded and fed through the Combiner model that operates on encoded inputs to combine them. On the output side, the combiner model's outputs are fed to decoders for each output feature for predictions and post-processing. Find out more about Ludwig's Combiner models like TabNet , Transformer, and Concat ( Wide and Deep learning ). Visualized, the ECD architecture looks like a butterfly and sometimes we refer to it as the \u201cbutterfly architecture\u201d. ECD flexibly handles many different combinations of input and output data types, making the tool well-suited for many different applications. Take a look at Examples to see how you can use Ludwig for several many different applications. Distributed training, data processing, and hyperparameter search with Ray \u00b6 Ludwig on Ray is a new backend introduced in v0.4 that enables users can scale their training process from running on their local laptop, to running in the cloud on a GPU instance, to scaling across hundreds of machines in parallel, all without changing a single line of code. By integrating with Ray, Ludwig is able to provide a unified way for doing distributed training: Ray enables you to provision a cluster of machines in a single command through its cluster launcher . Horovod on Ray enables you to do distributed training without needing to configure MPI in your environment. Dask on Ray enables you to process large datasets that don\u2019t fit in memory on a single machine. Ray Tune enables you to easily run distributed hyperparameter search across many machines in parallel.","title":"How Ludwig Works"},{"location":"user_guide/how_ludwig_works/#configuration","text":"Ludwig provides an expressive declarative configuration system for how users construct their ML pipeline, like data preprocessing, model architecting, backend infrastructure, the training loop, hyperparameter optimization, and more. input_features : - name : title type : text encoder : rnn cell : lstm num_layers : 2 state_size : 128 preprocessing : tokenizer : space_punct - name : author type : category embedding_size : 128 preprocessing : most_common : 10000 - name : description type : text encoder : bert - name : cover type : image encoder : resnet num_layers : 18 output_features : - name : genre type : set - name : price type : number preprocessing : normalization : zscore trainer : epochs : 50 batch_size : 256 optimizer : type : adam beat1 : 0.9 learning_rate : 0.001 backend : type : local cache_format : parquet hyperopt : metric : f1 sampler : random parameters : title.num_layers : lower : 1 upper : 5 training.learning_rate : values : [ 0.01 , 0.003 , 0.001 ] See Ludwig configurations for an in-depth reference.","title":"Configuration"},{"location":"user_guide/how_ludwig_works/#data-type-abstractions","text":"Every feature in Ludwig is described by a specific data type. Each data type maps to a specific set of modules that handle preprocessing, encoding, decoding, and post-processing for that type. Vice versa, every module (preprocessor, encoder, decoder) is registered to a specific set of data types that the module supports. Binary Number Category Bag Set Sequence Text Vector Audio Date H3 Image Timeseries Read more about Ludwig's supported feature types .","title":"Data type abstractions"},{"location":"user_guide/how_ludwig_works/#ecd-architecture","text":"Ludwig\u2019s core modeling architecture is referred to as ECD (encoder-combiner-decoder). Multiple input features are encoded and fed through the Combiner model that operates on encoded inputs to combine them. On the output side, the combiner model's outputs are fed to decoders for each output feature for predictions and post-processing. Find out more about Ludwig's Combiner models like TabNet , Transformer, and Concat ( Wide and Deep learning ). Visualized, the ECD architecture looks like a butterfly and sometimes we refer to it as the \u201cbutterfly architecture\u201d. ECD flexibly handles many different combinations of input and output data types, making the tool well-suited for many different applications. Take a look at Examples to see how you can use Ludwig for several many different applications.","title":"ECD Architecture"},{"location":"user_guide/how_ludwig_works/#distributed-training-data-processing-and-hyperparameter-search-with-ray","text":"Ludwig on Ray is a new backend introduced in v0.4 that enables users can scale their training process from running on their local laptop, to running in the cloud on a GPU instance, to scaling across hundreds of machines in parallel, all without changing a single line of code. By integrating with Ray, Ludwig is able to provide a unified way for doing distributed training: Ray enables you to provision a cluster of machines in a single command through its cluster launcher . Horovod on Ray enables you to do distributed training without needing to configure MPI in your environment. Dask on Ray enables you to process large datasets that don\u2019t fit in memory on a single machine. Ray Tune enables you to easily run distributed hyperparameter search across many machines in parallel.","title":"Distributed training, data processing, and hyperparameter search with Ray"},{"location":"user_guide/hyperopt/","text":"Ludwig supports hyperparameter optimization using Ray Tune or a local executor. The hyperparameter optimization strategy is specified as part of the Ludwig configuration and run using the ludwig hyperopt command. Every parameter within the config can be tuned using hyperopt. Hyperopt Configuration \u00b6 Most parameters or nested parameters of a ludwig configuration may be optimized, including input_features , output_features , combiner , preprocessing , and trainer . Supported types are float , int and category . To enable hyperparameter optimization, add the hyperopt dictionary at the top level of your config.yaml. The hyperopt section declares which parameters to optimize, the search strategy, and the optimization goal. hyperopt : parameters : training.learning_rate : space : loguniform lower : 0.0001 upper : 0.1 combiner.num_fc_layers : space : randint lower : 2 upper : 6 goal : minimize metric : loss Running Hyperparameter Optimization \u00b6 Use the ludwig hyperopt command to run hyperparameter optimization. ludwig hyperopt --dataset reuters-allcats.csv --config hyperopt_config.yaml For a complete reference of hyperparameter search and execution options, see the Hyperopt page of the Ludwig configuration guide.","title":"Hyperparameter Optimization"},{"location":"user_guide/hyperopt/#hyperopt-configuration","text":"Most parameters or nested parameters of a ludwig configuration may be optimized, including input_features , output_features , combiner , preprocessing , and trainer . Supported types are float , int and category . To enable hyperparameter optimization, add the hyperopt dictionary at the top level of your config.yaml. The hyperopt section declares which parameters to optimize, the search strategy, and the optimization goal. hyperopt : parameters : training.learning_rate : space : loguniform lower : 0.0001 upper : 0.1 combiner.num_fc_layers : space : randint lower : 2 upper : 6 goal : minimize metric : loss","title":"Hyperopt Configuration"},{"location":"user_guide/hyperopt/#running-hyperparameter-optimization","text":"Use the ludwig hyperopt command to run hyperparameter optimization. ludwig hyperopt --dataset reuters-allcats.csv --config hyperopt_config.yaml For a complete reference of hyperparameter search and execution options, see the Hyperopt page of the Ludwig configuration guide.","title":"Running Hyperparameter Optimization"},{"location":"user_guide/integrations/","text":"Using Integrations \u00b6 Ludwig provides an extendable interface to integrate with third-party systems. To activate a particular integration, simply insert its flag into the command line. Each integration may have specific requirements and use cases. Available integrations \u00b6 Comet ML \u00b6 --comet - logs training metrics, environment details, test results, visualizations, and more to Comet.ML . Requires a free account. For more details, see Comet's Running Ludwig with Comet . Aim \u00b6 --aim - complete experimentation trackings with configuration, metadata, hyperparameters, losses and terminal logs. In order to see and end to end Aim-Ludwig training and tracking example please refer to our demo . For more details about Aim refer to the documentation . Weights & Biases \u00b6 --wandb - logs training metrics, configuration parameters, environment details, and trained model to Weights & Biases . For more details, refer to W&B Quickstart . ML Flow \u00b6 --mlflow - logs training metrics, hyperopt parameters, output artifacts, and trained models to MLflow . Set the environment variable MLFLOW_TRACKING_URI to log results to a remote tracking server. Add more integrations \u00b6 For more information about integration contributions, please see the Developer Guide .","title":"Third-Party Integrations"},{"location":"user_guide/integrations/#using-integrations","text":"Ludwig provides an extendable interface to integrate with third-party systems. To activate a particular integration, simply insert its flag into the command line. Each integration may have specific requirements and use cases.","title":"Using Integrations"},{"location":"user_guide/integrations/#available-integrations","text":"","title":"Available integrations"},{"location":"user_guide/integrations/#comet-ml","text":"--comet - logs training metrics, environment details, test results, visualizations, and more to Comet.ML . Requires a free account. For more details, see Comet's Running Ludwig with Comet .","title":"Comet ML"},{"location":"user_guide/integrations/#aim","text":"--aim - complete experimentation trackings with configuration, metadata, hyperparameters, losses and terminal logs. In order to see and end to end Aim-Ludwig training and tracking example please refer to our demo . For more details about Aim refer to the documentation .","title":"Aim"},{"location":"user_guide/integrations/#weights-biases","text":"--wandb - logs training metrics, configuration parameters, environment details, and trained model to Weights & Biases . For more details, refer to W&B Quickstart .","title":"Weights &amp; Biases"},{"location":"user_guide/integrations/#ml-flow","text":"--mlflow - logs training metrics, hyperopt parameters, output artifacts, and trained models to MLflow . Set the environment variable MLFLOW_TRACKING_URI to log results to a remote tracking server.","title":"ML Flow"},{"location":"user_guide/integrations/#add-more-integrations","text":"For more information about integration contributions, please see the Developer Guide .","title":"Add more integrations"},{"location":"user_guide/serving/","text":"Serving Ludwig Models \u00b6 Ludwig models can be served using the serve command . ludwig serve --model_path = /path/to/model The command will spawn a Rest API using the FastAPI library. This API has two endpoints: predict and predict_batch . predict should be used to obtain predictions for individual examples, while predict_batch should be used to obtain predictions for an a batch of examples. Inputs sent to the REST API should be consistent with the feature names and types used to train the model. The output structure from the REST API depends on the model's output features and their data types. REST Endpoints \u00b6 predict \u00b6 Input format \u00b6 For each input of the model, the predict endpoint expects a field with a name. For instance, a model trained with an input text field named english_text would expect a POST like: curl http://0.0.0.0:8000/predict -X POST -F 'english_text=words to be translated' If the model was trained with an input image field, it will instead expects a POST with a file, like: curl http://0.0.0.0:8000/predict -X POST -F 'image=@path_to_image/example.png' A model with both a text and an image field will expect a POST like: curl http://0.0.0.0:8000/predict -X POST -F 'text=mixed together with' -F 'image=@path_to_image/example.png' Output format \u00b6 The response is a JSON dictionary with keys prefixed by the names of the model's output features. For binary outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" : false , \"NAME_probabilities_False\" : 0.76 , \"NAME_probabilities_True\" : 0.24 , \"NAME_probability\" : 0.76 } For number outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" : 0.381 } For categorical outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" : \"CLASSNAMEK\" , \"NAME_probability\" : 0.62 , \"NAME_probabilities_CLASSNAME1\" : 0.099 , \"NAME_probabilities_CLASSNAME2\" : 0.095 , ... \"NAME_probabilities_CLASSNAMEN\" : 0.077 } For set outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" :[ \"CLASSNAMEI\" , \"CLASSNAMEJ\" , \"CLASSNAMEK\" ], \"NAME_probabilities_CLASSNAME1\" : 0.490 , \"NAME_probabilities_CLASSNAME2\" : 0.245 , ... \"NAME_probabilities_CLASSNAMEN\" : 0.341 , \"NAME_probability\" :[ 0.53 , 0.62 , 0.95 ] } For sequence outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" :[ \"TOKEN1\" , \"TOKEN2\" , \"TOKEN3\" ], \"NAME_last_predictions\" : \"TOKEN3\" , \"NAME_probabilities\" :[ 0.106 , 0.122 , 0.118 , 0.133 ], \"NAME_probability\" : -6.4765729904174805 } For text outputs, the JSON structure returned by the REST API is the same as for sequences. batch_predict \u00b6 Input format \u00b6 You can also make a POST request on the /batch_predict endpoint to run inference on multiple samples at once. Requests must be submitted as form data, with one of fields being dataset : a JSON encoded string representation of the data to be predicted. The dataset JSON string is expected to be in the Pandas split format to reduce payload size. This format divides the dataset into three parts: columns : List[str] index (optional): List[Union[str, int]] data : List[List[object]] Additional form fields can be used to provide file resources like images that are referenced within the dataset. An example of batch prediction: curl http://0.0.0.0:8000/batch_predict -X POST -F 'dataset={\"columns\": [\"a\", \"b\"], \"data\": [[1, 2], [3, 4]]}' Output format \u00b6 The response is a JSON dictionary with keys prefixed by the names of the model's output features. For binary outputs, the JSON structure returned by the REST API is the following: { \"index\" : [ 0 , 1 ], \"columns\" : [ \"NAME_predictions\" , \"NAME_probabilities_False\" , \"NAME_probabilities_True\" , \"NAME_probability\" ], \"data\" : [ [ false , 0.768 , 0.231 , 0.768 ], [ true , 0.372 , 0.627 , 0.627 ] ] } For number outputs, the JSON structure returned by the REST API is the following: { \"index\" :[ 0 , 1 ], \"columns\" :[ \"NAME_predictions\" ], \"data\" :[[ 0.381 ],[ 0.202 ]]} For categorical outputs, the JSON structure returned by the REST API is the following: { \"index\" : [ 0 , 1 ], \"columns\" : [ \"NAME_predictions\" , \"NAME_probabilities_CLASSNAME1\" , \"NAME_probabilities_CLASSNAME2\" , ... \"NAME_probabilities_CLASSNAMEN\" , \"NAME_probability\" ], \"data\" : [ [ \"CLASSNAMEK\" , 0.099 , 0.095 , ... 0.077 , 0.623 ], [ \"CLASSNAMEK\" , 0.092 , 0.061 , ... 0.084 , 0.541 ] ] } For set outputs, the JSON structure returned by the REST API is the following: { \"index\" : [ 0 , 1 ], \"columns\" : [ \"NAME_predictions\" , \"NAME_probabilities_CLASSNAME1\" , \"NAME_probabilities_CLASSNAME2\" , ... \"NAME_probabilities_CLASSNAMEK\" , \"NAME_probability\" ], \"data\" : [ [ [ \"CLASSNAMEI\" , \"CLASSNAMEJ\" , \"CLASSNAMEK\" ], 0.490 , 0.453 , ... 0.500 , [ 0.53 , 0.62 , 0.95 ] ], [ [ \"CLASSNAMEM\" , \"CLASSNAMEN\" , \"CLASSNAMEO\" ], 0.481 , 0.466 , ... 0.485 , [ 0.63 , 0.72 , 0.81 ] ] ] } For sequence outputs, the JSON structure returned by the REST API is the following: { \"index\" : [ 0 , 1 ], \"columns\" : [ \"NAME_predictions\" , \"NAME_last_predictions\" , \"NAME_probabilities\" , \"NAME_probability\" ], \"data\" : [ [ [ \"TOKEN1\" , \"TOKEN1\" , \"TOKEN1\" ], \"TOKEN3\" , [ 0.106 , 0.122 , \u2026 0.083 ], -6.476 ], [ [ \"TOKEN4\" , \"TOKEN5\" , \"TOKEN6\" ], \"TOKEN6\" , [ 0.108 , 0.127 , \u2026 0.083 ], -6.482 ] ] } For text outputs, the JSON structure returned by the REST API is the same as for sequences.","title":"Serving"},{"location":"user_guide/serving/#serving-ludwig-models","text":"Ludwig models can be served using the serve command . ludwig serve --model_path = /path/to/model The command will spawn a Rest API using the FastAPI library. This API has two endpoints: predict and predict_batch . predict should be used to obtain predictions for individual examples, while predict_batch should be used to obtain predictions for an a batch of examples. Inputs sent to the REST API should be consistent with the feature names and types used to train the model. The output structure from the REST API depends on the model's output features and their data types.","title":"Serving Ludwig Models"},{"location":"user_guide/serving/#rest-endpoints","text":"","title":"REST Endpoints"},{"location":"user_guide/serving/#predict","text":"","title":"predict"},{"location":"user_guide/serving/#input-format","text":"For each input of the model, the predict endpoint expects a field with a name. For instance, a model trained with an input text field named english_text would expect a POST like: curl http://0.0.0.0:8000/predict -X POST -F 'english_text=words to be translated' If the model was trained with an input image field, it will instead expects a POST with a file, like: curl http://0.0.0.0:8000/predict -X POST -F 'image=@path_to_image/example.png' A model with both a text and an image field will expect a POST like: curl http://0.0.0.0:8000/predict -X POST -F 'text=mixed together with' -F 'image=@path_to_image/example.png'","title":"Input format"},{"location":"user_guide/serving/#output-format","text":"The response is a JSON dictionary with keys prefixed by the names of the model's output features. For binary outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" : false , \"NAME_probabilities_False\" : 0.76 , \"NAME_probabilities_True\" : 0.24 , \"NAME_probability\" : 0.76 } For number outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" : 0.381 } For categorical outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" : \"CLASSNAMEK\" , \"NAME_probability\" : 0.62 , \"NAME_probabilities_CLASSNAME1\" : 0.099 , \"NAME_probabilities_CLASSNAME2\" : 0.095 , ... \"NAME_probabilities_CLASSNAMEN\" : 0.077 } For set outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" :[ \"CLASSNAMEI\" , \"CLASSNAMEJ\" , \"CLASSNAMEK\" ], \"NAME_probabilities_CLASSNAME1\" : 0.490 , \"NAME_probabilities_CLASSNAME2\" : 0.245 , ... \"NAME_probabilities_CLASSNAMEN\" : 0.341 , \"NAME_probability\" :[ 0.53 , 0.62 , 0.95 ] } For sequence outputs, the JSON structure returned by the REST API is the following: { \"NAME_predictions\" :[ \"TOKEN1\" , \"TOKEN2\" , \"TOKEN3\" ], \"NAME_last_predictions\" : \"TOKEN3\" , \"NAME_probabilities\" :[ 0.106 , 0.122 , 0.118 , 0.133 ], \"NAME_probability\" : -6.4765729904174805 } For text outputs, the JSON structure returned by the REST API is the same as for sequences.","title":"Output format"},{"location":"user_guide/serving/#batch_predict","text":"","title":"batch_predict"},{"location":"user_guide/serving/#input-format_1","text":"You can also make a POST request on the /batch_predict endpoint to run inference on multiple samples at once. Requests must be submitted as form data, with one of fields being dataset : a JSON encoded string representation of the data to be predicted. The dataset JSON string is expected to be in the Pandas split format to reduce payload size. This format divides the dataset into three parts: columns : List[str] index (optional): List[Union[str, int]] data : List[List[object]] Additional form fields can be used to provide file resources like images that are referenced within the dataset. An example of batch prediction: curl http://0.0.0.0:8000/batch_predict -X POST -F 'dataset={\"columns\": [\"a\", \"b\"], \"data\": [[1, 2], [3, 4]]}'","title":"Input format"},{"location":"user_guide/serving/#output-format_1","text":"The response is a JSON dictionary with keys prefixed by the names of the model's output features. For binary outputs, the JSON structure returned by the REST API is the following: { \"index\" : [ 0 , 1 ], \"columns\" : [ \"NAME_predictions\" , \"NAME_probabilities_False\" , \"NAME_probabilities_True\" , \"NAME_probability\" ], \"data\" : [ [ false , 0.768 , 0.231 , 0.768 ], [ true , 0.372 , 0.627 , 0.627 ] ] } For number outputs, the JSON structure returned by the REST API is the following: { \"index\" :[ 0 , 1 ], \"columns\" :[ \"NAME_predictions\" ], \"data\" :[[ 0.381 ],[ 0.202 ]]} For categorical outputs, the JSON structure returned by the REST API is the following: { \"index\" : [ 0 , 1 ], \"columns\" : [ \"NAME_predictions\" , \"NAME_probabilities_CLASSNAME1\" , \"NAME_probabilities_CLASSNAME2\" , ... \"NAME_probabilities_CLASSNAMEN\" , \"NAME_probability\" ], \"data\" : [ [ \"CLASSNAMEK\" , 0.099 , 0.095 , ... 0.077 , 0.623 ], [ \"CLASSNAMEK\" , 0.092 , 0.061 , ... 0.084 , 0.541 ] ] } For set outputs, the JSON structure returned by the REST API is the following: { \"index\" : [ 0 , 1 ], \"columns\" : [ \"NAME_predictions\" , \"NAME_probabilities_CLASSNAME1\" , \"NAME_probabilities_CLASSNAME2\" , ... \"NAME_probabilities_CLASSNAMEK\" , \"NAME_probability\" ], \"data\" : [ [ [ \"CLASSNAMEI\" , \"CLASSNAMEJ\" , \"CLASSNAMEK\" ], 0.490 , 0.453 , ... 0.500 , [ 0.53 , 0.62 , 0.95 ] ], [ [ \"CLASSNAMEM\" , \"CLASSNAMEN\" , \"CLASSNAMEO\" ], 0.481 , 0.466 , ... 0.485 , [ 0.63 , 0.72 , 0.81 ] ] ] } For sequence outputs, the JSON structure returned by the REST API is the following: { \"index\" : [ 0 , 1 ], \"columns\" : [ \"NAME_predictions\" , \"NAME_last_predictions\" , \"NAME_probabilities\" , \"NAME_probability\" ], \"data\" : [ [ [ \"TOKEN1\" , \"TOKEN1\" , \"TOKEN1\" ], \"TOKEN3\" , [ 0.106 , 0.122 , \u2026 0.083 ], -6.476 ], [ [ \"TOKEN4\" , \"TOKEN5\" , \"TOKEN6\" ], \"TOKEN6\" , [ 0.108 , 0.127 , \u2026 0.083 ], -6.482 ] ] } For text outputs, the JSON structure returned by the REST API is the same as for sequences.","title":"Output format"},{"location":"user_guide/visualizations/","text":"Visualize Command \u00b6 Several visualizations can be obtained from the result files from both train , predict and experiment by using the ludwig visualize command. The command has several parameters, but not all the visualizations use all of them. Let's first present the parameters of the general script, and then, for each available visualization, we will discuss about the specific parameters needed and what visualization they produce. usage: ludwig visualize [options] This script analyzes results and shows some nice plots. optional arguments: -h, --help show this help message and exit -g, --ground_truth GROUND_TRUTH ground truth file -gm, --ground_truth_metadata GROUND_TRUTH_METADATA input metadata JSON file -sf, --split_file SPLIT_FILE file containing split values used in conjunction with ground truth file. -od, --output_directory OUTPUT_DIRECTORY directory where to save plots. If not specified, plots will be displayed in a window -ff, --file_format {pdf,png} file format of output plots -v, --visualization { binary_threshold_vs_metric, calibration_1_vs_all, calibration_multiclass, compare_classifiers_multiclass_multimetric, compare_classifiers_performance_changing_k, compare_classifiers_performance_from_pred, compare_classifiers_performance_from_prob compare_classifiers_performance_subset, compare_classifiers_predictions, compare_classifiers_predictions_distribution, compare_performance,confidence_thresholding, confidence_thresholding_2thresholds_2d, confidence_thresholding_2thresholds_3d, confidence_thresholding_data_vs_acc, confidence_thresholding_data_vs_acc_subset, confidence_thresholding_data_vs_acc_subset_per_class, confusion_matrix, frequency_vs_f1, hyperopt_hiplot, hyperopt_report, learning_curves, roc_curves, roc_curves_from_test_statistics }, The type of visualization to generate -ofn, --output_feature_name OUTPUT_FEATURE_NAME name of the output feature to visualize -gts, --ground_truth_split GROUND_TRUTH_SPLIT ground truth split - 0:train, 1:validation, 2:test split -tf, --threshold_output_feature_names THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...] names of output features for 2d threshold -pred, --predictions PREDICTIONS [PREDICTIONS ...] predictions files -prob, --probabilities PROBABILITIES [PROBABILITIES ...] probabilities files -trs, --training_statistics TRAINING_STATISTICS [TRAINING_STATISTICS ...] training stats files -tes, --test_statistics TEST_STATISTICS [TEST_STATISTICS ...] test stats files -hs, --hyperopt_stats_path HYPEROPT_STATS_PATH hyperopt stats file -mn, --model_names MODEL_NAMES [MODEL_NAMES ...] names of the models to use as labels -tn, --top_n_classes TOP_N_CLASSES [TOP_N_CLASSES ...] number of classes to plot -k, --top_k TOP_K number of elements in the ranklist to consider -ll, --labels_limit LABELS_LIMIT maximum numbers of labels. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels -ss, --subset {ground_truth,predictions} type of subset filtering -n, --normalize normalize rows in confusion matrix -m, --metrics METRICS [METRICS ...] metrics to dispay in threshold_vs_metric -pl, --positive_label POSITIVE_LABEL label of the positive class for the roc curve -l, --logging_level {critical, error, warning, info, debug, notset} the level of logging to use Some additional information on the parameters: The list parameters are all aligned. In other words, predictions , probabilities , training_statistics , test_statistics and model_names are parallel arrays, and the nth entry of model_names should be the name of the model corresponding to the nth entry of predictions . ground_truth and ground_truth_metadata are respectively the HDF5 and JSON file obtained during training preprocessing. If you plan to use visualizations do not use --skip_save_preprocessing when training. Those files contain the train/test split performed at preprocessing time. output_feature_name is the output feature to use for creating the visualization. Other parameters will be detailed for each visualization as different ones use them differently. Examples \u00b6 Example commands to generate the visualizations are based on running two experiments and comparing them. The experiments themselves are run with the following: ludwig experiment --experiment_name titanic --model_name Model1 --dataset train.csv -cf titanic_model1.yaml ludwig experiment --experiment_name titanic --model_name Model2 --dataset train.csv -cf titanic_model2.yaml To run these examples, you need to download the Titanic Kaggle competition dataset to get train.csv . Note that the example images associated with each visualization below were generated using a different dataset. The two models are defined with titanic_model1.yaml input_features : - name : Pclass type : category - name : Sex type : category - name : Age type : number preprocessing : missing_value_strategy : fill_with_mean - name : SibSp type : number - name : Parch type : number - name : Fare type : number preprocessing : missing_value_strategy : fill_with_mean - name : Embarked type : category output_features : - name : Survived type : binary and with titanic_model2.yaml : input_features : - name : Pclass type : category - name : Sex type : category - name : SibSp type : number - name : Parch type : number - name : Embarked type : category output_features : - name : Survived type : binary Learning Curves \u00b6 learning_curves \u00b6 Parameters for this visualization: output_directory file_format output_feature_name training_statistics model_names For each model (in the aligned lists of training_statistics and model_names ) and for each output feature and metric of the model, it produces a line plot showing how that metric changed over the course of the epochs of training on the training and validation sets. If output_feature_name is not specified, then all output features are plotted. Example command: ludwig visualize --visualization learning_curves \\ --output_feature_name Survived \\ --training_statistics results/titanic_Model1_0/training_statistics.json \\ results/titanic_Model2_0/training_statistics.json \\ --model_names Model1 Model2 Confusion Matrix \u00b6 confusion_matrix \u00b6 Parameters for this visualization: ground_truth_metadata output_directory file_format output_feature_name test_statistics model_names top_n_classes normalize For each model (in the aligned lists of test_statistics and model_names ) it produces a heatmap of the confusion matrix in the predictions for each field that has a confusion matrix in test_statistics . The value of top_n_classes limits the heatmap to the n most frequent classes. Example command: ludwig visualize --visualization confusion_matrix \\ --ground_truth_metadata results/titanic_Model1_0/model/train_set_metadata.json \\ --test_statistics results/titanic_Model1_0/test_statistics.json \\ --top_n_classes 2 The second plot produced is a bar chart showing the entropy of each class, ranked from most entropic to least entropic. Compare Performance \u00b6 compare_performance \u00b6 Parameters for this visualization: output_directory file_format output_feature_name test_statistics model_names For each model (in the aligned lists of test_statistics and model_names ) it produces bars in a bar plot, one for each overall metric available in the test_statistics file for the specified output_feature_name . Example command: ludwig visualize --visualization compare_performance \\ --output_feature_name Survived \\ --test_statistics results/titanic_Model1_0/test_statistics.json \\ results/titanic_Model2_0/test_statistics.json \\ --model_names Model1 Model2 compare_classifiers_performance_from_prob \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit output_feature_name must be the name of category feature. For each model (in the aligned lists of probabilities and model_names ) it produces bars in a bar plot, one for each overall metric computed from the probabilities of predictions for the specified output_feature_name . Example command: ludwig visualize --visualization compare_classifiers_performance_from_prob \\ --ground_truth train.hdf5 \\ --output_feature_name Survived \\ --probabilities results/titanic_Model1_0/Survived_probabilities.csv \\ results/titanic_Model2_0/Survived_probabilities.csv \\ --model_names Model1 Model2 compare_classifiers_performance_from_pred \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split predictions model_names labels_limit output_feature_name must name a category feature. For each model (in the aligned lists of predictions and model_names ) it produces bars in a bar plot, one for each overall metric computed on the fly from the predictions for the specified output_feature_name . Example command: ludwig visualize --visualization compare_classifiers_performance_from_pred \\ --ground_truth train.hdf5 \\ --ground_truth_metadata train.json \\ --output_feature_name Survived \\ --predictions results/titanic_Model1_0/Survived_predictions.csv \\ results/titanic_Model2_0/Survived_predictions.csv \\ --model_names Model1 Model2 compare_classifiers_performance_subset \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit subset output_feature_name must name a category feature. For each model (in the aligned lists of predictions and model_names ) it produces bars in a bar plot, one for each overall metric computed on the fly from the probabilities predictions for the specified output_feature_name , considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. If the values of subset is ground_truth , then only datapoints where the ground truth class is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed. Example command: ludwig visualize --visualization compare_classifiers_performance_subset \\ --ground_truth train.hdf5 \\ --ground_truth_metadata train.json \\ --output_feature_name Survived \\ --probabilities results/titanic_Model1_0/Survived_probabilities.csv \\ results/titanic_Model2_0/Survived_probabilities.csv \\ --model_names Model1 Model2 \\ --top_n_classes 2 \\ --subset ground_truth If the values of subset is predictions , then only datapoints where the model predicts a class that is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model. compare_classifiers_performance_changing_k \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_k labels_limit output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a line plot that shows the Hits@K metric (that counts a prediction as correct if the model produces it among the first k ) while changing k from 1 to top_k for the specified output_feature_name . Example command: ludwig visualize --visualization compare_classifiers_performance_changing_k \\ --ground_truth train.hdf5 \\ --output_feature_name Survived \\ --probabilities results/titanic_Model1_0/Survived_probabilities.csv \\ results/titanic_Model2_0/Survived_probabilities.csv \\ --model_names Model1 Model2 \\ --top_k 5 compare_classifiers_multiclass_multimetric \u00b6 Parameters for this visualization: ground_truth_metadata output_directory file_format output_feature_name test_statistics model_names top_n_classes output_feature_name must name a category feature. For each model (in the aligned lists of test_statistics and model_names ) it produces four plots that show the precision, recall and F1 of the model on several classes for the specified output_feature_name . The first one shows the metrics on the n most frequent classes. The second one shows the metrics on the n classes where the model performs the best. The third one shows the metrics on the n classes where the model performs the worst. The fourth one shows the metrics on all the classes, sorted by their frequency. This will become unreadable if the number of classes is too high. Compare Classifier Predictions \u00b6 compare_classifiers_predictions \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split predictions model_names labels_limit output_feature_name must name a category feature and there must be two and only two models (in the aligned lists of predictions and model_names ). This visualization produces a pie chart comparing the predictions of the two models for the specified output_feature_name . Example command: ludwig visualize --visualization compare_classifiers_predictions \\ --ground_truth train.hdf5 \\ --output_feature_name Survived \\ --predictions results/titanic_Model1_0/Survived_predictions.csv \\ results/titanic_Model2_0/Survived_predictions.csv \\ --model_names Model1 Model2 compare_classifiers_predictions_distribution \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split predictions model_names labels_limit output_feature_name must name a category feature. This visualization produces a radar plot comparing the distributions of predictions of the models for the first 10 classes of the specified output_feature_name . Confidence Thresholding \u00b6 confidence_thresholding \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names labels_limit output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a pair of lines indicating the accuracy of the model and the data coverage while increasing a threshold (x axis) on the probabilities of predictions for the specified output_feature_name . confidence_thresholding_data_vs_acc \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names labels_limit output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name . The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. confidence_thresholding_data_vs_acc_subset \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit subset output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name , considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. If the values of subset is ground_truth , then only datapoints where the ground truth class is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed. If the values of subset is predictions , then only datapoints where the model predicts a class that is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model. confidence_thresholding_data_vs_acc_subset_per_class \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit subset output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name , considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. If the values of subset is ground_truth , then only datapoints where the ground truth class is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed. If the values of subset is predictions , then only datapoints where the model predicts a class that is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model. The difference with confidence_thresholding_data_vs_acc_subset is that it produces one plot per class within the top_n_classes . confidence_thresholding_2thresholds_2d \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format ground_truth_split threshold_output_feature_names probabilities model_names labels_limit threshold_output_feature_names need to be exactly two, either category or binary. probabilities need to be exactly two, aligned with threshold_output_feature_names . model_names has to be exactly one. Three plots are produced. The first plot shows several semi transparent lines. They summarize the 3d surfaces displayed by confidence_thresholding_2thresholds_3d that have thresholds on the confidence of the predictions of the two threshold_output_feature_names as x and y axes and either the data coverage percentage or the accuracy as z axis. Each line represents a slice of the data coverage surface projected onto the accuracy surface. The second plot shows the max of all the lines displayed in the first plot. The third plot shows the max line and the values of the thresholds that obtained a specific data coverage vs accuracy pair of values. confidence_thresholding_2thresholds_3d \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format ground_truth_split threshold_output_feature_names probabilities labels_limit threshold_output_feature_names need to be exactly two, either category or binary. probabilities need to be exactly two, aligned with threshold_output_feature_names . The plot shows the 3d surfaces displayed by confidence_thresholding_2thresholds_3d that have thresholds on the confidence of the predictions of the two threshold_output_feature_names as x and y axes and either the data coverage percentage or the accuracy as z axis. Binary Threshold vs. Metric \u00b6 binary_threshold_vs_metric \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names metrics positive_label output_feature_name can be a category or binary feature. For each metric specified in metrics (options are f1 , precision , recall , accuracy ), this visualization produces a line chart plotting a threshold on the confidence of the model against the metric for the specified output_feature_name . If output_feature_name is a category feature, positive_label indicates which class is to be considered the positive class, all others will be considered negative. positive_label must be an integer, to find the integer label associated with a class check the ground_truth_metadata JSON file. ROC Curves \u00b6 roc_curves \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names positive_label output_feature_name can be a category or binary feature. This visualization produces a line chart plotting the roc curves for the specified output_feature_name . If output_feature_name is a category feature, positive_label indicates which class is considered the positive class, all others will be considered negative. positive_label must be an integer, to find the integer label associated with a class check the ground_truth_metadata JSON file. roc_curves_from_test_statistics \u00b6 Parameters for this visualization: output_directory file_format output_feature_name test_statistics model_names output_feature_name must name a binary feature. This visualization produces a line chart plotting the roc curves for the specified output_feature_name . Calibration Plot \u00b6 calibration_1_vs_all \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit output_feature_name must name a category or binary feature. For each class or each of the n most frequent classes if top_n_classes is specified, it produces two plots computed from the probabilities of predictions for the specified output_feature_name . The first plot is a calibration curve that shows the calibration of the predictions considering the current class to be the true one and all others to be a false one, drawing one line for each model (in the aligned lists of probabilities and model_names ). The second plot shows the distributions of the predictions considering the current class to be the true one and all others to be a false one, drawing the distribution for each model (in the aligned lists of probabilities and model_names ). calibration_multiclass \u00b6 Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names labels_limit output_feature_name must name a category feature. For each class, produces two plots computed from the probabilities of predictions for the specified output_feature_name . The first plot is a calibration curve that shows the calibration of the predictions considering all classes, drawing one line for each model (in the aligned lists of probabilities and model_names ). The second plot shows a bar plot of the Brier score (which calculates how calibrated are the probabilities of the predictions of a model), drawing one bar for each model (in the aligned lists of probabilities and model_names ). Class Frequency vs. F1 score \u00b6 frequency_vs_f1 \u00b6 Parameters for this visualization: ground_truth_metadata output_directory file_format output_feature_name test_statistics model_names top_n_classes output_feature_name must name a category feature. For each model (in the aligned lists of test_statistics and model_names ), produces two plots statistics of predictions for the specified output_feature_name . Generates plots for top_n_classes . The first plot is a line plot with one x axis representing the different classes and two vertical axes colored in orange and blue respectively. The orange one is the frequency of the class and an orange line is plotted to show the trend. The blue one is the F1 score for that class and a blue line is plotted to show the trend. The classes on the x axis are sorted by F1 score. The second plot has the same structure as the first one, but the axes are flipped and the classes on the x axis are sorted by frequency. Hyperparameter optimization visualization \u00b6 The examples of the hyperparameter visualizations shown here are obtained by running a random search with 100 samples on the ATIS dataset used for classifying intents given user utterances. hyperopt_report \u00b6 Parameters for this visualization: output_directory file_format hyperopt_stats_path The visualization creates one plot for each hyperparameter in the file at hyperopt_stats_path , plus an additional one containing a pair plot of hyperparameters interactions. Each plot will show the distribution of the parameters with respect to the metric to optimize. For float and int parameters a scatter plot is used, while for category parameters a violin plot is used instead. The pair plot shows a heatmap of how the values of pairs of hyperparameters correlate with the metric to optimize. hyperopt_hiplot \u00b6 Parameters for this visualization: output_directory file_format hyperopt_stats_path The visualization creates an interactive HTML page visualizing all the results from the hyperparameter optimization at once using a parallel coordinate plot. Tensorboard \u00b6 Users can visualize raw training metrics on Tensorboard with: tensorboard --logdir </path/to/model>/log","title":"Visualizations"},{"location":"user_guide/visualizations/#visualize-command","text":"Several visualizations can be obtained from the result files from both train , predict and experiment by using the ludwig visualize command. The command has several parameters, but not all the visualizations use all of them. Let's first present the parameters of the general script, and then, for each available visualization, we will discuss about the specific parameters needed and what visualization they produce. usage: ludwig visualize [options] This script analyzes results and shows some nice plots. optional arguments: -h, --help show this help message and exit -g, --ground_truth GROUND_TRUTH ground truth file -gm, --ground_truth_metadata GROUND_TRUTH_METADATA input metadata JSON file -sf, --split_file SPLIT_FILE file containing split values used in conjunction with ground truth file. -od, --output_directory OUTPUT_DIRECTORY directory where to save plots. If not specified, plots will be displayed in a window -ff, --file_format {pdf,png} file format of output plots -v, --visualization { binary_threshold_vs_metric, calibration_1_vs_all, calibration_multiclass, compare_classifiers_multiclass_multimetric, compare_classifiers_performance_changing_k, compare_classifiers_performance_from_pred, compare_classifiers_performance_from_prob compare_classifiers_performance_subset, compare_classifiers_predictions, compare_classifiers_predictions_distribution, compare_performance,confidence_thresholding, confidence_thresholding_2thresholds_2d, confidence_thresholding_2thresholds_3d, confidence_thresholding_data_vs_acc, confidence_thresholding_data_vs_acc_subset, confidence_thresholding_data_vs_acc_subset_per_class, confusion_matrix, frequency_vs_f1, hyperopt_hiplot, hyperopt_report, learning_curves, roc_curves, roc_curves_from_test_statistics }, The type of visualization to generate -ofn, --output_feature_name OUTPUT_FEATURE_NAME name of the output feature to visualize -gts, --ground_truth_split GROUND_TRUTH_SPLIT ground truth split - 0:train, 1:validation, 2:test split -tf, --threshold_output_feature_names THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...] names of output features for 2d threshold -pred, --predictions PREDICTIONS [PREDICTIONS ...] predictions files -prob, --probabilities PROBABILITIES [PROBABILITIES ...] probabilities files -trs, --training_statistics TRAINING_STATISTICS [TRAINING_STATISTICS ...] training stats files -tes, --test_statistics TEST_STATISTICS [TEST_STATISTICS ...] test stats files -hs, --hyperopt_stats_path HYPEROPT_STATS_PATH hyperopt stats file -mn, --model_names MODEL_NAMES [MODEL_NAMES ...] names of the models to use as labels -tn, --top_n_classes TOP_N_CLASSES [TOP_N_CLASSES ...] number of classes to plot -k, --top_k TOP_K number of elements in the ranklist to consider -ll, --labels_limit LABELS_LIMIT maximum numbers of labels. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels -ss, --subset {ground_truth,predictions} type of subset filtering -n, --normalize normalize rows in confusion matrix -m, --metrics METRICS [METRICS ...] metrics to dispay in threshold_vs_metric -pl, --positive_label POSITIVE_LABEL label of the positive class for the roc curve -l, --logging_level {critical, error, warning, info, debug, notset} the level of logging to use Some additional information on the parameters: The list parameters are all aligned. In other words, predictions , probabilities , training_statistics , test_statistics and model_names are parallel arrays, and the nth entry of model_names should be the name of the model corresponding to the nth entry of predictions . ground_truth and ground_truth_metadata are respectively the HDF5 and JSON file obtained during training preprocessing. If you plan to use visualizations do not use --skip_save_preprocessing when training. Those files contain the train/test split performed at preprocessing time. output_feature_name is the output feature to use for creating the visualization. Other parameters will be detailed for each visualization as different ones use them differently.","title":"Visualize Command"},{"location":"user_guide/visualizations/#examples","text":"Example commands to generate the visualizations are based on running two experiments and comparing them. The experiments themselves are run with the following: ludwig experiment --experiment_name titanic --model_name Model1 --dataset train.csv -cf titanic_model1.yaml ludwig experiment --experiment_name titanic --model_name Model2 --dataset train.csv -cf titanic_model2.yaml To run these examples, you need to download the Titanic Kaggle competition dataset to get train.csv . Note that the example images associated with each visualization below were generated using a different dataset. The two models are defined with titanic_model1.yaml input_features : - name : Pclass type : category - name : Sex type : category - name : Age type : number preprocessing : missing_value_strategy : fill_with_mean - name : SibSp type : number - name : Parch type : number - name : Fare type : number preprocessing : missing_value_strategy : fill_with_mean - name : Embarked type : category output_features : - name : Survived type : binary and with titanic_model2.yaml : input_features : - name : Pclass type : category - name : Sex type : category - name : SibSp type : number - name : Parch type : number - name : Embarked type : category output_features : - name : Survived type : binary","title":"Examples"},{"location":"user_guide/visualizations/#learning-curves","text":"","title":"Learning Curves"},{"location":"user_guide/visualizations/#learning_curves","text":"Parameters for this visualization: output_directory file_format output_feature_name training_statistics model_names For each model (in the aligned lists of training_statistics and model_names ) and for each output feature and metric of the model, it produces a line plot showing how that metric changed over the course of the epochs of training on the training and validation sets. If output_feature_name is not specified, then all output features are plotted. Example command: ludwig visualize --visualization learning_curves \\ --output_feature_name Survived \\ --training_statistics results/titanic_Model1_0/training_statistics.json \\ results/titanic_Model2_0/training_statistics.json \\ --model_names Model1 Model2","title":"learning_curves"},{"location":"user_guide/visualizations/#confusion-matrix","text":"","title":"Confusion Matrix"},{"location":"user_guide/visualizations/#confusion_matrix","text":"Parameters for this visualization: ground_truth_metadata output_directory file_format output_feature_name test_statistics model_names top_n_classes normalize For each model (in the aligned lists of test_statistics and model_names ) it produces a heatmap of the confusion matrix in the predictions for each field that has a confusion matrix in test_statistics . The value of top_n_classes limits the heatmap to the n most frequent classes. Example command: ludwig visualize --visualization confusion_matrix \\ --ground_truth_metadata results/titanic_Model1_0/model/train_set_metadata.json \\ --test_statistics results/titanic_Model1_0/test_statistics.json \\ --top_n_classes 2 The second plot produced is a bar chart showing the entropy of each class, ranked from most entropic to least entropic.","title":"confusion_matrix"},{"location":"user_guide/visualizations/#compare-performance","text":"","title":"Compare Performance"},{"location":"user_guide/visualizations/#compare_performance","text":"Parameters for this visualization: output_directory file_format output_feature_name test_statistics model_names For each model (in the aligned lists of test_statistics and model_names ) it produces bars in a bar plot, one for each overall metric available in the test_statistics file for the specified output_feature_name . Example command: ludwig visualize --visualization compare_performance \\ --output_feature_name Survived \\ --test_statistics results/titanic_Model1_0/test_statistics.json \\ results/titanic_Model2_0/test_statistics.json \\ --model_names Model1 Model2","title":"compare_performance"},{"location":"user_guide/visualizations/#compare_classifiers_performance_from_prob","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit output_feature_name must be the name of category feature. For each model (in the aligned lists of probabilities and model_names ) it produces bars in a bar plot, one for each overall metric computed from the probabilities of predictions for the specified output_feature_name . Example command: ludwig visualize --visualization compare_classifiers_performance_from_prob \\ --ground_truth train.hdf5 \\ --output_feature_name Survived \\ --probabilities results/titanic_Model1_0/Survived_probabilities.csv \\ results/titanic_Model2_0/Survived_probabilities.csv \\ --model_names Model1 Model2","title":"compare_classifiers_performance_from_prob"},{"location":"user_guide/visualizations/#compare_classifiers_performance_from_pred","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split predictions model_names labels_limit output_feature_name must name a category feature. For each model (in the aligned lists of predictions and model_names ) it produces bars in a bar plot, one for each overall metric computed on the fly from the predictions for the specified output_feature_name . Example command: ludwig visualize --visualization compare_classifiers_performance_from_pred \\ --ground_truth train.hdf5 \\ --ground_truth_metadata train.json \\ --output_feature_name Survived \\ --predictions results/titanic_Model1_0/Survived_predictions.csv \\ results/titanic_Model2_0/Survived_predictions.csv \\ --model_names Model1 Model2","title":"compare_classifiers_performance_from_pred"},{"location":"user_guide/visualizations/#compare_classifiers_performance_subset","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit subset output_feature_name must name a category feature. For each model (in the aligned lists of predictions and model_names ) it produces bars in a bar plot, one for each overall metric computed on the fly from the probabilities predictions for the specified output_feature_name , considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. If the values of subset is ground_truth , then only datapoints where the ground truth class is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed. Example command: ludwig visualize --visualization compare_classifiers_performance_subset \\ --ground_truth train.hdf5 \\ --ground_truth_metadata train.json \\ --output_feature_name Survived \\ --probabilities results/titanic_Model1_0/Survived_probabilities.csv \\ results/titanic_Model2_0/Survived_probabilities.csv \\ --model_names Model1 Model2 \\ --top_n_classes 2 \\ --subset ground_truth If the values of subset is predictions , then only datapoints where the model predicts a class that is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model.","title":"compare_classifiers_performance_subset"},{"location":"user_guide/visualizations/#compare_classifiers_performance_changing_k","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_k labels_limit output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a line plot that shows the Hits@K metric (that counts a prediction as correct if the model produces it among the first k ) while changing k from 1 to top_k for the specified output_feature_name . Example command: ludwig visualize --visualization compare_classifiers_performance_changing_k \\ --ground_truth train.hdf5 \\ --output_feature_name Survived \\ --probabilities results/titanic_Model1_0/Survived_probabilities.csv \\ results/titanic_Model2_0/Survived_probabilities.csv \\ --model_names Model1 Model2 \\ --top_k 5","title":"compare_classifiers_performance_changing_k"},{"location":"user_guide/visualizations/#compare_classifiers_multiclass_multimetric","text":"Parameters for this visualization: ground_truth_metadata output_directory file_format output_feature_name test_statistics model_names top_n_classes output_feature_name must name a category feature. For each model (in the aligned lists of test_statistics and model_names ) it produces four plots that show the precision, recall and F1 of the model on several classes for the specified output_feature_name . The first one shows the metrics on the n most frequent classes. The second one shows the metrics on the n classes where the model performs the best. The third one shows the metrics on the n classes where the model performs the worst. The fourth one shows the metrics on all the classes, sorted by their frequency. This will become unreadable if the number of classes is too high.","title":"compare_classifiers_multiclass_multimetric"},{"location":"user_guide/visualizations/#compare-classifier-predictions","text":"","title":"Compare Classifier Predictions"},{"location":"user_guide/visualizations/#compare_classifiers_predictions","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split predictions model_names labels_limit output_feature_name must name a category feature and there must be two and only two models (in the aligned lists of predictions and model_names ). This visualization produces a pie chart comparing the predictions of the two models for the specified output_feature_name . Example command: ludwig visualize --visualization compare_classifiers_predictions \\ --ground_truth train.hdf5 \\ --output_feature_name Survived \\ --predictions results/titanic_Model1_0/Survived_predictions.csv \\ results/titanic_Model2_0/Survived_predictions.csv \\ --model_names Model1 Model2","title":"compare_classifiers_predictions"},{"location":"user_guide/visualizations/#compare_classifiers_predictions_distribution","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split predictions model_names labels_limit output_feature_name must name a category feature. This visualization produces a radar plot comparing the distributions of predictions of the models for the first 10 classes of the specified output_feature_name .","title":"compare_classifiers_predictions_distribution"},{"location":"user_guide/visualizations/#confidence-thresholding","text":"","title":"Confidence Thresholding"},{"location":"user_guide/visualizations/#confidence_thresholding","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names labels_limit output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a pair of lines indicating the accuracy of the model and the data coverage while increasing a threshold (x axis) on the probabilities of predictions for the specified output_feature_name .","title":"confidence_thresholding"},{"location":"user_guide/visualizations/#confidence_thresholding_data_vs_acc","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names labels_limit output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name . The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold.","title":"confidence_thresholding_data_vs_acc"},{"location":"user_guide/visualizations/#confidence_thresholding_data_vs_acc_subset","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit subset output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name , considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. If the values of subset is ground_truth , then only datapoints where the ground truth class is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed. If the values of subset is predictions , then only datapoints where the model predicts a class that is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model.","title":"confidence_thresholding_data_vs_acc_subset"},{"location":"user_guide/visualizations/#confidence_thresholding_data_vs_acc_subset_per_class","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit subset output_feature_name must name a category feature. For each model (in the aligned lists of probabilities and model_names ) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name , considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. If the values of subset is ground_truth , then only datapoints where the ground truth class is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed. If the values of subset is predictions , then only datapoints where the model predicts a class that is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model. The difference with confidence_thresholding_data_vs_acc_subset is that it produces one plot per class within the top_n_classes .","title":"confidence_thresholding_data_vs_acc_subset_per_class"},{"location":"user_guide/visualizations/#confidence_thresholding_2thresholds_2d","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format ground_truth_split threshold_output_feature_names probabilities model_names labels_limit threshold_output_feature_names need to be exactly two, either category or binary. probabilities need to be exactly two, aligned with threshold_output_feature_names . model_names has to be exactly one. Three plots are produced. The first plot shows several semi transparent lines. They summarize the 3d surfaces displayed by confidence_thresholding_2thresholds_3d that have thresholds on the confidence of the predictions of the two threshold_output_feature_names as x and y axes and either the data coverage percentage or the accuracy as z axis. Each line represents a slice of the data coverage surface projected onto the accuracy surface. The second plot shows the max of all the lines displayed in the first plot. The third plot shows the max line and the values of the thresholds that obtained a specific data coverage vs accuracy pair of values.","title":"confidence_thresholding_2thresholds_2d"},{"location":"user_guide/visualizations/#confidence_thresholding_2thresholds_3d","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format ground_truth_split threshold_output_feature_names probabilities labels_limit threshold_output_feature_names need to be exactly two, either category or binary. probabilities need to be exactly two, aligned with threshold_output_feature_names . The plot shows the 3d surfaces displayed by confidence_thresholding_2thresholds_3d that have thresholds on the confidence of the predictions of the two threshold_output_feature_names as x and y axes and either the data coverage percentage or the accuracy as z axis.","title":"confidence_thresholding_2thresholds_3d"},{"location":"user_guide/visualizations/#binary-threshold-vs-metric","text":"","title":"Binary Threshold vs. Metric"},{"location":"user_guide/visualizations/#binary_threshold_vs_metric","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names metrics positive_label output_feature_name can be a category or binary feature. For each metric specified in metrics (options are f1 , precision , recall , accuracy ), this visualization produces a line chart plotting a threshold on the confidence of the model against the metric for the specified output_feature_name . If output_feature_name is a category feature, positive_label indicates which class is to be considered the positive class, all others will be considered negative. positive_label must be an integer, to find the integer label associated with a class check the ground_truth_metadata JSON file.","title":"binary_threshold_vs_metric"},{"location":"user_guide/visualizations/#roc-curves","text":"","title":"ROC Curves"},{"location":"user_guide/visualizations/#roc_curves","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names positive_label output_feature_name can be a category or binary feature. This visualization produces a line chart plotting the roc curves for the specified output_feature_name . If output_feature_name is a category feature, positive_label indicates which class is considered the positive class, all others will be considered negative. positive_label must be an integer, to find the integer label associated with a class check the ground_truth_metadata JSON file.","title":"roc_curves"},{"location":"user_guide/visualizations/#roc_curves_from_test_statistics","text":"Parameters for this visualization: output_directory file_format output_feature_name test_statistics model_names output_feature_name must name a binary feature. This visualization produces a line chart plotting the roc curves for the specified output_feature_name .","title":"roc_curves_from_test_statistics"},{"location":"user_guide/visualizations/#calibration-plot","text":"","title":"Calibration Plot"},{"location":"user_guide/visualizations/#calibration_1_vs_all","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names top_n_classes labels_limit output_feature_name must name a category or binary feature. For each class or each of the n most frequent classes if top_n_classes is specified, it produces two plots computed from the probabilities of predictions for the specified output_feature_name . The first plot is a calibration curve that shows the calibration of the predictions considering the current class to be the true one and all others to be a false one, drawing one line for each model (in the aligned lists of probabilities and model_names ). The second plot shows the distributions of the predictions considering the current class to be the true one and all others to be a false one, drawing the distribution for each model (in the aligned lists of probabilities and model_names ).","title":"calibration_1_vs_all"},{"location":"user_guide/visualizations/#calibration_multiclass","text":"Parameters for this visualization: ground_truth split_file ground_truth_metadata output_directory file_format output_feature_name ground_truth_split probabilities model_names labels_limit output_feature_name must name a category feature. For each class, produces two plots computed from the probabilities of predictions for the specified output_feature_name . The first plot is a calibration curve that shows the calibration of the predictions considering all classes, drawing one line for each model (in the aligned lists of probabilities and model_names ). The second plot shows a bar plot of the Brier score (which calculates how calibrated are the probabilities of the predictions of a model), drawing one bar for each model (in the aligned lists of probabilities and model_names ).","title":"calibration_multiclass"},{"location":"user_guide/visualizations/#class-frequency-vs-f1-score","text":"","title":"Class Frequency vs. F1 score"},{"location":"user_guide/visualizations/#frequency_vs_f1","text":"Parameters for this visualization: ground_truth_metadata output_directory file_format output_feature_name test_statistics model_names top_n_classes output_feature_name must name a category feature. For each model (in the aligned lists of test_statistics and model_names ), produces two plots statistics of predictions for the specified output_feature_name . Generates plots for top_n_classes . The first plot is a line plot with one x axis representing the different classes and two vertical axes colored in orange and blue respectively. The orange one is the frequency of the class and an orange line is plotted to show the trend. The blue one is the F1 score for that class and a blue line is plotted to show the trend. The classes on the x axis are sorted by F1 score. The second plot has the same structure as the first one, but the axes are flipped and the classes on the x axis are sorted by frequency.","title":"frequency_vs_f1"},{"location":"user_guide/visualizations/#hyperparameter-optimization-visualization","text":"The examples of the hyperparameter visualizations shown here are obtained by running a random search with 100 samples on the ATIS dataset used for classifying intents given user utterances.","title":"Hyperparameter optimization visualization"},{"location":"user_guide/visualizations/#hyperopt_report","text":"Parameters for this visualization: output_directory file_format hyperopt_stats_path The visualization creates one plot for each hyperparameter in the file at hyperopt_stats_path , plus an additional one containing a pair plot of hyperparameters interactions. Each plot will show the distribution of the parameters with respect to the metric to optimize. For float and int parameters a scatter plot is used, while for category parameters a violin plot is used instead. The pair plot shows a heatmap of how the values of pairs of hyperparameters correlate with the metric to optimize.","title":"hyperopt_report"},{"location":"user_guide/visualizations/#hyperopt_hiplot","text":"Parameters for this visualization: output_directory file_format hyperopt_stats_path The visualization creates an interactive HTML page visualizing all the results from the hyperparameter optimization at once using a parallel coordinate plot.","title":"hyperopt_hiplot"},{"location":"user_guide/visualizations/#tensorboard","text":"Users can visualize raw training metrics on Tensorboard with: tensorboard --logdir </path/to/model>/log","title":"Tensorboard"},{"location":"user_guide/what_is_ludwig/","text":"Introduction \u00b6 Ludwig is an open-source, declarative machine learning framework that makes it easy to define deep learning pipelines with a simple and flexible data-driven configuration system. Ludwig is suitable for a wide variety of AI tasks, and is hosted by the Linux Foundation AI & Data . Ludwig enables you to apply state-of-the-art tabular, natural language processing, and computer vision models to your existing data and put them into production with just a few short commands . CLI Python data.csv config.yaml ludwig train --config config.yaml --dataset data.csv ludwig predict --model_path results/experiment_run/model --dataset test.csv from ludwig.api import LudwigModel import pandas as pd # train a model config = { \"input_features\" : [ { \"name\" : \"sepal_length_cm\" , \"type\" : \"number\" }, { \"name\" : \"sepal_width_cm\" , \"type\" : \"number\" }, { \"name\" : \"petal_length_cm\" , \"type\" : \"number\" }, { \"name\" : \"petal_width_cm\" , \"type\" : \"number\" } ], \"output_features\" : [ { \"name\" : \"class\" , \"type\" : \"category\" } ] } model = LudwigModel ( config ) data = pd . read_csv ( \"data.csv\" ) train_stats , _ , model_dir = model . train ( data ) # or load a model model = LudwigModel . load ( model_dir ) # obtain predictions predictions = model . predict ( data ) sepal_length_cm,sepal_width_cm,petal_length_cm,petal_width_cm 4.9,3.0,1.4,0.2 4.7,3.2,1.3,0.2 4.6,3.1,1.5,0.2 5.0,3.6,1.4,0.2 5.4,3.9,1.7,0.4 4.6,3.4,1.4,0.3 5.0,3.4,1.5,0.2 4.4,2.9,1.4,0.2 4.9,3.1,1.5,0.1 input_features : - name : sepal_length_cm type : number - name : sepal_width_cm type : number - name : petal_length_cm type : number - name : petal_width_cm type : number output_features : - name : class type : category Ludwig makes this possible through its declarative approach to structuring machine learning pipelines. Instead of writing code for your model, training loop, preprocessing, postprocessing, evaluation and hyperparameter optimization, you only need to declare the schema of your data with a simple YAML configuration: input_features : - name : title type : text - name : author type : category - name : description type : text - name : cover type : image output_features : - name : genre type : set - name : price type : number Starting from a simple config like the one above, any and all aspects of the model architecture, training loop, hyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration to customize the pipeline to meet your requirements: input_features : - name : title type : text encoder : rnn cell : lstm num_layers : 2 state_size : 128 preprocessing : tokenizer : space_punct - name : author type : category embedding_size : 128 preprocessing : most_common : 10000 - name : description type : text encoder : bert - name : cover type : image encoder : resnet num_layers : 18 output_features : - name : genre type : set - name : price type : number preprocessing : normalization : zscore trainer : epochs : 50 batch_size : 256 optimizer : type : adam beat1 : 0.9 learning_rate : 0.001 backend : type : local cache_format : parquet hyperopt : metric : f1 sampler : random parameters : title.num_layers : lower : 1 upper : 5 training.learning_rate : values : [ 0.01 , 0.003 , 0.001 ] Ludwig is a single framework that guides you through machine learning end-to-end; from experimenting with different training recipes, exploring state-of-the-art model architectures, to scaling up to large out-of-memory datasets and multi-node clusters, and finally serving the best model in production. Why Declarative Machine Learning Systems \u00b6 Ludwig\u2019s declarative approach to machine learning provides the simplicity of an AutoML solution with the flexibility of writing your own PyTorch code. This is achieved by creating an extensible, declarative configuration with optional parameters for every aspect of the pipeline. Multi-modal, multi-task learning out-of-the-box \u00b6 Mix and match tabular data, text, images, and even audio into complex model configurations without writing code. Fully customizable and extensible \u00b6 Every part of the model and training process can be controlled through a simple configuration interface. Minimal machine learning boilerplate \u00b6 Engineering complexity of deep learning is handled out of the box, enabling research scientists to focus on building models at the highest level of abstraction. Data preprocessing, hyperparameter optimization, device management, and distributed training for newly registered torch.nn.Module models come completely free. Why Ludwig \u00b6 Ludwig\u2019s declarative programming model allows for key features such as: Highly configurable data preprocessing, modeling, and metrics \u00b6 Any and all aspects of the model architecture, training loop, hyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration to customize the pipeline to meet your requirements. For details on what can be configured, check out Ludwig Configuration docs. Integration with any structured data source \u00b6 If it can be read into a SQL table or Pandas DataFrame, Ludwig can train a model on it. Hyperparameter optimization \u00b6 Perform a variety of hyperparameter search algorithms locally or across many workers in parallel using Ray Tune. Rich model exporting and tracking \u00b6 Automatically track all trials and metrics with tools like Tensorboard, Comet ML, Weights & Biases, and MLflow. Automatically scale training to multi-GPU, multi-node clusters \u00b6 Go from training on your local machine to the cloud without code or config changes. Easily build your benchmarks \u00b6 Creating a state-of-the-art baseline and comapring it with a new model is a simple config change. Easily apply new architectures to multiple problems and datasets \u00b6 Apply new models across the extensive set of tasks and datasets that Ludwig supports. Ludwig includes a full benchmarking toolkit accessible to any user, for running experiments with multiple models across multiple datasets with just a simple configuration. Low-code interface for state-of-the-art models, including pre-trained Huggingface Transformers \u00b6 Ludwig also natively integrates with pre-trained models, such as the ones available in Huggingface Transformers . Users can choose from a vast collection of state-of-the-art pre-trained PyTorch models to use without needing to write any code at all. For example, training a BERT-based sentiment analysis model with Ludwig is as simple as: ludwig train --dataset sst5 -\u2013config_str \u201c { input_features: [{ name: sentence, type: text, encoder: bert }] , output_features: [{ name: label, type: category }]} \u201d Low-code interface for AutoML \u00b6 Ludwig AutoML allows users to obtain trained models by providing just a dataset, the target column, and a time budget. auto_train_results = ludwig . automl . auto_train ( dataset = my_dataset_df , target = target_column_name , time_limit_s = 7200 ) Easy productionisation \u00b6 Ludwig makes it easy to serve deep learning models, including on GPUs. Launch a REST API for your trained Ludwig model. ludwig serve --model_path = /path/to/model Ludwig supports exporting models to efficient Torschscript bundles. ludwig export_torchscript -\u2013model_path = /path/to/model","title":"What is Ludwig?"},{"location":"user_guide/what_is_ludwig/#introduction","text":"Ludwig is an open-source, declarative machine learning framework that makes it easy to define deep learning pipelines with a simple and flexible data-driven configuration system. Ludwig is suitable for a wide variety of AI tasks, and is hosted by the Linux Foundation AI & Data . Ludwig enables you to apply state-of-the-art tabular, natural language processing, and computer vision models to your existing data and put them into production with just a few short commands . CLI Python data.csv config.yaml ludwig train --config config.yaml --dataset data.csv ludwig predict --model_path results/experiment_run/model --dataset test.csv from ludwig.api import LudwigModel import pandas as pd # train a model config = { \"input_features\" : [ { \"name\" : \"sepal_length_cm\" , \"type\" : \"number\" }, { \"name\" : \"sepal_width_cm\" , \"type\" : \"number\" }, { \"name\" : \"petal_length_cm\" , \"type\" : \"number\" }, { \"name\" : \"petal_width_cm\" , \"type\" : \"number\" } ], \"output_features\" : [ { \"name\" : \"class\" , \"type\" : \"category\" } ] } model = LudwigModel ( config ) data = pd . read_csv ( \"data.csv\" ) train_stats , _ , model_dir = model . train ( data ) # or load a model model = LudwigModel . load ( model_dir ) # obtain predictions predictions = model . predict ( data ) sepal_length_cm,sepal_width_cm,petal_length_cm,petal_width_cm 4.9,3.0,1.4,0.2 4.7,3.2,1.3,0.2 4.6,3.1,1.5,0.2 5.0,3.6,1.4,0.2 5.4,3.9,1.7,0.4 4.6,3.4,1.4,0.3 5.0,3.4,1.5,0.2 4.4,2.9,1.4,0.2 4.9,3.1,1.5,0.1 input_features : - name : sepal_length_cm type : number - name : sepal_width_cm type : number - name : petal_length_cm type : number - name : petal_width_cm type : number output_features : - name : class type : category Ludwig makes this possible through its declarative approach to structuring machine learning pipelines. Instead of writing code for your model, training loop, preprocessing, postprocessing, evaluation and hyperparameter optimization, you only need to declare the schema of your data with a simple YAML configuration: input_features : - name : title type : text - name : author type : category - name : description type : text - name : cover type : image output_features : - name : genre type : set - name : price type : number Starting from a simple config like the one above, any and all aspects of the model architecture, training loop, hyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration to customize the pipeline to meet your requirements: input_features : - name : title type : text encoder : rnn cell : lstm num_layers : 2 state_size : 128 preprocessing : tokenizer : space_punct - name : author type : category embedding_size : 128 preprocessing : most_common : 10000 - name : description type : text encoder : bert - name : cover type : image encoder : resnet num_layers : 18 output_features : - name : genre type : set - name : price type : number preprocessing : normalization : zscore trainer : epochs : 50 batch_size : 256 optimizer : type : adam beat1 : 0.9 learning_rate : 0.001 backend : type : local cache_format : parquet hyperopt : metric : f1 sampler : random parameters : title.num_layers : lower : 1 upper : 5 training.learning_rate : values : [ 0.01 , 0.003 , 0.001 ] Ludwig is a single framework that guides you through machine learning end-to-end; from experimenting with different training recipes, exploring state-of-the-art model architectures, to scaling up to large out-of-memory datasets and multi-node clusters, and finally serving the best model in production.","title":"Introduction"},{"location":"user_guide/what_is_ludwig/#why-declarative-machine-learning-systems","text":"Ludwig\u2019s declarative approach to machine learning provides the simplicity of an AutoML solution with the flexibility of writing your own PyTorch code. This is achieved by creating an extensible, declarative configuration with optional parameters for every aspect of the pipeline.","title":"Why Declarative Machine Learning Systems"},{"location":"user_guide/what_is_ludwig/#multi-modal-multi-task-learning-out-of-the-box","text":"Mix and match tabular data, text, images, and even audio into complex model configurations without writing code.","title":"Multi-modal, multi-task learning out-of-the-box"},{"location":"user_guide/what_is_ludwig/#fully-customizable-and-extensible","text":"Every part of the model and training process can be controlled through a simple configuration interface.","title":"Fully customizable and extensible"},{"location":"user_guide/what_is_ludwig/#minimal-machine-learning-boilerplate","text":"Engineering complexity of deep learning is handled out of the box, enabling research scientists to focus on building models at the highest level of abstraction. Data preprocessing, hyperparameter optimization, device management, and distributed training for newly registered torch.nn.Module models come completely free.","title":"Minimal machine learning boilerplate"},{"location":"user_guide/what_is_ludwig/#why-ludwig","text":"Ludwig\u2019s declarative programming model allows for key features such as:","title":"Why Ludwig"},{"location":"user_guide/what_is_ludwig/#highly-configurable-data-preprocessing-modeling-and-metrics","text":"Any and all aspects of the model architecture, training loop, hyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration to customize the pipeline to meet your requirements. For details on what can be configured, check out Ludwig Configuration docs.","title":"Highly configurable data preprocessing, modeling, and metrics"},{"location":"user_guide/what_is_ludwig/#integration-with-any-structured-data-source","text":"If it can be read into a SQL table or Pandas DataFrame, Ludwig can train a model on it.","title":"Integration with any structured data source"},{"location":"user_guide/what_is_ludwig/#hyperparameter-optimization","text":"Perform a variety of hyperparameter search algorithms locally or across many workers in parallel using Ray Tune.","title":"Hyperparameter optimization"},{"location":"user_guide/what_is_ludwig/#rich-model-exporting-and-tracking","text":"Automatically track all trials and metrics with tools like Tensorboard, Comet ML, Weights & Biases, and MLflow.","title":"Rich model exporting and tracking"},{"location":"user_guide/what_is_ludwig/#automatically-scale-training-to-multi-gpu-multi-node-clusters","text":"Go from training on your local machine to the cloud without code or config changes.","title":"Automatically scale training to multi-GPU, multi-node clusters"},{"location":"user_guide/what_is_ludwig/#easily-build-your-benchmarks","text":"Creating a state-of-the-art baseline and comapring it with a new model is a simple config change.","title":"Easily build your benchmarks"},{"location":"user_guide/what_is_ludwig/#easily-apply-new-architectures-to-multiple-problems-and-datasets","text":"Apply new models across the extensive set of tasks and datasets that Ludwig supports. Ludwig includes a full benchmarking toolkit accessible to any user, for running experiments with multiple models across multiple datasets with just a simple configuration.","title":"Easily apply new architectures to multiple problems and datasets"},{"location":"user_guide/what_is_ludwig/#low-code-interface-for-state-of-the-art-models-including-pre-trained-huggingface-transformers","text":"Ludwig also natively integrates with pre-trained models, such as the ones available in Huggingface Transformers . Users can choose from a vast collection of state-of-the-art pre-trained PyTorch models to use without needing to write any code at all. For example, training a BERT-based sentiment analysis model with Ludwig is as simple as: ludwig train --dataset sst5 -\u2013config_str \u201c { input_features: [{ name: sentence, type: text, encoder: bert }] , output_features: [{ name: label, type: category }]} \u201d","title":"Low-code interface for state-of-the-art models, including pre-trained Huggingface Transformers"},{"location":"user_guide/what_is_ludwig/#low-code-interface-for-automl","text":"Ludwig AutoML allows users to obtain trained models by providing just a dataset, the target column, and a time budget. auto_train_results = ludwig . automl . auto_train ( dataset = my_dataset_df , target = target_column_name , time_limit_s = 7200 )","title":"Low-code interface for AutoML"},{"location":"user_guide/what_is_ludwig/#easy-productionisation","text":"Ludwig makes it easy to serve deep learning models, including on GPUs. Launch a REST API for your trained Ludwig model. ludwig serve --model_path = /path/to/model Ludwig supports exporting models to efficient Torschscript bundles. ludwig export_torchscript -\u2013model_path = /path/to/model","title":"Easy productionisation"},{"location":"user_guide/api/LudwigModel/","text":"LudwigModel class [source] \u00b6 ludwig . api . LudwigModel ( config , logging_level = 40 , backend = None , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , callbacks = None ) Class that allows access to high level Ludwig functionalities. Inputs config (Union[str, dict]): in-memory representation of config or string path to a YAML config file. logging_level (int): Log level that will be sent to stderr. backend (Union[Backend, str]): Backend or string name of backend to use to execute preprocessing / training steps. gpus (Union[str, int, List[int]], default: None ): GPUs to use (it uses the same syntax of CUDA_VISIBLE_DEVICES) gpu_memory_limit (int: default: None ): maximum memory in MB to allocate per GPU device. allow_parallel_threads (bool, default: True ): allow Torch to use multithreading parallelism to improve performance at the cost of determinism. Example usage: from ludwig.api import LudwigModel Train a model: config = { ... } ludwig_model = LudwigModel ( config ) train_stats , _ , _ = ludwig_model . train ( dataset = file_path ) or train_stats , _ , _ = ludwig_model . train ( dataset = dataframe ) If you have already trained a model you can load it and use it to predict ludwig_model = LudwigModel . load ( model_dir ) Predict: predictions , _ = ludwig_model . predict ( dataset = file_path ) or predictions , _ = ludwig_model . predict ( dataset = dataframe ) Evaluation: eval_stats , _ , _ = ludwig_model . evaluate ( dataset = file_path ) or eval_stats , _ , _ = ludwig_model . evaluate ( dataset = dataframe ) LudwigModel methods \u00b6 collect_activations \u00b6 collect_activations ( layer_names , dataset , data_format = None , split = 'full' , batch_size = 128 , debug = False ) Loads a pre-trained model model and input data to collect the values of the activations contained in the tensors. Inputs layer_names (list): list of strings for layer names in the model to collect activations. dataset (Union[str, Dict[str, list], pandas.DataFrame]): source containing the data to make predictions. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . :param: split: (str, default= 'full' ): if the input dataset contains a split column, this parameter indicates which split of the data to use. Possible values are 'full' , 'training' , 'validation' , 'test' . batch_size (int, default: 128): size of batch to use when making predictions. Return return (list): list of collected tensors. collect_weights \u00b6 collect_weights ( tensor_names = None ) Load a pre-trained model and collect the tensors with a specific name. Inputs tensor_names (list, default: None ): List of tensor names to collect weights Return return (list): List of tensors create_model \u00b6 create_model ( config , random_seed = 42 ) Instantiates Encoder-Combiner-Decoder (ECD) object. Inputs config (dict): Ludwig config random_seed (int, default: ludwig default random seed): Random seed used for weights initialization, splits and any other random function. Return return (ludwig.models.ECD): Instance of the Ludwig model object. evaluate \u00b6 ludwig . evaluate ( dataset = None , data_format = None , split = 'full' , batch_size = None , skip_save_unprocessed_output = True , skip_save_predictions = True , skip_save_eval_stats = True , collect_predictions = False , collect_overall_stats = False , output_directory = 'results' , return_type =< class ' pandas . core . frame . DataFrame '> ) This function is used to predict the output variables given the input variables using the trained model and compute test statistics like performance measures, confusion matrices and the like. Inputs dataset (Union[str, dict, pandas.DataFrame]): source containing the entire dataset to be evaluated. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . :param: split: (str, default= 'full' ): if the input dataset contains a split column, this parameter indicates which split of the data to use. Possible values are 'full' , 'training' , 'validation' , 'test' . batch_size (int, default: None): size of batch to use when making predictions. Defaults to model config eval_batch_size skip_save_unprocessed_output (bool, default: True ): if this parameter is False , predictions and their probabilities are saved in both raw unprocessed numpy files containing tensors and as postprocessed CSV files (one for each output feature). If this parameter is True , only the CSV ones are saved and the numpy ones are skipped. skip_save_predictions (bool, default: True ): skips saving test predictions CSV files. skip_save_eval_stats (bool, default: True ): skips saving test statistics JSON file. collect_predictions (bool, default: False ): if True collects post-processed predictions during eval. collect_overall_stats (bool, default: False): if True collects overall stats during eval. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. return_type (Union[str, dict, pd.DataFrame], default: pandas.DataFrame): indicates the format to of the returned predictions. Return return ( evaluation_statistics , predictions , output_directory ): evaluation_statistics dictionary containing evaluation performance statistics, postprocess_predictions contains predicted values, output_directory is location where results are stored. experiment \u00b6 experiment ( dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , experiment_name = 'experiment' , model_name = 'run' , model_load_path = None , model_resume_path = None , eval_split = 'test' , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = False , skip_save_unprocessed_output = False , skip_save_predictions = False , skip_save_eval_stats = False , skip_collect_predictions = False , skip_collect_overall_stats = False , output_directory = 'results' , random_seed = 42 ) Trains a model on a dataset's training and validation splits and uses it to predict on the test split. It saves the trained model and the statistics of training and testing. Inputs dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set (Union[str, dict, pandas.DataFrame], default: None ): source containing training data. validation_set (Union[str, dict, pandas.DataFrame], default: None ): source containing validation data. test_set (Union[str, dict, pandas.DataFrame], default: None ): source containing test data. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . experiment_name (str, default: 'experiment' ): name for the experiment. model_name (str, default: 'run' ): name of the model that is being used. model_load_path (str, default: None ): if this is specified the loaded model will be used as initialization (useful for transfer learning). model_resume_path (str, default: None ): resumes training of the model from the path specified. The config is restored. In addition to config, training statistics and loss for epoch and the state of the optimizer are restored such that training can be effectively continued from a previously interrupted training process. eval_split (str, default: test ): split on which to perform evaluation. Valid values are training , validation and test . skip_save_training_description (bool, default: False ): disables saving the description JSON file. skip_save_training_statistics (bool, default: False ): disables saving training statistics JSON file. skip_save_model (bool, default: False ): disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it, but the model will not be loadable later on and the returned model will have the weights obtained at the end of training, instead of the weights of the epoch with the best validation performance. skip_save_progress (bool, default: False ): disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on. skip_save_log (bool, default: False ): disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed. skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. skip_save_unprocessed_output (bool, default: False ): by default predictions and their probabilities are saved in both raw unprocessed numpy files containing tensors and as postprocessed CSV files (one for each output feature). If this parameter is True, only the CSV ones are saved and the numpy ones are skipped. skip_save_predictions (bool, default: False ): skips saving test predictions CSV files skip_save_eval_stats (bool, default: False ): skips saving test statistics JSON file skip_collect_predictions (bool, default: False ): skips collecting post-processed predictions during eval. skip_collect_overall_stats (bool, default: False ): skips collecting overall stats during eval. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. random_seed (int: default: 42): random seed used for weights initialization, splits and any other random function. Return return (Tuple[dict, dict, tuple, str)): (evaluation_statistics, training_statistics, preprocessed_data, output_directory) evaluation_statistics dictionary with evaluation performance statistics on the test_set, training_statistics is a nested dictionary of dataset -> feature_name -> metric_name -> List of metrics. Each metric corresponds to each training checkpoint. preprocessed_data tuple containing preprocessed (training_set, validation_set, test_set) , output_directory filepath string to where results are stored. load \u00b6 load ( model_dir , logging_level = 40 , backend = None , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , callbacks = None ) This function allows for loading pretrained models. Inputs model_dir (str): path to the directory containing the model. If the model was trained by the train or experiment command, the model is in results_dir/experiment_dir/model . logging_level (int, default: 40): log level that will be sent to stderr. backend (Union[Backend, str]): Backend or string name of backend to use to execute preprocessing / training steps. gpus (Union[str, int, List[int]], default: None ): GPUs to use (it uses the same syntax of CUDA_VISIBLE_DEVICES) gpu_memory_limit (int: default: None ): maximum memory in MB to allocate per GPU device. allow_parallel_threads (bool, default: True ): allow Torch to use multithreading parallelism to improve performance at the cost of determinism. callbacks (list, default: None ): a list of ludwig.callbacks.Callback objects that provide hooks into the Ludwig pipeline. Return return (LudwigModel): a LudwigModel object Example usage ludwig_model = LudwigModel . load ( model_dir ) load_weights \u00b6 load_weights ( model_dir ) Loads weights from a pre-trained model. Inputs model_dir (str): filepath string to location of a pre-trained model Return return ( Non): None` Example usage ludwig_model . load_weights ( model_dir ) predict \u00b6 ludwig . predict ( dataset = None , data_format = None , split = 'full' , batch_size = 128 , skip_save_unprocessed_output = True , skip_save_predictions = True , output_directory = 'results' , return_type =< class ' pandas . core . frame . DataFrame '>, callbacks = None ) Using a trained model, make predictions from the provided dataset. Inputs dataset (Union[str, dict, pandas.DataFrame]): source containing the entire dataset to be evaluated. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . :param: split: (str, default= 'full' ): if the input dataset contains a split column, this parameter indicates which split of the data to use. Possible values are 'full' , 'training' , 'validation' , 'test' . batch_size (int, default: 128): size of batch to use when making predictions. skip_save_unprocessed_output (bool, default: True ): if this parameter is False , predictions and their probabilities are saved in both raw unprocessed numpy files containing tensors and as postprocessed CSV files (one for each output feature). If this parameter is True , only the CSV ones are saved and the numpy ones are skipped. skip_save_predictions (bool, default: True ): skips saving test predictions CSV files. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. return_type (Union[str, dict, pandas.DataFrame], default: pd.DataFrame): indicates the format of the returned predictions. callbacks (Optional[List[Callback]], default: None): optional list of callbacks to use during this predict operation. Any callbacks already registered to the model will be preserved. Return return (Tuple[Union[dict, pd.DataFrame], str]) (predictions, output_directory): predictions predictions from the provided dataset, output_directory filepath string to where data was stored. preprocess \u00b6 preprocess ( dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , skip_save_processed_input = True , random_seed = 42 ) This function is used to preprocess data. Inputs dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set (Union[str, dict, pandas.DataFrame], default: None ): source containing training data. validation_set (Union[str, dict, pandas.DataFrame], default: None ): source containing validation data. test_set (Union[str, dict, pandas.DataFrame], default: None ): source containing test data. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. random_seed (int, default: 42 ): a random seed that will be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling Return return (Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, Dict]): tuple containing (proc_training_set, proc_validation_set, proc_test_set, training_set_metadata) . save \u00b6 save ( save_path ) This function allows to save models on disk. Inputs save_path (str): path to the directory where the model is going to be saved. Both a JSON file containing the model architecture hyperparameters and checkpoints files containing model weights will be saved. Return return (None): None Example usage ludwig_model . save ( save_path ) save_config \u00b6 save_config ( save_path ) Save config to specified location. Inputs save_path (str): filepath string to save config as a JSON file. Return return ( None): None` save_torchscript \u00b6 save_torchscript ( save_path , model_only = False ) Saves the Torchscript model to disk. set_logging_level \u00b6 set_logging_level ( logging_level ) Sets level for log messages. Inputs logging_level (int): Set/Update the logging level. Use logging constants like logging.DEBUG , logging.INFO and logging.ERROR . Return return ( None): None` to_torchscript \u00b6 to_torchscript ( model_only = False ) Converts the trained LudwigModule, including preprocessing and postprocessing, to Torchscript. The scripted module takes in a Dict[str, Union[List[str], Tensor]] as input. More specifically, for every input feature, we provide either a Tensor of batch_size inputs, a list of Tensors batch_size in length, or a list of strings batch_size in length. Note that the dimensions of all Tensors and lengths of all lists must match. Similarly, the output will be a dictionary of dictionaries, where each feature has its own dictionary of outputs. The outputs will be a list of strings for predictions with string types, while other outputs will be tensors of varying dimensions for probabilities, logits, etc. Args: model_only (bool, optional): If True, only the ECD model will be converted to Torchscript. Else, preprocessing and postprocessing will also be converted to Torchscript. train \u00b6 train ( dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , experiment_name = 'api_experiment' , model_name = 'run' , model_resume_path = None , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = False , output_directory = 'results' , random_seed = 42 ) This function is used to perform a full training of the model on the specified dataset. During training if the skip parameters are False the model and statistics will be saved in a directory [output_dir]/[experiment_name]_[model_name]_n where all variables are resolved to user specified ones and n is an increasing number starting from 0 used to differentiate among repeated runs. Inputs dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set (Union[str, dict, pandas.DataFrame], default: None ): source containing training data. validation_set (Union[str, dict, pandas.DataFrame], default: None ): source containing validation data. test_set (Union[str, dict, pandas.DataFrame], default: None ): source containing test data. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . experiment_name (str, default: 'experiment' ): name for the experiment. model_name (str, default: 'run' ): name of the model that is being used. model_resume_path (str, default: None ): resumes training of the model from the path specified. The config is restored. In addition to config, training statistics, loss for each epoch and the state of the optimizer are restored such that training can be effectively continued from a previously interrupted training process. skip_save_training_description (bool, default: False ): disables saving the description JSON file. skip_save_training_statistics (bool, default: False ): disables saving training statistics JSON file. skip_save_model (bool, default: False ): disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it, but the model will not be loadable later on and the returned model will have the weights obtained at the end of training, instead of the weights of the epoch with the best validation performance. skip_save_progress (bool, default: False ): disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on. skip_save_log (bool, default: False ): disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed. skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. random_seed (int, default: 42 ): a random seed that will be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling Return return (Tuple[Dict, Union[Dict, pd.DataFrame], str]): tuple containing (training_statistics, preprocessed_data, output_directory) . training_statistics is a nested dictionary of dataset -> feature_name -> metric_name -> List of metrics. Each metric corresponds to each training checkpoint. preprocessed_data is the tuple containing these three data sets (training_set, validation_set, test_set) . output_directory filepath to where training results are stored. train_online \u00b6 train_online ( dataset , training_set_metadata = None , data_format = 'auto' , random_seed = 42 ) Performs one epoch of training of the model on dataset . Inputs dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . random_seed (int, default: 42 ): a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling Return return (None): None Module functions \u00b6 kfold_cross_validate \u00b6 ludwig . api . kfold_cross_validate ( num_folds , config , dataset = None , data_format = None , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = False , skip_save_predictions = False , skip_save_eval_stats = False , skip_collect_predictions = False , skip_collect_overall_stats = False , output_directory = 'results' , random_seed = 42 , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , backend = None , logging_level = 20 ) Performs k-fold cross validation and returns result data structures. Inputs num_folds (int): number of folds to create for the cross-validation config (Union[dict, str]): model specification required to build a model. Parameter may be a dictionary or string specifying the file path to a yaml configuration file. Refer to the User Guide for details. dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used for k_fold processing. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . Currently hdf5 format is not supported for k_fold cross validation. skip_save_training_description (bool, default: False ): disables saving the description JSON file. skip_save_training_statistics (bool, default: False ): disables saving training statistics JSON file. skip_save_model (bool, default: False ): disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it, but the model will not be loadable later on and the returned model will have the weights obtained at the end of training, instead of the weights of the epoch with the best validation performance. skip_save_progress (bool, default: False ): disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on. skip_save_log (bool, default: False ): disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed. skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. skip_save_predictions (bool, default: False ): skips saving test predictions CSV files. skip_save_eval_stats (bool, default: False ): skips saving test statistics JSON file. skip_collect_predictions (bool, default: False ): skips collecting post-processed predictions during eval. skip_collect_overall_stats (bool, default: False ): skips collecting overall stats during eval. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. random_seed (int, default: 42 ): Random seed used for weights initialization, splits and any other random function. gpus (list, default: None ): list of GPUs that are available for training. gpu_memory_limit (int, default: None ): maximum memory in MB to allocate per GPU device. allow_parallel_threads (bool, default: True ): allow Torch to use multithreading parallelism to improve performance at the cost of determinism. backend (Union[Backend, str]): Backend or string name of backend to use to execute preprocessing / training steps. logging_level (int, default: INFO): log level to send to stderr. Return return (tuple(kfold_cv_statistics, kfold_split_indices), dict): a tuple of dictionaries kfold_cv_statistics : contains metrics from cv run. kfold_split_indices : indices to split training data into training fold and test fold. hyperopt \u00b6 ludwig . hyperopt . run . hyperopt ( config , dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , experiment_name = 'hyperopt' , model_name = 'run' , resume = None , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = True , skip_save_unprocessed_output = False , skip_save_predictions = False , skip_save_eval_stats = False , skip_save_hyperopt_statistics = False , output_directory = 'results' , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , callbacks = None , backend = None , random_seed = 42 , hyperopt_log_verbosity = 3 ) This method performs an hyperparameter optimization. Inputs config (Union[str, dict]): config which defines the different parameters of the model, features, preprocessing and training. If str , filepath to yaml configuration file. dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set (Union[str, dict, pandas.DataFrame], default: None ): source containing training data. validation_set (Union[str, dict, pandas.DataFrame], default: None ): source containing validation data. test_set (Union[str, dict, pandas.DataFrame], default: None ): source containing test data. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . experiment_name (str, default: 'experiment' ): name for the experiment. model_name (str, default: 'run' ): name of the model that is being used. resume (bool): If true, continue hyperopt from the state of the previous run in the output directory with the same experiment name. If false, will create new trials, ignoring any previous state, even if they exist in the output_directory. By default, will attempt to resume if there is already an existing experiment with the same name, and will create new trials if not. skip_save_training_description (bool, default: False ): disables saving the description JSON file. skip_save_training_statistics (bool, default: False ): disables saving training statistics JSON file. skip_save_model (bool, default: False ): disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it, but the model will not be loadable later on and the returned model will have the weights obtained at the end of training, instead of the weights of the epoch with the best validation performance. skip_save_progress (bool, default: False ): disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on. skip_save_log (bool, default: False ): disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed. skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. skip_save_unprocessed_output (bool, default: False ): by default predictions and their probabilities are saved in both raw unprocessed numpy files containing tensors and as postprocessed CSV files (one for each output feature). If this parameter is True, only the CSV ones are saved and the numpy ones are skipped. skip_save_predictions (bool, default: False ): skips saving test predictions CSV files. skip_save_eval_stats (bool, default: False ): skips saving test statistics JSON file. skip_save_hyperopt_statistics (bool, default: False ): skips saving hyperopt stats file. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. gpus (list, default: None ): list of GPUs that are available for training. gpu_memory_limit (int, default: None ): maximum memory in MB to allocate per GPU device. allow_parallel_threads (bool, default: True ): allow TensorFlow to use multithreading parallelism to improve performance at the cost of determinism. callbacks (list, default: None ): a list of ludwig.callbacks.Callback objects that provide hooks into the Ludwig pipeline. backend (Union[Backend, str]): Backend or string name of backend to use to execute preprocessing / training steps. random_seed (int: default: 42): random seed used for weights initialization, splits and any other random function. hyperopt_log_verbosity (int: default: 3): controls verbosity of ray tune log messages. Valid values: 0 = silent, 1 = only status updates, 2 = status and brief trial results, 3 = status and detailed trial results. Return return (List[dict]): List of results for each trial, ordered by descending performance on the target metric.","title":"LudwigModel"},{"location":"user_guide/api/LudwigModel/#ludwigmodel-class-source","text":"ludwig . api . LudwigModel ( config , logging_level = 40 , backend = None , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , callbacks = None ) Class that allows access to high level Ludwig functionalities. Inputs config (Union[str, dict]): in-memory representation of config or string path to a YAML config file. logging_level (int): Log level that will be sent to stderr. backend (Union[Backend, str]): Backend or string name of backend to use to execute preprocessing / training steps. gpus (Union[str, int, List[int]], default: None ): GPUs to use (it uses the same syntax of CUDA_VISIBLE_DEVICES) gpu_memory_limit (int: default: None ): maximum memory in MB to allocate per GPU device. allow_parallel_threads (bool, default: True ): allow Torch to use multithreading parallelism to improve performance at the cost of determinism. Example usage: from ludwig.api import LudwigModel Train a model: config = { ... } ludwig_model = LudwigModel ( config ) train_stats , _ , _ = ludwig_model . train ( dataset = file_path ) or train_stats , _ , _ = ludwig_model . train ( dataset = dataframe ) If you have already trained a model you can load it and use it to predict ludwig_model = LudwigModel . load ( model_dir ) Predict: predictions , _ = ludwig_model . predict ( dataset = file_path ) or predictions , _ = ludwig_model . predict ( dataset = dataframe ) Evaluation: eval_stats , _ , _ = ludwig_model . evaluate ( dataset = file_path ) or eval_stats , _ , _ = ludwig_model . evaluate ( dataset = dataframe )","title":"LudwigModel class [source]"},{"location":"user_guide/api/LudwigModel/#ludwigmodel-methods","text":"","title":"LudwigModel methods"},{"location":"user_guide/api/LudwigModel/#collect_activations","text":"collect_activations ( layer_names , dataset , data_format = None , split = 'full' , batch_size = 128 , debug = False ) Loads a pre-trained model model and input data to collect the values of the activations contained in the tensors. Inputs layer_names (list): list of strings for layer names in the model to collect activations. dataset (Union[str, Dict[str, list], pandas.DataFrame]): source containing the data to make predictions. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . :param: split: (str, default= 'full' ): if the input dataset contains a split column, this parameter indicates which split of the data to use. Possible values are 'full' , 'training' , 'validation' , 'test' . batch_size (int, default: 128): size of batch to use when making predictions. Return return (list): list of collected tensors.","title":"collect_activations"},{"location":"user_guide/api/LudwigModel/#collect_weights","text":"collect_weights ( tensor_names = None ) Load a pre-trained model and collect the tensors with a specific name. Inputs tensor_names (list, default: None ): List of tensor names to collect weights Return return (list): List of tensors","title":"collect_weights"},{"location":"user_guide/api/LudwigModel/#create_model","text":"create_model ( config , random_seed = 42 ) Instantiates Encoder-Combiner-Decoder (ECD) object. Inputs config (dict): Ludwig config random_seed (int, default: ludwig default random seed): Random seed used for weights initialization, splits and any other random function. Return return (ludwig.models.ECD): Instance of the Ludwig model object.","title":"create_model"},{"location":"user_guide/api/LudwigModel/#evaluate","text":"ludwig . evaluate ( dataset = None , data_format = None , split = 'full' , batch_size = None , skip_save_unprocessed_output = True , skip_save_predictions = True , skip_save_eval_stats = True , collect_predictions = False , collect_overall_stats = False , output_directory = 'results' , return_type =< class ' pandas . core . frame . DataFrame '> ) This function is used to predict the output variables given the input variables using the trained model and compute test statistics like performance measures, confusion matrices and the like. Inputs dataset (Union[str, dict, pandas.DataFrame]): source containing the entire dataset to be evaluated. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . :param: split: (str, default= 'full' ): if the input dataset contains a split column, this parameter indicates which split of the data to use. Possible values are 'full' , 'training' , 'validation' , 'test' . batch_size (int, default: None): size of batch to use when making predictions. Defaults to model config eval_batch_size skip_save_unprocessed_output (bool, default: True ): if this parameter is False , predictions and their probabilities are saved in both raw unprocessed numpy files containing tensors and as postprocessed CSV files (one for each output feature). If this parameter is True , only the CSV ones are saved and the numpy ones are skipped. skip_save_predictions (bool, default: True ): skips saving test predictions CSV files. skip_save_eval_stats (bool, default: True ): skips saving test statistics JSON file. collect_predictions (bool, default: False ): if True collects post-processed predictions during eval. collect_overall_stats (bool, default: False): if True collects overall stats during eval. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. return_type (Union[str, dict, pd.DataFrame], default: pandas.DataFrame): indicates the format to of the returned predictions. Return return ( evaluation_statistics , predictions , output_directory ): evaluation_statistics dictionary containing evaluation performance statistics, postprocess_predictions contains predicted values, output_directory is location where results are stored.","title":"evaluate"},{"location":"user_guide/api/LudwigModel/#experiment","text":"experiment ( dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , experiment_name = 'experiment' , model_name = 'run' , model_load_path = None , model_resume_path = None , eval_split = 'test' , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = False , skip_save_unprocessed_output = False , skip_save_predictions = False , skip_save_eval_stats = False , skip_collect_predictions = False , skip_collect_overall_stats = False , output_directory = 'results' , random_seed = 42 ) Trains a model on a dataset's training and validation splits and uses it to predict on the test split. It saves the trained model and the statistics of training and testing. Inputs dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set (Union[str, dict, pandas.DataFrame], default: None ): source containing training data. validation_set (Union[str, dict, pandas.DataFrame], default: None ): source containing validation data. test_set (Union[str, dict, pandas.DataFrame], default: None ): source containing test data. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . experiment_name (str, default: 'experiment' ): name for the experiment. model_name (str, default: 'run' ): name of the model that is being used. model_load_path (str, default: None ): if this is specified the loaded model will be used as initialization (useful for transfer learning). model_resume_path (str, default: None ): resumes training of the model from the path specified. The config is restored. In addition to config, training statistics and loss for epoch and the state of the optimizer are restored such that training can be effectively continued from a previously interrupted training process. eval_split (str, default: test ): split on which to perform evaluation. Valid values are training , validation and test . skip_save_training_description (bool, default: False ): disables saving the description JSON file. skip_save_training_statistics (bool, default: False ): disables saving training statistics JSON file. skip_save_model (bool, default: False ): disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it, but the model will not be loadable later on and the returned model will have the weights obtained at the end of training, instead of the weights of the epoch with the best validation performance. skip_save_progress (bool, default: False ): disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on. skip_save_log (bool, default: False ): disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed. skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. skip_save_unprocessed_output (bool, default: False ): by default predictions and their probabilities are saved in both raw unprocessed numpy files containing tensors and as postprocessed CSV files (one for each output feature). If this parameter is True, only the CSV ones are saved and the numpy ones are skipped. skip_save_predictions (bool, default: False ): skips saving test predictions CSV files skip_save_eval_stats (bool, default: False ): skips saving test statistics JSON file skip_collect_predictions (bool, default: False ): skips collecting post-processed predictions during eval. skip_collect_overall_stats (bool, default: False ): skips collecting overall stats during eval. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. random_seed (int: default: 42): random seed used for weights initialization, splits and any other random function. Return return (Tuple[dict, dict, tuple, str)): (evaluation_statistics, training_statistics, preprocessed_data, output_directory) evaluation_statistics dictionary with evaluation performance statistics on the test_set, training_statistics is a nested dictionary of dataset -> feature_name -> metric_name -> List of metrics. Each metric corresponds to each training checkpoint. preprocessed_data tuple containing preprocessed (training_set, validation_set, test_set) , output_directory filepath string to where results are stored.","title":"experiment"},{"location":"user_guide/api/LudwigModel/#load","text":"load ( model_dir , logging_level = 40 , backend = None , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , callbacks = None ) This function allows for loading pretrained models. Inputs model_dir (str): path to the directory containing the model. If the model was trained by the train or experiment command, the model is in results_dir/experiment_dir/model . logging_level (int, default: 40): log level that will be sent to stderr. backend (Union[Backend, str]): Backend or string name of backend to use to execute preprocessing / training steps. gpus (Union[str, int, List[int]], default: None ): GPUs to use (it uses the same syntax of CUDA_VISIBLE_DEVICES) gpu_memory_limit (int: default: None ): maximum memory in MB to allocate per GPU device. allow_parallel_threads (bool, default: True ): allow Torch to use multithreading parallelism to improve performance at the cost of determinism. callbacks (list, default: None ): a list of ludwig.callbacks.Callback objects that provide hooks into the Ludwig pipeline. Return return (LudwigModel): a LudwigModel object Example usage ludwig_model = LudwigModel . load ( model_dir )","title":"load"},{"location":"user_guide/api/LudwigModel/#load_weights","text":"load_weights ( model_dir ) Loads weights from a pre-trained model. Inputs model_dir (str): filepath string to location of a pre-trained model Return return ( Non): None` Example usage ludwig_model . load_weights ( model_dir )","title":"load_weights"},{"location":"user_guide/api/LudwigModel/#predict","text":"ludwig . predict ( dataset = None , data_format = None , split = 'full' , batch_size = 128 , skip_save_unprocessed_output = True , skip_save_predictions = True , output_directory = 'results' , return_type =< class ' pandas . core . frame . DataFrame '>, callbacks = None ) Using a trained model, make predictions from the provided dataset. Inputs dataset (Union[str, dict, pandas.DataFrame]): source containing the entire dataset to be evaluated. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . :param: split: (str, default= 'full' ): if the input dataset contains a split column, this parameter indicates which split of the data to use. Possible values are 'full' , 'training' , 'validation' , 'test' . batch_size (int, default: 128): size of batch to use when making predictions. skip_save_unprocessed_output (bool, default: True ): if this parameter is False , predictions and their probabilities are saved in both raw unprocessed numpy files containing tensors and as postprocessed CSV files (one for each output feature). If this parameter is True , only the CSV ones are saved and the numpy ones are skipped. skip_save_predictions (bool, default: True ): skips saving test predictions CSV files. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. return_type (Union[str, dict, pandas.DataFrame], default: pd.DataFrame): indicates the format of the returned predictions. callbacks (Optional[List[Callback]], default: None): optional list of callbacks to use during this predict operation. Any callbacks already registered to the model will be preserved. Return return (Tuple[Union[dict, pd.DataFrame], str]) (predictions, output_directory): predictions predictions from the provided dataset, output_directory filepath string to where data was stored.","title":"predict"},{"location":"user_guide/api/LudwigModel/#preprocess","text":"preprocess ( dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , skip_save_processed_input = True , random_seed = 42 ) This function is used to preprocess data. Inputs dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set (Union[str, dict, pandas.DataFrame], default: None ): source containing training data. validation_set (Union[str, dict, pandas.DataFrame], default: None ): source containing validation data. test_set (Union[str, dict, pandas.DataFrame], default: None ): source containing test data. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. random_seed (int, default: 42 ): a random seed that will be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling Return return (Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, Dict]): tuple containing (proc_training_set, proc_validation_set, proc_test_set, training_set_metadata) .","title":"preprocess"},{"location":"user_guide/api/LudwigModel/#save","text":"save ( save_path ) This function allows to save models on disk. Inputs save_path (str): path to the directory where the model is going to be saved. Both a JSON file containing the model architecture hyperparameters and checkpoints files containing model weights will be saved. Return return (None): None Example usage ludwig_model . save ( save_path )","title":"save"},{"location":"user_guide/api/LudwigModel/#save_config","text":"save_config ( save_path ) Save config to specified location. Inputs save_path (str): filepath string to save config as a JSON file. Return return ( None): None`","title":"save_config"},{"location":"user_guide/api/LudwigModel/#save_torchscript","text":"save_torchscript ( save_path , model_only = False ) Saves the Torchscript model to disk.","title":"save_torchscript"},{"location":"user_guide/api/LudwigModel/#set_logging_level","text":"set_logging_level ( logging_level ) Sets level for log messages. Inputs logging_level (int): Set/Update the logging level. Use logging constants like logging.DEBUG , logging.INFO and logging.ERROR . Return return ( None): None`","title":"set_logging_level"},{"location":"user_guide/api/LudwigModel/#to_torchscript","text":"to_torchscript ( model_only = False ) Converts the trained LudwigModule, including preprocessing and postprocessing, to Torchscript. The scripted module takes in a Dict[str, Union[List[str], Tensor]] as input. More specifically, for every input feature, we provide either a Tensor of batch_size inputs, a list of Tensors batch_size in length, or a list of strings batch_size in length. Note that the dimensions of all Tensors and lengths of all lists must match. Similarly, the output will be a dictionary of dictionaries, where each feature has its own dictionary of outputs. The outputs will be a list of strings for predictions with string types, while other outputs will be tensors of varying dimensions for probabilities, logits, etc. Args: model_only (bool, optional): If True, only the ECD model will be converted to Torchscript. Else, preprocessing and postprocessing will also be converted to Torchscript.","title":"to_torchscript"},{"location":"user_guide/api/LudwigModel/#train","text":"train ( dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , experiment_name = 'api_experiment' , model_name = 'run' , model_resume_path = None , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = False , output_directory = 'results' , random_seed = 42 ) This function is used to perform a full training of the model on the specified dataset. During training if the skip parameters are False the model and statistics will be saved in a directory [output_dir]/[experiment_name]_[model_name]_n where all variables are resolved to user specified ones and n is an increasing number starting from 0 used to differentiate among repeated runs. Inputs dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set (Union[str, dict, pandas.DataFrame], default: None ): source containing training data. validation_set (Union[str, dict, pandas.DataFrame], default: None ): source containing validation data. test_set (Union[str, dict, pandas.DataFrame], default: None ): source containing test data. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . experiment_name (str, default: 'experiment' ): name for the experiment. model_name (str, default: 'run' ): name of the model that is being used. model_resume_path (str, default: None ): resumes training of the model from the path specified. The config is restored. In addition to config, training statistics, loss for each epoch and the state of the optimizer are restored such that training can be effectively continued from a previously interrupted training process. skip_save_training_description (bool, default: False ): disables saving the description JSON file. skip_save_training_statistics (bool, default: False ): disables saving training statistics JSON file. skip_save_model (bool, default: False ): disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it, but the model will not be loadable later on and the returned model will have the weights obtained at the end of training, instead of the weights of the epoch with the best validation performance. skip_save_progress (bool, default: False ): disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on. skip_save_log (bool, default: False ): disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed. skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. random_seed (int, default: 42 ): a random seed that will be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling Return return (Tuple[Dict, Union[Dict, pd.DataFrame], str]): tuple containing (training_statistics, preprocessed_data, output_directory) . training_statistics is a nested dictionary of dataset -> feature_name -> metric_name -> List of metrics. Each metric corresponds to each training checkpoint. preprocessed_data is the tuple containing these three data sets (training_set, validation_set, test_set) . output_directory filepath to where training results are stored.","title":"train"},{"location":"user_guide/api/LudwigModel/#train_online","text":"train_online ( dataset , training_set_metadata = None , data_format = 'auto' , random_seed = 42 ) Performs one epoch of training of the model on dataset . Inputs dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . random_seed (int, default: 42 ): a random seed that is going to be used anywhere there is a call to a random number generator: data splitting, parameter initialization and training set shuffling Return return (None): None","title":"train_online"},{"location":"user_guide/api/LudwigModel/#module-functions","text":"","title":"Module functions"},{"location":"user_guide/api/LudwigModel/#kfold_cross_validate","text":"ludwig . api . kfold_cross_validate ( num_folds , config , dataset = None , data_format = None , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = False , skip_save_predictions = False , skip_save_eval_stats = False , skip_collect_predictions = False , skip_collect_overall_stats = False , output_directory = 'results' , random_seed = 42 , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , backend = None , logging_level = 20 ) Performs k-fold cross validation and returns result data structures. Inputs num_folds (int): number of folds to create for the cross-validation config (Union[dict, str]): model specification required to build a model. Parameter may be a dictionary or string specifying the file path to a yaml configuration file. Refer to the User Guide for details. dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used for k_fold processing. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . Currently hdf5 format is not supported for k_fold cross validation. skip_save_training_description (bool, default: False ): disables saving the description JSON file. skip_save_training_statistics (bool, default: False ): disables saving training statistics JSON file. skip_save_model (bool, default: False ): disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it, but the model will not be loadable later on and the returned model will have the weights obtained at the end of training, instead of the weights of the epoch with the best validation performance. skip_save_progress (bool, default: False ): disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on. skip_save_log (bool, default: False ): disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed. skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. skip_save_predictions (bool, default: False ): skips saving test predictions CSV files. skip_save_eval_stats (bool, default: False ): skips saving test statistics JSON file. skip_collect_predictions (bool, default: False ): skips collecting post-processed predictions during eval. skip_collect_overall_stats (bool, default: False ): skips collecting overall stats during eval. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. random_seed (int, default: 42 ): Random seed used for weights initialization, splits and any other random function. gpus (list, default: None ): list of GPUs that are available for training. gpu_memory_limit (int, default: None ): maximum memory in MB to allocate per GPU device. allow_parallel_threads (bool, default: True ): allow Torch to use multithreading parallelism to improve performance at the cost of determinism. backend (Union[Backend, str]): Backend or string name of backend to use to execute preprocessing / training steps. logging_level (int, default: INFO): log level to send to stderr. Return return (tuple(kfold_cv_statistics, kfold_split_indices), dict): a tuple of dictionaries kfold_cv_statistics : contains metrics from cv run. kfold_split_indices : indices to split training data into training fold and test fold.","title":"kfold_cross_validate"},{"location":"user_guide/api/LudwigModel/#hyperopt","text":"ludwig . hyperopt . run . hyperopt ( config , dataset = None , training_set = None , validation_set = None , test_set = None , training_set_metadata = None , data_format = None , experiment_name = 'hyperopt' , model_name = 'run' , resume = None , skip_save_training_description = False , skip_save_training_statistics = False , skip_save_model = False , skip_save_progress = False , skip_save_log = False , skip_save_processed_input = True , skip_save_unprocessed_output = False , skip_save_predictions = False , skip_save_eval_stats = False , skip_save_hyperopt_statistics = False , output_directory = 'results' , gpus = None , gpu_memory_limit = None , allow_parallel_threads = True , callbacks = None , backend = None , random_seed = 42 , hyperopt_log_verbosity = 3 ) This method performs an hyperparameter optimization. Inputs config (Union[str, dict]): config which defines the different parameters of the model, features, preprocessing and training. If str , filepath to yaml configuration file. dataset (Union[str, dict, pandas.DataFrame], default: None ): source containing the entire dataset to be used in the experiment. If it has a split column, it will be used for splitting (0 for train, 1 for validation, 2 for test), otherwise the dataset will be randomly split. training_set (Union[str, dict, pandas.DataFrame], default: None ): source containing training data. validation_set (Union[str, dict, pandas.DataFrame], default: None ): source containing validation data. test_set (Union[str, dict, pandas.DataFrame], default: None ): source containing test data. training_set_metadata (Union[str, dict], default: None ): metadata JSON file or loaded metadata. Intermediate preprocessed structure containing the mappings of the input dataset created the first time an input file is used in the same directory with the same name and a '.meta.json' extension. data_format (str, default: None ): format to interpret data sources. Will be inferred automatically if not specified. Valid formats are 'auto' , 'csv' , 'df' , 'dict' , 'excel' , 'feather' , 'fwf' , 'hdf5' (cache file produced during previous training), 'html' (file containing a single HTML <table> ), 'json' , 'jsonl' , 'parquet' , 'pickle' (pickled Pandas DataFrame), 'sas' , 'spss' , 'stata' , 'tsv' . experiment_name (str, default: 'experiment' ): name for the experiment. model_name (str, default: 'run' ): name of the model that is being used. resume (bool): If true, continue hyperopt from the state of the previous run in the output directory with the same experiment name. If false, will create new trials, ignoring any previous state, even if they exist in the output_directory. By default, will attempt to resume if there is already an existing experiment with the same name, and will create new trials if not. skip_save_training_description (bool, default: False ): disables saving the description JSON file. skip_save_training_statistics (bool, default: False ): disables saving training statistics JSON file. skip_save_model (bool, default: False ): disables saving model weights and hyperparameters each time the model improves. By default Ludwig saves model weights after each epoch the validation metric improves, but if the model is really big that can be time consuming. If you do not want to keep the weights and just find out what performance a model can get with a set of hyperparameters, use this parameter to skip it, but the model will not be loadable later on and the returned model will have the weights obtained at the end of training, instead of the weights of the epoch with the best validation performance. skip_save_progress (bool, default: False ): disables saving progress each epoch. By default Ludwig saves weights and stats after each epoch for enabling resuming of training, but if the model is really big that can be time consuming and will uses twice as much space, use this parameter to skip it, but training cannot be resumed later on. skip_save_log (bool, default: False ): disables saving TensorBoard logs. By default Ludwig saves logs for the TensorBoard, but if it is not needed turning it off can slightly increase the overall speed. skip_save_processed_input (bool, default: False ): if input dataset is provided it is preprocessed and cached by saving an HDF5 and JSON files to avoid running the preprocessing again. If this parameter is False , the HDF5 and JSON file are not saved. skip_save_unprocessed_output (bool, default: False ): by default predictions and their probabilities are saved in both raw unprocessed numpy files containing tensors and as postprocessed CSV files (one for each output feature). If this parameter is True, only the CSV ones are saved and the numpy ones are skipped. skip_save_predictions (bool, default: False ): skips saving test predictions CSV files. skip_save_eval_stats (bool, default: False ): skips saving test statistics JSON file. skip_save_hyperopt_statistics (bool, default: False ): skips saving hyperopt stats file. output_directory (str, default: 'results' ): the directory that will contain the training statistics, TensorBoard logs, the saved model and the training progress files. gpus (list, default: None ): list of GPUs that are available for training. gpu_memory_limit (int, default: None ): maximum memory in MB to allocate per GPU device. allow_parallel_threads (bool, default: True ): allow TensorFlow to use multithreading parallelism to improve performance at the cost of determinism. callbacks (list, default: None ): a list of ludwig.callbacks.Callback objects that provide hooks into the Ludwig pipeline. backend (Union[Backend, str]): Backend or string name of backend to use to execute preprocessing / training steps. random_seed (int: default: 42): random seed used for weights initialization, splits and any other random function. hyperopt_log_verbosity (int: default: 3): controls verbosity of ray tune log messages. Valid values: 0 = silent, 1 = only status updates, 2 = status and brief trial results, 3 = status and detailed trial results. Return return (List[dict]): List of results for each trial, ordered by descending performance on the target metric.","title":"hyperopt"},{"location":"user_guide/api/visualization/","text":"Module functions \u00b6 learning_curves \u00b6 ludwig . visualize . learning_curves ( train_stats_per_model , output_feature_name = None , model_names = None , output_directory = None , file_format = 'pdf' , callbacks = None ) Show how model metrics change over training and validation data epochs. For each model and for each output feature and metric of the model, it produces a line plot showing how that metric changed over the course of the epochs of training on the training and validation sets. Inputs train_stats_per_model (List[dict]): list containing dictionary of training statistics per model. output_feature_name (Union[str, None ], default: None ): name of the output feature to use for the visualization. If None , use all output features. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . callbacks (list, default: None ): a list of ludwig.callbacks.Callback objects that provide hooks into the Ludwig pipeline. Return return (None): compare_performance \u00b6 ludwig . visualize . compare_performance ( test_stats_per_model , output_feature_name = None , model_names = None , output_directory = None , file_format = 'pdf' ) Produces model comparison barplot visualization for each overall metric. For each model (in the aligned lists of test_statistics and model_names) it produces bars in a bar plot, one for each overall metric available in the test_statistics file for the specified output_feature_name. Inputs test_stats_per_model (List[dict]): dictionary containing evaluation performance statistics. output_feature_name (Union[str, None ], default: None ): name of the output feature to use for the visualization. If None , use all output features. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (Non): (None) Example usage: model_a = LudwigModel ( config ) model_a . train ( dataset ) a_evaluation_stats , _ , _ = model_a . evaluate ( eval_set ) model_b = LudwigModel . load ( \"path/to/model/\" ) b_evaluation_stats , _ , _ = model_b . evaluate ( eval_set ) compare_performance ([ a_evaluation_stats , b_evaluation_stats ], model_names = [ \"A\" , \"B\" ]) compare_classifiers_performance_from_prob \u00b6 ludwig . visualize . compare_classifiers_performance_from_prob ( probabilities_per_model , ground_truth , metadata , output_feature_name , labels_limit = 0 , top_n_classes = 3 , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Produces model comparison barplot visualization from probabilities. For each model it produces bars in a bar plot, one for each overall metric computed on the fly from the probabilities of predictions for the specified model_names . Inputs probabilities_per_model (List[np.ndarray]): path to experiment probabilities file ground_truth (pd.Series): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_n_classes (List[int]): list containing the number of classes to plot. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): compare_classifiers_performance_from_pred \u00b6 ludwig . visualize . compare_classifiers_performance_from_pred ( predictions_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Produces model comparison barplot visualization from predictions. For each model it produces bars in a bar plot, one for each overall metric computed on the fly from the predictions for the specified model_names . Inputs predictions_per_model (List[str]): path to experiment predictions file. ground_truth (pd.Series): ground truth values metadata (dict): feature metadata dictionary. output_feature_name (str): name of the output feature to visualize. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): compare_classifiers_performance_subset \u00b6 ludwig . visualize . compare_classifiers_performance_subset ( probabilities_per_model , ground_truth , metadata , output_feature_name , top_n_classes , labels_limit , subset , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Produces model comparison barplot visualization from train subset. For each model it produces bars in a bar plot, one for each overall metric computed on the fly from the probabilities predictions for the specified model_names , considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_n_classes (List[int]): list containing the number of classes to plot. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. subset (str): string specifying type of subset filtering. Valid values are ground_truth or predictions . model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): compare_classifiers_performance_changing_k \u00b6 ludwig . visualize . compare_classifiers_performance_changing_k ( probabilities_per_model , ground_truth , metadata , output_feature_name , top_k , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Produce lineplot that show Hits@K metric while k goes from 1 to top_k . For each model it produces a line plot that shows the Hits@K metric (that counts a prediction as correct if the model produces it among the first k) while changing k from 1 to top_k for the specified output_feature_name . Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_k (int): number of elements in the ranklist to consider. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): compare_classifiers_multiclass_multimetric \u00b6 ludwig . visualize . compare_classifiers_multiclass_multimetric ( test_stats_per_model , metadata , output_feature_name , top_n_classes , model_names = None , output_directory = None , file_format = 'pdf' ) Show the precision, recall and F1 of the model for the specified output_feature_name. For each model it produces four plots that show the precision, recall and F1 of the model on several classes for the specified output_feature_name. Inputs test_stats_per_model (List[dict]): list containing dictionary of evaluation performance statistics metadata (dict): intermediate preprocess structure created during training containing the mappings of the input dataset. output_feature_name (Union[str, None ]): name of the output feature to use for the visualization. If None , use all output features. top_n_classes (List[int]): list containing the number of classes to plot. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None): compare_classifiers_predictions \u00b6 ludwig . visualize . compare_classifiers_predictions ( predictions_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show two models comparison of their output_feature_name predictions. Inputs predictions_per_model (List[list]): list containing the model predictions for the specified output_feature_name. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): confidence_thresholding_2thresholds_2d \u00b6 ludwig . visualize . confidence_thresholding_2thresholds_2d ( probabilities_per_model , ground_truths , metadata , threshold_output_feature_names , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' ) Show confidence threshold data vs accuracy for two output feature names. The first plot shows several semi transparent lines. They summarize the 3d surfaces displayed by confidence_thresholding_2thresholds_3d that have thresholds on the confidence of the predictions of the two threshold_output_feature_names as x and y axes and either the data coverage percentage or the accuracy as z axis. Each line represents a slice of the data coverage surface projected onto the accuracy surface. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[List[np.array], List[pd.Series]]): containing ground truth data metadata (dict): feature metadata dictionary threshold_output_feature_names (List[str]): List containing two output feature names for visualization. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None): confidence_thresholding_2thresholds_3d \u00b6 ludwig . visualize . confidence_thresholding_2thresholds_3d ( probabilities_per_model , ground_truths , metadata , threshold_output_feature_names , labels_limit , output_directory = None , file_format = 'pdf' ) Show 3d confidence threshold data vs accuracy for two output feature names. The plot shows the 3d surfaces displayed by confidence_thresholding_2thresholds_3d that have thresholds on the confidence of the predictions of the two threshold_output_feature_names as x and y axes and either the data coverage percentage or the accuracy as z axis. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[List[np.array], List[pd.Series]]): containing ground truth data metadata (dict): feature metadata dictionary threshold_output_feature_names (List[str]): List containing two output feature names for visualization. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None): confidence_thresholding \u00b6 ludwig . visualize . confidence_thresholding ( probabilities_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models accuracy and data coverage while increasing treshold. For each model it produces a pair of lines indicating the accuracy of the model and the data coverage while increasing a threshold (x axis) on the probabilities of predictions for the specified output_feature_name. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): confidence_thresholding_data_vs_acc \u00b6 ludwig . visualize . confidence_thresholding_data_vs_acc ( probabilities_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models comparison of confidence threshold data vs accuracy. For each model it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name. The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): confidence_thresholding_data_vs_acc_subset \u00b6 ludwig . visualize . confidence_thresholding_data_vs_acc_subset ( probabilities_per_model , ground_truth , metadata , output_feature_name , top_n_classes , labels_limit , subset , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models comparison of confidence threshold data vs accuracy on a subset of data. For each model it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name, considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. If the values of subset is ground_truth , then only datapoints where the ground truth class is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed. If the values of subset is predictions , then only datapoints where the the model predicts a class that is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_n_classes (List[int]): list containing the number of classes to plot. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. subset (str): string specifying type of subset filtering. Valid values are ground_truth or predictions . model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): binary_threshold_vs_metric \u00b6 ludwig . visualize . binary_threshold_vs_metric ( probabilities_per_model , ground_truth , metadata , output_feature_name , metrics , positive_label = 1 , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show confidence of the model against metric for the specified output_feature_name. For each metric specified in metrics (options are f1 , precision , recall , accuracy ), this visualization produces a line chart plotting a threshold on the confidence of the model against the metric for the specified output_feature_name. If output_feature_name is a category feature, positive_label, which is specified as the numeric encoded value, indicates the class to be considered positive class and all others will be considered negative. To figure out the association between classes and numeric encoded values check the ground_truth_metadata JSON file. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name metrics (List[str]): metrics to display ( 'f1' , 'precision' , 'recall' , 'accuracy' ). positive_label (int, default: 1 ): numeric encoded value for the positive class. model_names (List[str], default: None ): list of the names of the models to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return ( None ): roc_curves \u00b6 ludwig . visualize . roc_curves ( probabilities_per_model , ground_truth , metadata , output_feature_name , positive_label = 1 , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show the roc curves for output features in the specified models. This visualization produces a line chart plotting the roc curves for the specified output feature name. If output feature name is a category feature, positive_label indicates which is the class to be considered positive class and all the others will be considered negative. positive_label is the encoded numeric value for category classes. The numeric value can be determined by association between classes and integers captured in the training metadata JSON file. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name positive_label (int, default: 1 ): numeric encoded value for the positive class. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): roc_curves_from_test_statistics \u00b6 ludwig . visualize . roc_curves_from_test_statistics ( test_stats_per_model , output_feature_name , model_names = None , output_directory = None , file_format = 'pdf' ) Show the roc curves for the specified models output binary output_feature_name . This visualization uses output_feature_name , test_stats_per_model and model_names parameters. output_feature_name needs to be binary feature. This visualization produces a line chart plotting the roc curves for the specified output_feature_name . Inputs test_stats_per_model (List[dict]): dictionary containing evaluation performance statistics. output_feature_name (str): name of the output feature to use for the visualization. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None): calibration_1_vs_all \u00b6 ludwig . visualize . calibration_1_vs_all ( probabilities_per_model , ground_truth , metadata , output_feature_name , top_n_classes , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models probability of predictions for the specified output_feature_name. For each class or each of the k most frequent classes if top_k is specified, it produces two plots computed on the fly from the probabilities of predictions for the specified output_feature_name. The first plot is a calibration curve that shows the calibration of the predictions considering the current class to be the true one and all others to be a false one, drawing one line for each model (in the aligned lists of probabilities and model_names). The second plot shows the distributions of the predictions considering the current class to be the true one and all others to be a false one, drawing the distribution for each model (in the aligned lists of probabilities and model_names). Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_n_classes (list): List containing the number of classes to plot. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (List[str], default: None ): list of the names of the models to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize String return (None): calibration_multiclass \u00b6 ludwig . visualize . calibration_multiclass ( probabilities_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models probability of predictions for each class of the specified output_feature_name. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (List[str], default: None ): list of the names of the models to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None): confusion_matrix \u00b6 ludwig . visualize . confusion_matrix ( test_stats_per_model , metadata , output_feature_name , top_n_classes , normalize , model_names = None , output_directory = None , file_format = 'pdf' ) Show confusion matrix in the models predictions for each output_feature_name . For each model (in the aligned lists of test_statistics and model_names) it produces a heatmap of the confusion matrix in the predictions for each output_feature_name that has a confusion matrix in test_statistics. The value of top_n_classes limits the heatmap to the n most frequent classes. Inputs test_stats_per_model (List[dict]): dictionary containing evaluation performance statistics. metadata (dict): intermediate preprocess structure created during training containing the mappings of the input dataset. output_feature_name (Union[str, None ]): name of the output feature to use for the visualization. If None , use all output features. top_n_classes (List[int]): number of top classes or list containing the number of top classes to plot. normalize (bool): flag to normalize rows in confusion matrix. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None): frequency_vs_f1 \u00b6 ludwig . visualize . frequency_vs_f1 ( test_stats_per_model , metadata , output_feature_name , top_n_classes , model_names = None , output_directory = None , file_format = 'pdf' ) Show prediction statistics for the specified output_feature_name for each model. For each model (in the aligned lists of test_stats_per_model and model_names ), produces two plots statistics of predictions for the specified output_feature_name . The first plot is a line plot with one x axis representing the different classes and two vertical axes colored in orange and blue respectively. The orange one is the frequency of the class and an orange line is plotted to show the trend. The blue one is the F1 score for that class and a blue line is plotted to show the trend. The classes on the x axis are sorted by f1 score. The second plot has the same structure of the first one, but the axes are flipped and the classes on the x axis are sorted by frequency. Inputs test_stats_per_model (List[dict]): dictionary containing evaluation performance statistics. metadata (dict): intermediate preprocess structure created during training containing the mappings of the input dataset. output_feature_name (Union[str, None ]): name of the output feature to use for the visualization. If None , use all output features. top_n_classes (List[int]): number of top classes or list containing the number of top classes to plot. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None): hyperopt_report \u00b6 ludwig . visualize . hyperopt_report ( hyperopt_stats_path , output_directory = None , file_format = 'pdf' ) Produces a report about hyperparameter optimization creating one graph per hyperparameter to show the distribution of results and one additional graph of pairwise hyperparameters interactions. Inputs hyperopt_stats_path (str): path to the hyperopt results JSON file. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window. file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None): hyperopt_hiplot \u00b6 ludwig . visualize . hyperopt_hiplot ( hyperopt_stats_path , output_directory = None ) Produces a parallel coordinate plot about hyperparameter optimization creating one HTML file and optionally a CSV file to be read by hiplot. Inputs hyperopt_stats_path (str): path to the hyperopt results JSON file. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window. Return return (None):","title":"Visualization"},{"location":"user_guide/api/visualization/#module-functions","text":"","title":"Module functions"},{"location":"user_guide/api/visualization/#learning_curves","text":"ludwig . visualize . learning_curves ( train_stats_per_model , output_feature_name = None , model_names = None , output_directory = None , file_format = 'pdf' , callbacks = None ) Show how model metrics change over training and validation data epochs. For each model and for each output feature and metric of the model, it produces a line plot showing how that metric changed over the course of the epochs of training on the training and validation sets. Inputs train_stats_per_model (List[dict]): list containing dictionary of training statistics per model. output_feature_name (Union[str, None ], default: None ): name of the output feature to use for the visualization. If None , use all output features. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . callbacks (list, default: None ): a list of ludwig.callbacks.Callback objects that provide hooks into the Ludwig pipeline. Return return (None):","title":"learning_curves"},{"location":"user_guide/api/visualization/#compare_performance","text":"ludwig . visualize . compare_performance ( test_stats_per_model , output_feature_name = None , model_names = None , output_directory = None , file_format = 'pdf' ) Produces model comparison barplot visualization for each overall metric. For each model (in the aligned lists of test_statistics and model_names) it produces bars in a bar plot, one for each overall metric available in the test_statistics file for the specified output_feature_name. Inputs test_stats_per_model (List[dict]): dictionary containing evaluation performance statistics. output_feature_name (Union[str, None ], default: None ): name of the output feature to use for the visualization. If None , use all output features. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (Non): (None) Example usage: model_a = LudwigModel ( config ) model_a . train ( dataset ) a_evaluation_stats , _ , _ = model_a . evaluate ( eval_set ) model_b = LudwigModel . load ( \"path/to/model/\" ) b_evaluation_stats , _ , _ = model_b . evaluate ( eval_set ) compare_performance ([ a_evaluation_stats , b_evaluation_stats ], model_names = [ \"A\" , \"B\" ])","title":"compare_performance"},{"location":"user_guide/api/visualization/#compare_classifiers_performance_from_prob","text":"ludwig . visualize . compare_classifiers_performance_from_prob ( probabilities_per_model , ground_truth , metadata , output_feature_name , labels_limit = 0 , top_n_classes = 3 , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Produces model comparison barplot visualization from probabilities. For each model it produces bars in a bar plot, one for each overall metric computed on the fly from the probabilities of predictions for the specified model_names . Inputs probabilities_per_model (List[np.ndarray]): path to experiment probabilities file ground_truth (pd.Series): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_n_classes (List[int]): list containing the number of classes to plot. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"compare_classifiers_performance_from_prob"},{"location":"user_guide/api/visualization/#compare_classifiers_performance_from_pred","text":"ludwig . visualize . compare_classifiers_performance_from_pred ( predictions_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Produces model comparison barplot visualization from predictions. For each model it produces bars in a bar plot, one for each overall metric computed on the fly from the predictions for the specified model_names . Inputs predictions_per_model (List[str]): path to experiment predictions file. ground_truth (pd.Series): ground truth values metadata (dict): feature metadata dictionary. output_feature_name (str): name of the output feature to visualize. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"compare_classifiers_performance_from_pred"},{"location":"user_guide/api/visualization/#compare_classifiers_performance_subset","text":"ludwig . visualize . compare_classifiers_performance_subset ( probabilities_per_model , ground_truth , metadata , output_feature_name , top_n_classes , labels_limit , subset , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Produces model comparison barplot visualization from train subset. For each model it produces bars in a bar plot, one for each overall metric computed on the fly from the probabilities predictions for the specified model_names , considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_n_classes (List[int]): list containing the number of classes to plot. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. subset (str): string specifying type of subset filtering. Valid values are ground_truth or predictions . model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"compare_classifiers_performance_subset"},{"location":"user_guide/api/visualization/#compare_classifiers_performance_changing_k","text":"ludwig . visualize . compare_classifiers_performance_changing_k ( probabilities_per_model , ground_truth , metadata , output_feature_name , top_k , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Produce lineplot that show Hits@K metric while k goes from 1 to top_k . For each model it produces a line plot that shows the Hits@K metric (that counts a prediction as correct if the model produces it among the first k) while changing k from 1 to top_k for the specified output_feature_name . Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_k (int): number of elements in the ranklist to consider. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"compare_classifiers_performance_changing_k"},{"location":"user_guide/api/visualization/#compare_classifiers_multiclass_multimetric","text":"ludwig . visualize . compare_classifiers_multiclass_multimetric ( test_stats_per_model , metadata , output_feature_name , top_n_classes , model_names = None , output_directory = None , file_format = 'pdf' ) Show the precision, recall and F1 of the model for the specified output_feature_name. For each model it produces four plots that show the precision, recall and F1 of the model on several classes for the specified output_feature_name. Inputs test_stats_per_model (List[dict]): list containing dictionary of evaluation performance statistics metadata (dict): intermediate preprocess structure created during training containing the mappings of the input dataset. output_feature_name (Union[str, None ]): name of the output feature to use for the visualization. If None , use all output features. top_n_classes (List[int]): list containing the number of classes to plot. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None):","title":"compare_classifiers_multiclass_multimetric"},{"location":"user_guide/api/visualization/#compare_classifiers_predictions","text":"ludwig . visualize . compare_classifiers_predictions ( predictions_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show two models comparison of their output_feature_name predictions. Inputs predictions_per_model (List[list]): list containing the model predictions for the specified output_feature_name. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"compare_classifiers_predictions"},{"location":"user_guide/api/visualization/#confidence_thresholding_2thresholds_2d","text":"ludwig . visualize . confidence_thresholding_2thresholds_2d ( probabilities_per_model , ground_truths , metadata , threshold_output_feature_names , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' ) Show confidence threshold data vs accuracy for two output feature names. The first plot shows several semi transparent lines. They summarize the 3d surfaces displayed by confidence_thresholding_2thresholds_3d that have thresholds on the confidence of the predictions of the two threshold_output_feature_names as x and y axes and either the data coverage percentage or the accuracy as z axis. Each line represents a slice of the data coverage surface projected onto the accuracy surface. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[List[np.array], List[pd.Series]]): containing ground truth data metadata (dict): feature metadata dictionary threshold_output_feature_names (List[str]): List containing two output feature names for visualization. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None):","title":"confidence_thresholding_2thresholds_2d"},{"location":"user_guide/api/visualization/#confidence_thresholding_2thresholds_3d","text":"ludwig . visualize . confidence_thresholding_2thresholds_3d ( probabilities_per_model , ground_truths , metadata , threshold_output_feature_names , labels_limit , output_directory = None , file_format = 'pdf' ) Show 3d confidence threshold data vs accuracy for two output feature names. The plot shows the 3d surfaces displayed by confidence_thresholding_2thresholds_3d that have thresholds on the confidence of the predictions of the two threshold_output_feature_names as x and y axes and either the data coverage percentage or the accuracy as z axis. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[List[np.array], List[pd.Series]]): containing ground truth data metadata (dict): feature metadata dictionary threshold_output_feature_names (List[str]): List containing two output feature names for visualization. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None):","title":"confidence_thresholding_2thresholds_3d"},{"location":"user_guide/api/visualization/#confidence_thresholding","text":"ludwig . visualize . confidence_thresholding ( probabilities_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models accuracy and data coverage while increasing treshold. For each model it produces a pair of lines indicating the accuracy of the model and the data coverage while increasing a threshold (x axis) on the probabilities of predictions for the specified output_feature_name. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"confidence_thresholding"},{"location":"user_guide/api/visualization/#confidence_thresholding_data_vs_acc","text":"ludwig . visualize . confidence_thresholding_data_vs_acc ( probabilities_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models comparison of confidence threshold data vs accuracy. For each model it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name. The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"confidence_thresholding_data_vs_acc"},{"location":"user_guide/api/visualization/#confidence_thresholding_data_vs_acc_subset","text":"ludwig . visualize . confidence_thresholding_data_vs_acc_subset ( probabilities_per_model , ground_truth , metadata , output_feature_name , top_n_classes , labels_limit , subset , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models comparison of confidence threshold data vs accuracy on a subset of data. For each model it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified output_feature_name, considering only a subset of the full training set. The way the subset is obtained is using the top_n_classes and subset parameters. The difference with confidence_thresholding is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold. If the values of subset is ground_truth , then only datapoints where the ground truth class is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed. If the values of subset is predictions , then only datapoints where the the model predicts a class that is within the top n most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_n_classes (List[int]): list containing the number of classes to plot. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. subset (str): string specifying type of subset filtering. Valid values are ground_truth or predictions . model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"confidence_thresholding_data_vs_acc_subset"},{"location":"user_guide/api/visualization/#binary_threshold_vs_metric","text":"ludwig . visualize . binary_threshold_vs_metric ( probabilities_per_model , ground_truth , metadata , output_feature_name , metrics , positive_label = 1 , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show confidence of the model against metric for the specified output_feature_name. For each metric specified in metrics (options are f1 , precision , recall , accuracy ), this visualization produces a line chart plotting a threshold on the confidence of the model against the metric for the specified output_feature_name. If output_feature_name is a category feature, positive_label, which is specified as the numeric encoded value, indicates the class to be considered positive class and all others will be considered negative. To figure out the association between classes and numeric encoded values check the ground_truth_metadata JSON file. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name metrics (List[str]): metrics to display ( 'f1' , 'precision' , 'recall' , 'accuracy' ). positive_label (int, default: 1 ): numeric encoded value for the positive class. model_names (List[str], default: None ): list of the names of the models to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return ( None ):","title":"binary_threshold_vs_metric"},{"location":"user_guide/api/visualization/#roc_curves","text":"ludwig . visualize . roc_curves ( probabilities_per_model , ground_truth , metadata , output_feature_name , positive_label = 1 , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show the roc curves for output features in the specified models. This visualization produces a line chart plotting the roc curves for the specified output feature name. If output feature name is a category feature, positive_label indicates which is the class to be considered positive class and all the others will be considered negative. positive_label is the encoded numeric value for category classes. The numeric value can be determined by association between classes and integers captured in the training metadata JSON file. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name positive_label (int, default: 1 ): numeric encoded value for the positive class. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"roc_curves"},{"location":"user_guide/api/visualization/#roc_curves_from_test_statistics","text":"ludwig . visualize . roc_curves_from_test_statistics ( test_stats_per_model , output_feature_name , model_names = None , output_directory = None , file_format = 'pdf' ) Show the roc curves for the specified models output binary output_feature_name . This visualization uses output_feature_name , test_stats_per_model and model_names parameters. output_feature_name needs to be binary feature. This visualization produces a line chart plotting the roc curves for the specified output_feature_name . Inputs test_stats_per_model (List[dict]): dictionary containing evaluation performance statistics. output_feature_name (str): name of the output feature to use for the visualization. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None):","title":"roc_curves_from_test_statistics"},{"location":"user_guide/api/visualization/#calibration_1_vs_all","text":"ludwig . visualize . calibration_1_vs_all ( probabilities_per_model , ground_truth , metadata , output_feature_name , top_n_classes , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models probability of predictions for the specified output_feature_name. For each class or each of the k most frequent classes if top_k is specified, it produces two plots computed on the fly from the probabilities of predictions for the specified output_feature_name. The first plot is a calibration curve that shows the calibration of the predictions considering the current class to be the true one and all others to be a false one, drawing one line for each model (in the aligned lists of probabilities and model_names). The second plot shows the distributions of the predictions considering the current class to be the true one and all others to be a false one, drawing the distribution for each model (in the aligned lists of probabilities and model_names). Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name top_n_classes (list): List containing the number of classes to plot. labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (List[str], default: None ): list of the names of the models to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize String return (None):","title":"calibration_1_vs_all"},{"location":"user_guide/api/visualization/#calibration_multiclass","text":"ludwig . visualize . calibration_multiclass ( probabilities_per_model , ground_truth , metadata , output_feature_name , labels_limit , model_names = None , output_directory = None , file_format = 'pdf' , ground_truth_apply_idx = True ) Show models probability of predictions for each class of the specified output_feature_name. Inputs probabilities_per_model (List[numpy.array]): list of model probabilities. ground_truth (Union[pd.Series, np.ndarray]): ground truth values metadata (dict): feature metadata dictionary output_feature_name (str): output feature name labels_limit (int): upper limit on the numeric encoded label value. Encoded numeric label values in dataset that are higher than labels_limit are considered to be \"rare\" labels. model_names (List[str], default: None ): list of the names of the models to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . ground_truth_apply_idx (bool, default: True ): whether to use metadata['str2idx'] in np.vectorize Return return (None):","title":"calibration_multiclass"},{"location":"user_guide/api/visualization/#confusion_matrix","text":"ludwig . visualize . confusion_matrix ( test_stats_per_model , metadata , output_feature_name , top_n_classes , normalize , model_names = None , output_directory = None , file_format = 'pdf' ) Show confusion matrix in the models predictions for each output_feature_name . For each model (in the aligned lists of test_statistics and model_names) it produces a heatmap of the confusion matrix in the predictions for each output_feature_name that has a confusion matrix in test_statistics. The value of top_n_classes limits the heatmap to the n most frequent classes. Inputs test_stats_per_model (List[dict]): dictionary containing evaluation performance statistics. metadata (dict): intermediate preprocess structure created during training containing the mappings of the input dataset. output_feature_name (Union[str, None ]): name of the output feature to use for the visualization. If None , use all output features. top_n_classes (List[int]): number of top classes or list containing the number of top classes to plot. normalize (bool): flag to normalize rows in confusion matrix. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None):","title":"confusion_matrix"},{"location":"user_guide/api/visualization/#frequency_vs_f1","text":"ludwig . visualize . frequency_vs_f1 ( test_stats_per_model , metadata , output_feature_name , top_n_classes , model_names = None , output_directory = None , file_format = 'pdf' ) Show prediction statistics for the specified output_feature_name for each model. For each model (in the aligned lists of test_stats_per_model and model_names ), produces two plots statistics of predictions for the specified output_feature_name . The first plot is a line plot with one x axis representing the different classes and two vertical axes colored in orange and blue respectively. The orange one is the frequency of the class and an orange line is plotted to show the trend. The blue one is the F1 score for that class and a blue line is plotted to show the trend. The classes on the x axis are sorted by f1 score. The second plot has the same structure of the first one, but the axes are flipped and the classes on the x axis are sorted by frequency. Inputs test_stats_per_model (List[dict]): dictionary containing evaluation performance statistics. metadata (dict): intermediate preprocess structure created during training containing the mappings of the input dataset. output_feature_name (Union[str, None ]): name of the output feature to use for the visualization. If None , use all output features. top_n_classes (List[int]): number of top classes or list containing the number of top classes to plot. model_names (Union[str, List[str]], default: None ): model name or list of the model names to use as labels. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None):","title":"frequency_vs_f1"},{"location":"user_guide/api/visualization/#hyperopt_report","text":"ludwig . visualize . hyperopt_report ( hyperopt_stats_path , output_directory = None , file_format = 'pdf' ) Produces a report about hyperparameter optimization creating one graph per hyperparameter to show the distribution of results and one additional graph of pairwise hyperparameters interactions. Inputs hyperopt_stats_path (str): path to the hyperopt results JSON file. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window. file_format (str, default: 'pdf' ): file format of output plots - 'pdf' or 'png' . Return return (None):","title":"hyperopt_report"},{"location":"user_guide/api/visualization/#hyperopt_hiplot","text":"ludwig . visualize . hyperopt_hiplot ( hyperopt_stats_path , output_directory = None ) Produces a parallel coordinate plot about hyperparameter optimization creating one HTML file and optionally a CSV file to be read by hiplot. Inputs hyperopt_stats_path (str): path to the hyperopt results JSON file. output_directory (str, default: None ): directory where to save plots. If not specified, plots will be displayed in a window. Return return (None):","title":"hyperopt_hiplot"},{"location":"user_guide/datasets/data_postprocessing/","text":"The JSON metadata file obtained during preprocessing is also used for postprocessing: Ludwig models return output predictions and, depending on their datatype they are mapped back into raw data. Number and timeseries do not require additional transformations and are returned as they are, directly from the model. Category, set, sequence, and text features are represented in the model as integers. These predictions are mapped back into the original tokens / names using the idx2str in the JSON file. Users running experiment or predict will find multiple prediction results files: 1) a CSV file for each output containing the mapped predictions, 2) a probability CSV file containing the probability of that prediction, 3) a probabilities CSV file containing the probabilities for all alternatives (for instance, the probabilities of all the categories in case of a categorical feature). Users will also get the raw unmapped predictions from the model as NPY files. If you don't need them users can use the --skip_save_unprocessed_output argument.","title":"Data Postprocessing"},{"location":"user_guide/datasets/data_preprocessing/","text":"Overview \u00b6 Ludwig data preprocessing performs a few different operations on the incoming dataset: Computing metadata like vocabulary, vocabulary size, and sequence lengths. This allows Ludwig to create dictionaries like idx2str or str2idx to map between raw data values to tensor values. Handling missing values any rows/examples that have missing feature values are filled in with constants or other example-derived values (see Preprocessing Configuration ). (optional) Splitting dataset into train, validation, and test based on splitting percentages, or using explicitly specified splits. (optional) Balancing data which can be useful for datasets with heavily underrepresented or overrepresented classes. Data preprocessing maps raw data to two files: 1) an HDF5 file containing tensors and 2) a JSON file of metadata. The HDF5 and JSON files are saved in the same directory as the input dataset, unless --skip_save_processed_input is used. The two files will serve as a cache to help avoid performing the same preprocessing again, which can be time consuming. The preprocessing process is highly customizable via the Preprocessing section of the Ludwig config. The basic assumption is always that all data is UTF-8 encoded and contains one row for each example and one column for each feature. It's helpful to assign types to each feature. Some types assume a specific format, and different types will have different ways of mapping raw data into tensors. From v0.5, users also have the option to rely on Ludwig AutoML to assign types automatically. Preprocessing for different data types \u00b6 Each datatype is preprocessed in a different way, using different parameters and different tokenizers. Details on how to set those parameters for each feature type and for each specific feature is described in the Configuration - Preprocessing section. Binary features \u00b6 Binary features are directly transformed into a binary valued vector of length n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. No additional information about them is available in the JSON metadata file. Number features \u00b6 Number features are directly transformed into a float valued vector of length n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. No additional information about them is available in the JSON metadata file. Category features \u00b6 Category features are transformed into an integer valued vector of size n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. The way categories are mapped into integers consists of first collecting a dictionary of all the unique category strings present in the column of the dataset, then rank them by frequency and then assign them an increasing integer ID from the most frequent to the most rare (with 0 being assigned to a <UNK> token). The column name is added to the JSON file, with an associated dictionary containing: the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the size of the set of all tokens ( vocab_size ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values) Set features \u00b6 Set features are transformed into a binary (int8 actually) valued matrix of size n x l (where n is the size of the dataset and l is the minimum of the size of the biggest set and a max_size parameter) and added to HDF5 with a key that reflects the name of column in the dataset. The way sets are mapped into integers consists in first using a tokenizer to map from strings to sequences of set items (by default this is done by splitting on spaces). Then a dictionary of all the different set item strings present in the column of the dataset is collected, then they are ranked by frequency and an increasing integer ID is assigned to them from the most frequent to the most rare (with 0 being assigned to <PAD> used for padding and 1 assigned to <UNK> item). The column name is added to the JSON file, with an associated dictionary containing: the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the maximum size of all sets ( max_set_size ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values) Bag features \u00b6 Bag features are treated in the same way of set features, with the only difference being that the matrix had float values (frequencies). Sequence Features \u00b6 Sequence features by default are managed by space tokenizers. This splits the content of the feature value into a list of strings using space. before tokenizer after tokenizer \"token3 token4 token2\" [token3, token4, token2] \"token3 token1\" [token3, token1] Computing metadata: A list idx2str and two dictionaries str2idx and str2freq are created containing all the tokens in all the lists obtained by splitting all the rows of the column and an integer id is assigned to each of them (in order of frequency). { \"column_name\" : { \"idx2str\" : [ \"<PAD>\" , \"<UNK>\" , \"token3\" , \"token2\" , \"token4\" , \"token1\" ], \"str2idx\" : { \"<PAD>\" : 0 , \"<UNK>\" : 1 , \"token3\" : 2 , \"token2\" : 3 , \"token4\" : 4 , \"token1\" : 5 }, \"str2freq\" : { \"<PAD>\" : 0 , \"<UNK>\" : 0 , \"token3\" : 2 , \"token2\" : 1 , \"token4\" : 1 , \"token1\" : 1 } } } Finally, a numpy matrix is created with sizes n x l where n is the number of rows in the column and l is the minimum of the longest tokenized list and a max_length parameter that can be set. All sequences shorter than l are right-padded to the max_length (though this behavior may also be modified through a parameter). after tokenizer numpy matrix [token3, token4, token2] 2 4 3 [token3, token1] 2 5 0 The final result matrix is saved in the HDF5 with the name of the original column in the dataset as key, while the mapping from token to integer ID (and its inverse mapping) is saved in the JSON file. A frequency-ordered vocabulary dictionary is created which maps tokens to integer IDs. Special symbols like <PAD> , <START> , <STOP> , and <UNK> have specific indices. By default, we use [0, 1, 2, 3] , but these can be overridden manually. If a huggingface encoder is specified, then that encoder's special symbol indices will be used instead. The computed metadata includes: the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the maximum length of all sequences ( max_sequence_length ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values) Text features \u00b6 Text features are treated in the same way of sequence features, with a couple differences. Two different tokenizations happen, one that splits at every character and one that uses a custom tokenizer. Two different keys are added to the HDF5 file, one for the matrix of characters and one for the matrix of symbols. The same thing happens in the JSON file, where there are two sets of dictionaries, one for mapping characters to integers (and the inverse) and symbols to integers (and their inverse). If a huggingface encoder is specified, then that encoder's tokenizer will be used for the symbol-based tokenizer. In the configuration users can specify which level of representation to use: the character level or the symbol level. Timeseries features \u00b6 Timeseries features are treated in the same way of sequence features, with the only difference being that the matrix in the HDF5 file does not have integer values, but float values. The JSON file has no additional mapping information. Image features \u00b6 Image features are transformed into a int8 valued tensor of size n x h x w x c (where n is the size of the dataset and h x w is a specific resizing of the image that can be set, and c is the number of color channels) and added to HDF5 with a key that reflects the name of column in the dataset. The column name is added to the JSON file, with an associated dictionary containing preprocessing information about the sizes of the resizing.","title":"Data Preprocessing"},{"location":"user_guide/datasets/data_preprocessing/#overview","text":"Ludwig data preprocessing performs a few different operations on the incoming dataset: Computing metadata like vocabulary, vocabulary size, and sequence lengths. This allows Ludwig to create dictionaries like idx2str or str2idx to map between raw data values to tensor values. Handling missing values any rows/examples that have missing feature values are filled in with constants or other example-derived values (see Preprocessing Configuration ). (optional) Splitting dataset into train, validation, and test based on splitting percentages, or using explicitly specified splits. (optional) Balancing data which can be useful for datasets with heavily underrepresented or overrepresented classes. Data preprocessing maps raw data to two files: 1) an HDF5 file containing tensors and 2) a JSON file of metadata. The HDF5 and JSON files are saved in the same directory as the input dataset, unless --skip_save_processed_input is used. The two files will serve as a cache to help avoid performing the same preprocessing again, which can be time consuming. The preprocessing process is highly customizable via the Preprocessing section of the Ludwig config. The basic assumption is always that all data is UTF-8 encoded and contains one row for each example and one column for each feature. It's helpful to assign types to each feature. Some types assume a specific format, and different types will have different ways of mapping raw data into tensors. From v0.5, users also have the option to rely on Ludwig AutoML to assign types automatically.","title":"Overview"},{"location":"user_guide/datasets/data_preprocessing/#preprocessing-for-different-data-types","text":"Each datatype is preprocessed in a different way, using different parameters and different tokenizers. Details on how to set those parameters for each feature type and for each specific feature is described in the Configuration - Preprocessing section.","title":"Preprocessing for different data types"},{"location":"user_guide/datasets/data_preprocessing/#binary-features","text":"Binary features are directly transformed into a binary valued vector of length n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. No additional information about them is available in the JSON metadata file.","title":"Binary features"},{"location":"user_guide/datasets/data_preprocessing/#number-features","text":"Number features are directly transformed into a float valued vector of length n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. No additional information about them is available in the JSON metadata file.","title":"Number features"},{"location":"user_guide/datasets/data_preprocessing/#category-features","text":"Category features are transformed into an integer valued vector of size n (where n is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset. The way categories are mapped into integers consists of first collecting a dictionary of all the unique category strings present in the column of the dataset, then rank them by frequency and then assign them an increasing integer ID from the most frequent to the most rare (with 0 being assigned to a <UNK> token). The column name is added to the JSON file, with an associated dictionary containing: the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the size of the set of all tokens ( vocab_size ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values)","title":"Category features"},{"location":"user_guide/datasets/data_preprocessing/#set-features","text":"Set features are transformed into a binary (int8 actually) valued matrix of size n x l (where n is the size of the dataset and l is the minimum of the size of the biggest set and a max_size parameter) and added to HDF5 with a key that reflects the name of column in the dataset. The way sets are mapped into integers consists in first using a tokenizer to map from strings to sequences of set items (by default this is done by splitting on spaces). Then a dictionary of all the different set item strings present in the column of the dataset is collected, then they are ranked by frequency and an increasing integer ID is assigned to them from the most frequent to the most rare (with 0 being assigned to <PAD> used for padding and 1 assigned to <UNK> item). The column name is added to the JSON file, with an associated dictionary containing: the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the maximum size of all sets ( max_set_size ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values)","title":"Set features"},{"location":"user_guide/datasets/data_preprocessing/#bag-features","text":"Bag features are treated in the same way of set features, with the only difference being that the matrix had float values (frequencies).","title":"Bag features"},{"location":"user_guide/datasets/data_preprocessing/#sequence-features","text":"Sequence features by default are managed by space tokenizers. This splits the content of the feature value into a list of strings using space. before tokenizer after tokenizer \"token3 token4 token2\" [token3, token4, token2] \"token3 token1\" [token3, token1] Computing metadata: A list idx2str and two dictionaries str2idx and str2freq are created containing all the tokens in all the lists obtained by splitting all the rows of the column and an integer id is assigned to each of them (in order of frequency). { \"column_name\" : { \"idx2str\" : [ \"<PAD>\" , \"<UNK>\" , \"token3\" , \"token2\" , \"token4\" , \"token1\" ], \"str2idx\" : { \"<PAD>\" : 0 , \"<UNK>\" : 1 , \"token3\" : 2 , \"token2\" : 3 , \"token4\" : 4 , \"token1\" : 5 }, \"str2freq\" : { \"<PAD>\" : 0 , \"<UNK>\" : 0 , \"token3\" : 2 , \"token2\" : 1 , \"token4\" : 1 , \"token1\" : 1 } } } Finally, a numpy matrix is created with sizes n x l where n is the number of rows in the column and l is the minimum of the longest tokenized list and a max_length parameter that can be set. All sequences shorter than l are right-padded to the max_length (though this behavior may also be modified through a parameter). after tokenizer numpy matrix [token3, token4, token2] 2 4 3 [token3, token1] 2 5 0 The final result matrix is saved in the HDF5 with the name of the original column in the dataset as key, while the mapping from token to integer ID (and its inverse mapping) is saved in the JSON file. A frequency-ordered vocabulary dictionary is created which maps tokens to integer IDs. Special symbols like <PAD> , <START> , <STOP> , and <UNK> have specific indices. By default, we use [0, 1, 2, 3] , but these can be overridden manually. If a huggingface encoder is specified, then that encoder's special symbol indices will be used instead. The computed metadata includes: the mapping from integer to string ( idx2str ) the mapping from string to id ( str2idx ) the mapping from string to frequency ( str2freq ) the maximum length of all sequences ( max_sequence_length ) additional preprocessing information (by default how to fill missing values and what token to use to fill missing values)","title":"Sequence Features"},{"location":"user_guide/datasets/data_preprocessing/#text-features","text":"Text features are treated in the same way of sequence features, with a couple differences. Two different tokenizations happen, one that splits at every character and one that uses a custom tokenizer. Two different keys are added to the HDF5 file, one for the matrix of characters and one for the matrix of symbols. The same thing happens in the JSON file, where there are two sets of dictionaries, one for mapping characters to integers (and the inverse) and symbols to integers (and their inverse). If a huggingface encoder is specified, then that encoder's tokenizer will be used for the symbol-based tokenizer. In the configuration users can specify which level of representation to use: the character level or the symbol level.","title":"Text features"},{"location":"user_guide/datasets/data_preprocessing/#timeseries-features","text":"Timeseries features are treated in the same way of sequence features, with the only difference being that the matrix in the HDF5 file does not have integer values, but float values. The JSON file has no additional mapping information.","title":"Timeseries features"},{"location":"user_guide/datasets/data_preprocessing/#image-features","text":"Image features are transformed into a int8 valued tensor of size n x h x w x c (where n is the size of the dataset and h x w is a specific resizing of the image that can be set, and c is the number of color channels) and added to HDF5 with a key that reflects the name of column in the dataset. The column name is added to the JSON file, with an associated dictionary containing preprocessing information about the sizes of the resizing.","title":"Image features"},{"location":"user_guide/datasets/dataset_zoo/","text":"The Ludwig Dataset Zoo provides datasets that can be directly plugged into a Ludwig model. The simplest way to use a dataset is to import and load it. The .load() method will return a Pandas DataFrame. from ludwig.datasets import reuters # Loads into single dataframe with a 'split' column: dataset_df = reuters . load () # Loads into split dataframes: train_df , test_df , _ = reuters . load ( split = True ) The ludwig.datasets API also provides functions to list, describe, and get datasets. For example: import ludwig.datasets # Gets a list of all available dataset names. dataset_names = ludwig . datasets . list_datasets () # Prints the description of the titanic dataset. print ( ludwig . datasets . describe_dataset ( \"titanic\" )) titanic = ludwig . datasets . get_dataset ( \"titanic\" ) # Loads into single dataframe with a 'split' column: dataset_df = titanic . load () # Loads into split dataframes: train_df , test_df , _ = titanic . load ( split = True ) Kaggle Datasets \u00b6 Some datasets are hosted on Kaggle and require a kaggle account. To use these, you'll need to set up Kaggle credentials in your environment. If the dataset is part of a Kaggle competition, you'll need to accept the terms on the competition page. To check programmatically, datasets have an .is_kaggle_dataset property. Downloading, Processing, and Exporting \u00b6 Datasets are first downloaded into LUDWIG_CACHE , which may be set as an environment variable and defaults to $HOME/.ludwig_cache . Datasets are automatically loaded, processed, and re-saved as parquet files in the cache. To export the processed dataset, including any files it depends on, use the .export(output_directory) method. This is recommended if the dataset contains media files like images or audio files. File paths are relative to the working directory of the training process. from ludwig.datasets import twitter_bots # Exports twitter bots dataset and image files to the current working directory. twitter_bots . export ( \".\" ) End-to-end Example \u00b6 Here's an end-to-end example of training a model using the MNIST dataset: from ludwig.api import LudwigModel from ludwig.datasets import mnist # Initializes a Ludwig model config = { \"input_features\" : [{ \"name\" : \"image_path\" , \"type\" : \"image\" }], \"output_features\" : [{ \"name\" : \"label\" , \"type\" : \"category\" }], } model = LudwigModel ( config ) # Loads and splits MNIST dataset training_set , test_set , _ = mnist . load ( split = True ) # Exports the mnist image files to the current working directory. mnist . export ( \".\" ) # Runs model training train_stats , _ , _ = model . train ( training_set = training_set , test_set = test_set , model_name = \"mnist_model\" ) Zoo Datasets \u00b6 Here is the list of the currently available datasets: Dataset Hosted On Description adult_census_income archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/adult . Whether a person makes over $50K a year or not. agnews Github https://search.r-project.org/CRAN/refmans/textdata/html/dataset_ag_news.html allstate_claims_severity Kaggle https://www.kaggle.com/c/allstate-claims-severity amazon_employee_access_challenge Kaggle https://www.kaggle.com/c/amazon-employee-access-challenge amazon_review_polarity S3 https://paperswithcode.com/sota/sentiment-analysis-on-amazon-review-polarity amazon_reviews S3 https://s3.amazonaws.com/amazon-reviews-pds/readme.html ames_housing Kaggle https://www.kaggle.com/c/ames-housing-data bbc_news Kaggle https://www.kaggle.com/c/learn-ai-bbc bnp_claims_management Kaggle https://www.kaggle.com/c/bnp-paribas-cardif-claims-management connect4 Kaggle https://www.kaggle.com/c/connectx/discussion/124397 creditcard_fraud Kaggle https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud dbpedia S3 https://paperswithcode.com/dataset/dbpedia electricity S3 Predict electricity demand from day of week and outside temperature. ethos_binary Github https://github.com/huggingface/datasets/blob/master/datasets/ethos/README.md fever S3 https://arxiv.org/abs/1803.05355 flickr8k Github https://www.kaggle.com/adityajn105/flickr8k forest_cover archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/covertype goemotions Github https://arxiv.org/abs/2005.00547 higgs archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/HIGGS ieee_fraud Kaggle https://www.kaggle.com/c/ieee-fraud-detection imbalanced_insurance Kaggle https://www.kaggle.com/datasets/arashnic/imbalanced-data-practice imdb Kaggle https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews insurance_lite Kaggle https://www.kaggle.com/infernape/fast-furious-and-insured iris archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/iris irony Github https://github.com/bwallace/ACL-2014-irony kdd_appetency kdd.org https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data kdd_churn kdd.org https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data kdd_upselling kdd.org https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data mnist yann.lecun.com http://yann.lecun.com/exdb/mnist/ mushroom_edibility archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/mushroom naval archive.ics.uci.edu https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/24098 noshow_appointments Kaggle https://www.kaggle.com/datasets/joniarroba/noshowappointments numerai28pt6 Kaggle https://www.kaggle.com/numerai/encrypted-stock-market-data-from-numerai ohsumed_7400 Kaggle https://www.kaggle.com/datasets/weipengfei/ohr8r52 ohsumed_cmu boston.lti.cs.cmu.edu http://boston.lti.cs.cmu.edu/classes/95-865-K/HW/HW2/ otto_group_product Kaggle https://www.kaggle.com/c/otto-group-product-classification-challenge poker_hand archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/Poker+Hand porto_seguro_safe_driver Kaggle https://www.kaggle.com/c/porto-seguro-safe-driver-prediction protein archive.ics.uci.edu https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2932-0 reuters_cmu boston.lti.cs.cmu.edu http://boston.lti.cs.cmu.edu/classes/95-865-K/HW/HW2/ reuters_r8 Kaggle Reuters R8 subset of Reuters 21578 dataset from Kaggle. rossmann_store_sales Kaggle https://www.kaggle.com/c/rossmann-store-sales santander_customer_satisfaction Kaggle https://www.kaggle.com/c/santander-customer-satisfaction santander_customer_transaction_prediction Kaggle https://www.kaggle.com/c/santander-customer-transaction-prediction santander_value_prediction Kaggle https://www.kaggle.com/c/santander-value-prediction-challenge sarcos gaussianprocess.org http://www.gaussianprocess.org/gpml/data/ sst2 nlp.stanford.edu https://paperswithcode.com/dataset/sst sst3 nlp.stanford.edu Merging very negative and negative, and very positive and positive classes. sst5 nlp.stanford.edu https://paperswithcode.com/dataset/sst synthetic_fraud Kaggle https://www.kaggle.com/ealaxi/paysim1 temperature Kaggle https://www.kaggle.com/selfishgene/historical-hourly-weather-data titanic Kaggle https://www.kaggle.com/c/titanic walmart_recruiting Kaggle https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting wmt15 Kaggle https://www.kaggle.com/dhruvildave/en-fr-translation-dataset yahoo_answers S3 Question classification. yelp_review_polarity S3 https://www.yelp.com/dataset . Predict the polarity or sentiment of a yelp review. yelp_reviews S3 https://www.yelp.com/dataset yosemite Github https://github.com/ourownstory/neural_prophet Yosemite temperatures dataset. Adding datasets \u00b6 To add a dataset to the Ludwig Dataset Zoo, see Add a Dataset .","title":"Dataset Zoo"},{"location":"user_guide/datasets/dataset_zoo/#kaggle-datasets","text":"Some datasets are hosted on Kaggle and require a kaggle account. To use these, you'll need to set up Kaggle credentials in your environment. If the dataset is part of a Kaggle competition, you'll need to accept the terms on the competition page. To check programmatically, datasets have an .is_kaggle_dataset property.","title":"Kaggle Datasets"},{"location":"user_guide/datasets/dataset_zoo/#downloading-processing-and-exporting","text":"Datasets are first downloaded into LUDWIG_CACHE , which may be set as an environment variable and defaults to $HOME/.ludwig_cache . Datasets are automatically loaded, processed, and re-saved as parquet files in the cache. To export the processed dataset, including any files it depends on, use the .export(output_directory) method. This is recommended if the dataset contains media files like images or audio files. File paths are relative to the working directory of the training process. from ludwig.datasets import twitter_bots # Exports twitter bots dataset and image files to the current working directory. twitter_bots . export ( \".\" )","title":"Downloading, Processing, and Exporting"},{"location":"user_guide/datasets/dataset_zoo/#end-to-end-example","text":"Here's an end-to-end example of training a model using the MNIST dataset: from ludwig.api import LudwigModel from ludwig.datasets import mnist # Initializes a Ludwig model config = { \"input_features\" : [{ \"name\" : \"image_path\" , \"type\" : \"image\" }], \"output_features\" : [{ \"name\" : \"label\" , \"type\" : \"category\" }], } model = LudwigModel ( config ) # Loads and splits MNIST dataset training_set , test_set , _ = mnist . load ( split = True ) # Exports the mnist image files to the current working directory. mnist . export ( \".\" ) # Runs model training train_stats , _ , _ = model . train ( training_set = training_set , test_set = test_set , model_name = \"mnist_model\" )","title":"End-to-end Example"},{"location":"user_guide/datasets/dataset_zoo/#zoo-datasets","text":"Here is the list of the currently available datasets: Dataset Hosted On Description adult_census_income archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/adult . Whether a person makes over $50K a year or not. agnews Github https://search.r-project.org/CRAN/refmans/textdata/html/dataset_ag_news.html allstate_claims_severity Kaggle https://www.kaggle.com/c/allstate-claims-severity amazon_employee_access_challenge Kaggle https://www.kaggle.com/c/amazon-employee-access-challenge amazon_review_polarity S3 https://paperswithcode.com/sota/sentiment-analysis-on-amazon-review-polarity amazon_reviews S3 https://s3.amazonaws.com/amazon-reviews-pds/readme.html ames_housing Kaggle https://www.kaggle.com/c/ames-housing-data bbc_news Kaggle https://www.kaggle.com/c/learn-ai-bbc bnp_claims_management Kaggle https://www.kaggle.com/c/bnp-paribas-cardif-claims-management connect4 Kaggle https://www.kaggle.com/c/connectx/discussion/124397 creditcard_fraud Kaggle https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud dbpedia S3 https://paperswithcode.com/dataset/dbpedia electricity S3 Predict electricity demand from day of week and outside temperature. ethos_binary Github https://github.com/huggingface/datasets/blob/master/datasets/ethos/README.md fever S3 https://arxiv.org/abs/1803.05355 flickr8k Github https://www.kaggle.com/adityajn105/flickr8k forest_cover archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/covertype goemotions Github https://arxiv.org/abs/2005.00547 higgs archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/HIGGS ieee_fraud Kaggle https://www.kaggle.com/c/ieee-fraud-detection imbalanced_insurance Kaggle https://www.kaggle.com/datasets/arashnic/imbalanced-data-practice imdb Kaggle https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews insurance_lite Kaggle https://www.kaggle.com/infernape/fast-furious-and-insured iris archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/iris irony Github https://github.com/bwallace/ACL-2014-irony kdd_appetency kdd.org https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data kdd_churn kdd.org https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data kdd_upselling kdd.org https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data mnist yann.lecun.com http://yann.lecun.com/exdb/mnist/ mushroom_edibility archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/mushroom naval archive.ics.uci.edu https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/24098 noshow_appointments Kaggle https://www.kaggle.com/datasets/joniarroba/noshowappointments numerai28pt6 Kaggle https://www.kaggle.com/numerai/encrypted-stock-market-data-from-numerai ohsumed_7400 Kaggle https://www.kaggle.com/datasets/weipengfei/ohr8r52 ohsumed_cmu boston.lti.cs.cmu.edu http://boston.lti.cs.cmu.edu/classes/95-865-K/HW/HW2/ otto_group_product Kaggle https://www.kaggle.com/c/otto-group-product-classification-challenge poker_hand archive.ics.uci.edu https://archive.ics.uci.edu/ml/datasets/Poker+Hand porto_seguro_safe_driver Kaggle https://www.kaggle.com/c/porto-seguro-safe-driver-prediction protein archive.ics.uci.edu https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2932-0 reuters_cmu boston.lti.cs.cmu.edu http://boston.lti.cs.cmu.edu/classes/95-865-K/HW/HW2/ reuters_r8 Kaggle Reuters R8 subset of Reuters 21578 dataset from Kaggle. rossmann_store_sales Kaggle https://www.kaggle.com/c/rossmann-store-sales santander_customer_satisfaction Kaggle https://www.kaggle.com/c/santander-customer-satisfaction santander_customer_transaction_prediction Kaggle https://www.kaggle.com/c/santander-customer-transaction-prediction santander_value_prediction Kaggle https://www.kaggle.com/c/santander-value-prediction-challenge sarcos gaussianprocess.org http://www.gaussianprocess.org/gpml/data/ sst2 nlp.stanford.edu https://paperswithcode.com/dataset/sst sst3 nlp.stanford.edu Merging very negative and negative, and very positive and positive classes. sst5 nlp.stanford.edu https://paperswithcode.com/dataset/sst synthetic_fraud Kaggle https://www.kaggle.com/ealaxi/paysim1 temperature Kaggle https://www.kaggle.com/selfishgene/historical-hourly-weather-data titanic Kaggle https://www.kaggle.com/c/titanic walmart_recruiting Kaggle https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting wmt15 Kaggle https://www.kaggle.com/dhruvildave/en-fr-translation-dataset yahoo_answers S3 Question classification. yelp_review_polarity S3 https://www.yelp.com/dataset . Predict the polarity or sentiment of a yelp review. yelp_reviews S3 https://www.yelp.com/dataset yosemite Github https://github.com/ourownstory/neural_prophet Yosemite temperatures dataset.","title":"Zoo Datasets"},{"location":"user_guide/datasets/dataset_zoo/#adding-datasets","text":"To add a dataset to the Ludwig Dataset Zoo, see Add a Dataset .","title":"Adding datasets"},{"location":"user_guide/datasets/supported_formats/","text":"Ludwig is able to read UTF-8 encoded data from 14 file formats. Supported formats are: Comma Separated Values ( csv ) Excel Workbooks ( excel ) Feather ( feather ) Fixed Width Format ( fwf ) Hierarchical Data Format 5 ( hdf5 ) Hypertext Markup Language ( html ) Note: limited to single table in the file. JavaScript Object Notation ( json and jsonl ) Parquet ( parquet ) Pickled Pandas DataFrame ( pickle ) SAS data sets in XPORT or SAS7BDAT format ( sas ) SPSS file ( spss ) Stata file ( stata ) Tab Separated Values ( tsv ) Ludwig uses Pandas and Dask under the hood to read the UTF-8 encoded dataset files, which allows support for CSV, Excel, Feather, fwf, HDF5, HTML (containing a <table> ), JSON, JSONL, Parquet, pickle (pickled Pandas DataFrame), SAS, SPSS, Stata and TSV formats. Ludwig tries to automatically identify the format by the extension. In case a *SV file is provided, Ludwig tries to identify the separator (generally , ) from the data. The default escape character is \\ . For example, if , is the column separator and one of your data columns has a , in it, Pandas would fail to load the data properly. To handle such cases, we expect the values in the columns to be escaped with backslashes (replace , in the data with \\, ).","title":"Supported Formats"}]}