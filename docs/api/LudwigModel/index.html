
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Deep learning toolbox">
      
      
        <link rel="canonical" href="https://ludwig-ai.github.io/ludwig-docs/api/LudwigModel/">
      
      
        <meta name="author" content="Piero Molino">
      
      <link rel="shortcut icon" href="../../favicon.ico">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.0.2">
    
    
      
        <title>LudwigModel - Ludwig</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.38780c08.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.3f72e892.min.css">
        
          
          
          <meta name="theme-color" content="#757575">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../stylesheets/monokai.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="grey" data-md-color-accent="grey">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#ludwigmodel-class" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://ludwig-ai.github.io/ludwig-docs/" title="Ludwig" class="md-header-nav__button md-logo" aria-label="Ludwig">
      
<img alt="logo" src="../../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Ludwig
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              LudwigModel
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/uber/ludwig/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    uber/ludwig
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav aria-label="Navigation" class="md-nav md-nav--primary"
     data-md-level="0">
    <label class="md-nav__title" for="__drawer">
        <a aria-label="Ludwig" class="md-nav__button md-logo"
           href="https://ludwig-ai.github.io/ludwig-docs/"
           title="Ludwig">
            <img alt="logo" src="../../images/ludwig_logo.svg"
                 style="width:10rem;height:auto;">
        </a>
    </label>
    
    <div class="md-nav__source">
        
<a href="https://github.com/uber/ludwig/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    uber/ludwig
  </div>
</a>
    </div>
    
    <ul class="md-nav__list" data-md-scrollfix>
        
        
        
        


  <li class="md-nav__item">
    <a href="../.." class="md-nav__link">
      About
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../getting_started/" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../examples/" class="md-nav__link">
      Examples
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../user_guide/" class="md-nav__link">
      User Guide
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../developer_guide/" class="md-nav__link">
      Developer Guide
    </a>
  </li>

        
        
        
        

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6" checked>
    
    <label class="md-nav__link" for="nav-6">
      API
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="API" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon"></span>
        API
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        LudwigModel
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      LudwigModel
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ludwigmodel-class" class="md-nav__link">
    LudwigModel class
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ludwigmodel-methods" class="md-nav__link">
    LudwigModel methods
  </a>
  
    <nav class="md-nav" aria-label="LudwigModel methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#collect_activations" class="md-nav__link">
    collect_activations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collect_weights" class="md-nav__link">
    collect_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#create_model" class="md-nav__link">
    create_model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experiment" class="md-nav__link">
    experiment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load" class="md-nav__link">
    load
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocess" class="md-nav__link">
    preprocess
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_config" class="md-nav__link">
    save_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_savedmodel" class="md-nav__link">
    save_savedmodel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_logging_level" class="md-nav__link">
    set_logging_level
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_online" class="md-nav__link">
    train_online
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-functions" class="md-nav__link">
    Module functions
  </a>
  
    <nav class="md-nav" aria-label="Module functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kfold_cross_validate" class="md-nav__link">
    kfold_cross_validate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt" class="md-nav__link">
    hyperopt
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../visualization/" class="md-nav__link">
      Visualization
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../community/" class="md-nav__link">
      Community
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../faq/" class="md-nav__link">
      FAQ
    </a>
  </li>

        
    </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ludwigmodel-class" class="md-nav__link">
    LudwigModel class
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ludwigmodel-methods" class="md-nav__link">
    LudwigModel methods
  </a>
  
    <nav class="md-nav" aria-label="LudwigModel methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#collect_activations" class="md-nav__link">
    collect_activations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collect_weights" class="md-nav__link">
    collect_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#create_model" class="md-nav__link">
    create_model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experiment" class="md-nav__link">
    experiment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load" class="md-nav__link">
    load
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocess" class="md-nav__link">
    preprocess
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_config" class="md-nav__link">
    save_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_savedmodel" class="md-nav__link">
    save_savedmodel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_logging_level" class="md-nav__link">
    set_logging_level
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_online" class="md-nav__link">
    train_online
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-functions" class="md-nav__link">
    Module functions
  </a>
  
    <nav class="md-nav" aria-label="Module functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kfold_cross_validate" class="md-nav__link">
    kfold_cross_validate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt" class="md-nav__link">
    hyperopt
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/uber/ludwig/edit/master/mkdocs/docs/api/LudwigModel.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  <h1>LudwigModel</h1>
                
                <p><span style="float:right;"><a href="https://github.com/uber/ludwig/blob/master/ludwig/api.py#L74">[source]</a></span></p>
<h2 id="ludwigmodel-class">LudwigModel class<a class="headerlink" href="#ludwigmodel-class" title="Permanent link">&para;</a></h2>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">LudwigModel</span><span class="p">(</span>
  <span class="n">config</span><span class="p">,</span>
  <span class="n">logging_level</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
  <span class="n">use_horovod</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">gpus</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">gpu_memory_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">allow_parallel_threads</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>


<p>Class that allows access to high level Ludwig functionalities.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>config</strong> (Union[str, dict]): in-memory representation of
    config or string path to a YAML config file.</li>
<li><strong>logging_level</strong> (int): Log level that will be sent to stderr.</li>
<li><strong>use_horovod</strong> (bool): use Horovod for distributed training.
Will be set automatically if <code>horovodrun</code> is used to launch
the training script.</li>
<li><strong>gpus</strong> (Union[str, int, List[int]], default: <code>None</code>): GPUs
to use (it uses the same syntax of CUDA_VISIBLE_DEVICES)</li>
<li><strong>gpu_memory_limit</strong> (int: default: <code>None</code>): maximum memory in MB to
allocate per GPU device.</li>
<li><strong>allow_parallel_threads</strong> (bool, default: <code>True</code>): allow TensorFlow
to use multithreading parallelism to improve performance at the
cost of determinism.</li>
</ul>
<p><strong>Example usage:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">ludwig.api</span> <span class="kn">import</span> <span class="n">LudwigModel</span>
</code></pre></div>


<p>Train a model:</p>
<div class="codehilite"><pre><span></span><code><span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="n">ludwig_model</span> <span class="o">=</span> <span class="n">LudwigModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">train_stats</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span>  <span class="o">=</span> <span class="n">ludwig_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">file_path</span><span class="p">)</span>
</code></pre></div>


<p>or</p>
<div class="codehilite"><pre><span></span><code><span class="n">train_stats</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">ludwig_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataframe</span><span class="p">)</span>
</code></pre></div>


<p>If you have already trained a model you can load it and use it to predict</p>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig_model</span> <span class="o">=</span> <span class="n">LudwigModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_dir</span><span class="p">)</span>
</code></pre></div>


<p>Predict:</p>
<div class="codehilite"><pre><span></span><code><span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">ludwig_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">file_path</span><span class="p">)</span>
</code></pre></div>


<p>or</p>
<div class="codehilite"><pre><span></span><code><span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">ludwig_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataframe</span><span class="p">)</span>
</code></pre></div>


<p>Evaluation:</p>
<div class="codehilite"><pre><span></span><code><span class="n">eval_stats</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">ludwig_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">file_path</span><span class="p">)</span>
</code></pre></div>


<p>or</p>
<div class="codehilite"><pre><span></span><code><span class="n">eval_stats</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">ludwig_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataframe</span><span class="p">)</span>
</code></pre></div>


<hr />
<h2 id="ludwigmodel-methods">LudwigModel methods<a class="headerlink" href="#ludwigmodel-methods" title="Permanent link">&para;</a></h2>
<h3 id="collect_activations">collect_activations<a class="headerlink" href="#collect_activations" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">collect_activations</span><span class="p">(</span>
  <span class="n">layer_names</span><span class="p">,</span>
  <span class="n">dataset</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">split</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>Loads a pre-trained model model and input data to collect the values
of the activations contained in the tensors.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>layer_names</strong> (list): list of strings for layer names in the model
to collect activations.</li>
<li><strong>dataset</strong> (Union[str, Dict[str, list], pandas.DataFrame]): source
containing the data to make predictions.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
sources. Will be inferred automatically if not specified.  Valid
formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>, <code>'feather'</code>,
<code>'fwf'</code>, <code>'hdf5'</code> (cache file produced during previous training),
<code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>), <code>'json'</code>, <code>'jsonl'</code>,
<code>'parquet'</code>, <code>'pickle'</code> (pickled Pandas DataFrame), <code>'sas'</code>, <code>'spss'</code>,
<code>'stata'</code>, <code>'tsv'</code>.
:param: split: (str, default= <code>'full'</code>): if the input dataset contains
a split column, this parameter indicates which split of the data
to use. Possible values are <code>'full'</code>, <code>'training'</code>, <code>'validation'</code>, <code>'test'</code>.</li>
<li><strong>batch_size</strong> (int, default: 128): size of batch to use when making
predictions.</li>
<li><strong>debug</strong> (bool, default: <code>False</code>): if <code>True</code> turns on <code>tfdbg</code>
with <code>inf_or_nan</code> checks.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (list): list of collected tensors.</li>
</ul>
<hr />
<h3 id="collect_weights">collect_weights<a class="headerlink" href="#collect_weights" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">collect_weights</span><span class="p">(</span>
  <span class="n">tensor_names</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>


<p>Load a pre-trained model and collect the tensors with a specific name</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>tensor_names</strong> (list, default: <code>None</code>): List of tensor names to collect
weights</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (list): List of tensors</li>
</ul>
<hr />
<h3 id="create_model">create_model<a class="headerlink" href="#create_model" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">create_model</span><span class="p">(</span>
  <span class="n">config</span><span class="p">,</span>
  <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</code></pre></div>


<p>Instantiates Encoder-Combiner-Decoder (ECD) object</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>config</strong> (dict): Ludwig config</li>
<li><strong>random_seed</strong> (int, default: ludwig default random seed): Random
seed used for weights initialization,
splits and any other random function.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (ludwig.models.ECD): Instance of the Ludwig model object.</li>
</ul>
<hr />
<h3 id="evaluate">evaluate<a class="headerlink" href="#evaluate" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
  <span class="n">dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">split</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
  <span class="n">skip_save_unprocessed_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">skip_save_predictions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">skip_save_eval_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">collect_predictions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">collect_overall_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="s1">&#39;results&#39;</span><span class="p">,</span>
  <span class="n">return_type</span><span class="o">=&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">pandas</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">frame</span><span class="o">.</span><span class="n">DataFrame</span><span class="s1">&#39;&gt;,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>This function is used to predict the output variables given the
input variables using the trained model and compute test statistics
like performance measures, confusion matrices and the like.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>dataset</strong> (Union[str, dict, pandas.DataFrame]): source containing
the entire dataset to be evaluated.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
sources. Will be inferred automatically if not specified.  Valid
formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>, <code>'feather'</code>,
<code>'fwf'</code>, <code>'hdf5'</code> (cache file produced during previous training),
<code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>), <code>'json'</code>, <code>'jsonl'</code>,
<code>'parquet'</code>, <code>'pickle'</code> (pickled Pandas DataFrame), <code>'sas'</code>, <code>'spss'</code>,
<code>'stata'</code>, <code>'tsv'</code>.
:param: split: (str, default= <code>'full'</code>): if the input dataset contains
a split column, this parameter indicates which split of the data
to use. Possible values are <code>'full'</code>, <code>'training'</code>, <code>'validation'</code>, <code>'test'</code>.</li>
<li><strong>batch_size</strong> (int, default: 128): size of batch to use when making
predictions.</li>
<li><strong>skip_save_unprocessed_output</strong> (bool, default: <code>True</code>): if this
parameter is <code>False</code>, predictions and their probabilities are saved
in both raw unprocessed numpy files containing tensors and as
postprocessed CSV files (one for each output feature).
If this parameter is <code>True</code>, only the CSV ones are saved and the
numpy ones are skipped.</li>
<li><strong>skip_save_predictions</strong> (bool, default: <code>True</code>): skips saving
test predictions CSV files.</li>
<li><strong>skip_save_eval_stats</strong> (bool, default: <code>True</code>): skips saving
test statistics JSON file.</li>
<li><strong>collect_predictions</strong> (bool, default: <code>False</code>): if <code>True</code>
collects post-processed predictions during eval.</li>
<li><strong>collect_overall_stats</strong> (bool, default: False): if <code>True</code>
collects overall stats during eval.</li>
<li><strong>output_directory</strong> (str, default: <code>'results'</code>): the directory that
will contain the training statistics, TensorBoard logs, the saved
model and the training progress files.</li>
<li><strong>return_type</strong> (Union[str, dict, pandas.DataFrame], default: pandas.DataFrame): indicates
the format to of the returned predictions.</li>
<li><strong>debug</strong> (bool, default: <code>False</code>): If <code>True</code> turns on <code>tfdbg</code>
    with <code>inf_or_nan</code> checks.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (<code>evaluation_statistics</code>, <code>predictions</code>, <code>output_directory</code>):
<code>evaluation_statistics</code> dictionary containing evaluation performance
    statistics,
<code>postprocess_predictions</code> contains predicted values,
<code>output_directory</code> is location where results are stored.</li>
</ul>
<hr />
<h3 id="experiment">experiment<a class="headerlink" href="#experiment" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">experiment</span><span class="p">(</span>
  <span class="n">dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">training_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">validation_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">test_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">training_set_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;experiment&#39;</span><span class="p">,</span>
  <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;run&#39;</span><span class="p">,</span>
  <span class="n">model_load_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">model_resume_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">eval_split</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span>
  <span class="n">skip_save_training_description</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_training_statistics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_processed_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_unprocessed_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_predictions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_eval_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_collect_predictions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_collect_overall_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="s1">&#39;results&#39;</span><span class="p">,</span>
  <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>Trains a model on a dataset's training and validation splits and
uses it to predict on the test split.
It saves the trained model and the statistics of training and testing.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>dataset</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing the entire dataset to be used in the experiment.
If it has a split column, it will be used for splitting (0 for train,
1 for validation, 2 for test), otherwise the dataset will be
randomly split.</li>
<li><strong>training_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing training data.</li>
<li><strong>validation_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing validation data.</li>
<li><strong>test_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing test data.</li>
<li><strong>training_set_metadata</strong> (Union[str, dict], default: <code>None</code>):
metadata JSON file or loaded metadata.  Intermediate preprocess
structure containing the mappings of the input
dataset created the first time an input file is used in the same
directory with the same name and a '.meta.json' extension.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
sources. Will be inferred automatically if not specified.  Valid
formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>, <code>'feather'</code>,
<code>'fwf'</code>, <code>'hdf5'</code> (cache file produced during previous training),
<code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>), <code>'json'</code>, <code>'jsonl'</code>,
<code>'parquet'</code>, <code>'pickle'</code> (pickled Pandas DataFrame), <code>'sas'</code>, <code>'spss'</code>,
<code>'stata'</code>, <code>'tsv'</code>.</li>
<li><strong>experiment_name</strong> (str, default: <code>'experiment'</code>): name for
the experiment.</li>
<li><strong>model_name</strong> (str, default: <code>'run'</code>): name of the model that is
being used.</li>
<li><strong>model_load_path</strong> (str, default: <code>None</code>): if this is specified the
loaded model will be used as initialization
(useful for transfer learning).</li>
<li><strong>model_resume_path</strong> (str, default: <code>None</code>): resumes training of
the model from the path specified. The config is restored.
In addition to config, training statistics and loss for
epoch and the state of the optimizer are restored such that
training can be effectively continued from a previously interrupted
training process.</li>
<li><strong>eval_split</strong> (str, default: <code>test</code>): split on which
to perform evaluation. Valid values are <code>training</code>, <code>validation</code>
and <code>test</code>.</li>
<li><strong>skip_save_training_description</strong> (bool, default: <code>False</code>): disables
saving the description JSON file.</li>
<li><strong>skip_save_training_statistics</strong> (bool, default: <code>False</code>): disables
saving training statistics JSON file.</li>
<li><strong>skip_save_model</strong> (bool, default: <code>False</code>): disables
saving model weights and hyperparameters each time the model
improves. By default Ludwig saves model weights after each epoch
the validation metric improves, but if the model is really big
that can be time consuming if you do not want to keep
the weights and just find out what performance a model can get
with a set of hyperparameters, use this parameter to skip it,
but the model will not be loadable later on and the returned model
will have the weights obtained at the end of training, instead of
the weights of the epoch with the best validation performance.</li>
<li><strong>skip_save_progress</strong> (bool, default: <code>False</code>): disables saving
progress each epoch. By default Ludwig saves weights and stats
after each epoch for enabling resuming of training, but if
the model is really big that can be time consuming and will uses
twice as much space, use this parameter to skip it, but training
cannot be resumed later on.</li>
<li><strong>skip_save_log</strong> (bool, default: <code>False</code>): disables saving
TensorBoard logs. By default Ludwig saves logs for the TensorBoard,
but if it is not needed turning it off can slightly increase the
overall speed.</li>
<li><strong>skip_save_processed_input</strong> (bool, default: <code>False</code>): if input
dataset is provided it is preprocessed and cached by saving an HDF5
and JSON files to avoid running the preprocessing again. If this
parameter is <code>False</code>, the HDF5 and JSON file are not saved.</li>
<li><strong>skip_save_unprocessed_output</strong> (bool, default: <code>False</code>): by default
predictions and their probabilities are saved in both raw
unprocessed numpy files containing tensors and as postprocessed
CSV files (one for each output feature). If this parameter is True,
only the CSV ones are saved and the numpy ones are skipped.</li>
<li><strong>skip_save_predictions</strong> (bool, default: <code>False</code>): skips saving test
predictions CSV files</li>
<li><strong>skip_save_eval_stats</strong> (bool, default: <code>False</code>): skips saving test
statistics JSON file</li>
<li><strong>skip_collect_predictions</strong> (bool, default: <code>False</code>): skips
collecting post-processed predictions during eval.</li>
<li><strong>skip_collect_overall_stats</strong> (bool, default: <code>False</code>): skips
collecting overall stats during eval.</li>
<li><strong>output_directory</strong> (str, default: <code>'results'</code>): the directory that
will contain the training statistics, TensorBoard logs, the saved
model and the training progress files.</li>
<li><strong>gpus</strong> (list, default: <code>None</code>): list of GPUs that are available
for training.</li>
<li><strong>gpu_memory_limit</strong> (int, default: <code>None</code>): maximum memory in MB to
allocate per GPU device.</li>
<li><strong>allow_parallel_threads</strong> (bool, default: <code>True</code>): allow TensorFlow
to use multithreading parallelism to improve performance at
the cost of determinism.</li>
<li><strong>use_horovod</strong> (bool, default: <code>None</code>): flag for using horovod.</li>
<li><strong>random_seed</strong> (int: default: 42): random seed used for weights
initialization, splits and any other random function.</li>
<li><strong>debug</strong> (bool, default: <code>False): if</code>True<code>turns on</code>tfdbg<code>with</code>inf_or_nan` checks.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (Tuple[dict, dict, tuple, str)) <code>(evaluation_statistics, training_statistics, preprocessed_data, output_directory):</code>
<code>evaluation_statistics</code> dictionary with evaluation performance
    statistics on the test_set,
<code>training_statistics</code> is a dictionary of training statistics for
    each output
feature containing loss and metrics values for each epoch,
<code>preprocessed_data</code> tuple containing preprocessed
<code>(training_set, validation_set, test_set)</code>, <code>output_directory</code>
filepath string to where results are stored.</li>
</ul>
<hr />
<h3 id="load">load<a class="headerlink" href="#load" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">load</span><span class="p">(</span>
  <span class="n">model_dir</span><span class="p">,</span>
  <span class="n">logging_level</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
  <span class="n">use_horovod</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">gpus</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">gpu_memory_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">allow_parallel_threads</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>


<p>This function allows for loading pretrained models</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>model_dir</strong> (str): path to the directory containing the model.
   If the model was trained by the <code>train</code> or <code>experiment</code> command,
   the model is in <code>results_dir/experiment_dir/model</code>.</li>
<li><strong>logging_level</strong> (int, default: 40): log level that will be sent to
stderr.</li>
<li><strong>use_horovod</strong> (bool, default: <code>None</code>): use Horovod for distributed
training. Will be set
automatically if <code>horovodrun</code> is used to launch the training script.</li>
<li><strong>gpus</strong> (Union[str, int, List[int]], default: <code>None</code>): GPUs
to use (it uses the same syntax of CUDA_VISIBLE_DEVICES)</li>
<li><strong>gpu_memory_limit</strong> (int: default: <code>None</code>): maximum memory in MB to
allocate per GPU device.</li>
<li><strong>allow_parallel_threads</strong> (bool, default: <code>True</code>): allow TensorFlow
to use
multithreading parallelism to improve performance at the cost of
determinism.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (LudwigModel): a LudwigModel object</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig_model</span> <span class="o">=</span> <span class="n">LudwigModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_dir</span><span class="p">)</span>
</code></pre></div>


<hr />
<h3 id="load_weights">load_weights<a class="headerlink" href="#load_weights" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">load_weights</span><span class="p">(</span>
  <span class="n">model_dir</span>
<span class="p">)</span>
</code></pre></div>


<p>Loads weights from a pre-trained model</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>model_dir</strong> (str): filepath string to location of a pre-trained
model</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> ( <code>Non):</code>None`</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">model_dir</span><span class="p">)</span>
</code></pre></div>


<hr />
<h3 id="predict">predict<a class="headerlink" href="#predict" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
  <span class="n">dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">split</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
  <span class="n">skip_save_unprocessed_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">skip_save_predictions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="s1">&#39;results&#39;</span><span class="p">,</span>
  <span class="n">return_type</span><span class="o">=&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">pandas</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">frame</span><span class="o">.</span><span class="n">DataFrame</span><span class="s1">&#39;&gt;,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>Using a trained model, make predictions from the provided dataset.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>dataset</strong> (Union[str, dict, pandas.DataFrame]): source containing
the entire dataset to be evaluated.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
sources. Will be inferred automatically if not specified.  Valid
formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>, <code>'feather'</code>,
<code>'fwf'</code>, <code>'hdf5'</code> (cache file produced during previous training),
<code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>), <code>'json'</code>, <code>'jsonl'</code>,
<code>'parquet'</code>, <code>'pickle'</code> (pickled Pandas DataFrame), <code>'sas'</code>, <code>'spss'</code>,
<code>'stata'</code>, <code>'tsv'</code>.
:param: split: (str, default= <code>'full'</code>): if the input dataset contains
a split column, this parameter indicates which split of the data
to use. Possible values are <code>'full'</code>, <code>'training'</code>, <code>'validation'</code>, <code>'test'</code>.</li>
<li><strong>batch_size</strong> (int, default: 128): size of batch to use when making
predictions.</li>
<li><strong>skip_save_unprocessed_output</strong> (bool, default: <code>True</code>): if this
parameter is <code>False</code>, predictions and their probabilities are saved
in both raw unprocessed numpy files containing tensors and as
postprocessed CSV files (one for each output feature).
If this parameter is <code>True</code>, only the CSV ones are saved and the
numpy ones are skipped.</li>
<li><strong>skip_save_predictions</strong> (bool, default: <code>True</code>): skips saving
test predictions CSV files.</li>
<li><strong>output_directory</strong> (str, default: <code>'results'</code>): the directory that
will contain the training statistics, TensorBoard logs, the saved
model and the training progress files.</li>
<li><strong>return_type</strong> (Union[str, dict, pandas.DataFrame], default: pd.DataFrame):
indicates the format of the returned predictions.</li>
<li><strong>debug</strong> (bool, default: <code>False</code>): If <code>True</code> turns on <code>tfdbg</code>
    with <code>inf_or_nan checks</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (Tuple[Union[dict, pd.DataFrame], str]) <code>(predictions, output_directory):</code>
<code>predictions</code> predictions from the provided dataset,
<code>output_directory</code> filepath string to where data was stored.</li>
</ul>
<hr />
<h3 id="preprocess">preprocess<a class="headerlink" href="#preprocess" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">preprocess</span><span class="p">(</span>
  <span class="n">dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">training_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">validation_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">test_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">training_set_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">skip_save_processed_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>This function is used to preprocess data.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>dataset</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing the entire dataset to be used in the experiment.
If it has a split column, it will be used for splitting
(0 for train, 1 for validation, 2 for test),
otherwise the dataset will be randomly split.</li>
<li><strong>training_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing training data.</li>
<li><strong>validation_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing validation data.</li>
<li><strong>test_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing test data.</li>
<li><strong>training_set_metadata</strong> (Union[str, dict], default: <code>None</code>):
metadata JSON file or loaded metadata. Intermediate preprocess
structure containing the mappings of the input
dataset created the first time an input file is used in the same
directory with the same name and a '.meta.json' extension.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
sources. Will be inferred automatically if not specified.  Valid
formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>,
<code>'feather'</code>, <code>'fwf'</code>,
<code>'hdf5'</code> (cache file produced during previous training),
<code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>),
<code>'json'</code>, <code>'jsonl'</code>, <code>'parquet'</code>,
<code>'pickle'</code> (pickled Pandas DataFrame),
<code>'sas'</code>, <code>'spss'</code>, <code>'stata'</code>, <code>'tsv'</code>.</li>
<li><strong>skip_save_processed_input</strong> (bool, default: <code>False</code>): if input
dataset is provided it is preprocessed and cached by saving an HDF5
and JSON files to avoid running the preprocessing again. If this
parameter is <code>False</code>, the HDF5 and JSON file are not saved.</li>
<li><strong>output_directory</strong> (str, default: <code>'results'</code>): the directory that
will contain the training statistics, TensorBoard logs, the saved
model and the training progress files.</li>
<li><strong>random_seed</strong> (int, default: <code>42</code>): a random seed that will be
   used anywhere there is a call to a random number generator: data
   splitting, parameter initialization and training set shuffling</li>
<li><strong>debug</strong> (bool, default: <code>False</code>):  if <code>True</code> turns on <code>tfdbg</code> with
<code>inf_or_nan</code> checks.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (Tuple[dict, Union[dict, pd.DataFrame], str]): tuple containing
<code>(training_statistics, preprocessed_data, output_directory)</code>.
<code>training_statistics</code> is a dictionary of training statistics
for each output feature containing loss and metrics values
for each epoch.
<code>preprocessed_data</code> is the tuple containing these three data sets
<code>(training_set, validation_set, test_set)</code>.
<code>output_directory</code> filepath to where training results are stored.</li>
</ul>
<hr />
<h3 id="save">save<a class="headerlink" href="#save" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">save</span><span class="p">(</span>
  <span class="n">save_path</span>
<span class="p">)</span>
</code></pre></div>


<p>This function allows to save models on disk</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong> save_path</strong> (str): path to the directory where the model is
    going to be saved. Both a JSON file containing the model
    architecture hyperparameters and checkpoints files containing
    model weights will be saved.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None): <code>None</code></li>
</ul>
<p><strong>Example usage</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</code></pre></div>


<hr />
<h3 id="save_config">save_config<a class="headerlink" href="#save_config" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">save_config</span><span class="p">(</span>
  <span class="n">save_path</span>
<span class="p">)</span>
</code></pre></div>


<p>Save config to specoficed location.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>save_path</strong> (str): filepath string to save config as a
JSON file.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> ( <code>Non):</code>None`</li>
</ul>
<hr />
<h3 id="save_savedmodel">save_savedmodel<a class="headerlink" href="#save_savedmodel" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">save_savedmodel</span><span class="p">(</span>
  <span class="n">save_path</span>
<span class="p">)</span>
</code></pre></div>


<p>This function allows to save models on disk</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong> save_path</strong> (str): path to the directory where the SavedModel
    is going to be saved.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> ( <code>Non):</code>None`</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig_model</span><span class="o">.</span><span class="n">save_for_serving</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</code></pre></div>


<hr />
<h3 id="set_logging_level">set_logging_level<a class="headerlink" href="#set_logging_level" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">set_logging_level</span><span class="p">(</span>
  <span class="n">logging_level</span>
<span class="p">)</span>
</code></pre></div>


<p>Sets level for log messages.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>logging_level</strong> (int): Set/Update the logging level. Use logging
constants like <code>logging.DEBUG</code> , <code>logging.INFO</code> and <code>logging.ERROR</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> ( <code>None):</code>None`</li>
</ul>
<hr />
<h3 id="train">train<a class="headerlink" href="#train" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">train</span><span class="p">(</span>
  <span class="n">dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">training_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">validation_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">test_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">training_set_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;api_experiment&#39;</span><span class="p">,</span>
  <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;run&#39;</span><span class="p">,</span>
  <span class="n">model_resume_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">skip_save_training_description</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_training_statistics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_processed_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="s1">&#39;results&#39;</span><span class="p">,</span>
  <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>This function is used to perform a full training of the model on the
specified dataset.</p>
<p>During training if the skip parameters are False
the model and statistics will be saved in a directory
<code>[output_dir]/[experiment_name]_[model_name]_n</code> where all variables are
resolved to user specified ones and <code>n</code> is an increasing number
starting from 0 used to differentiate among repeated runs.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>dataset</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing the entire dataset to be used in the experiment.
If it has a split column, it will be used for splitting
(0 for train, 1 for validation, 2 for test),
otherwise the dataset will be randomly split.</li>
<li><strong>training_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing training data.</li>
<li><strong>validation_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing validation data.</li>
<li><strong>test_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing test data.</li>
<li><strong>training_set_metadata</strong> (Union[str, dict], default: <code>None</code>):
metadata JSON file or loaded metadata. Intermediate preprocess
structure containing the mappings of the input
dataset created the first time an input file is used in the same
directory with the same name and a '.meta.json' extension.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
sources. Will be inferred automatically if not specified.  Valid
formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>,
<code>'feather'</code>, <code>'fwf'</code>,
<code>'hdf5'</code> (cache file produced during previous training),
<code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>),
<code>'json'</code>, <code>'jsonl'</code>, <code>'parquet'</code>,
<code>'pickle'</code> (pickled Pandas DataFrame),
<code>'sas'</code>, <code>'spss'</code>, <code>'stata'</code>, <code>'tsv'</code>.</li>
<li><strong>experiment_name</strong> (str, default: <code>'experiment'</code>): name for
the experiment.</li>
<li><strong>model_name</strong> (str, default: <code>'run'</code>): name of the model that is
being used.</li>
<li><strong>model_resume_path</strong> (str, default: <code>None</code>): resumes training of
the model from the path specified. The config is restored.
In addition to config, training statistics, loss for each
epoch and the state of the optimizer are restored such that
training can be effectively continued from a previously interrupted
training process.</li>
<li><strong>skip_save_training_description</strong> (bool, default: <code>False</code>):
disables saving the description JSON file.</li>
<li><strong>skip_save_training_statistics</strong> (bool, default: <code>False</code>):
disables saving training statistics JSON file.</li>
<li><strong>skip_save_model</strong> (bool, default: <code>False</code>): disables
saving model weights and hyperparameters each time the model
improves. By default Ludwig saves model weights after each epoch
the validation metric improves, but if the model is really big
that can be time consuming if you do not want to keep
the weights and just find out what performance a model can get
with a set of hyperparameters, use this parameter to skip it,
but the model will not be loadable later on and the returned model
will have the weights obtained at the end of training, instead of
the weights of the epoch with the best validation performance.</li>
<li><strong>skip_save_progress</strong> (bool, default: <code>False</code>): disables saving
progress each epoch. By default Ludwig saves weights and stats
after each epoch for enabling resuming of training, but if
the model is really big that can be time consuming and will uses
twice as much space, use this parameter to skip it, but training
cannot be resumed later on.</li>
<li><strong>skip_save_log</strong> (bool, default: <code>False</code>): disables saving
TensorBoard logs. By default Ludwig saves logs for the TensorBoard,
but if it is not needed turning it off can slightly increase the
overall speed.</li>
<li><strong>skip_save_processed_input</strong> (bool, default: <code>False</code>): if input
dataset is provided it is preprocessed and cached by saving an HDF5
and JSON files to avoid running the preprocessing again. If this
parameter is <code>False</code>, the HDF5 and JSON file are not saved.</li>
<li><strong>output_directory</strong> (str, default: <code>'results'</code>): the directory that
will contain the training statistics, TensorBoard logs, the saved
model and the training progress files.</li>
<li><strong>random_seed</strong> (int, default: <code>42</code>): a random seed that will be
   used anywhere there is a call to a random number generator: data
   splitting, parameter initialization and training set shuffling</li>
<li><strong>debug</strong> (bool, default: <code>False</code>):  if <code>True</code> turns on <code>tfdbg</code> with
<code>inf_or_nan</code> checks.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (Tuple[dict, Union[dict, pd.DataFrame], str]): tuple containing
<code>(training_statistics, preprocessed_data, output_directory)</code>.
<code>training_statistics</code> is a dictionary of training statistics
for each output feature containing loss and metrics values
for each epoch.
<code>preprocessed_data</code> is the tuple containing these three data sets
<code>(training_set, validation_set, test_set)</code>.
<code>output_directory</code> filepath to where training results are stored.</li>
</ul>
<hr />
<h3 id="train_online">train_online<a class="headerlink" href="#train_online" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">train_online</span><span class="p">(</span>
  <span class="n">dataset</span><span class="p">,</span>
  <span class="n">training_set_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
  <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>Performs one epoch of training of the model on <code>dataset</code>.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>dataset</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing the entire dataset to be used in the experiment.
If it has a split column, it will be used for splitting (0 for train,
1 for validation, 2 for test), otherwise the dataset will be
randomly split.</li>
<li><strong>training_set_metadata</strong> (Union[str, dict], default: <code>None</code>):
metadata JSON file or loaded metadata.  Intermediate preprocess
structure containing the mappings of the input
dataset created the first time an input file is used in the same
directory with the same name and a '.meta.json' extension.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
sources. Will be inferred automatically if not specified.  Valid
formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>, <code>'feather'</code>,
<code>'fwf'</code>, <code>'hdf5'</code> (cache file produced during previous training),
<code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>), <code>'json'</code>, <code>'jsonl'</code>,
<code>'parquet'</code>, <code>'pickle'</code> (pickled Pandas DataFrame), <code>'sas'</code>, <code>'spss'</code>,
<code>'stata'</code>, <code>'tsv'</code>.</li>
<li><strong>random_seed</strong> (int, default: <code>42</code>): a random seed that is going to be
   used anywhere there is a call to a random number generator: data
   splitting, parameter initialization and training set shuffling</li>
<li><strong>debug</strong> (bool, default: <code>False</code>): If <code>True</code> turns on <code>tfdbg</code>
    with <code>inf_or_nan</code> checks.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None): <code>None</code></li>
</ul>
<hr />
<h2 id="module-functions">Module functions<a class="headerlink" href="#module-functions" title="Permanent link">&para;</a></h2>
<hr />
<h3 id="kfold_cross_validate">kfold_cross_validate<a class="headerlink" href="#kfold_cross_validate" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">kfold_cross_validate</span><span class="p">(</span>
  <span class="n">num_folds</span><span class="p">,</span>
  <span class="n">config</span><span class="p">,</span>
  <span class="n">dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">skip_save_training_description</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_training_statistics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_processed_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_predictions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_eval_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_collect_predictions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_collect_overall_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="s1">&#39;results&#39;</span><span class="p">,</span>
  <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
  <span class="n">gpus</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">gpu_memory_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">allow_parallel_threads</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">use_horovod</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">logging_level</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>Performs k-fold cross validation and returns result data structures.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>num_folds</strong> (int): number of folds to create for the cross-validation</li>
<li><strong>config</strong> (Union[dict, str]): model specification
   required to build a model. Parameter may be a dictionary or string
   specifying the file path to a yaml configuration file.  Refer to the
   <a href="http://ludwig.ai/user_guide/#model-config">User Guide</a>
   for details.</li>
<li><strong>dataset</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing the entire dataset to be used for k_fold processing.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
    sources. Will be inferred automatically if not specified.  Valid
    formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>, <code>'feather'</code>,
    <code>'fwf'</code>,
    <code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>), <code>'json'</code>, <code>'jsonl'</code>,
    <code>'parquet'</code>, <code>'pickle'</code> (pickled Pandas DataFrame), <code>'sas'</code>, <code>'spss'</code>,
    <code>'stata'</code>, <code>'tsv'</code>.  Currenlty <code>hdf5</code> format is not supported for
    k_fold cross validation.</li>
<li><strong>skip_save_training_description</strong> (bool, default: <code>False</code>): disables
    saving the description JSON file.</li>
<li><strong>skip_save_training_statistics</strong> (bool, default: <code>False</code>): disables
    saving training statistics JSON file.</li>
<li><strong>skip_save_model</strong> (bool, default: <code>False</code>): disables
saving model weights and hyperparameters each time the model
improves. By default Ludwig saves model weights after each epoch
the validation metric improves, but if the model is really big
that can be time consuming if you do not want to keep
the weights and just find out what performance a model can get
with a set of hyperparameters, use this parameter to skip it,
but the model will not be loadable later on and the returned model
will have the weights obtained at the end of training, instead of
the weights of the epoch with the best validation performance.</li>
<li><strong>skip_save_progress</strong> (bool, default: <code>False</code>): disables saving
   progress each epoch. By default Ludwig saves weights and stats
   after each epoch for enabling resuming of training, but if
   the model is really big that can be time consuming and will uses
   twice as much space, use this parameter to skip it, but training
   cannot be resumed later on.</li>
<li><strong>skip_save_log</strong> (bool, default: <code>False</code>): disables saving TensorBoard
   logs. By default Ludwig saves logs for the TensorBoard, but if it
   is not needed turning it off can slightly increase the
   overall speed.</li>
<li><strong>skip_save_processed_input</strong> (bool, default: <code>False</code>): if input
dataset is provided it is preprocessed and cached by saving an HDF5
and JSON files to avoid running the preprocessing again. If this
parameter is <code>False</code>, the HDF5 and JSON file are not saved.</li>
<li><strong>skip_save_predictions</strong> (bool, default: <code>False</code>): skips saving test
    predictions CSV files.</li>
<li><strong>skip_save_eval_stats</strong> (bool, default: <code>False</code>): skips saving test
    statistics JSON file.</li>
<li><strong>skip_collect_predictions</strong> (bool, default: <code>False</code>): skips collecting
    post-processed predictions during eval.</li>
<li><strong>skip_collect_overall_stats</strong> (bool, default: <code>False</code>): skips collecting
    overall stats during eval.</li>
<li><strong>output_directory</strong> (str, default: <code>'results'</code>): the directory that
will contain the training statistics, TensorBoard logs, the saved
model and the training progress files.</li>
<li><strong>random_seed</strong> (int, default: <code>42</code>): Random seed
    used for weights initialization,
   splits and any other random function.</li>
<li><strong>gpus</strong> (list, default: <code>None</code>): list of GPUs that are available
    for training.</li>
<li><strong>gpu_memory_limit</strong> (int, default: <code>None</code>): maximum memory in MB to
    allocate per GPU device.</li>
<li><strong>allow_parallel_threads</strong> (bool, default: <code>True</code>): allow TensorFlow to
    use multithreading parallelism
   to improve performance at the cost of determinism.</li>
<li><strong>use_horovod</strong> (bool, default: <code>None</code>): flag for using horovod</li>
<li><strong>debug</strong> (bool, default: <code>False</code>): If <code>True</code> turns on tfdbg
    with <code>inf_or_nan</code> checks.</li>
<li><strong>logging_level</strong> (int, default: INFO): log level to send to stderr.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (tuple(kfold_cv_statistics, kfold_split_indices), dict): a tuple of
    dictionaries <code>kfold_cv_statistics</code>: contains metrics from cv run.
     <code>kfold_split_indices</code>: indices to split training data into
     training fold and test fold.</li>
</ul>
<hr />
<h3 id="hyperopt">hyperopt<a class="headerlink" href="#hyperopt" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">hyperopt</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">hyperopt</span><span class="p">(</span>
  <span class="n">config</span><span class="p">,</span>
  <span class="n">dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">training_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">validation_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">test_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">training_set_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;hyperopt&#39;</span><span class="p">,</span>
  <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;run&#39;</span><span class="p">,</span>
  <span class="n">skip_save_training_description</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_training_statistics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_processed_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_unprocessed_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_predictions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_eval_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">skip_save_hyperopt_statistics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="s1">&#39;results&#39;</span><span class="p">,</span>
  <span class="n">gpus</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">gpu_memory_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">allow_parallel_threads</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">use_horovod</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
  <span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>


<p>This method performs an hyperparameter optimization.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>config</strong> (Union[str, dict]): config which defines
the different parameters of the model, features, preprocessing and
training.  If <code>str</code>, filepath to yaml configuration file.</li>
<li><strong>dataset</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing the entire dataset to be used in the experiment.
If it has a split column, it will be used for splitting (0 for train,
1 for validation, 2 for test), otherwise the dataset will be
randomly split.</li>
<li><strong>training_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing training data.</li>
<li><strong>validation_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing validation data.</li>
<li><strong>test_set</strong> (Union[str, dict, pandas.DataFrame], default: <code>None</code>):
source containing test data.</li>
<li><strong>training_set_metadata</strong> (Union[str, dict], default: <code>None</code>):
metadata JSON file or loaded metadata.  Intermediate preprocess
structure containing the mappings of the input
dataset created the first time an input file is used in the same
directory with the same name and a '.meta.json' extension.</li>
<li><strong>data_format</strong> (str, default: <code>None</code>): format to interpret data
sources. Will be inferred automatically if not specified.  Valid
formats are <code>'auto'</code>, <code>'csv'</code>, <code>'df'</code>, <code>'dict'</code>, <code>'excel'</code>, <code>'feather'</code>,
<code>'fwf'</code>, <code>'hdf5'</code> (cache file produced during previous training),
<code>'html'</code> (file containing a single HTML <code>&lt;table&gt;</code>), <code>'json'</code>, <code>'jsonl'</code>,
<code>'parquet'</code>, <code>'pickle'</code> (pickled Pandas DataFrame), <code>'sas'</code>, <code>'spss'</code>,
<code>'stata'</code>, <code>'tsv'</code>.</li>
<li><strong>experiment_name</strong> (str, default: <code>'experiment'</code>): name for
the experiment.</li>
<li><strong>model_name</strong> (str, default: <code>'run'</code>): name of the model that is
being used.</li>
<li><strong>skip_save_training_description</strong> (bool, default: <code>False</code>): disables
saving the description JSON file.</li>
<li><strong>skip_save_training_statistics</strong> (bool, default: <code>False</code>): disables
saving training statistics JSON file.</li>
<li><strong>skip_save_model</strong> (bool, default: <code>False</code>): disables
saving model weights and hyperparameters each time the model
improves. By default Ludwig saves model weights after each epoch
the validation metric improves, but if the model is really big
that can be time consuming if you do not want to keep
the weights and just find out what performance a model can get
with a set of hyperparameters, use this parameter to skip it,
but the model will not be loadable later on and the returned model
will have the weights obtained at the end of training, instead of
the weights of the epoch with the best validation performance.</li>
<li><strong>skip_save_progress</strong> (bool, default: <code>False</code>): disables saving
progress each epoch. By default Ludwig saves weights and stats
after each epoch for enabling resuming of training, but if
the model is really big that can be time consuming and will uses
twice as much space, use this parameter to skip it, but training
cannot be resumed later on.</li>
<li><strong>skip_save_log</strong> (bool, default: <code>False</code>): disables saving
TensorBoard logs. By default Ludwig saves logs for the TensorBoard,
but if it is not needed turning it off can slightly increase the
overall speed.</li>
<li><strong>skip_save_processed_input</strong> (bool, default: <code>False</code>): if input
dataset is provided it is preprocessed and cached by saving an HDF5
and JSON files to avoid running the preprocessing again. If this
parameter is <code>False</code>, the HDF5 and JSON file are not saved.</li>
<li><strong>skip_save_unprocessed_output</strong> (bool, default: <code>False</code>): by default
predictions and their probabilities are saved in both raw
unprocessed numpy files containing tensors and as postprocessed
CSV files (one for each output feature). If this parameter is True,
only the CSV ones are saved and the numpy ones are skipped.</li>
<li><strong>skip_save_predictions</strong> (bool, default: <code>False</code>): skips saving test
predictions CSV files.</li>
<li><strong>skip_save_eval_stats</strong> (bool, default: <code>False</code>): skips saving test
statistics JSON file.</li>
<li><strong>skip_save_hyperopt_statistics</strong> (bool, default: <code>False</code>): skips saving
hyperopt stats file.</li>
<li><strong>output_directory</strong> (str, default: <code>'results'</code>): the directory that
will contain the training statistics, TensorBoard logs, the saved
model and the training progress files.</li>
<li><strong>gpus</strong> (list, default: <code>None</code>): list of GPUs that are available
for training.</li>
<li><strong>gpu_memory_limit</strong> (int, default: <code>None</code>): maximum memory in MB to
allocate per GPU device.</li>
<li><strong>allow_parallel_threads</strong> (bool, default: <code>True</code>): allow TensorFlow
to use multithreading parallelism to improve performance at
the cost of determinism.</li>
<li><strong>use_horovod</strong> (bool, default: <code>None</code>): flag for using horovod.</li>
<li><strong>random_seed</strong> (int: default: 42): random seed used for weights
initialization, splits and any other random function.</li>
<li><strong>debug</strong> (bool, default: <code>False): if</code>True<code>turns on</code>tfdbg<code>with</code>inf_or_nan` checks.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (List[dict]): The results for the hyperparameter optimization</li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

<!-- Application footer -->
<footer class="md-footer">

    <!-- Link to previous and/or next page -->
    
    <div class="md-footer-nav">
        <nav aria-label="Footer"
             class="md-footer-nav__inner md-grid">
            
            <a class="md-footer-nav__link md-footer-nav__link--prev"
               href="../../developer_guide/" rel="prev"
               title="Developer Guide">
                <div class="md-footer-nav__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
                </div>
                <div class="md-footer-nav__title">
                    <div class="md-ellipsis">
                 <span class="md-footer-nav__direction">
                   Previous
                 </span>
                        Developer Guide
                    </div>
                </div>
            </a>
            
            
            <a class="md-footer-nav__link md-footer-nav__link--next"
               href="../visualization/" rel="next"
               title="Visualization">
                <div class="md-footer-nav__title">
                    <div class="md-ellipsis">
                 <span class="md-footer-nav__direction">
                   Next
                 </span>
                        Visualization
                    </div>
                </div>
                <div class="md-footer-nav__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
                </div>
            </a>
            
        </nav>
    </div>
    

    <!-- Further information -->
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">

            <!-- Copyright and theme information -->
            <div class="md-footer-copyright">
                <div class="footer-logo-smallpad"></div>
                
                <div class="md-footer-copyright__highlight">
                    Copyright &copy; 2018 - 2020 Uber Technologies Inc.
                </div>
                
                Website by <a href="http://w4nderlu.st">w4nderlust</a> powered by
                <a href="https://www.mkdocs.org">MkDocs</a>,
                <a href="https://squidfunk.github.io/mkdocs-material/">Material for MkDocs</a>,
                <a href="http://www.styleshout.com/">styleshout</a> and
                <a href="http://cables.gl/">cables</a>.
            </div>

            <!-- Social links -->
            
            
            
        </div>
    </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.77e55a48.min.js"></script>
      <script src="../../assets/javascripts/bundle.9554a270.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>