
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Deep learning toolbox">
      
      
        <link rel="canonical" href="https://ludwig-ai.github.io/ludwig-docs/api/visualization/">
      
      
        <meta name="author" content="Piero Molino">
      
      <link rel="shortcut icon" href="../../favicon.ico">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.0.2">
    
    
      
        <title>Visualization - Ludwig</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.38780c08.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.3f72e892.min.css">
        
          
          
          <meta name="theme-color" content="#757575">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../stylesheets/monokai.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="grey" data-md-color-accent="grey">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-functions" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://ludwig-ai.github.io/ludwig-docs/" title="Ludwig" class="md-header-nav__button md-logo" aria-label="Ludwig">
      
<img alt="logo" src="../../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Ludwig
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Visualization
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/uber/ludwig/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    uber/ludwig
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav aria-label="Navigation" class="md-nav md-nav--primary"
     data-md-level="0">
    <label class="md-nav__title" for="__drawer">
        <a aria-label="Ludwig" class="md-nav__button md-logo"
           href="https://ludwig-ai.github.io/ludwig-docs/"
           title="Ludwig">
            <img alt="logo" src="../../images/ludwig_logo.svg"
                 style="width:10rem;height:auto;">
        </a>
    </label>
    
    <div class="md-nav__source">
        
<a href="https://github.com/uber/ludwig/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    uber/ludwig
  </div>
</a>
    </div>
    
    <ul class="md-nav__list" data-md-scrollfix>
        
        
        
        


  <li class="md-nav__item">
    <a href="../.." class="md-nav__link">
      About
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../getting_started/" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../examples/" class="md-nav__link">
      Examples
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../user_guide/" class="md-nav__link">
      User Guide
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../developer_guide/" class="md-nav__link">
      Developer Guide
    </a>
  </li>

        
        
        
        

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6" checked>
    
    <label class="md-nav__link" for="nav-6">
      API
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="API" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon"></span>
        API
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../LudwigModel/" class="md-nav__link">
      LudwigModel
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Visualization
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      Visualization
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module-functions" class="md-nav__link">
    Module functions
  </a>
  
    <nav class="md-nav" aria-label="Module functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning_curves" class="md-nav__link">
    learning_curves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_performance" class="md-nav__link">
    compare_performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_from_prob" class="md-nav__link">
    compare_classifiers_performance_from_prob
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_from_pred" class="md-nav__link">
    compare_classifiers_performance_from_pred
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_subset" class="md-nav__link">
    compare_classifiers_performance_subset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_changing_k" class="md-nav__link">
    compare_classifiers_performance_changing_k
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_multiclass_multimetric" class="md-nav__link">
    compare_classifiers_multiclass_multimetric
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_predictions" class="md-nav__link">
    compare_classifiers_predictions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_2thresholds_2d" class="md-nav__link">
    confidence_thresholding_2thresholds_2d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_2thresholds_3d" class="md-nav__link">
    confidence_thresholding_2thresholds_3d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding" class="md-nav__link">
    confidence_thresholding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc" class="md-nav__link">
    confidence_thresholding_data_vs_acc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc_subset" class="md-nav__link">
    confidence_thresholding_data_vs_acc_subset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary_threshold_vs_metric" class="md-nav__link">
    binary_threshold_vs_metric
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_curves" class="md-nav__link">
    roc_curves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_curves_from_test_statistics" class="md-nav__link">
    roc_curves_from_test_statistics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calibration_1_vs_all" class="md-nav__link">
    calibration_1_vs_all
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calibration_multiclass" class="md-nav__link">
    calibration_multiclass
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confusion_matrix" class="md-nav__link">
    confusion_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frequency_vs_f1" class="md-nav__link">
    frequency_vs_f1
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt_report" class="md-nav__link">
    hyperopt_report
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt_hiplot" class="md-nav__link">
    hyperopt_hiplot
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../community/" class="md-nav__link">
      Community
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../../faq/" class="md-nav__link">
      FAQ
    </a>
  </li>

        
    </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module-functions" class="md-nav__link">
    Module functions
  </a>
  
    <nav class="md-nav" aria-label="Module functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning_curves" class="md-nav__link">
    learning_curves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_performance" class="md-nav__link">
    compare_performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_from_prob" class="md-nav__link">
    compare_classifiers_performance_from_prob
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_from_pred" class="md-nav__link">
    compare_classifiers_performance_from_pred
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_subset" class="md-nav__link">
    compare_classifiers_performance_subset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_changing_k" class="md-nav__link">
    compare_classifiers_performance_changing_k
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_multiclass_multimetric" class="md-nav__link">
    compare_classifiers_multiclass_multimetric
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_predictions" class="md-nav__link">
    compare_classifiers_predictions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_2thresholds_2d" class="md-nav__link">
    confidence_thresholding_2thresholds_2d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_2thresholds_3d" class="md-nav__link">
    confidence_thresholding_2thresholds_3d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding" class="md-nav__link">
    confidence_thresholding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc" class="md-nav__link">
    confidence_thresholding_data_vs_acc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc_subset" class="md-nav__link">
    confidence_thresholding_data_vs_acc_subset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary_threshold_vs_metric" class="md-nav__link">
    binary_threshold_vs_metric
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_curves" class="md-nav__link">
    roc_curves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_curves_from_test_statistics" class="md-nav__link">
    roc_curves_from_test_statistics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calibration_1_vs_all" class="md-nav__link">
    calibration_1_vs_all
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calibration_multiclass" class="md-nav__link">
    calibration_multiclass
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confusion_matrix" class="md-nav__link">
    confusion_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frequency_vs_f1" class="md-nav__link">
    frequency_vs_f1
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt_report" class="md-nav__link">
    hyperopt_report
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt_hiplot" class="md-nav__link">
    hyperopt_hiplot
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/uber/ludwig/edit/master/mkdocs/docs/api/visualization.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  <h1>Visualization</h1>
                
                <h2 id="module-functions">Module functions<a class="headerlink" href="#module-functions" title="Permanent link">&para;</a></h2>
<hr />
<h3 id="learning_curves">learning_curves<a class="headerlink" href="#learning_curves" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">learning_curves</span><span class="p">(</span>
  <span class="n">train_stats_per_model</span><span class="p">,</span>
  <span class="n">output_feature_name</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show how model metrics change over training and validation data epochs.</p>
<p>For each model and for each output feature and metric of the model,
it produces a line plot showing how that metric changed over the course
of the epochs of training on the training and validation sets.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>train_stats_per_model</strong> (List[dict]): list containing dictionary of
training statistics per model.</li>
<li><strong>output_feature_name</strong> (Union[str, <code>None</code>]): name of the output feature
to use for the visualization.  If <code>None</code>, use all output features.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="compare_performance">compare_performance<a class="headerlink" href="#compare_performance" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">compare_performance</span><span class="p">(</span>
  <span class="n">test_stats_per_model</span><span class="p">,</span>
  <span class="n">output_feature_name</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Produces model comparison barplot visualization for each overall metric</p>
<p>For each model (in the aligned lists of test_statistics and model_names)
it produces bars in a bar plot, one for each overall metric available
in the test_statistics file for the specified output_feature_name.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>test_stats_per_model</strong> (List[dict]): dictionary containing evaluation
performance statistics.</li>
<li><strong>output_feature_name</strong> (Union[str, <code>None</code>]): name of the output feature
to use for the visualization.  If <code>None</code>, use all output features.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="compare_classifiers_performance_from_prob">compare_classifiers_performance_from_prob<a class="headerlink" href="#compare_classifiers_performance_from_prob" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">compare_classifiers_performance_from_prob</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">top_n_classes</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Produces model comparison barplot visualization from probabilities.</p>
<p>For each model it produces bars in a bar plot, one for each overall metric
computed on the fly from the probabilities of predictions for the specified
<code>model_names</code>.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>top_n_classes</strong> (List[int]): list containing the number of classes
to plot.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="compare_classifiers_performance_from_pred">compare_classifiers_performance_from_pred<a class="headerlink" href="#compare_classifiers_performance_from_pred" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">compare_classifiers_performance_from_pred</span><span class="p">(</span>
  <span class="n">predictions_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">metadata</span><span class="p">,</span>
  <span class="n">output_feature_name</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Produces model comparison barplot visualization from predictions.</p>
<p>For each model it produces bars in a bar plot, one for each overall metric
computed on the fly from the predictions for the specified
<code>model_names</code>.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>predictions_per_model</strong> (List[list]): list containing the model
predictions for the specified output_feature_name.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>metadata</strong> (dict): intermediate preprocess structure created during
training containing the mappings of the input dataset.</li>
<li><strong>output_feature_name</strong> (str): name of the output feature to use
for the visualization.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="compare_classifiers_performance_subset">compare_classifiers_performance_subset<a class="headerlink" href="#compare_classifiers_performance_subset" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">compare_classifiers_performance_subset</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">top_n_classes</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">subset</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Produces model comparison barplot visualization from train subset.</p>
<p>For each model  it produces bars in a bar plot, one for each overall metric
computed on the fly from the probabilities predictions for the
specified <code>model_names</code>, considering only a subset of the full training set.
The way the subset is obtained is using the <code>top_n_classes</code> and
<code>subset</code> parameters.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
   probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
   which are the numeric encoded values the category.</li>
<li><strong>top_n_classes</strong> (List[int]): list containing the number of classes
   to plot.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
   Encoded numeric label values in dataset that are higher than
   <code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>subset</strong> (str): string specifying type of subset filtering.  Valid
   values are <code>ground_truth</code> or <code>predictions</code>.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
   list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
   plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
   <code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="compare_classifiers_performance_changing_k">compare_classifiers_performance_changing_k<a class="headerlink" href="#compare_classifiers_performance_changing_k" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">compare_classifiers_performance_changing_k</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">top_k</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Produce lineplot that show Hits@K metric while k goes from 1 to <code>top_k</code>.</p>
<p>For each model it produces a line plot that shows the Hits@K metric
(that counts a prediction as correct if the model produces it among the
first k) while changing k from 1 to top_k for the specified
<code>output_feature_name</code>.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>top_k</strong> (int): number of elements in the ranklist to consider.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="compare_classifiers_multiclass_multimetric">compare_classifiers_multiclass_multimetric<a class="headerlink" href="#compare_classifiers_multiclass_multimetric" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">compare_classifiers_multiclass_multimetric</span><span class="p">(</span>
  <span class="n">test_stats_per_model</span><span class="p">,</span>
  <span class="n">metadata</span><span class="p">,</span>
  <span class="n">output_feature_name</span><span class="p">,</span>
  <span class="n">top_n_classes</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show the precision, recall and F1 of the model for the specified output_feature_name.</p>
<p>For each model it produces four plots that show the precision,
recall and F1 of the model on several classes for the specified output_feature_name.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>test_stats_per_model</strong> (List[dict]): list containing dictionary of
evaluation performance statistics</li>
<li><strong>metadata</strong> (dict): intermediate preprocess structure created during
training containing the mappings of the input dataset.</li>
<li><strong>output_feature_name</strong> (Union[str, <code>None</code>]): name of the output feature
to use for the visualization.  If <code>None</code>, use all output features.</li>
<li><strong>top_n_classes</strong> (List[int]): list containing the number of classes
to plot.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="compare_classifiers_predictions">compare_classifiers_predictions<a class="headerlink" href="#compare_classifiers_predictions" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">compare_classifiers_predictions</span><span class="p">(</span>
  <span class="n">predictions_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show two models comparison of their output_feature_name predictions.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>predictions_per_model</strong> (List[list]): list containing the model
predictions for the specified output_feature_name.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="confidence_thresholding_2thresholds_2d">confidence_thresholding_2thresholds_2d<a class="headerlink" href="#confidence_thresholding_2thresholds_2d" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">confidence_thresholding_2thresholds_2d</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truths</span><span class="p">,</span>
  <span class="n">threshold_output_feature_names</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show confidence threshold data vs accuracy for two output feature names.</p>
<p>The first plot shows several semi transparent lines. They summarize the
3d surfaces displayed by confidence_thresholding_2thresholds_3d that have
thresholds on the confidence of the predictions of the two
<code>threshold_output_feature_names</code>  as x and y axes and either the data
coverage percentage or
the accuracy as z axis. Each line represents a slice of the data
coverage  surface projected onto the accuracy surface.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>threshold_output_feature_names</strong> (List[str]): List containing two output
feature names for visualization.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="confidence_thresholding_2thresholds_3d">confidence_thresholding_2thresholds_3d<a class="headerlink" href="#confidence_thresholding_2thresholds_3d" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">confidence_thresholding_2thresholds_3d</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truths</span><span class="p">,</span>
  <span class="n">threshold_output_feature_names</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show 3d confidence threshold data vs accuracy for two output feature names.</p>
<p>The plot shows the 3d surfaces displayed by
confidence_thresholding_2thresholds_3d that have thresholds on the
confidence of the predictions of the two <code>threshold_output_feature_names</code>
as x and y axes and either the data coverage percentage or the accuracy
as z axis.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>threshold_output_feature_names</strong> (List[str]): List containing two output
feature names for visualization.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="confidence_thresholding">confidence_thresholding<a class="headerlink" href="#confidence_thresholding" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">confidence_thresholding</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show models accuracy and data coverage while increasing treshold</p>
<p>For each model it produces a pair of lines indicating the accuracy of
the model and the data coverage while increasing a threshold (x axis) on
the probabilities of predictions for the specified output_feature_name.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="confidence_thresholding_data_vs_acc">confidence_thresholding_data_vs_acc<a class="headerlink" href="#confidence_thresholding_data_vs_acc" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">confidence_thresholding_data_vs_acc</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show models comparison of confidence threshold data vs accuracy.</p>
<p>For each model it produces a line indicating the accuracy of the model
and the data coverage while increasing a threshold on the probabilities
of predictions for the specified output_feature_name. The difference with
confidence_thresholding is that it uses two axes instead of three,
not visualizing the threshold and having coverage as x axis instead of
the threshold.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="confidence_thresholding_data_vs_acc_subset">confidence_thresholding_data_vs_acc_subset<a class="headerlink" href="#confidence_thresholding_data_vs_acc_subset" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">confidence_thresholding_data_vs_acc_subset</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">top_n_classes</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">subset</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show models comparison of confidence threshold data vs accuracy on a
subset of data.</p>
<p>For each model it produces a line indicating the accuracy of the model
and the data coverage while increasing a threshold on the probabilities
of predictions for the specified output_feature_name, considering only a subset of the
full training set. The way the subset is obtained is using the <code>top_n_classes</code>
and subset parameters.
The difference with confidence_thresholding is that it uses two axes
instead of three, not visualizing the threshold and having coverage as
x axis instead of the threshold.</p>
<p>If the values of subset is <code>ground_truth</code>, then only datapoints where the
ground truth class is within the top n most frequent ones will be
considered  as test set, and the percentage of datapoints that have been
kept  from the original set will be displayed. If the values of subset is
<code>predictions</code>, then only datapoints where the the model predicts a class
that is within the top n most frequent ones will be considered as test set,
and the percentage of datapoints that have been kept from the original set
will be displayed for each model.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>top_n_classes</strong> (List[int]): list containing the number of classes
to plot.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>subset</strong> (str): string specifying type of subset filtering.  Valid
values are <code>ground_truth</code> or <code>predictions</code>.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="binary_threshold_vs_metric">binary_threshold_vs_metric<a class="headerlink" href="#binary_threshold_vs_metric" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">binary_threshold_vs_metric</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">metrics</span><span class="p">,</span>
  <span class="n">positive_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show confidence of the model against metric for the specified output_feature_name.</p>
<p>For each metric specified in metrics (options are <code>f1</code>, <code>precision</code>, <code>recall</code>,
<code>accuracy</code>), this visualization produces a line chart plotting a threshold
on  the confidence of the model against the metric for the specified
output_feature_name.  If output_feature_name is a category feature,
positive_label, which is specified as the numeric encoded value, indicates
the class to be considered positive class and all others will be
considered negative. To figure out the
association between classes and numeric encoded values check the
ground_truth_metadata JSON file.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>metrics</strong> (List[str]): metrics to display (<code>'f1'</code>, <code>'precision'</code>,
<code>'recall'</code>, <code>'accuracy'</code>).</li>
<li><strong>positive_label</strong> (int, default: <code>1</code>): numeric encoded value for the
positive class.</li>
<li><strong>model_names</strong> (List[str], default: <code>None</code>): list of the names of the
models to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (<code>None</code>):</li>
</ul>
<hr />
<h3 id="roc_curves">roc_curves<a class="headerlink" href="#roc_curves" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">roc_curves</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">positive_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show the roc curves for output features in the specified models.</p>
<p>This visualization produces a line chart plotting the roc curves for the
specified output feature name. If output feature name is a category feature,
<code>positive_label</code> indicates which is the class to be considered positive
class and all the others will be considered negative. <code>positive_label</code> is
the encoded numeric value for category classes. The numeric value can be
determined by association between classes and integers captured in the
training metadata JSON file.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>positive_label</strong> (int, default: <code>1</code>): numeric encoded value for the
positive class.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="roc_curves_from_test_statistics">roc_curves_from_test_statistics<a class="headerlink" href="#roc_curves_from_test_statistics" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">roc_curves_from_test_statistics</span><span class="p">(</span>
  <span class="n">test_stats_per_model</span><span class="p">,</span>
  <span class="n">output_feature_name</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show the roc curves for the specified models output binary
<code>output_feature_name</code>.</p>
<p>This visualization uses <code>output_feature_name</code>, <code>test_stats_per_model</code> and
<code>model_names</code> parameters. <code>output_feature_name</code> needs to be binary feature.
This visualization produces a line chart plotting the roc curves for the
specified <code>output_feature_name</code>.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>test_stats_per_model</strong> (List[dict]): dictionary containing evaluation
performance statistics.</li>
<li><strong>output_feature_name</strong> (str): name of the output feature to use
for the visualization.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="calibration_1_vs_all">calibration_1_vs_all<a class="headerlink" href="#calibration_1_vs_all" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">calibration_1_vs_all</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">top_n_classes</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show models probability of predictions for the specified output_feature_name.</p>
<p>For each class or each of the k most frequent classes if top_k is
specified,  it produces two plots computed on the fly from the
probabilities  of predictions for the specified output_feature_name.</p>
<p>The first plot is a calibration curve that shows the calibration of the
predictions considering the current class to be the true one and all
others  to be a false one, drawing one line for each model (in the
aligned  lists of probabilities and model_names).</p>
<p>The second plot shows the distributions of the predictions considering
the  current class to be the true one and all others to be a false one,
drawing the distribution for each model (in the aligned lists of
probabilities and model_names).</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>top_n_classes</strong> (list): List containing the number of classes to plot.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (List[str], default: <code>None</code>): list of the names of the
models to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>String</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="calibration_multiclass">calibration_multiclass<a class="headerlink" href="#calibration_multiclass" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">calibration_multiclass</span><span class="p">(</span>
  <span class="n">probabilities_per_model</span><span class="p">,</span>
  <span class="n">ground_truth</span><span class="p">,</span>
  <span class="n">labels_limit</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show models probability of predictions for each class of the
specified output_feature_name.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>probabilities_per_model</strong> (List[numpy.array]): list of model
probabilities.</li>
<li><strong>ground_truth</strong> (numpy.array): numpy.array containing ground truth data,
which are the numeric encoded values the category.</li>
<li><strong>labels_limit</strong> (int): upper limit on the numeric encoded label value.
Encoded numeric label values in dataset that are higher than
<code>label_limit</code> are considered to be "rare" labels.</li>
<li><strong>model_names</strong> (List[str], default: <code>None</code>): list of the names of the
models to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="confusion_matrix">confusion_matrix<a class="headerlink" href="#confusion_matrix" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span>
  <span class="n">test_stats_per_model</span><span class="p">,</span>
  <span class="n">metadata</span><span class="p">,</span>
  <span class="n">output_feature_name</span><span class="p">,</span>
  <span class="n">top_n_classes</span><span class="p">,</span>
  <span class="n">normalize</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show confision matrix in the models predictions for each
<code>output_feature_name</code>.</p>
<p>For each model (in the aligned lists of test_statistics and model_names)
it  produces a heatmap of the confusion matrix in the predictions for
each  output_feature_name that has a confusion matrix in test_statistics.
The value of <code>top_n_classes</code> limits the heatmap to the n most frequent
classes.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>test_stats_per_model</strong> (List[dict]): dictionary containing evaluation
  performance statistics.</li>
<li><strong>metadata</strong> (dict): intermediate preprocess structure created during
training containing the mappings of the input dataset.</li>
<li><strong>output_feature_name</strong> (Union[str, <code>None</code>]): name of the output feature
to use for the visualization.  If <code>None</code>, use all output features.</li>
<li><strong>top_n_classes</strong> (List[int]): number of top classes or list
containing the number of top classes to plot.</li>
<li><strong>normalize</strong> (bool): flag to normalize rows in confusion matrix.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="frequency_vs_f1">frequency_vs_f1<a class="headerlink" href="#frequency_vs_f1" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">frequency_vs_f1</span><span class="p">(</span>
  <span class="n">test_stats_per_model</span><span class="p">,</span>
  <span class="n">metadata</span><span class="p">,</span>
  <span class="n">output_feature_name</span><span class="p">,</span>
  <span class="n">top_n_classes</span><span class="p">,</span>
  <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Show prediction statistics for the specified <code>output_feature_name</code> for
each model.</p>
<p>For each model (in the aligned lists of <code>test_stats_per_model</code> and
<code>model_names</code>), produces two plots statistics of predictions for the
specified <code>output_feature_name</code>.</p>
<p>The first plot is a line plot with one x axis representing the different
classes and two vertical axes colored in orange and blue respectively.
The orange one is the frequency of the class and an orange line is plotted
to show the trend. The blue one is the F1 score for that class and a blue
line is plotted to show the trend. The classes on the x axis are sorted by
f1 score.</p>
<p>The second plot has the same structure of the first one,
but the axes are flipped and the classes on the x axis are sorted by
frequency.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>test_stats_per_model</strong> (List[dict]): dictionary containing evaluation
performance statistics.</li>
<li><strong>metadata</strong> (dict): intermediate preprocess structure created during
training containing the mappings of the input dataset.</li>
<li><strong>output_feature_name</strong> (Union[str, <code>None</code>]): name of the output feature
to use for the visualization.  If <code>None</code>, use all output features.</li>
<li><strong>top_n_classes</strong> (List[int]): number of top classes or list
containing the number of top classes to plot.</li>
<li><strong>model_names</strong> (Union[str, List[str]], default: <code>None</code>): model name or
list of the model names to use as labels.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="hyperopt_report">hyperopt_report<a class="headerlink" href="#hyperopt_report" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">hyperopt_report</span><span class="p">(</span>
  <span class="n">hyperopt_stats_path</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span>
<span class="p">)</span>
</code></pre></div>


<p>Produces a report about hyperparameter optimization
creating one graph per hyperparameter to show the distribution of results
and one additional graph of pairwise hyperparameters interactions.</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>hyperopt_stats_path</strong> (str): path to the hyperopt results JSON file.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window.</li>
<li><strong>file_format</strong> (str, default: <code>'pdf'</code>): file format of output plots -
<code>'pdf'</code> or <code>'png'</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
<hr />
<h3 id="hyperopt_hiplot">hyperopt_hiplot<a class="headerlink" href="#hyperopt_hiplot" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><code><span class="n">ludwig</span><span class="o">.</span><span class="n">visualize</span><span class="o">.</span><span class="n">hyperopt_hiplot</span><span class="p">(</span>
  <span class="n">hyperopt_stats_path</span><span class="p">,</span>
  <span class="n">output_directory</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>


<p>Produces a parallel coordinate plot about hyperparameter optimization
creating one HTML file and optionally a CSV file to be read by hiplot</p>
<p><strong>Inputs</strong></p>
<ul>
<li><strong>hyperopt_stats_path</strong> (str): path to the hyperopt results JSON file.</li>
<li><strong>output_directory</strong> (str, default: <code>None</code>): directory where to save
plots. If not specified, plots will be displayed in a window.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><strong>return</strong> (None):</li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

<!-- Application footer -->
<footer class="md-footer">

    <!-- Link to previous and/or next page -->
    
    <div class="md-footer-nav">
        <nav aria-label="Footer"
             class="md-footer-nav__inner md-grid">
            
            <a class="md-footer-nav__link md-footer-nav__link--prev"
               href="../LudwigModel/" rel="prev"
               title="LudwigModel">
                <div class="md-footer-nav__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
                </div>
                <div class="md-footer-nav__title">
                    <div class="md-ellipsis">
                 <span class="md-footer-nav__direction">
                   Previous
                 </span>
                        LudwigModel
                    </div>
                </div>
            </a>
            
            
            <a class="md-footer-nav__link md-footer-nav__link--next"
               href="../../community/" rel="next"
               title="Community">
                <div class="md-footer-nav__title">
                    <div class="md-ellipsis">
                 <span class="md-footer-nav__direction">
                   Next
                 </span>
                        Community
                    </div>
                </div>
                <div class="md-footer-nav__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
                </div>
            </a>
            
        </nav>
    </div>
    

    <!-- Further information -->
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">

            <!-- Copyright and theme information -->
            <div class="md-footer-copyright">
                <div class="footer-logo-smallpad"></div>
                
                <div class="md-footer-copyright__highlight">
                    Copyright &copy; 2018 - 2020 Uber Technologies Inc.
                </div>
                
                Website by <a href="http://w4nderlu.st">w4nderlust</a> powered by
                <a href="https://www.mkdocs.org">MkDocs</a>,
                <a href="https://squidfunk.github.io/mkdocs-material/">Material for MkDocs</a>,
                <a href="http://www.styleshout.com/">styleshout</a> and
                <a href="http://cables.gl/">cables</a>.
            </div>

            <!-- Social links -->
            
            
            
        </div>
    </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.77e55a48.min.js"></script>
      <script src="../../assets/javascripts/bundle.9554a270.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>