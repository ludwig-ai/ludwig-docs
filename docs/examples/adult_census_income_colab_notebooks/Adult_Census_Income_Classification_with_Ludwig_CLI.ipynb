{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "cnE-hnjqVyXC",
        "outputId": "b5a09de0-434e-4920-cfc3-ab0860112415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 136 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 398 kB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 69.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 73.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.5 MB/s \n",
            "\u001b[?25h  Building wheel for ludwig (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Prerequisite: Installs the latest version of Ludwig in the Colab environment\n",
        "!python -m pip install git+https://github.com/ludwig-ai/ludwig.git --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ludwig datasets download adult_census_income"
      ],
      "metadata": {
        "id": "PFg2eYGnWL1e",
        "outputId": "59f2540b-cd1d-4124-fe70-d929ddf2a540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n",
            "███████████████████████\n",
            "█ █ █ █  ▜█ █ █ █ █   █\n",
            "█ █ █ █ █ █ █ █ █ █ ███\n",
            "█ █   █ █ █ █ █ █ █ ▌ █\n",
            "█ █████ █ █ █ █ █ █ █ █\n",
            "█     █  ▟█     █ █   █\n",
            "███████████████████████\n",
            "ludwig v0.5rc2 - Datasets download\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "raw_df = pd.read_csv('./adult_census_income.csv')\n",
        "raw_df.head()"
      ],
      "metadata": {
        "id": "mXcIK6aCWvN_",
        "outputId": "a9b11664-7e49-47ee-9e0a-f4f07476e1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age          workclass  fnlwgt   education  education-num  \\\n",
              "0   39          State-gov   77516   Bachelors             13   \n",
              "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
              "2   38            Private  215646     HS-grad              9   \n",
              "3   53            Private  234721        11th              7   \n",
              "4   28            Private  338409   Bachelors             13   \n",
              "\n",
              "        marital-status          occupation    relationship    race      sex  \\\n",
              "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
              "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
              "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
              "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
              "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
              "\n",
              "   capital-gain  capital-loss  hours-per-week  native-country  income  split  \n",
              "0          2174             0              40   United-States   <=50K      0  \n",
              "1             0             0              13   United-States   <=50K      0  \n",
              "2             0             0              40   United-States   <=50K      0  \n",
              "3             0             0              40   United-States   <=50K      0  \n",
              "4             0             0              40            Cuba   <=50K      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af0ec793-e227-49d2-a6d2-3dc662e99eb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af0ec793-e227-49d2-a6d2-3dc662e99eb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af0ec793-e227-49d2-a6d2-3dc662e99eb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af0ec793-e227-49d2-a6d2-3dc662e99eb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_yaml = \"\"\"\n",
        "preprocessing:\n",
        "  number:\n",
        "    normalization: zscore\n",
        "    missing_value_strategy: fill_with_mode\n",
        "\n",
        "input_features:\n",
        "  - name: age\n",
        "    type: number\n",
        "  - name: workclass\n",
        "    type: category\n",
        "  - name: fnlwgt\n",
        "    type: number\n",
        "  - name: education\n",
        "    type: category\n",
        "  - name: education-num\n",
        "    type: number\n",
        "  - name: marital-status\n",
        "    type: category\n",
        "  - name: occupation\n",
        "    type: category\n",
        "  - name: relationship\n",
        "    type: category\n",
        "  - name: race\n",
        "    type: category\n",
        "  - name: sex\n",
        "    type: category\n",
        "  - name: capital-gain\n",
        "    type: number\n",
        "  - name: capital-loss\n",
        "    type: number\n",
        "  - name: hours-per-week\n",
        "    type: number\n",
        "  - name: native-country\n",
        "    type: category\n",
        "\n",
        "combiner:\n",
        "  type: concat\n",
        "  num_fc_layers: 3\n",
        "  output_size: 128\n",
        "  dropout: 0.2\n",
        "\n",
        "output_features:\n",
        "  - name: income\n",
        "    type: binary\n",
        "    preprocessing:\n",
        "      fallback_true_label: \" >50K\"\n",
        "    num_fc_layers: 4\n",
        "    output_size: 32\n",
        "\n",
        "trainer:\n",
        "  epochs: 3\n",
        "\"\"\"\n",
        "\n",
        "# Writes config to a file called \"config.yaml\"\n",
        "with open(\"config.yaml\", \"w\") as f:\n",
        "  f.write(config_yaml)"
      ],
      "metadata": {
        "id": "sM6D4_F6q4Iq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains the model. This cell might take a few minutes.\n",
        "!ludwig train --dataset adult_census_income.csv \\\n",
        "              --config config.yaml \\\n",
        "              --skip_save_processed_input"
      ],
      "metadata": {
        "id": "3vICrf3Ms8jS",
        "outputId": "815c0c42-0ce3-4ec5-8155-722e4566bd98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n",
            "import ray failed with exception: No module named 'ray'\n",
            "███████████████████████\n",
            "█ █ █ █  ▜█ █ █ █ █   █\n",
            "█ █ █ █ █ █ █ █ █ █ ███\n",
            "█ █   █ █ █ █ █ █ █ ▌ █\n",
            "█ █████ █ █ █ █ █ █ █ █\n",
            "█     █  ▟█     █ █   █\n",
            "███████████████████████\n",
            "ludwig v0.5rc2 - Train\n",
            "\n",
            "\n",
            "╒════════════════════════╕\n",
            "│ EXPERIMENT DESCRIPTION │\n",
            "╘════════════════════════╛\n",
            "\n",
            "╒══════════════════╤════════════════════════════════════════════════════════════════════════════╕\n",
            "│ Experiment name  │ experiment                                                                 │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ Model name       │ run                                                                        │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ Output directory │ /content/results/experiment_run                                            │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ ludwig_version   │ '0.5rc2'                                                                   │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ command          │ ('/usr/local/bin/ludwig train --dataset adult_census_income.csv --config ' │\n",
            "│                  │  'config.yaml --skip_save_processed_input')                                │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ random_seed      │ 42                                                                         │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ dataset          │ 'adult_census_income.csv'                                                  │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ data_format      │ 'csv'                                                                      │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ torch_version    │ '1.10.0+cu111'                                                             │\n",
            "├──────────────────┼────────────────────────────────────────────────────────────────────────────┤\n",
            "│ compute          │ {'num_nodes': 1}                                                           │\n",
            "╘══════════════════╧════════════════════════════════════════════════════════════════════════════╛\n",
            "\n",
            "╒═══════════════╕\n",
            "│ LUDWIG CONFIG │\n",
            "╘═══════════════╛\n",
            "\n",
            "{   'combiner': {   'dropout': 0.2,\n",
            "                    'num_fc_layers': 3,\n",
            "                    'output_size': 128,\n",
            "                    'type': 'concat'},\n",
            "    'input_features': [   {   'column': 'age',\n",
            "                              'name': 'age',\n",
            "                              'proc_column': 'age_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'workclass',\n",
            "                              'name': 'workclass',\n",
            "                              'proc_column': 'workclass_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'fnlwgt',\n",
            "                              'name': 'fnlwgt',\n",
            "                              'proc_column': 'fnlwgt_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'education',\n",
            "                              'name': 'education',\n",
            "                              'proc_column': 'education_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'education-num',\n",
            "                              'name': 'education-num',\n",
            "                              'proc_column': 'education_num_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'marital-status',\n",
            "                              'name': 'marital-status',\n",
            "                              'proc_column': 'marital_status_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'occupation',\n",
            "                              'name': 'occupation',\n",
            "                              'proc_column': 'occupation_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'relationship',\n",
            "                              'name': 'relationship',\n",
            "                              'proc_column': 'relationship_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'race',\n",
            "                              'name': 'race',\n",
            "                              'proc_column': 'race_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'sex',\n",
            "                              'name': 'sex',\n",
            "                              'proc_column': 'sex_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'capital-gain',\n",
            "                              'name': 'capital-gain',\n",
            "                              'proc_column': 'capital_gain_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'capital-loss',\n",
            "                              'name': 'capital-loss',\n",
            "                              'proc_column': 'capital_loss_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'hours-per-week',\n",
            "                              'name': 'hours-per-week',\n",
            "                              'proc_column': 'hours_per_week_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'native-country',\n",
            "                              'name': 'native-country',\n",
            "                              'proc_column': 'native_country_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'}],\n",
            "    'output_features': [   {   'column': 'income',\n",
            "                               'dependencies': [],\n",
            "                               'loss': {   'confidence_penalty': 0,\n",
            "                                           'positive_class_weight': None,\n",
            "                                           'robust_lambda': 0,\n",
            "                                           'weight': 1},\n",
            "                               'name': 'income',\n",
            "                               'num_fc_layers': 4,\n",
            "                               'output_size': 32,\n",
            "                               'preprocessing': {   'fallback_true_label': ' '\n",
            "                                                                           '>50K',\n",
            "                                                    'missing_value_strategy': 'drop_row'},\n",
            "                               'proc_column': 'income_acRTnD',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'threshold': 0.5,\n",
            "                               'type': 'binary'}],\n",
            "    'preprocessing': {   'audio': {   'audio_feature': {'type': 'raw'},\n",
            "                                      'audio_file_length_limit_in_s': 7.5,\n",
            "                                      'in_memory': True,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'norm': None,\n",
            "                                      'padding_value': 0},\n",
            "                         'bag': {   'fill_value': '<UNK>',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000,\n",
            "                                    'tokenizer': 'space'},\n",
            "                         'binary': {   'missing_value_strategy': 'fill_with_false'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'date': {   'datetime_format': None,\n",
            "                                     'fill_value': '',\n",
            "                                     'missing_value_strategy': 'fill_with_const'},\n",
            "                         'force_split': False,\n",
            "                         'h3': {   'fill_value': 576495936675512319,\n",
            "                                   'missing_value_strategy': 'fill_with_const'},\n",
            "                         'image': {   'in_memory': True,\n",
            "                                      'infer_image_dimensions': True,\n",
            "                                      'infer_image_max_height': 256,\n",
            "                                      'infer_image_max_width': 256,\n",
            "                                      'infer_image_num_channels': True,\n",
            "                                      'infer_image_sample_size': 100,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'num_processes': 1,\n",
            "                                      'resize_method': 'interpolate',\n",
            "                                      'scaling': 'pixel_normalization'},\n",
            "                         'number': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_mode',\n",
            "                                       'normalization': 'zscore'},\n",
            "                         'oversample_minority': None,\n",
            "                         'sequence': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'max_sequence_length': 256,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'tokenizer': 'space',\n",
            "                                         'unknown_symbol': '<UNK>',\n",
            "                                         'vocab_file': None},\n",
            "                         'set': {   'fill_value': '<UNK>',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000,\n",
            "                                    'tokenizer': 'space'},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'fill_value': '<UNK>',\n",
            "                                     'lowercase': True,\n",
            "                                     'max_sequence_length': 256,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'most_common': 20000,\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'pretrained_model_name_or_path': None,\n",
            "                                     'tokenizer': 'space_punct',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'vocab_file': None},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256,\n",
            "                                           'tokenizer': 'space'},\n",
            "                         'undersample_majority': None,\n",
            "                         'vector': {   'fill_value': '',\n",
            "                                       'missing_value_strategy': 'fill_with_const'}},\n",
            "    'trainer': {   'batch_size': 128,\n",
            "                   'decay': False,\n",
            "                   'decay_rate': 0.96,\n",
            "                   'decay_steps': 10000,\n",
            "                   'early_stop': 1000,\n",
            "                   'epochs': 3,\n",
            "                   'eval_batch_size': None,\n",
            "                   'gradient_clipping': None,\n",
            "                   'increase_batch_size_on_plateau': 0,\n",
            "                   'increase_batch_size_on_plateau_max': 512,\n",
            "                   'increase_batch_size_on_plateau_patience': 5,\n",
            "                   'increase_batch_size_on_plateau_rate': 2,\n",
            "                   'learning_rate': 0.001,\n",
            "                   'learning_rate_warmup_epochs': 1,\n",
            "                   'optimizer': {   'betas': (0.9, 0.999),\n",
            "                                    'eps': 1e-08,\n",
            "                                    'type': 'adam'},\n",
            "                   'reduce_learning_rate_on_plateau': 0,\n",
            "                   'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                   'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                   'regularization_lambda': 0,\n",
            "                   'regularization_type': 'l2',\n",
            "                   'staircase': False,\n",
            "                   'steps_per_checkpoint': 0,\n",
            "                   'validation_field': 'combined',\n",
            "                   'validation_metric': 'loss'}}\n",
            "\n",
            "╒═══════════════╕\n",
            "│ PREPROCESSING │\n",
            "╘═══════════════╛\n",
            "\n",
            "Using full raw dataset, no hdf5 and json file with the same name have been found\n",
            "Building dataset (it may take a while)\n",
            "Binary feature income has at least 1 unconventional boolean value: Cannot automatically map value  <=50K to a boolean and no `fallback_true_label` specified.. We will now interpret  >50K as 1 and the other values as 0. If this is incorrect, please use the category feature type or manually specify the true value with `preprocessing.fallback_true_label`.\n",
            "Building dataset: DONE\n",
            "\n",
            "Dataset sizes:\n",
            "╒═══════════╤════════╕\n",
            "│ Dataset   │   Size │\n",
            "╞═══════════╪════════╡\n",
            "│ Training  │  32561 │\n",
            "├───────────┼────────┤\n",
            "│ Test      │  16281 │\n",
            "╘═══════════╧════════╛\n",
            "\n",
            "╒═══════╕\n",
            "│ MODEL │\n",
            "╘═══════╛\n",
            "\n",
            "Warnings and other logs:\n",
            "  embedding_size (50) is greater than vocab_size (10). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (17). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (8). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (16). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (7). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (6). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (3). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (43). Setting embedding size to be equal to vocab_size.\n",
            "\n",
            "╒══════════╕\n",
            "│ TRAINING │\n",
            "╘══════════╛\n",
            "\n",
            "Note: steps_per_checkpoint (was 255) is now set to the number of steps per epoch: 255.\n",
            "\n",
            "Training for 765 step(s), approximately 3 epoch(s).\n",
            "Starting with step 0, epoch: 0\n",
            "Training:  32% 243/765 [00:03<00:04, 121.97it/s]\n",
            "Running evaluation for step: 255, epoch: 0\n",
            "Evaluation train: 100% 255/255 [00:01<00:00, 208.61it/s]\n",
            "Evaluation test : 100% 128/128 [00:00<00:00, 220.58it/s]\n",
            "╒══════════╤════════╤═══════════╤════════════╕\n",
            "│ income   │   loss │   roc_auc │   accuracy │\n",
            "╞══════════╪════════╪═══════════╪════════════╡\n",
            "│ train    │ 0.4035 │    0.8403 │     0.8141 │\n",
            "├──────────┼────────┼───────────┼────────────┤\n",
            "│ test     │ 0.4075 │    0.8337 │     0.8094 │\n",
            "╘══════════╧════════╧═══════════╧════════════╛\n",
            "╒════════════╤════════╕\n",
            "│ combined   │   loss │\n",
            "╞════════════╪════════╡\n",
            "│ train      │ 0.4035 │\n",
            "├────────────┼────────┤\n",
            "│ test       │ 0.4075 │\n",
            "╘════════════╧════════╛\n",
            "Training:  66% 503/765 [00:07<00:02, 127.17it/s]\n",
            "Running evaluation for step: 510, epoch: 1\n",
            "Evaluation train: 100% 255/255 [00:01<00:00, 204.58it/s]\n",
            "Evaluation test : 100% 128/128 [00:00<00:00, 224.78it/s]\n",
            "╒══════════╤════════╤═══════════╤════════════╕\n",
            "│ income   │   loss │   roc_auc │   accuracy │\n",
            "╞══════════╪════════╪═══════════╪════════════╡\n",
            "│ train    │ 0.3886 │    0.8467 │     0.8199 │\n",
            "├──────────┼────────┼───────────┼────────────┤\n",
            "│ test     │ 0.3910 │    0.8415 │     0.8177 │\n",
            "╘══════════╧════════╧═══════════╧════════════╛\n",
            "╒════════════╤════════╕\n",
            "│ combined   │   loss │\n",
            "╞════════════╪════════╡\n",
            "│ train      │ 0.3886 │\n",
            "├────────────┼────────┤\n",
            "│ test       │ 0.3910 │\n",
            "╘════════════╧════════╛\n",
            "Training:  99% 757/765 [00:10<00:00, 127.11it/s]\n",
            "Running evaluation for step: 765, epoch: 2\n",
            "Evaluation train: 100% 255/255 [00:01<00:00, 210.31it/s]\n",
            "Evaluation test : 100% 128/128 [00:00<00:00, 211.38it/s]\n",
            "╒══════════╤════════╤═══════════╤════════════╕\n",
            "│ income   │   loss │   roc_auc │   accuracy │\n",
            "╞══════════╪════════╪═══════════╪════════════╡\n",
            "│ train    │ 0.3875 │    0.8473 │     0.8216 │\n",
            "├──────────┼────────┼───────────┼────────────┤\n",
            "│ test     │ 0.3897 │    0.8424 │     0.8180 │\n",
            "╘══════════╧════════╧═══════════╧════════════╛\n",
            "╒════════════╤════════╕\n",
            "│ combined   │   loss │\n",
            "╞════════════╪════════╡\n",
            "│ train      │ 0.3875 │\n",
            "├────────────┼────────┤\n",
            "│ test       │ 0.3897 │\n",
            "╘════════════╧════════╛\n",
            "\n",
            "╒══════════╕\n",
            "│ FINISHED │\n",
            "╘══════════╛\n",
            "\n",
            "Training: 100% 765/765 [00:13<00:00, 58.70it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract subset of test data for evaluation due to limitations in amount of data displayable in colab notebook.\n",
        "np.random.seed(13)\n",
        "raw_df.loc[raw_df.split == 2].sample(n=200).to_csv('evaluation_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "KXwkcGeYOviz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates predictions and performance statistics for the test set.\n",
        "!ludwig evaluate --model_path results/experiment_run/model \\\n",
        "                 --dataset evaluation_dataset.csv \\\n",
        "                 --split full \\\n",
        "                 --output_directory test_results"
      ],
      "metadata": {
        "id": "7e0VLhn2tjF7",
        "outputId": "e8a729be-0e8e-45cc-8657-6e8e152e32c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n",
            "import ray failed with exception: No module named 'ray'\n",
            "███████████████████████\n",
            "█ █ █ █  ▜█ █ █ █ █   █\n",
            "█ █ █ █ █ █ █ █ █ █ ███\n",
            "█ █   █ █ █ █ █ █ █ ▌ █\n",
            "█ █████ █ █ █ █ █ █ █ █\n",
            "█     █  ▟█     █ █   █\n",
            "███████████████████████\n",
            "ludwig v0.5rc2 - Evaluate\n",
            "\n",
            "Dataset path: evaluation_dataset.csv\n",
            "Model path: results/experiment_run/model\n",
            "\n",
            "  embedding_size (50) is greater than vocab_size (10). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (17). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (8). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (16). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (7). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (6). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (3). Setting embedding size to be equal to vocab_size.\n",
            "  embedding_size (50) is greater than vocab_size (43). Setting embedding size to be equal to vocab_size.\n",
            "Loading metadata from: results/experiment_run/model/training_set_metadata.json\n",
            "Evaluation: 100% 2/2 [00:00<00:00, 141.04it/s]\n",
            "\n",
            "===== income =====\n",
            "accuracy: 0.8199999928474426\n",
            "average_precision_macro: 0.6549752445334105\n",
            "average_precision_micro: 0.6549752445334105\n",
            "average_precision_samples: 0.6549752445334105\n",
            "loss: 0.40561342239379883\n",
            "overall_stats: { 'avg_f1_score_macro': 0.72875226039783,\n",
            "  'avg_f1_score_micro': 0.82,\n",
            "  'avg_f1_score_weighted': 0.8105605786618446,\n",
            "  'avg_precision_macro': 0.7601626016260162,\n",
            "  'avg_precision_micro': 0.82,\n",
            "  'avg_precision_weighted': 0.82,\n",
            "  'avg_recall_macro': 0.7105263157894737,\n",
            "  'avg_recall_micro': 0.82,\n",
            "  'avg_recall_weighted': 0.82,\n",
            "  'kappa_score': 0.460431654676259,\n",
            "  'token_accuracy': 0.82}\n",
            "per_class_stats: {False: {   'accuracy': 0.82,\n",
            "    'f1_score': 0.8860759493670887,\n",
            "    'fall_out': 0.5,\n",
            "    'false_discovery_rate': 0.14634146341463417,\n",
            "    'false_negative_rate': 0.07894736842105265,\n",
            "    'false_negatives': 12,\n",
            "    'false_omission_rate': 0.33333333333333337,\n",
            "    'false_positive_rate': 0.5,\n",
            "    'false_positives': 24,\n",
            "    'hit_rate': 0.9210526315789473,\n",
            "    'informedness': 0.42105263157894735,\n",
            "    'markedness': 0.5203252032520325,\n",
            "    'matthews_correlation_coefficient': 0.46806441448386027,\n",
            "    'miss_rate': 0.07894736842105265,\n",
            "    'negative_predictive_value': 0.6666666666666666,\n",
            "    'positive_predictive_value': 0.8536585365853658,\n",
            "    'precision': 0.8536585365853658,\n",
            "    'recall': 0.9210526315789473,\n",
            "    'sensitivity': 0.9210526315789473,\n",
            "    'specificity': 0.5,\n",
            "    'true_negative_rate': 0.5,\n",
            "    'true_negatives': 24,\n",
            "    'true_positive_rate': 0.9210526315789473,\n",
            "    'true_positives': 140},\n",
            "  True: {   'accuracy': 0.82,\n",
            "    'f1_score': 0.5714285714285715,\n",
            "    'fall_out': 0.07894736842105265,\n",
            "    'false_discovery_rate': 0.33333333333333337,\n",
            "    'false_negative_rate': 0.5,\n",
            "    'false_negatives': 24,\n",
            "    'false_omission_rate': 0.14634146341463417,\n",
            "    'false_positive_rate': 0.07894736842105265,\n",
            "    'false_positives': 12,\n",
            "    'hit_rate': 0.5,\n",
            "    'informedness': 0.42105263157894735,\n",
            "    'markedness': 0.5203252032520325,\n",
            "    'matthews_correlation_coefficient': 0.46806441448386027,\n",
            "    'miss_rate': 0.5,\n",
            "    'negative_predictive_value': 0.8536585365853658,\n",
            "    'positive_predictive_value': 0.6666666666666666,\n",
            "    'precision': 0.6666666666666666,\n",
            "    'recall': 0.5,\n",
            "    'sensitivity': 0.5,\n",
            "    'specificity': 0.9210526315789473,\n",
            "    'true_negative_rate': 0.9210526315789473,\n",
            "    'true_negatives': 140,\n",
            "    'true_positive_rate': 0.5,\n",
            "    'true_positives': 24}}\n",
            "precision_recall_curve: { 'precisions': [ 0.25396825396825395,\n",
            "                  0.25,\n",
            "                  0.25133689839572193,\n",
            "                  0.25268817204301075,\n",
            "                  0.25405405405405407,\n",
            "                  0.2554347826086957,\n",
            "                  0.2568306010928962,\n",
            "                  0.25824175824175827,\n",
            "                  0.2596685082872928,\n",
            "                  0.2611111111111111,\n",
            "                  0.26256983240223464,\n",
            "                  0.2640449438202247,\n",
            "                  0.2655367231638418,\n",
            "                  0.26704545454545453,\n",
            "                  0.26857142857142857,\n",
            "                  0.27011494252873564,\n",
            "                  0.27167630057803466,\n",
            "                  0.27325581395348836,\n",
            "                  0.27485380116959063,\n",
            "                  0.27647058823529413,\n",
            "                  0.2781065088757396,\n",
            "                  0.27976190476190477,\n",
            "                  0.281437125748503,\n",
            "                  0.28313253012048195,\n",
            "                  0.28484848484848485,\n",
            "                  0.2865853658536585,\n",
            "                  0.2883435582822086,\n",
            "                  0.29012345679012347,\n",
            "                  0.2919254658385093,\n",
            "                  0.29375,\n",
            "                  0.29559748427672955,\n",
            "                  0.2974683544303797,\n",
            "                  0.29936305732484075,\n",
            "                  0.30128205128205127,\n",
            "                  0.3032258064516129,\n",
            "                  0.3051948051948052,\n",
            "                  0.30718954248366015,\n",
            "                  0.3092105263157895,\n",
            "                  0.31125827814569534,\n",
            "                  0.31333333333333335,\n",
            "                  0.31543624161073824,\n",
            "                  0.31756756756756754,\n",
            "                  0.3197278911564626,\n",
            "                  0.3219178082191781,\n",
            "                  0.32413793103448274,\n",
            "                  0.3263888888888889,\n",
            "                  0.32867132867132864,\n",
            "                  0.33098591549295775,\n",
            "                  0.3262411347517731,\n",
            "                  0.32857142857142857,\n",
            "                  0.33093525179856115,\n",
            "                  0.3333333333333333,\n",
            "                  0.3357664233576642,\n",
            "                  0.3382352941176471,\n",
            "                  0.34074074074074073,\n",
            "                  0.34328358208955223,\n",
            "                  0.3458646616541353,\n",
            "                  0.3484848484848485,\n",
            "                  0.3435114503816794,\n",
            "                  0.34615384615384615,\n",
            "                  0.34108527131782945,\n",
            "                  0.34375,\n",
            "                  0.3464566929133858,\n",
            "                  0.3492063492063492,\n",
            "                  0.352,\n",
            "                  0.3548387096774194,\n",
            "                  0.35772357723577236,\n",
            "                  0.36065573770491804,\n",
            "                  0.35537190082644626,\n",
            "                  0.35833333333333334,\n",
            "                  0.36134453781512604,\n",
            "                  0.3644067796610169,\n",
            "                  0.36752136752136755,\n",
            "                  0.3706896551724138,\n",
            "                  0.3739130434782609,\n",
            "                  0.37719298245614036,\n",
            "                  0.3805309734513274,\n",
            "                  0.38392857142857145,\n",
            "                  0.3783783783783784,\n",
            "                  0.38181818181818183,\n",
            "                  0.3853211009174312,\n",
            "                  0.3888888888888889,\n",
            "                  0.38317757009345793,\n",
            "                  0.3867924528301887,\n",
            "                  0.3904761904761905,\n",
            "                  0.38461538461538464,\n",
            "                  0.3883495145631068,\n",
            "                  0.39215686274509803,\n",
            "                  0.39603960396039606,\n",
            "                  0.39,\n",
            "                  0.3939393939393939,\n",
            "                  0.3877551020408163,\n",
            "                  0.3917525773195876,\n",
            "                  0.3854166666666667,\n",
            "                  0.3894736842105263,\n",
            "                  0.3829787234042553,\n",
            "                  0.3763440860215054,\n",
            "                  0.3804347826086957,\n",
            "                  0.37362637362637363,\n",
            "                  0.37777777777777777,\n",
            "                  0.38202247191011235,\n",
            "                  0.38636363636363635,\n",
            "                  0.39080459770114945,\n",
            "                  0.3953488372093023,\n",
            "                  0.4,\n",
            "                  0.40476190476190477,\n",
            "                  0.40963855421686746,\n",
            "                  0.4146341463414634,\n",
            "                  0.41975308641975306,\n",
            "                  0.425,\n",
            "                  0.43037974683544306,\n",
            "                  0.4358974358974359,\n",
            "                  0.44155844155844154,\n",
            "                  0.4342105263157895,\n",
            "                  0.44,\n",
            "                  0.44594594594594594,\n",
            "                  0.4520547945205479,\n",
            "                  0.4583333333333333,\n",
            "                  0.4647887323943662,\n",
            "                  0.45714285714285713,\n",
            "                  0.463768115942029,\n",
            "                  0.47058823529411764,\n",
            "                  0.47761194029850745,\n",
            "                  0.48484848484848486,\n",
            "                  0.49230769230769234,\n",
            "                  0.5,\n",
            "                  0.5079365079365079,\n",
            "                  0.5,\n",
            "                  0.5081967213114754,\n",
            "                  0.5166666666666667,\n",
            "                  0.5084745762711864,\n",
            "                  0.5172413793103449,\n",
            "                  0.5263157894736842,\n",
            "                  0.5357142857142857,\n",
            "                  0.5454545454545454,\n",
            "                  0.5555555555555556,\n",
            "                  0.5660377358490566,\n",
            "                  0.5769230769230769,\n",
            "                  0.5686274509803921,\n",
            "                  0.58,\n",
            "                  0.5714285714285714,\n",
            "                  0.5833333333333334,\n",
            "                  0.5957446808510638,\n",
            "                  0.6086956521739131,\n",
            "                  0.6222222222222222,\n",
            "                  0.6363636363636364,\n",
            "                  0.6511627906976745,\n",
            "                  0.6666666666666666,\n",
            "                  0.6829268292682927,\n",
            "                  0.7,\n",
            "                  0.6923076923076923,\n",
            "                  0.6842105263157895,\n",
            "                  0.6756756756756757,\n",
            "                  0.6666666666666666,\n",
            "                  0.6571428571428571,\n",
            "                  0.6764705882352942,\n",
            "                  0.6666666666666666,\n",
            "                  0.6875,\n",
            "                  0.7096774193548387,\n",
            "                  0.7,\n",
            "                  0.6896551724137931,\n",
            "                  0.6785714285714286,\n",
            "                  0.6666666666666666,\n",
            "                  0.6538461538461539,\n",
            "                  0.64,\n",
            "                  0.625,\n",
            "                  0.6521739130434783,\n",
            "                  0.6818181818181818,\n",
            "                  0.7142857142857143,\n",
            "                  0.7,\n",
            "                  0.7368421052631579,\n",
            "                  0.7777777777777778,\n",
            "                  0.8235294117647058,\n",
            "                  0.875,\n",
            "                  0.8666666666666667,\n",
            "                  0.8571428571428571,\n",
            "                  0.9230769230769231,\n",
            "                  0.9166666666666666,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0,\n",
            "                  1.0],\n",
            "  'recalls': [ 1.0,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9791666666666666,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9583333333333334,\n",
            "               0.9375,\n",
            "               0.9375,\n",
            "               0.9166666666666666,\n",
            "               0.9166666666666666,\n",
            "               0.9166666666666666,\n",
            "               0.9166666666666666,\n",
            "               0.9166666666666666,\n",
            "               0.9166666666666666,\n",
            "               0.9166666666666666,\n",
            "               0.9166666666666666,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.8958333333333334,\n",
            "               0.875,\n",
            "               0.875,\n",
            "               0.875,\n",
            "               0.875,\n",
            "               0.8541666666666666,\n",
            "               0.8541666666666666,\n",
            "               0.8541666666666666,\n",
            "               0.8333333333333334,\n",
            "               0.8333333333333334,\n",
            "               0.8333333333333334,\n",
            "               0.8333333333333334,\n",
            "               0.8125,\n",
            "               0.8125,\n",
            "               0.7916666666666666,\n",
            "               0.7916666666666666,\n",
            "               0.7708333333333334,\n",
            "               0.7708333333333334,\n",
            "               0.75,\n",
            "               0.7291666666666666,\n",
            "               0.7291666666666666,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.7083333333333334,\n",
            "               0.6875,\n",
            "               0.6875,\n",
            "               0.6875,\n",
            "               0.6875,\n",
            "               0.6875,\n",
            "               0.6875,\n",
            "               0.6666666666666666,\n",
            "               0.6666666666666666,\n",
            "               0.6666666666666666,\n",
            "               0.6666666666666666,\n",
            "               0.6666666666666666,\n",
            "               0.6666666666666666,\n",
            "               0.6666666666666666,\n",
            "               0.6666666666666666,\n",
            "               0.6458333333333334,\n",
            "               0.6458333333333334,\n",
            "               0.6458333333333334,\n",
            "               0.625,\n",
            "               0.625,\n",
            "               0.625,\n",
            "               0.625,\n",
            "               0.625,\n",
            "               0.625,\n",
            "               0.625,\n",
            "               0.625,\n",
            "               0.6041666666666666,\n",
            "               0.6041666666666666,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5833333333333334,\n",
            "               0.5625,\n",
            "               0.5416666666666666,\n",
            "               0.5208333333333334,\n",
            "               0.5,\n",
            "               0.4791666666666667,\n",
            "               0.4791666666666667,\n",
            "               0.4583333333333333,\n",
            "               0.4583333333333333,\n",
            "               0.4583333333333333,\n",
            "               0.4375,\n",
            "               0.4166666666666667,\n",
            "               0.3958333333333333,\n",
            "               0.375,\n",
            "               0.3541666666666667,\n",
            "               0.3333333333333333,\n",
            "               0.3125,\n",
            "               0.3125,\n",
            "               0.3125,\n",
            "               0.3125,\n",
            "               0.2916666666666667,\n",
            "               0.2916666666666667,\n",
            "               0.2916666666666667,\n",
            "               0.2916666666666667,\n",
            "               0.2916666666666667,\n",
            "               0.2708333333333333,\n",
            "               0.25,\n",
            "               0.25,\n",
            "               0.22916666666666666,\n",
            "               0.22916666666666666,\n",
            "               0.20833333333333334,\n",
            "               0.1875,\n",
            "               0.16666666666666666,\n",
            "               0.14583333333333334,\n",
            "               0.125,\n",
            "               0.10416666666666667,\n",
            "               0.08333333333333333,\n",
            "               0.0625,\n",
            "               0.041666666666666664,\n",
            "               0.020833333333333332,\n",
            "               0.0]}\n",
            "roc_auc: 0.8148300647735596\n",
            "roc_auc_macro: 0.8127741228070176\n",
            "roc_auc_micro: 0.8127741228070176\n",
            "Saved to: test_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7g-l1sExF3DI"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Adult_Census_Income_Classification_with_Ludwig_CLI.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}