{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multimodal Classification with Ludwig - CLI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal Classification of Twitter Bots - Ludwig CLI\n",
        "\n",
        "*We recommend using a GPU runtime for this example. In the Colab menu bar, choose **Runtime** > **Change Runtime Type** and choose **GPU** under Hardware Accelerator.*\n",
        "\n",
        "In this notebook, we will show how to use the Ludwig CLI to:\n",
        "\n",
        "\n",
        "1.   [Train a Ludwig Model](#scrollTo=Train)\n",
        "2.   [Evaluate the trained model](#scrollTo=Evaluate)\n",
        "3.   [Visualize training and test metrics](#scrollTo=Visualize_Metrics)\n",
        "\n",
        "\n",
        "This example is uses a dataset from Kaggle, so you'll need a [Kaggle account](https://www.kaggle.com/account/login) to download it."
      ],
      "metadata": {
        "id": "dqW_BZ60kyWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Kaggle Credentials\n",
        "\n",
        "If you have a kaggle.json file, paste its contents into the code cell below, then run to write your kaggle API key into the Colab environment."
      ],
      "metadata": {
        "id": "yTysvPY3_E56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace this string with the contents of your kaggle.json file.\n",
        "KAGGLE_JSON = \"\"\"\n",
        "{\"username\":\"\",\"key\":\"\"}\n",
        "\"\"\"\n",
        "\n",
        "# Creates the .kaggle directory if it does not already exist.\n",
        "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "\n",
        "# Writes the contents of KAGGLE_JSON into ~/.kaggle/kaggle.json\n",
        "with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"w\") as f:\n",
        "  f.write(KAGGLE_JSON)\n",
        "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)"
      ],
      "metadata": {
        "id": "b7eTuBup_zEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset\n",
        "\n",
        "We'll be using the [twitter human-bots dataset](https://www.kaggle.com/code/davidmartngutirrez/bots-accounts-eda/data), composed of 37438 rows each corresponding to a Twitter user account. Each row contains 20 feature columns collected via Twitter API. These features contain multiple data modalities, including the account description and the profile image.\n",
        "\n",
        "The target column **account_type** has two unique values: **bot** or **human**. 25013 user accounts were annotated as human accounts, the remaining 12425 are bots.\n",
        "\n",
        "\n",
        "This dataset contains 20 columns, but we'll only use these 16 (15 input + 1 target):\n",
        "\n",
        "| column      | type | description                                         |\n",
        "|-------------|------|-----------------------------------------------------|\n",
        "| default_profile | binary | Boolean indicating whether the account has a default profile |\n",
        "| default_profile_image | binary | Boolean indicating whether the account has a default profile image |\n",
        "| description | text |  User account description                           |\n",
        "| favorites_count | number | Total number of favourited tweets             |\n",
        "| followers_count | number | Total number of followers                     |\n",
        "| friends_count | number | Total number of friends                         |\n",
        "| geo_enabled | binary | Boolean indicating whether the account has the geographic location enabled  |\n",
        "| lang | category | Language of the account                                |\n",
        "| location | category | Location of the account                            |\n",
        "| profile_background_image_url | image | Profile background image url      |\n",
        "| profile_image_url | image | Profile image url                            |\n",
        "| statuses_count | number | Total number of tweets                         |\n",
        "| verified | binary | Boolean indicating whether the account has been verified |\n",
        "| average_tweets_per_day | number | Average tweets posted per day          |\n",
        "| account_age_days | number | Account age measured in days                 |\n",
        "| account_type   | category | Account type, one of {bot, human}            |\n"
      ],
      "metadata": {
        "id": "zYOMqI9UiBpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloads the dataset to the current working directory\n",
        "!kaggle datasets download danieltreiman/twitter-human-bots-dataset\n",
        "\n",
        "# Unzips the downloaded dataset, creates profile_images,\n",
        "# profile_background_images, and twitter_human_bots_dataset.csv\n",
        "!unzip -q -o twitter-human-bots-dataset.zip"
      ],
      "metadata": {
        "id": "V-USzcQ9J75t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previews a few rows of the dataset:\n",
        "!head twitter_human_bots_dataset.csv"
      ],
      "metadata": {
        "id": "13d3EPZoCVxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "9zSzY2SmRt-v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FczUptADgreZ"
      },
      "outputs": [],
      "source": [
        "# Prerequisite: Installs the latest version of Ludwig in the Colab environment\n",
        "!python -m pip install git+https://github.com/ludwig-ai/ludwig.git --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define ludwig config\n",
        "\n",
        "The Ludwig config declares the machine learning task: which columns to use, their datatypes, and which columns to predict."
      ],
      "metadata": {
        "id": "m-7NypeYh2hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_yaml = \"\"\"\n",
        "input_features:\n",
        "  - name: default_profile\n",
        "    type: binary\n",
        "  - name: default_profile_image\n",
        "    type: binary\n",
        "  - name: description\n",
        "    type: text\n",
        "  - name: favourites_count\n",
        "    type: number\n",
        "  - name: followers_count\n",
        "    type: number\n",
        "  - name: friends_count\n",
        "    type: number\n",
        "  - name: geo_enabled\n",
        "    type: binary\n",
        "  - name: lang\n",
        "    type: category\n",
        "  - name: location\n",
        "    type: category\n",
        "  - name: profile_background_image_path\n",
        "    type: category\n",
        "  - name: profile_image_path\n",
        "    type: image\n",
        "    preprocessing:\n",
        "      num_channels: 3\n",
        "  - name: statuses_count\n",
        "    type: number\n",
        "  - name: verified\n",
        "    type: binary\n",
        "  - name: average_tweets_per_day\n",
        "    type: number\n",
        "  - name: account_age_days\n",
        "    type: number\n",
        "output_features:\n",
        "  - name: account_type\n",
        "    type: binary\n",
        "\"\"\"\n",
        "\n",
        "# Writes config to \"config.yaml\"\n",
        "with open(\"config.yaml\", \"w\") as f:\n",
        "  f.write(config_yaml)"
      ],
      "metadata": {
        "id": "wPg-qTQ6htyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and train a model"
      ],
      "metadata": {
        "id": "87VXm-aH9DYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains the model. This cell might take a few minutes.\n",
        "!ludwig train --dataset twitter_human_bots_dataset.csv -c config.yaml"
      ],
      "metadata": {
        "id": "fEizUlhwrSMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "47tFtYwUuucY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates predictions and performance statistics for the test set.\n",
        "!ludwig evaluate --model_path results/experiment_run/model \\\n",
        "                 --dataset twitter_human_bots_dataset.csv \\\n",
        "                 --split test \\\n",
        "                 --output_directory results/experiment_run"
      ],
      "metadata": {
        "id": "WTe2wDNguw5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Metrics"
      ],
      "metadata": {
        "id": "F1VTQf6flpxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls visualizations"
      ],
      "metadata": {
        "id": "R400sFXuwsDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizes confusion matrix, which gives an overview of classifier performance\n",
        "# for each class.\n",
        "!ludwig visualize --visualization confusion_matrix \\\n",
        "                  --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\\n",
        "                  --test_statistics results/experiment_run/test_statistics.json \\\n",
        "                  --output_directory visualizations \\\n",
        "                  --file_format png\n",
        "\n",
        "# If you run ludwig visualize locally, visualizations will automatically show in\n",
        "# a window. Here in Colab, we can run the following code to load and display\n",
        "# generated plots inline.\n",
        "from IPython import display\n",
        "import ipywidgets\n",
        "from pathlib import Path\n",
        "\n",
        "ipywidgets.HBox([\n",
        "  ipywidgets.Image(value=Path(\"visualizations/confusion_matrix__account_type_top3.png\").read_bytes()),\n",
        "  ipywidgets.Image(value=Path(\"visualizations/confusion_matrix_entropy__account_type_top3.png\").read_bytes()),\n",
        "])"
      ],
      "metadata": {
        "id": "zj1ocMUtaMRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizes learning curves, which show how performance metrics changed over\n",
        "# time during training.\n",
        "!ludwig visualize --visualization learning_curves \\\n",
        "                  --training_statistics results/experiment_run/training_statistics.json \\\n",
        "                  --output_directory visualizations \\\n",
        "                  --file_format png\n",
        "\n",
        "\n",
        "ipywidgets.HBox([\n",
        "  ipywidgets.Image(value=Path(\"visualizations/learning_curves_account_type_loss.png\").read_bytes()),\n",
        "  ipywidgets.Image(value=Path(\"visualizations/learning_curves_account_type_accuracy.png\").read_bytes()),\n",
        "])"
      ],
      "metadata": {
        "id": "jaYNW7T71CMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d6S_KAnzaQdT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}