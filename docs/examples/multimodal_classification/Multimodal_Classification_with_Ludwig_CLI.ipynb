{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqW_BZ60kyWP"
      },
      "source": [
        "# Multimodal Classification of Twitter Bots - Ludwig CLI\n",
        "\n",
        "*We recommend using a GPU runtime for this example. In the Colab menu bar, choose **Runtime** > **Change Runtime Type** and choose **GPU** under Hardware Accelerator.*\n",
        "\n",
        "In this notebook, we will show how to use the Ludwig CLI to:\n",
        "\n",
        "\n",
        "1.   [Train a Ludwig Model](#scrollTo=Train)\n",
        "2.   [Evaluate the trained model](#scrollTo=Evaluate)\n",
        "3.   [Visualize training and test metrics](#scrollTo=Visualize_Metrics)\n",
        "\n",
        "\n",
        "This example is uses a dataset from Kaggle, so you'll need a [Kaggle account](https://www.kaggle.com/account/login) to download it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTysvPY3_E56"
      },
      "source": [
        "# Upload Kaggle Credentials\n",
        "\n",
        "If you have a kaggle.json file, paste its contents into the code cell below, then run to write your kaggle API key into the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7eTuBup_zEE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Replace this string with the contents of your kaggle.json file.\n",
        "KAGGLE_JSON = \"\"\"\n",
        "{\"username\":\"\",\"key\":\"\"}\n",
        "\"\"\"\n",
        "\n",
        "# Creates the .kaggle directory if it does not already exist.\n",
        "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "\n",
        "# Writes the contents of KAGGLE_JSON into ~/.kaggle/kaggle.json\n",
        "with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"w\") as f:\n",
        "  f.write(KAGGLE_JSON)\n",
        "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYOMqI9UiBpz"
      },
      "source": [
        "# Download Dataset\n",
        "\n",
        "We'll be using the [twitter human-bots dataset](https://www.kaggle.com/code/davidmartngutirrez/bots-accounts-eda/data), composed of 37438 rows each corresponding to a Twitter user account. Each row contains 20 feature columns collected via Twitter API. These features contain multiple data modalities, including the account description and the profile image.\n",
        "\n",
        "The target column **account_type** has two unique values: **bot** or **human**. 25013 user accounts were annotated as human accounts, the remaining 12425 are bots.\n",
        "\n",
        "\n",
        "This dataset contains 20 columns, but we'll only use these 16 (15 input + 1 target):\n",
        "\n",
        "| column      | type | description                                         |\n",
        "|-------------|------|-----------------------------------------------------|\n",
        "| default_profile | binary | Boolean indicating whether the account has a default profile |\n",
        "| default_profile_image | binary | Boolean indicating whether the account has a default profile image |\n",
        "| description | text |  User account description                           |\n",
        "| favorites_count | number | Total number of favourited tweets             |\n",
        "| followers_count | number | Total number of followers                     |\n",
        "| friends_count | number | Total number of friends                         |\n",
        "| geo_enabled | binary | Boolean indicating whether the account has the geographic location enabled  |\n",
        "| lang | category | Language of the account                                |\n",
        "| location | category | Location of the account                            |\n",
        "| profile_background_image_url | image | Profile background image url      |\n",
        "| profile_image_url | image | Profile image url                            |\n",
        "| statuses_count | number | Total number of tweets                         |\n",
        "| verified | binary | Boolean indicating whether the account has been verified |\n",
        "| average_tweets_per_day | number | Average tweets posted per day          |\n",
        "| account_age_days | number | Account age measured in days                 |\n",
        "| account_type   | category | Account type, one of {bot, human}            |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-USzcQ9J75t"
      },
      "outputs": [],
      "source": [
        "# Downloads the dataset to the current working directory\n",
        "!kaggle datasets download danieltreiman/twitter-human-bots-dataset\n",
        "\n",
        "# Unzips the downloaded dataset, creates profile_images,\n",
        "# profile_background_images, and twitter_human_bots_dataset.csv\n",
        "!unzip -q -o twitter-human-bots-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13d3EPZoCVxm"
      },
      "outputs": [],
      "source": [
        "# Previews a few rows of the dataset:\n",
        "!head twitter_human_bots_dataset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zSzY2SmRt-v"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FczUptADgreZ"
      },
      "outputs": [],
      "source": [
        "# Prerequisite: Installs the latest version of Ludwig in the Colab environment\n",
        "!python -m pip install git+https://github.com/ludwig-ai/ludwig.git --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-7NypeYh2hb"
      },
      "source": [
        "## Define ludwig config\n",
        "\n",
        "The Ludwig config declares the machine learning task: which columns to use, their datatypes, and which columns to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPg-qTQ6htyq"
      },
      "outputs": [],
      "source": [
        "config_yaml = \"\"\"\n",
        "input_features:\n",
        "  - name: default_profile\n",
        "    type: binary\n",
        "  - name: default_profile_image\n",
        "    type: binary\n",
        "  - name: description\n",
        "    type: text\n",
        "  - name: favourites_count\n",
        "    type: number\n",
        "  - name: followers_count\n",
        "    type: number\n",
        "  - name: friends_count\n",
        "    type: number\n",
        "  - name: geo_enabled\n",
        "    type: binary\n",
        "  - name: lang\n",
        "    type: category\n",
        "  - name: location\n",
        "    type: category\n",
        "  - name: profile_background_image_path\n",
        "    type: category\n",
        "  - name: profile_image_path\n",
        "    type: image\n",
        "    preprocessing:\n",
        "      num_channels: 3\n",
        "  - name: statuses_count\n",
        "    type: number\n",
        "  - name: verified\n",
        "    type: binary\n",
        "  - name: average_tweets_per_day\n",
        "    type: number\n",
        "  - name: account_age_days\n",
        "    type: number\n",
        "output_features:\n",
        "  - name: account_type\n",
        "    type: binary\n",
        "\"\"\"\n",
        "\n",
        "# Writes config to \"config.yaml\"\n",
        "with open(\"config.yaml\", \"w\") as f:\n",
        "  f.write(config_yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87VXm-aH9DYf"
      },
      "source": [
        "## Create and train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fEizUlhwrSMn",
        "outputId": "6de941d1-9f0a-4ba9-f2bb-3f771c98d6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumExpr defaulting to 2 threads.\n",
            "torchtext>=0.12.0 is not installed, so the following tokenizers are not available: {'sentencepiece_tokenizer'}\n",
            "import ray failed with exception: No module named 'ray'\n",
            "███████████████████████\n",
            "█ █ █ █  ▜█ █ █ █ █   █\n",
            "█ █ █ █ █ █ █ █ █ █ ███\n",
            "█ █   █ █ █ █ █ █ █ ▌ █\n",
            "█ █████ █ █ █ █ █ █ █ █\n",
            "█     █  ▟█     █ █   █\n",
            "███████████████████████\n",
            "ludwig v0.5rc2 - Train\n",
            "\n",
            "\n",
            "╒════════════════════════╕\n",
            "│ EXPERIMENT DESCRIPTION │\n",
            "╘════════════════════════╛\n",
            "\n",
            "╒══════════════════╤═════════════════════════════════════════════════════════════════════════════╕\n",
            "│ Experiment name  │ experiment                                                                  │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ Model name       │ run                                                                         │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ Output directory │ /content/results/experiment_run                                             │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ ludwig_version   │ '0.5rc2'                                                                    │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ command          │ ('/usr/local/bin/ludwig train --dataset twitter_human_bots_dataset.csv -c ' │\n",
            "│                  │  'config.yaml')                                                             │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ random_seed      │ 42                                                                          │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ dataset          │ 'twitter_human_bots_dataset.csv'                                            │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ data_format      │ 'csv'                                                                       │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ torch_version    │ '1.10.0+cu111'                                                              │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
            "│ compute          │ {'num_nodes': 1}                                                            │\n",
            "╘══════════════════╧═════════════════════════════════════════════════════════════════════════════╛\n",
            "\n",
            "╒═══════════════╕\n",
            "│ LUDWIG CONFIG │\n",
            "╘═══════════════╛\n",
            "\n",
            "{   'combiner': {'type': 'concat'},\n",
            "    'input_features': [   {   'column': 'default_profile',\n",
            "                              'name': 'default_profile',\n",
            "                              'proc_column': 'default_profile_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'binary'},\n",
            "                          {   'column': 'default_profile_image',\n",
            "                              'name': 'default_profile_image',\n",
            "                              'proc_column': 'default_profile_image_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'binary'},\n",
            "                          {   'column': 'description',\n",
            "                              'encoder': 'parallel_cnn',\n",
            "                              'name': 'description',\n",
            "                              'proc_column': 'description_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'text'},\n",
            "                          {   'column': 'favourites_count',\n",
            "                              'name': 'favourites_count',\n",
            "                              'proc_column': 'favourites_count_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'followers_count',\n",
            "                              'name': 'followers_count',\n",
            "                              'proc_column': 'followers_count_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'friends_count',\n",
            "                              'name': 'friends_count',\n",
            "                              'proc_column': 'friends_count_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'geo_enabled',\n",
            "                              'name': 'geo_enabled',\n",
            "                              'proc_column': 'geo_enabled_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'binary'},\n",
            "                          {   'column': 'lang',\n",
            "                              'name': 'lang',\n",
            "                              'proc_column': 'lang_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'location',\n",
            "                              'name': 'location',\n",
            "                              'proc_column': 'location_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'profile_background_image_path',\n",
            "                              'name': 'profile_background_image_path',\n",
            "                              'proc_column': 'profile_background_image_path_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'category'},\n",
            "                          {   'column': 'profile_image_path',\n",
            "                              'name': 'profile_image_path',\n",
            "                              'preprocessing': {'num_channels': 3},\n",
            "                              'proc_column': 'profile_image_path_CbAmln',\n",
            "                              'tied': None,\n",
            "                              'type': 'image'},\n",
            "                          {   'column': 'statuses_count',\n",
            "                              'name': 'statuses_count',\n",
            "                              'proc_column': 'statuses_count_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'verified',\n",
            "                              'name': 'verified',\n",
            "                              'proc_column': 'verified_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'binary'},\n",
            "                          {   'column': 'average_tweets_per_day',\n",
            "                              'name': 'average_tweets_per_day',\n",
            "                              'proc_column': 'average_tweets_per_day_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'},\n",
            "                          {   'column': 'account_age_days',\n",
            "                              'name': 'account_age_days',\n",
            "                              'proc_column': 'account_age_days_mZFLky',\n",
            "                              'tied': None,\n",
            "                              'type': 'number'}],\n",
            "    'output_features': [   {   'column': 'account_type',\n",
            "                               'dependencies': [],\n",
            "                               'loss': {   'confidence_penalty': 0,\n",
            "                                           'positive_class_weight': None,\n",
            "                                           'robust_lambda': 0,\n",
            "                                           'weight': 1},\n",
            "                               'name': 'account_type',\n",
            "                               'preprocessing': {   'missing_value_strategy': 'drop_row'},\n",
            "                               'proc_column': 'account_type_mZFLky',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'threshold': 0.5,\n",
            "                               'type': 'binary'}],\n",
            "    'preprocessing': {   'audio': {   'audio_feature': {'type': 'raw'},\n",
            "                                      'audio_file_length_limit_in_s': 7.5,\n",
            "                                      'in_memory': True,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'norm': None,\n",
            "                                      'padding_value': 0},\n",
            "                         'bag': {   'fill_value': '<UNK>',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000,\n",
            "                                    'tokenizer': 'space'},\n",
            "                         'binary': {   'missing_value_strategy': 'fill_with_false'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'date': {   'datetime_format': None,\n",
            "                                     'fill_value': '',\n",
            "                                     'missing_value_strategy': 'fill_with_const'},\n",
            "                         'force_split': False,\n",
            "                         'h3': {   'fill_value': 576495936675512319,\n",
            "                                   'missing_value_strategy': 'fill_with_const'},\n",
            "                         'image': {   'in_memory': True,\n",
            "                                      'infer_image_dimensions': True,\n",
            "                                      'infer_image_max_height': 256,\n",
            "                                      'infer_image_max_width': 256,\n",
            "                                      'infer_image_num_channels': True,\n",
            "                                      'infer_image_sample_size': 100,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'num_processes': 1,\n",
            "                                      'resize_method': 'interpolate',\n",
            "                                      'scaling': 'pixel_normalization'},\n",
            "                         'number': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_const',\n",
            "                                       'normalization': None},\n",
            "                         'oversample_minority': None,\n",
            "                         'sample_ratio': 1.0,\n",
            "                         'sequence': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'max_sequence_length': 256,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'tokenizer': 'space',\n",
            "                                         'unknown_symbol': '<UNK>',\n",
            "                                         'vocab_file': None},\n",
            "                         'set': {   'fill_value': '<UNK>',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000,\n",
            "                                    'tokenizer': 'space'},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'fill_value': '<UNK>',\n",
            "                                     'lowercase': True,\n",
            "                                     'max_sequence_length': 256,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'most_common': 20000,\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'pretrained_model_name_or_path': None,\n",
            "                                     'tokenizer': 'space_punct',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'vocab_file': None},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256,\n",
            "                                           'tokenizer': 'space'},\n",
            "                         'undersample_majority': None,\n",
            "                         'vector': {   'fill_value': '',\n",
            "                                       'missing_value_strategy': 'fill_with_const'}},\n",
            "    'trainer': {   'batch_size': 128,\n",
            "                   'decay': False,\n",
            "                   'decay_rate': 0.96,\n",
            "                   'decay_steps': 10000,\n",
            "                   'early_stop': 1000,\n",
            "                   'epochs': 100,\n",
            "                   'eval_batch_size': None,\n",
            "                   'gradient_clipping': None,\n",
            "                   'increase_batch_size_on_plateau': 0,\n",
            "                   'increase_batch_size_on_plateau_max': 512,\n",
            "                   'increase_batch_size_on_plateau_patience': 5,\n",
            "                   'increase_batch_size_on_plateau_rate': 2,\n",
            "                   'learning_rate': 0.001,\n",
            "                   'learning_rate_warmup_epochs': 1,\n",
            "                   'optimizer': {   'betas': (0.9, 0.999),\n",
            "                                    'eps': 1e-08,\n",
            "                                    'type': 'adam'},\n",
            "                   'reduce_learning_rate_on_plateau': 0,\n",
            "                   'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                   'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                   'regularization_lambda': 0,\n",
            "                   'regularization_type': 'l2',\n",
            "                   'staircase': False,\n",
            "                   'steps_per_checkpoint': 0,\n",
            "                   'validation_field': 'combined',\n",
            "                   'validation_metric': 'loss'}}\n",
            "\n",
            "╒═══════════════╕\n",
            "│ PREPROCESSING │\n",
            "╘═══════════════╛\n",
            "\n",
            "Using full raw dataset, no hdf5 and json file with the same name have been found\n",
            "Building dataset (it may take a while)\n",
            "Binary feature account_type has at least 1 unconventional boolean value: Cannot automatically map value bot to a boolean and no `fallback_true_label` specified.. We will now interpret bot as 1 and the other values as 0. If this is incorrect, please use the category feature type or manually specify the true value with `preprocessing.fallback_true_label`.\n",
            "reading image url /content/profile_images/cc7a93d7affbb07eca5abcb2bea4d91f06f1b4db.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/cc7a93d7affbb07eca5abcb2bea4d91f06f1b4db.gif cannot be read\n",
            "/content/profile_images/cc7a93d7affbb07eca5abcb2bea4d91f06f1b4db.gif cannot be read\n",
            "/content/profile_images/cc7a93d7affbb07eca5abcb2bea4d91f06f1b4db.gif cannot be read\n",
            "/content/profile_images/cc7a93d7affbb07eca5abcb2bea4d91f06f1b4db.gif cannot be read\n",
            "reading image url /content/profile_images/1b87b48f40977cae42b249a3a88608755e12c2e1.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/1b87b48f40977cae42b249a3a88608755e12c2e1.gif cannot be read\n",
            "/content/profile_images/1b87b48f40977cae42b249a3a88608755e12c2e1.gif cannot be read\n",
            "reading image url /content/profile_images/9d2ba3bba478c34c225bf7c8a1dea8c1645e5e66.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/9d2ba3bba478c34c225bf7c8a1dea8c1645e5e66.gif cannot be read\n",
            "/content/profile_images/9d2ba3bba478c34c225bf7c8a1dea8c1645e5e66.gif cannot be read\n",
            "reading image url /content/profile_images/ab9436d50c3f1b0b114e0acb106cd426f7e5497d.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/ab9436d50c3f1b0b114e0acb106cd426f7e5497d.gif cannot be read\n",
            "/content/profile_images/ab9436d50c3f1b0b114e0acb106cd426f7e5497d.gif cannot be read\n",
            "/content/profile_images/ab9436d50c3f1b0b114e0acb106cd426f7e5497d.gif cannot be read\n",
            "/content/profile_images/ab9436d50c3f1b0b114e0acb106cd426f7e5497d.gif cannot be read\n",
            "reading image url /content/profile_images/461557f73db8cfb3627a1f34f38c63a131531637.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/461557f73db8cfb3627a1f34f38c63a131531637.gif cannot be read\n",
            "reading image url /content/profile_images/0c71171ce7afc853ff0390fd1600999b21245ac6.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/0c71171ce7afc853ff0390fd1600999b21245ac6.gif cannot be read\n",
            "/content/profile_images/0c71171ce7afc853ff0390fd1600999b21245ac6.gif cannot be read\n",
            "reading image url /content/profile_images/efb98b0fb02e58c9701b616941a4ac201361c40a.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/efb98b0fb02e58c9701b616941a4ac201361c40a.gif cannot be read\n",
            "reading image url /content/profile_images/703f1087ed8b882d657007620711503477a1de4b.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/703f1087ed8b882d657007620711503477a1de4b.gif cannot be read\n",
            "/content/profile_images/703f1087ed8b882d657007620711503477a1de4b.gif cannot be read\n",
            "/content/profile_images/703f1087ed8b882d657007620711503477a1de4b.gif cannot be read\n",
            "/content/profile_images/703f1087ed8b882d657007620711503477a1de4b.gif cannot be read\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "reading image url /content/profile_images/b23a49d31d173982a100d18d317396a3f887c0f5.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/b23a49d31d173982a100d18d317396a3f887c0f5.gif cannot be read\n",
            "/content/profile_images/b23a49d31d173982a100d18d317396a3f887c0f5.gif cannot be read\n",
            "reading image url /content/profile_images/f9498e3737a8c7c4eda681608ff5a5b219c497fd.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/f9498e3737a8c7c4eda681608ff5a5b219c497fd.gif cannot be read\n",
            "reading image url /content/profile_images/1f5864b1f49b0d35144f62f64d6c34064b55c0f3.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/1f5864b1f49b0d35144f62f64d6c34064b55c0f3.bmp cannot be read\n",
            "reading image url /content/profile_images/d09bc2bd08263948d232af12331cd1084c324398.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/d09bc2bd08263948d232af12331cd1084c324398.bmp cannot be read\n",
            "/content/profile_images/d09bc2bd08263948d232af12331cd1084c324398.bmp cannot be read\n",
            "/content/profile_images/d09bc2bd08263948d232af12331cd1084c324398.bmp cannot be read\n",
            "reading image url /content/profile_images/86d093cfff56f498ef0c955edae1670d9545e6ab.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/86d093cfff56f498ef0c955edae1670d9545e6ab.gif cannot be read\n",
            "reading image url /content/profile_images/60392b21035bb5810368bb923a63253aa938428a.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/60392b21035bb5810368bb923a63253aa938428a.gif cannot be read\n",
            "reading image url /content/profile_images/0491509c23a869bc3b8ee8b1c9dd017587aa5311.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/0491509c23a869bc3b8ee8b1c9dd017587aa5311.bmp cannot be read\n",
            "/content/profile_images/0491509c23a869bc3b8ee8b1c9dd017587aa5311.bmp cannot be read\n",
            "/content/profile_images/0491509c23a869bc3b8ee8b1c9dd017587aa5311.bmp cannot be read\n",
            "/content/profile_images/0491509c23a869bc3b8ee8b1c9dd017587aa5311.bmp cannot be read\n",
            "reading image url /content/profile_images/21cd2ce710629049651731b8f5540f9fd0d9f64c.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/21cd2ce710629049651731b8f5540f9fd0d9f64c.gif cannot be read\n",
            "reading image url /content/profile_images/c59c0c2ac910c6bd58ed94ed2272a398e707136e.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/c59c0c2ac910c6bd58ed94ed2272a398e707136e.gif cannot be read\n",
            "reading image url /content/profile_images/8792ea3d506addd5e324e7f2f52a6b58b2b7f31a.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/8792ea3d506addd5e324e7f2f52a6b58b2b7f31a.gif cannot be read\n",
            "reading image url /content/profile_images/65cacc786d6daf18717540084d72af1e4bc2881a.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/65cacc786d6daf18717540084d72af1e4bc2881a.bmp cannot be read\n",
            "reading image url /content/profile_images/b8cdcdf8b2970d3a51caf0c2c7d68477dd0ddd76.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/b8cdcdf8b2970d3a51caf0c2c7d68477dd0ddd76.gif cannot be read\n",
            "reading image url /content/profile_images/a3c19d8287eb4abf02e5dae80f10c37ab7967bb3.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/a3c19d8287eb4abf02e5dae80f10c37ab7967bb3.gif cannot be read\n",
            "/content/profile_images/a3c19d8287eb4abf02e5dae80f10c37ab7967bb3.gif cannot be read\n",
            "/content/profile_images/a3c19d8287eb4abf02e5dae80f10c37ab7967bb3.gif cannot be read\n",
            "/content/profile_images/a3c19d8287eb4abf02e5dae80f10c37ab7967bb3.gif cannot be read\n",
            "reading image url /content/profile_images/c62072c973bc9549cedc499a83e06a143d5c7d6f.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/c62072c973bc9549cedc499a83e06a143d5c7d6f.gif cannot be read\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "reading image url /content/profile_images/e99f07d723368922e6ed034ba1e716885d937bca.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/e99f07d723368922e6ed034ba1e716885d937bca.gif cannot be read\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "reading image url /content/profile_images/097c4e4523cc8ad6c9afb2ffe058d5d8b0233b6d.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/097c4e4523cc8ad6c9afb2ffe058d5d8b0233b6d.gif cannot be read\n",
            "reading image url /content/profile_images/139464e0250beb182702d327eb2b1fc36bae1ae5.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/139464e0250beb182702d327eb2b1fc36bae1ae5.gif cannot be read\n",
            "reading image url /content/profile_images/1a13fe493fc9e7554461d29350a90ce1e02f7b5b.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/1a13fe493fc9e7554461d29350a90ce1e02f7b5b.gif cannot be read\n",
            "reading image url /content/profile_images/43adba1f21466fc7218ffaeb3941cf69648e7ace.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/43adba1f21466fc7218ffaeb3941cf69648e7ace.gif cannot be read\n",
            "libpng warning: iCCP: profile 'icc': 'RGB ': RGB color space not permitted on grayscale PNG\n",
            "reading image url /content/profile_images/a44fbf7a4afc30b46919b09c5babea97ce2bcd4b.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/a44fbf7a4afc30b46919b09c5babea97ce2bcd4b.gif cannot be read\n",
            "reading image url /content/profile_images/e6ae63ecfb80c70c41edc7b42b21601de5053ea2.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/e6ae63ecfb80c70c41edc7b42b21601de5053ea2.gif cannot be read\n",
            "reading image url /content/profile_images/1b9cd9e45c6b4afc244a8e16f2cfc2b82fa5ccf2.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/1b9cd9e45c6b4afc244a8e16f2cfc2b82fa5ccf2.bmp cannot be read\n",
            "reading image url /content/profile_images/e60401ce936a433f0998ff7d517952635c1f72b6.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/e60401ce936a433f0998ff7d517952635c1f72b6.gif cannot be read\n",
            "/content/profile_images/e60401ce936a433f0998ff7d517952635c1f72b6.gif cannot be read\n",
            "/content/profile_images/e60401ce936a433f0998ff7d517952635c1f72b6.gif cannot be read\n",
            "/content/profile_images/e60401ce936a433f0998ff7d517952635c1f72b6.gif cannot be read\n",
            "reading image url /content/profile_images/90bc19a9dba123591f5f128bc966981c65da9876.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/90bc19a9dba123591f5f128bc966981c65da9876.bmp cannot be read\n",
            "/content/profile_images/90bc19a9dba123591f5f128bc966981c65da9876.bmp cannot be read\n",
            "reading image url /content/profile_images/e4e89e3f75cd99492e830ebe9f3f5209fa92c4cf.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/e4e89e3f75cd99492e830ebe9f3f5209fa92c4cf.bmp cannot be read\n",
            "libpng warning: iCCP: profile 'icc': 'RGB ': RGB color space not permitted on grayscale PNG\n",
            "reading image url /content/profile_images/05e3ba239dd1bce70228852a01085fdcd4297381.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/05e3ba239dd1bce70228852a01085fdcd4297381.bmp cannot be read\n",
            "reading image url /content/profile_images/04beddfd7816df77c1285dde56e402fc2f31db7e.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/04beddfd7816df77c1285dde56e402fc2f31db7e.gif cannot be read\n",
            "reading image url /content/profile_images/dffcc037cb085f7c2e3137c9399e1b61cb4492f7.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/dffcc037cb085f7c2e3137c9399e1b61cb4492f7.bmp cannot be read\n",
            "reading image url /content/profile_images/b599d1a4163740ebfbed97fa0c6674350c48666d.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/b599d1a4163740ebfbed97fa0c6674350c48666d.gif cannot be read\n",
            "reading image url /content/profile_images/a1c32e13bbe2d290a0b66b786634466536b9866c.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/a1c32e13bbe2d290a0b66b786634466536b9866c.gif cannot be read\n",
            "reading image url /content/profile_images/93857a1e5243f31851b6e1f91326617addaa094f.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/93857a1e5243f31851b6e1f91326617addaa094f.gif cannot be read\n",
            "reading image url /content/profile_images/8431ccc99c310fdcc0d0916b664c507be72f1748.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/8431ccc99c310fdcc0d0916b664c507be72f1748.gif cannot be read\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "reading image url /content/profile_images/1114c905a161eca328d0e91494f7f6523dbea81a.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/1114c905a161eca328d0e91494f7f6523dbea81a.gif cannot be read\n",
            "/content/profile_images/1114c905a161eca328d0e91494f7f6523dbea81a.gif cannot be read\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "reading image url /content/profile_images/ab79266130e327b4151f09581e79fa9ac921e6e8.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/ab79266130e327b4151f09581e79fa9ac921e6e8.gif cannot be read\n",
            "/content/profile_images/ab79266130e327b4151f09581e79fa9ac921e6e8.gif cannot be read\n",
            "reading image url /content/profile_images/d3faba12684f0245c792ac515bbfe02e7caeb088.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/d3faba12684f0245c792ac515bbfe02e7caeb088.gif cannot be read\n",
            "/content/profile_images/d3faba12684f0245c792ac515bbfe02e7caeb088.gif cannot be read\n",
            "/content/profile_images/d3faba12684f0245c792ac515bbfe02e7caeb088.gif cannot be read\n",
            "/content/profile_images/d3faba12684f0245c792ac515bbfe02e7caeb088.gif cannot be read\n",
            "reading image url /content/profile_images/df70595012f077c7f9c60cf05818b68968663633.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/df70595012f077c7f9c60cf05818b68968663633.gif cannot be read\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "reading image url /content/profile_images/c6d616aa3c645dd23617772adf9f377a0fabf353.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/c6d616aa3c645dd23617772adf9f377a0fabf353.gif cannot be read\n",
            "reading image url /content/profile_images/74586c7c620bcb53d619d99ef9970d1f2aa47374.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/74586c7c620bcb53d619d99ef9970d1f2aa47374.gif cannot be read\n",
            "reading image url /content/profile_images/723155a9f692835ecafd78e2078a6d1db14f5cdf.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/723155a9f692835ecafd78e2078a6d1db14f5cdf.gif cannot be read\n",
            "reading image url /content/profile_images/da1da7c1dfbf487f1f67500999f7c9f72b7d8f30.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/da1da7c1dfbf487f1f67500999f7c9f72b7d8f30.gif cannot be read\n",
            "reading image url /content/profile_images/7c1d5bfd65c6faf6b4d1348de031a3f70a5ee4e9.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/7c1d5bfd65c6faf6b4d1348de031a3f70a5ee4e9.gif cannot be read\n",
            "/content/profile_images/7c1d5bfd65c6faf6b4d1348de031a3f70a5ee4e9.gif cannot be read\n",
            "/content/profile_images/7c1d5bfd65c6faf6b4d1348de031a3f70a5ee4e9.gif cannot be read\n",
            "/content/profile_images/7c1d5bfd65c6faf6b4d1348de031a3f70a5ee4e9.gif cannot be read\n",
            "/content/profile_images/7c1d5bfd65c6faf6b4d1348de031a3f70a5ee4e9.gif cannot be read\n",
            "reading image url /content/profile_images/01976ce75f98cb63b933f025462938a59303a036.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/01976ce75f98cb63b933f025462938a59303a036.gif cannot be read\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "reading image url /content/profile_images/05537b20d41205f81b564a221a4a1b72524058b2.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/05537b20d41205f81b564a221a4a1b72524058b2.gif cannot be read\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "reading image url /content/profile_images/237a6a8b9788c403bf990b9bdfc8217d27d1298b.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/237a6a8b9788c403bf990b9bdfc8217d27d1298b.bmp cannot be read\n",
            "/content/profile_images/237a6a8b9788c403bf990b9bdfc8217d27d1298b.bmp cannot be read\n",
            "/content/profile_images/237a6a8b9788c403bf990b9bdfc8217d27d1298b.bmp cannot be read\n",
            "/content/profile_images/237a6a8b9788c403bf990b9bdfc8217d27d1298b.bmp cannot be read\n",
            "/content/profile_images/237a6a8b9788c403bf990b9bdfc8217d27d1298b.bmp cannot be read\n",
            "/content/profile_images/237a6a8b9788c403bf990b9bdfc8217d27d1298b.bmp cannot be read\n",
            "reading image url /content/profile_images/41a87acdaaeccba371cf656a07ad607f0dcb0f8e.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/41a87acdaaeccba371cf656a07ad607f0dcb0f8e.gif cannot be read\n",
            "reading image url /content/profile_images/70dfb5001113162a326877b84a822ec1953dc6f1.bmp failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/70dfb5001113162a326877b84a822ec1953dc6f1.bmp cannot be read\n",
            "reading image url /content/profile_images/eda3bdcd88e143cfe591fa0cb3f57816a79768b7.GIF failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/eda3bdcd88e143cfe591fa0cb3f57816a79768b7.GIF cannot be read\n",
            "reading image url /content/profile_images/98af52f241b3c740dc213fa92d6e9a7b72c64186.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/98af52f241b3c740dc213fa92d6e9a7b72c64186.gif cannot be read\n",
            "/content/profile_images/98af52f241b3c740dc213fa92d6e9a7b72c64186.gif cannot be read\n",
            "reading image url /content/profile_images/bf8f43ebc779942d2d3bb9b7e5e13786ec2a230b.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/bf8f43ebc779942d2d3bb9b7e5e13786ec2a230b.gif cannot be read\n",
            "reading image url /content/profile_images/91b566d3733656df27bc07c25865fd5d30446f0a.gif failed due to Unsupported image file. Only jpeg and png are currently supported.\n",
            "/content/profile_images/91b566d3733656df27bc07c25865fd5d30446f0a.gif cannot be read\n",
            "/content/profile_images/91b566d3733656df27bc07c25865fd5d30446f0a.gif cannot be read\n",
            "/content/profile_images/91b566d3733656df27bc07c25865fd5d30446f0a.gif cannot be read\n",
            "Could not read image nan, unsupported type <class 'float'>\n",
            "nan cannot be read\n",
            "Could not read image nan, unsupported type <class 'float'>\n",
            "nan cannot be read\n",
            "Could not read image nan, unsupported type <class 'float'>\n",
            "nan cannot be read\n",
            "Could not read image nan, unsupported type <class 'float'>\n",
            "nan cannot be read\n",
            "Building dataset: DONE\n",
            "Writing preprocessed training set cache\n",
            "Writing preprocessed test set cache\n",
            "Writing preprocessed validation set cache\n",
            "Writing train set metadata\n",
            "\n",
            "Dataset sizes:\n",
            "╒════════════╤════════╕\n",
            "│ Dataset    │   Size │\n",
            "╞════════════╪════════╡\n",
            "│ Training   │  29950 │\n",
            "├────────────┼────────┤\n",
            "│ Validation │   3743 │\n",
            "├────────────┼────────┤\n",
            "│ Test       │   3745 │\n",
            "╘════════════╧════════╛\n",
            "\n",
            "╒═══════╕\n",
            "│ MODEL │\n",
            "╘═══════╛\n",
            "\n",
            "Warnings and other logs:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n",
            "  self.padding, self.dilation, self.groups)\n",
            "\n",
            "╒══════════╕\n",
            "│ TRAINING │\n",
            "╘══════════╛\n",
            "\n",
            "Note: steps_per_checkpoint (was 234) is now set to the number of steps per epoch: 234.\n",
            "\n",
            "Training for 23400 step(s), approximately 100 epoch(s).\n",
            "Starting with step 0, epoch: 0\n",
            "Training:   1% 234/23400 [13:33<19:43:20,  3.06s/it]\n",
            "Running evaluation for step: 234, epoch: 0\n",
            "Evaluation train: 100% 234/234 [03:34<00:00,  1.09it/s]\n",
            "Evaluation vali : 100% 30/30 [00:27<00:00,  1.10it/s]\n",
            "Evaluation test : 100% 30/30 [00:27<00:00,  1.10it/s]\n",
            "╒════════════════╤═════════╤═══════════╤════════════╕\n",
            "│ account_type   │    loss │   roc_auc │   accuracy │\n",
            "╞════════════════╪═════════╪═══════════╪════════════╡\n",
            "│ train          │ 13.9499 │    0.7847 │     0.7493 │\n",
            "├────────────────┼─────────┼───────────┼────────────┤\n",
            "│ vali           │ 11.9272 │    0.7805 │     0.7486 │\n",
            "├────────────────┼─────────┼───────────┼────────────┤\n",
            "│ test           │ 14.2973 │    0.7890 │     0.7511 │\n",
            "╘════════════════╧═════════╧═══════════╧════════════╛\n",
            "╒════════════╤═════════╕\n",
            "│ combined   │    loss │\n",
            "╞════════════╪═════════╡\n",
            "│ train      │ 13.9499 │\n",
            "├────────────┼─────────┤\n",
            "│ vali       │ 11.9272 │\n",
            "├────────────┼─────────┤\n",
            "│ test       │ 14.2973 │\n",
            "╘════════════╧═════════╛\n",
            "Validation loss on combined improved, model saved.\n",
            "\n",
            "Training:   2% 468/23400 [30:08<19:23:48,  3.05s/it]\n",
            "Running evaluation for step: 468, epoch: 1\n",
            "Evaluation train: 100% 234/234 [03:48<00:00,  1.02it/s]\n",
            "Evaluation vali : 100% 30/30 [00:28<00:00,  1.06it/s]\n",
            "Evaluation test : 100% 30/30 [00:27<00:00,  1.07it/s]\n",
            "╒════════════════╤══════════╤═══════════╤════════════╕\n",
            "│ account_type   │     loss │   roc_auc │   accuracy │\n",
            "╞════════════════╪══════════╪═══════════╪════════════╡\n",
            "│ train          │ 114.0118 │    0.4891 │     0.5374 │\n",
            "├────────────────┼──────────┼───────────┼────────────┤\n",
            "│ vali           │ 112.8270 │    0.4922 │     0.5255 │\n",
            "├────────────────┼──────────┼───────────┼────────────┤\n",
            "│ test           │ 135.3027 │    0.4946 │     0.5461 │\n",
            "╘════════════════╧══════════╧═══════════╧════════════╛\n",
            "╒════════════╤══════════╕\n",
            "│ combined   │     loss │\n",
            "╞════════════╪══════════╡\n",
            "│ train      │ 114.0118 │\n",
            "├────────────┼──────────┤\n",
            "│ vali       │ 112.8270 │\n",
            "├────────────┼──────────┤\n",
            "│ test       │ 135.3027 │\n",
            "╘════════════╧══════════╛\n",
            "Last improvement of combined validation loss happened 234 step(s) ago.\n",
            "\n",
            "Training:   3% 702/23400 [47:00<19:37:39,  3.11s/it]\n",
            "Running evaluation for step: 702, epoch: 2\n",
            "Evaluation train: 100% 234/234 [03:47<00:00,  1.03it/s]\n",
            "Evaluation vali : 100% 30/30 [00:27<00:00,  1.08it/s]\n",
            "Evaluation test : 100% 30/30 [00:28<00:00,  1.06it/s]\n",
            "╒════════════════╤══════════╤═══════════╤════════════╕\n",
            "│ account_type   │     loss │   roc_auc │   accuracy │\n",
            "╞════════════════╪══════════╪═══════════╪════════════╡\n",
            "│ train          │  89.2472 │    0.6335 │     0.6319 │\n",
            "├────────────────┼──────────┼───────────┼────────────┤\n",
            "│ vali           │  88.3682 │    0.6123 │     0.6139 │\n",
            "├────────────────┼──────────┼───────────┼────────────┤\n",
            "│ test           │ 106.0248 │    0.6190 │     0.6232 │\n",
            "╘════════════════╧══════════╧═══════════╧════════════╛\n",
            "╒════════════╤══════════╕\n",
            "│ combined   │     loss │\n",
            "╞════════════╪══════════╡\n",
            "│ train      │  89.2472 │\n",
            "├────────────┼──────────┤\n",
            "│ vali       │  88.3682 │\n",
            "├────────────┼──────────┤\n",
            "│ test       │ 106.0248 │\n",
            "╘════════════╧══════════╛\n",
            "Last improvement of combined validation loss happened 468 step(s) ago.\n",
            "\n",
            "Training:   4% 851/23400 [59:25<20:00:10,  3.19s/it]"
          ]
        }
      ],
      "source": [
        "# Trains the model. This cell might take a few minutes.\n",
        "!ludwig train --dataset twitter_human_bots_dataset.csv -c config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47tFtYwUuucY"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTe2wDNguw5D"
      },
      "outputs": [],
      "source": [
        "# Generates predictions and performance statistics for the test set.\n",
        "!ludwig evaluate --model_path results/experiment_run/model \\\n",
        "                 --dataset twitter_human_bots_dataset.csv \\\n",
        "                 --split test \\\n",
        "                 --output_directory results/experiment_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1VTQf6flpxU"
      },
      "source": [
        "# Visualize Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj1ocMUtaMRJ"
      },
      "outputs": [],
      "source": [
        "# Visualizes confusion matrix, which gives an overview of classifier performance\n",
        "# for each class.\n",
        "!ludwig visualize --visualization confusion_matrix \\\n",
        "                  --ground_truth_metadata results/experiment_run/model/training_set_metadata.json \\\n",
        "                  --test_statistics results/experiment_run/test_statistics.json \\\n",
        "                  --output_directory visualizations \\\n",
        "                  --file_format png\n",
        "\n",
        "# If you run ludwig visualize locally, visualizations will automatically show in\n",
        "# a window. Here in Colab, we can run the following code to load and display\n",
        "# generated plots inline.\n",
        "from IPython import display\n",
        "import ipywidgets\n",
        "from pathlib import Path\n",
        "\n",
        "ipywidgets.HBox([\n",
        "  ipywidgets.Image(value=Path(\"visualizations/confusion_matrix__account_type_top3.png\").read_bytes()),\n",
        "  ipywidgets.Image(value=Path(\"visualizations/confusion_matrix_entropy__account_type_top3.png\").read_bytes()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaYNW7T71CMf"
      },
      "outputs": [],
      "source": [
        "# Visualizes learning curves, which show how performance metrics changed over\n",
        "# time during training.\n",
        "!ludwig visualize --visualization learning_curves \\\n",
        "                  --training_statistics results/experiment_run/training_statistics.json \\\n",
        "                  --output_directory visualizations \\\n",
        "                  --file_format png\n",
        "\n",
        "\n",
        "ipywidgets.HBox([\n",
        "  ipywidgets.Image(value=Path(\"visualizations/learning_curves_account_type_loss.png\").read_bytes()),\n",
        "  ipywidgets.Image(value=Path(\"visualizations/learning_curves_account_type_accuracy.png\").read_bytes()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6S_KAnzaQdT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Multimodal Classification with Ludwig - CLI.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}