
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Deep learning toolbox">
      
      
        <link rel="canonical" href="https://ludwig-ai.github.io/ludwig-docs/user_guide/">
      
      
        <meta name="author" content="Piero Molino">
      
      <link rel="shortcut icon" href="../favicon.ico">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.0.2">
    
    
      
        <title>User Guide - Ludwig</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.38780c08.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.3f72e892.min.css">
        
          
          
          <meta name="theme-color" content="#757575">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../stylesheets/monokai.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="grey" data-md-color-accent="grey">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#command-line-interface" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://ludwig-ai.github.io/ludwig-docs/" title="Ludwig" class="md-header-nav__button md-logo" aria-label="Ludwig">
      
<img alt="logo" src="../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Ludwig
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              User Guide
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/ludwig-ai/ludwig/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ludwig-ai/ludwig
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav aria-label="Navigation" class="md-nav md-nav--primary"
     data-md-level="0">
    <label class="md-nav__title" for="__drawer">
        <a aria-label="Ludwig" class="md-nav__button md-logo"
           href="https://ludwig-ai.github.io/ludwig-docs/"
           title="Ludwig">
            <img alt="logo" src="../images/ludwig_logo.svg"
                 style="width:10rem;height:auto;">
        </a>
    </label>
    
    <div class="md-nav__source">
        
<a href="https://github.com/ludwig-ai/ludwig/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ludwig-ai/ludwig
  </div>
</a>
    </div>
    
    <ul class="md-nav__list" data-md-scrollfix>
        
        
        
        


  <li class="md-nav__item">
    <a href=".." class="md-nav__link">
      About
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../getting_started/" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../examples/" class="md-nav__link">
      Examples
    </a>
  </li>

        
        
        
        

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        User Guide
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      User Guide
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#command-line-interface" class="md-nav__link">
    Command Line Interface
  </a>
  
    <nav class="md-nav" aria-label="Command Line Interface">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experiment" class="md-nav__link">
    experiment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt" class="md-nav__link">
    hyperopt
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#serve" class="md-nav__link">
    serve
  </a>
  
    <nav class="md-nav" aria-label="serve">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-curl" class="md-nav__link">
    Example curl
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualize" class="md-nav__link">
    visualize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collect_summary" class="md-nav__link">
    collect_summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collect_weights" class="md-nav__link">
    collect_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collect_activations" class="md-nav__link">
    collect_activations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#export_savedmodel" class="md-nav__link">
    export_savedmodel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#export_neuropod" class="md-nav__link">
    export_neuropod
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocess" class="md-nav__link">
    preprocess
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#synthesize_dataset" class="md-nav__link">
    synthesize_dataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-preprocessing" class="md-nav__link">
    Data Preprocessing
  </a>
  
    <nav class="md-nav" aria-label="Data Preprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataset-format" class="md-nav__link">
    Dataset Format
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-postprocessing" class="md-nav__link">
    Data Postprocessing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    Configuration
  </a>
  
    <nav class="md-nav" aria-label="Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#input-features" class="md-nav__link">
    Input features
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#combiner" class="md-nav__link">
    Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-features" class="md-nav__link">
    Output Features
  </a>
  
    <nav class="md-nav" aria-label="Output Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-task-learning" class="md-nav__link">
    Multi-task Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-features-dependencies" class="md-nav__link">
    Output Features Dependencies
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    Training
  </a>
  
    <nav class="md-nav" aria-label="Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#optimizers-details" class="md-nav__link">
    Optimizers details
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    Preprocessing
  </a>
  
    <nav class="md-nav" aria-label="Preprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokenizers" class="md-nav__link">
    Tokenizers
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-features" class="md-nav__link">
    Binary Features
  </a>
  
    <nav class="md-nav" aria-label="Binary Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary-features-preprocessing" class="md-nav__link">
    Binary Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-input-features-and-encoders" class="md-nav__link">
    Binary Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dense-encoder-parameters" class="md-nav__link">
    Dense Encoder Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-output-features-and-decoders" class="md-nav__link">
    Binary Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-features-measures" class="md-nav__link">
    Binary Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-features" class="md-nav__link">
    Numerical Features
  </a>
  
    <nav class="md-nav" aria-label="Numerical Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#numerical-features-preprocessing" class="md-nav__link">
    Numerical Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-input-features-and-encoders" class="md-nav__link">
    Numerical Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dense-encoder-parameters_1" class="md-nav__link">
    Dense Encoder Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-output-features-and-decoders" class="md-nav__link">
    Numerical Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-features-measures" class="md-nav__link">
    Numerical Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-features" class="md-nav__link">
    Category Features
  </a>
  
    <nav class="md-nav" aria-label="Category Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#category-features-preprocessing" class="md-nav__link">
    Category Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-input-features-and-encoders" class="md-nav__link">
    Category Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Category Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dense-encoder" class="md-nav__link">
    Dense Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse-encoder" class="md-nav__link">
    Sparse Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-output-features-and-decoders" class="md-nav__link">
    Category Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-features-measures" class="md-nav__link">
    Category Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-features" class="md-nav__link">
    Set Features
  </a>
  
    <nav class="md-nav" aria-label="Set Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#set-features-preprocessing" class="md-nav__link">
    Set Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-input-features-and-encoders" class="md-nav__link">
    Set Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-output-features-and-decoders" class="md-nav__link">
    Set Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-features-measures" class="md-nav__link">
    Set Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bag-features" class="md-nav__link">
    Bag Features
  </a>
  
    <nav class="md-nav" aria-label="Bag Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bag-features-preprocessing" class="md-nav__link">
    Bag Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bag-input-features-and-encoders" class="md-nav__link">
    Bag Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bag-output-features-and-decoders" class="md-nav__link">
    Bag Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bag-features-measures" class="md-nav__link">
    Bag Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-features" class="md-nav__link">
    Sequence Features
  </a>
  
    <nav class="md-nav" aria-label="Sequence Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sequence-features-preprocessing" class="md-nav__link">
    Sequence Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-input-features-and-encoders" class="md-nav__link">
    Sequence Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Sequence Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-cnn-encoder" class="md-nav__link">
    Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-cnn-encoder" class="md-nav__link">
    Stacked CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-parallel-cnn-encoder" class="md-nav__link">
    Stacked Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-encoder" class="md-nav__link">
    RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-rnn-encoder" class="md-nav__link">
    CNN RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-encoder" class="md-nav__link">
    Transformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#passthrough-encoder" class="md-nav__link">
    Passthrough Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-output-features-and-decoders" class="md-nav__link">
    Sequence Output Features and Decoders
  </a>
  
    <nav class="md-nav" aria-label="Sequence Output Features and Decoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tagger-decoder" class="md-nav__link">
    Tagger Decoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generator-decoder" class="md-nav__link">
    Generator Decoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-features-measures" class="md-nav__link">
    Sequence Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-features" class="md-nav__link">
    Text Features
  </a>
  
    <nav class="md-nav" aria-label="Text Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#text-features-preprocessing" class="md-nav__link">
    Text Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-input-features-and-encoders" class="md-nav__link">
    Text Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Text Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bert-encoder" class="md-nav__link">
    BERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-encoder" class="md-nav__link">
    GPT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-2-encoder" class="md-nav__link">
    GPT-2 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlnet-encoder" class="md-nav__link">
    XLNet Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlm-encoder" class="md-nav__link">
    XLM Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roberta-encoder" class="md-nav__link">
    RoBERTa Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distilbert-encoder" class="md-nav__link">
    DistilBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ctrl-encoder" class="md-nav__link">
    CTRL Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camembert-encoder" class="md-nav__link">
    CamemBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#albert-encoder" class="md-nav__link">
    ALBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t5-encoder" class="md-nav__link">
    T5 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlm-roberta-encoder" class="md-nav__link">
    XLM-RoBERTa Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flaubert-encoder" class="md-nav__link">
    FlauBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#electra-encoder" class="md-nav__link">
    ELECTRA Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#longformer-encoder" class="md-nav__link">
    Longformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-transformer-encoder" class="md-nav__link">
    Auto-Transformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-usage" class="md-nav__link">
    Example usage
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-output-features-and-decoders" class="md-nav__link">
    Text Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-features-measures" class="md-nav__link">
    Text Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-series-features" class="md-nav__link">
    Time Series Features
  </a>
  
    <nav class="md-nav" aria-label="Time Series Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#time-series-features-preprocessing" class="md-nav__link">
    Time Series Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-series-input-features-and-encoders" class="md-nav__link">
    Time Series Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-series-output-features-and-decoders" class="md-nav__link">
    Time Series Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-series-features-measures" class="md-nav__link">
    Time Series Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-features" class="md-nav__link">
    Audio Features
  </a>
  
    <nav class="md-nav" aria-label="Audio Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#audio-features-preprocessing" class="md-nav__link">
    Audio Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-input-features-and-encoders" class="md-nav__link">
    Audio Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-output-features-and-decoders" class="md-nav__link">
    Audio Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-features-measures" class="md-nav__link">
    Audio Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-features" class="md-nav__link">
    Image Features
  </a>
  
    <nav class="md-nav" aria-label="Image Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#image-features-preprocessing" class="md-nav__link">
    Image Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-input-features-and-encoders" class="md-nav__link">
    Image Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Image Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolutional-stack-encoder" class="md-nav__link">
    Convolutional Stack Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnet-encoder" class="md-nav__link">
    ResNet Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-output-features-and-decoders" class="md-nav__link">
    Image Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-features-measures" class="md-nav__link">
    Image Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#date-features" class="md-nav__link">
    Date Features
  </a>
  
    <nav class="md-nav" aria-label="Date Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#date-features-preprocessing" class="md-nav__link">
    Date Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#date-input-features-and-encoders" class="md-nav__link">
    Date Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Date Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder_1" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wave-encoder" class="md-nav__link">
    Wave Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#date-output-features-and-decoders" class="md-nav__link">
    Date Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#date-features-measures" class="md-nav__link">
    Date Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#h3-features" class="md-nav__link">
    H3 Features
  </a>
  
    <nav class="md-nav" aria-label="H3 Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#h3-features-preprocessing" class="md-nav__link">
    H3 Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#h3-input-features-and-encoders" class="md-nav__link">
    H3 Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="H3 Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder_2" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weighted-sum-embed-encoder" class="md-nav__link">
    Weighted Sum Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-encoder_1" class="md-nav__link">
    RNN Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#h3-output-features-and-decoders" class="md-nav__link">
    H3 Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#h3-features-measures" class="md-nav__link">
    H3 Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-features" class="md-nav__link">
    Vector Features
  </a>
  
    <nav class="md-nav" aria-label="Vector Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vector-feature-preprocessing" class="md-nav__link">
    Vector Feature Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-feature-encoders" class="md-nav__link">
    Vector Feature Encoders
  </a>
  
    <nav class="md-nav" aria-label="Vector Feature Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dense-encoder_1" class="md-nav__link">
    Dense Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-feature-decoders" class="md-nav__link">
    Vector Feature Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-features-measures" class="md-nav__link">
    Vector Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#combiners" class="md-nav__link">
    Combiners
  </a>
  
    <nav class="md-nav" aria-label="Combiners">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#concat-combiner" class="md-nav__link">
    Concat Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-concat-combiner" class="md-nav__link">
    Sequence Concat Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-combiner" class="md-nav__link">
    Sequence Combiner
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-training" class="md-nav__link">
    Distributed Training
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyper-parameter-optimization" class="md-nav__link">
    Hyper-parameter optimization
  </a>
  
    <nav class="md-nav" aria-label="Hyper-parameter optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyper-parameters" class="md-nav__link">
    Hyper-parameters
  </a>
  
    <nav class="md-nav" aria-label="Hyper-parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#float-parameters" class="md-nav__link">
    Float parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#int-parameters" class="md-nav__link">
    Int parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-parameters" class="md-nav__link">
    Category parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sampler" class="md-nav__link">
    Sampler
  </a>
  
    <nav class="md-nav" aria-label="Sampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#grid-sampler" class="md-nav__link">
    Grid sampler
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-sampler" class="md-nav__link">
    Random sampler
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pysot-sampler" class="md-nav__link">
    PySOT sampler
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#executor" class="md-nav__link">
    Executor
  </a>
  
    <nav class="md-nav" aria-label="Executor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#serial-executor" class="md-nav__link">
    Serial Executor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-executor" class="md-nav__link">
    Parallel Executor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fiber-executor" class="md-nav__link">
    Fiber Executor
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full-hyper-parameter-optimization-example" class="md-nav__link">
    Full hyper-parameter optimization example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integrations" class="md-nav__link">
    Integrations
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#programmatic-api" class="md-nav__link">
    Programmatic API
  </a>
  
    <nav class="md-nav" aria-label="Programmatic API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#training-a-model" class="md-nav__link">
    Training a Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loading-a-pre-trained-model" class="md-nav__link">
    Loading a Pre-trained Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predicting" class="md-nav__link">
    Predicting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visualizations" class="md-nav__link">
    Visualizations
  </a>
  
    <nav class="md-nav" aria-label="Visualizations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning-curves" class="md-nav__link">
    Learning Curves
  </a>
  
    <nav class="md-nav" aria-label="Learning Curves">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning_curves" class="md-nav__link">
    learning_curves
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confusion-matrix" class="md-nav__link">
    Confusion Matrix
  </a>
  
    <nav class="md-nav" aria-label="Confusion Matrix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#confusion_matrix" class="md-nav__link">
    confusion_matrix
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare-performance" class="md-nav__link">
    Compare Performance
  </a>
  
    <nav class="md-nav" aria-label="Compare Performance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compare_performance" class="md-nav__link">
    compare_performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_from_prob" class="md-nav__link">
    compare_classifiers_performance_from_prob
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_from_pred" class="md-nav__link">
    compare_classifiers_performance_from_pred
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_subset" class="md-nav__link">
    compare_classifiers_performance_subset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_changing_k" class="md-nav__link">
    compare_classifiers_performance_changing_k
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_multiclass_multimetric" class="md-nav__link">
    compare_classifiers_multiclass_multimetric
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare-classifier-predictions" class="md-nav__link">
    Compare Classifier Predictions
  </a>
  
    <nav class="md-nav" aria-label="Compare Classifier Predictions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_predictions" class="md-nav__link">
    compare_classifiers_predictions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_predictions_distribution" class="md-nav__link">
    compare_classifiers_predictions_distribution
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding" class="md-nav__link">
    Confidence_Thresholding
  </a>
  
    <nav class="md-nav" aria-label="Confidence_Thresholding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_1" class="md-nav__link">
    confidence_thresholding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc" class="md-nav__link">
    confidence_thresholding_data_vs_acc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc_subset" class="md-nav__link">
    confidence_thresholding_data_vs_acc_subset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc_subset_per_class" class="md-nav__link">
    confidence_thresholding_data_vs_acc_subset_per_class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_2thresholds_2d" class="md-nav__link">
    confidence_thresholding_2thresholds_2d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_2thresholds_3d" class="md-nav__link">
    confidence_thresholding_2thresholds_3d
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-threshold-vs-metric" class="md-nav__link">
    Binary Threshold vs. Metric
  </a>
  
    <nav class="md-nav" aria-label="Binary Threshold vs. Metric">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary_threshold_vs_metric" class="md-nav__link">
    binary_threshold_vs_metric
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc-curves" class="md-nav__link">
    ROC Curves
  </a>
  
    <nav class="md-nav" aria-label="ROC Curves">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#roc_curves" class="md-nav__link">
    roc_curves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_curves_from_test_statistics" class="md-nav__link">
    roc_curves_from_test_statistics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calibration-plot" class="md-nav__link">
    Calibration Plot
  </a>
  
    <nav class="md-nav" aria-label="Calibration Plot">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#calibration_1_vs_all" class="md-nav__link">
    calibration_1_vs_all
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calibration_multiclass" class="md-nav__link">
    calibration_multiclass
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-frequency-vs-f1-score" class="md-nav__link">
    Class Frequency vs. F1 score
  </a>
  
    <nav class="md-nav" aria-label="Class Frequency vs. F1 score">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#frequency_vs_f1" class="md-nav__link">
    frequency_vs_f1
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyper-parameter-optimization-visualization" class="md-nav__link">
    Hyper-parameter optimization visualization
  </a>
  
    <nav class="md-nav" aria-label="Hyper-parameter optimization visualization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperopt_report" class="md-nav__link">
    hyperopt_report
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt_hiplot" class="md-nav__link">
    hyperopt_hiplot
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../developer_guide/" class="md-nav__link">
      Developer Guide
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      API
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="API" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon"></span>
        API
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../api/LudwigModel/" class="md-nav__link">
      LudwigModel
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../api/visualization/" class="md-nav__link">
      Visualization
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../community/" class="md-nav__link">
      Community
    </a>
  </li>

        
        
        
        


  <li class="md-nav__item">
    <a href="../faq/" class="md-nav__link">
      FAQ
    </a>
  </li>

        
    </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#command-line-interface" class="md-nav__link">
    Command Line Interface
  </a>
  
    <nav class="md-nav" aria-label="Command Line Interface">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experiment" class="md-nav__link">
    experiment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt" class="md-nav__link">
    hyperopt
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#serve" class="md-nav__link">
    serve
  </a>
  
    <nav class="md-nav" aria-label="serve">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-curl" class="md-nav__link">
    Example curl
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualize" class="md-nav__link">
    visualize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collect_summary" class="md-nav__link">
    collect_summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collect_weights" class="md-nav__link">
    collect_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collect_activations" class="md-nav__link">
    collect_activations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#export_savedmodel" class="md-nav__link">
    export_savedmodel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#export_neuropod" class="md-nav__link">
    export_neuropod
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocess" class="md-nav__link">
    preprocess
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#synthesize_dataset" class="md-nav__link">
    synthesize_dataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-preprocessing" class="md-nav__link">
    Data Preprocessing
  </a>
  
    <nav class="md-nav" aria-label="Data Preprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataset-format" class="md-nav__link">
    Dataset Format
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-postprocessing" class="md-nav__link">
    Data Postprocessing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    Configuration
  </a>
  
    <nav class="md-nav" aria-label="Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#input-features" class="md-nav__link">
    Input features
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#combiner" class="md-nav__link">
    Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-features" class="md-nav__link">
    Output Features
  </a>
  
    <nav class="md-nav" aria-label="Output Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-task-learning" class="md-nav__link">
    Multi-task Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-features-dependencies" class="md-nav__link">
    Output Features Dependencies
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    Training
  </a>
  
    <nav class="md-nav" aria-label="Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#optimizers-details" class="md-nav__link">
    Optimizers details
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    Preprocessing
  </a>
  
    <nav class="md-nav" aria-label="Preprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokenizers" class="md-nav__link">
    Tokenizers
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-features" class="md-nav__link">
    Binary Features
  </a>
  
    <nav class="md-nav" aria-label="Binary Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary-features-preprocessing" class="md-nav__link">
    Binary Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-input-features-and-encoders" class="md-nav__link">
    Binary Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dense-encoder-parameters" class="md-nav__link">
    Dense Encoder Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-output-features-and-decoders" class="md-nav__link">
    Binary Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-features-measures" class="md-nav__link">
    Binary Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-features" class="md-nav__link">
    Numerical Features
  </a>
  
    <nav class="md-nav" aria-label="Numerical Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#numerical-features-preprocessing" class="md-nav__link">
    Numerical Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-input-features-and-encoders" class="md-nav__link">
    Numerical Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dense-encoder-parameters_1" class="md-nav__link">
    Dense Encoder Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-output-features-and-decoders" class="md-nav__link">
    Numerical Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-features-measures" class="md-nav__link">
    Numerical Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-features" class="md-nav__link">
    Category Features
  </a>
  
    <nav class="md-nav" aria-label="Category Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#category-features-preprocessing" class="md-nav__link">
    Category Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-input-features-and-encoders" class="md-nav__link">
    Category Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Category Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dense-encoder" class="md-nav__link">
    Dense Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse-encoder" class="md-nav__link">
    Sparse Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-output-features-and-decoders" class="md-nav__link">
    Category Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-features-measures" class="md-nav__link">
    Category Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-features" class="md-nav__link">
    Set Features
  </a>
  
    <nav class="md-nav" aria-label="Set Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#set-features-preprocessing" class="md-nav__link">
    Set Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-input-features-and-encoders" class="md-nav__link">
    Set Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-output-features-and-decoders" class="md-nav__link">
    Set Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set-features-measures" class="md-nav__link">
    Set Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bag-features" class="md-nav__link">
    Bag Features
  </a>
  
    <nav class="md-nav" aria-label="Bag Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bag-features-preprocessing" class="md-nav__link">
    Bag Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bag-input-features-and-encoders" class="md-nav__link">
    Bag Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bag-output-features-and-decoders" class="md-nav__link">
    Bag Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bag-features-measures" class="md-nav__link">
    Bag Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-features" class="md-nav__link">
    Sequence Features
  </a>
  
    <nav class="md-nav" aria-label="Sequence Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sequence-features-preprocessing" class="md-nav__link">
    Sequence Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-input-features-and-encoders" class="md-nav__link">
    Sequence Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Sequence Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-cnn-encoder" class="md-nav__link">
    Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-cnn-encoder" class="md-nav__link">
    Stacked CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-parallel-cnn-encoder" class="md-nav__link">
    Stacked Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-encoder" class="md-nav__link">
    RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-rnn-encoder" class="md-nav__link">
    CNN RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-encoder" class="md-nav__link">
    Transformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#passthrough-encoder" class="md-nav__link">
    Passthrough Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-output-features-and-decoders" class="md-nav__link">
    Sequence Output Features and Decoders
  </a>
  
    <nav class="md-nav" aria-label="Sequence Output Features and Decoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tagger-decoder" class="md-nav__link">
    Tagger Decoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generator-decoder" class="md-nav__link">
    Generator Decoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-features-measures" class="md-nav__link">
    Sequence Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-features" class="md-nav__link">
    Text Features
  </a>
  
    <nav class="md-nav" aria-label="Text Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#text-features-preprocessing" class="md-nav__link">
    Text Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-input-features-and-encoders" class="md-nav__link">
    Text Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Text Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bert-encoder" class="md-nav__link">
    BERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-encoder" class="md-nav__link">
    GPT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-2-encoder" class="md-nav__link">
    GPT-2 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlnet-encoder" class="md-nav__link">
    XLNet Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlm-encoder" class="md-nav__link">
    XLM Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roberta-encoder" class="md-nav__link">
    RoBERTa Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distilbert-encoder" class="md-nav__link">
    DistilBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ctrl-encoder" class="md-nav__link">
    CTRL Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camembert-encoder" class="md-nav__link">
    CamemBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#albert-encoder" class="md-nav__link">
    ALBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t5-encoder" class="md-nav__link">
    T5 Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlm-roberta-encoder" class="md-nav__link">
    XLM-RoBERTa Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flaubert-encoder" class="md-nav__link">
    FlauBERT Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#electra-encoder" class="md-nav__link">
    ELECTRA Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#longformer-encoder" class="md-nav__link">
    Longformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-transformer-encoder" class="md-nav__link">
    Auto-Transformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-usage" class="md-nav__link">
    Example usage
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-output-features-and-decoders" class="md-nav__link">
    Text Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-features-measures" class="md-nav__link">
    Text Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-series-features" class="md-nav__link">
    Time Series Features
  </a>
  
    <nav class="md-nav" aria-label="Time Series Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#time-series-features-preprocessing" class="md-nav__link">
    Time Series Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-series-input-features-and-encoders" class="md-nav__link">
    Time Series Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-series-output-features-and-decoders" class="md-nav__link">
    Time Series Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-series-features-measures" class="md-nav__link">
    Time Series Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-features" class="md-nav__link">
    Audio Features
  </a>
  
    <nav class="md-nav" aria-label="Audio Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#audio-features-preprocessing" class="md-nav__link">
    Audio Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-input-features-and-encoders" class="md-nav__link">
    Audio Input Features and Encoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-output-features-and-decoders" class="md-nav__link">
    Audio Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-features-measures" class="md-nav__link">
    Audio Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-features" class="md-nav__link">
    Image Features
  </a>
  
    <nav class="md-nav" aria-label="Image Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#image-features-preprocessing" class="md-nav__link">
    Image Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-input-features-and-encoders" class="md-nav__link">
    Image Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Image Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolutional-stack-encoder" class="md-nav__link">
    Convolutional Stack Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnet-encoder" class="md-nav__link">
    ResNet Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-output-features-and-decoders" class="md-nav__link">
    Image Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-features-measures" class="md-nav__link">
    Image Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#date-features" class="md-nav__link">
    Date Features
  </a>
  
    <nav class="md-nav" aria-label="Date Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#date-features-preprocessing" class="md-nav__link">
    Date Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#date-input-features-and-encoders" class="md-nav__link">
    Date Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="Date Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder_1" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wave-encoder" class="md-nav__link">
    Wave Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#date-output-features-and-decoders" class="md-nav__link">
    Date Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#date-features-measures" class="md-nav__link">
    Date Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#h3-features" class="md-nav__link">
    H3 Features
  </a>
  
    <nav class="md-nav" aria-label="H3 Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#h3-features-preprocessing" class="md-nav__link">
    H3 Features Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#h3-input-features-and-encoders" class="md-nav__link">
    H3 Input Features and Encoders
  </a>
  
    <nav class="md-nav" aria-label="H3 Input Features and Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder_2" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weighted-sum-embed-encoder" class="md-nav__link">
    Weighted Sum Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-encoder_1" class="md-nav__link">
    RNN Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#h3-output-features-and-decoders" class="md-nav__link">
    H3 Output Features and Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#h3-features-measures" class="md-nav__link">
    H3 Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-features" class="md-nav__link">
    Vector Features
  </a>
  
    <nav class="md-nav" aria-label="Vector Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vector-feature-preprocessing" class="md-nav__link">
    Vector Feature Preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-feature-encoders" class="md-nav__link">
    Vector Feature Encoders
  </a>
  
    <nav class="md-nav" aria-label="Vector Feature Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dense-encoder_1" class="md-nav__link">
    Dense Encoder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-feature-decoders" class="md-nav__link">
    Vector Feature Decoders
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-features-measures" class="md-nav__link">
    Vector Features Measures
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#combiners" class="md-nav__link">
    Combiners
  </a>
  
    <nav class="md-nav" aria-label="Combiners">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#concat-combiner" class="md-nav__link">
    Concat Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-concat-combiner" class="md-nav__link">
    Sequence Concat Combiner
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-combiner" class="md-nav__link">
    Sequence Combiner
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-training" class="md-nav__link">
    Distributed Training
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyper-parameter-optimization" class="md-nav__link">
    Hyper-parameter optimization
  </a>
  
    <nav class="md-nav" aria-label="Hyper-parameter optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyper-parameters" class="md-nav__link">
    Hyper-parameters
  </a>
  
    <nav class="md-nav" aria-label="Hyper-parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#float-parameters" class="md-nav__link">
    Float parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#int-parameters" class="md-nav__link">
    Int parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#category-parameters" class="md-nav__link">
    Category parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sampler" class="md-nav__link">
    Sampler
  </a>
  
    <nav class="md-nav" aria-label="Sampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#grid-sampler" class="md-nav__link">
    Grid sampler
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-sampler" class="md-nav__link">
    Random sampler
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pysot-sampler" class="md-nav__link">
    PySOT sampler
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#executor" class="md-nav__link">
    Executor
  </a>
  
    <nav class="md-nav" aria-label="Executor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#serial-executor" class="md-nav__link">
    Serial Executor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-executor" class="md-nav__link">
    Parallel Executor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fiber-executor" class="md-nav__link">
    Fiber Executor
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full-hyper-parameter-optimization-example" class="md-nav__link">
    Full hyper-parameter optimization example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integrations" class="md-nav__link">
    Integrations
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#programmatic-api" class="md-nav__link">
    Programmatic API
  </a>
  
    <nav class="md-nav" aria-label="Programmatic API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#training-a-model" class="md-nav__link">
    Training a Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loading-a-pre-trained-model" class="md-nav__link">
    Loading a Pre-trained Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predicting" class="md-nav__link">
    Predicting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visualizations" class="md-nav__link">
    Visualizations
  </a>
  
    <nav class="md-nav" aria-label="Visualizations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning-curves" class="md-nav__link">
    Learning Curves
  </a>
  
    <nav class="md-nav" aria-label="Learning Curves">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning_curves" class="md-nav__link">
    learning_curves
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confusion-matrix" class="md-nav__link">
    Confusion Matrix
  </a>
  
    <nav class="md-nav" aria-label="Confusion Matrix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#confusion_matrix" class="md-nav__link">
    confusion_matrix
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare-performance" class="md-nav__link">
    Compare Performance
  </a>
  
    <nav class="md-nav" aria-label="Compare Performance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compare_performance" class="md-nav__link">
    compare_performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_from_prob" class="md-nav__link">
    compare_classifiers_performance_from_prob
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_from_pred" class="md-nav__link">
    compare_classifiers_performance_from_pred
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_subset" class="md-nav__link">
    compare_classifiers_performance_subset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_performance_changing_k" class="md-nav__link">
    compare_classifiers_performance_changing_k
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_multiclass_multimetric" class="md-nav__link">
    compare_classifiers_multiclass_multimetric
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare-classifier-predictions" class="md-nav__link">
    Compare Classifier Predictions
  </a>
  
    <nav class="md-nav" aria-label="Compare Classifier Predictions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_predictions" class="md-nav__link">
    compare_classifiers_predictions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compare_classifiers_predictions_distribution" class="md-nav__link">
    compare_classifiers_predictions_distribution
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding" class="md-nav__link">
    Confidence_Thresholding
  </a>
  
    <nav class="md-nav" aria-label="Confidence_Thresholding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_1" class="md-nav__link">
    confidence_thresholding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc" class="md-nav__link">
    confidence_thresholding_data_vs_acc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc_subset" class="md-nav__link">
    confidence_thresholding_data_vs_acc_subset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_data_vs_acc_subset_per_class" class="md-nav__link">
    confidence_thresholding_data_vs_acc_subset_per_class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_2thresholds_2d" class="md-nav__link">
    confidence_thresholding_2thresholds_2d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence_thresholding_2thresholds_3d" class="md-nav__link">
    confidence_thresholding_2thresholds_3d
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-threshold-vs-metric" class="md-nav__link">
    Binary Threshold vs. Metric
  </a>
  
    <nav class="md-nav" aria-label="Binary Threshold vs. Metric">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary_threshold_vs_metric" class="md-nav__link">
    binary_threshold_vs_metric
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc-curves" class="md-nav__link">
    ROC Curves
  </a>
  
    <nav class="md-nav" aria-label="ROC Curves">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#roc_curves" class="md-nav__link">
    roc_curves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_curves_from_test_statistics" class="md-nav__link">
    roc_curves_from_test_statistics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calibration-plot" class="md-nav__link">
    Calibration Plot
  </a>
  
    <nav class="md-nav" aria-label="Calibration Plot">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#calibration_1_vs_all" class="md-nav__link">
    calibration_1_vs_all
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calibration_multiclass" class="md-nav__link">
    calibration_multiclass
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-frequency-vs-f1-score" class="md-nav__link">
    Class Frequency vs. F1 score
  </a>
  
    <nav class="md-nav" aria-label="Class Frequency vs. F1 score">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#frequency_vs_f1" class="md-nav__link">
    frequency_vs_f1
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyper-parameter-optimization-visualization" class="md-nav__link">
    Hyper-parameter optimization visualization
  </a>
  
    <nav class="md-nav" aria-label="Hyper-parameter optimization visualization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperopt_report" class="md-nav__link">
    hyperopt_report
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt_hiplot" class="md-nav__link">
    hyperopt_hiplot
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/ludwig-ai/ludwig/edit/master/mkdocs/docs/user_guide.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  <h1>User Guide</h1>
                
                <h2 id="command-line-interface">Command Line Interface<a class="headerlink" href="#command-line-interface" title="Permanent link">&para;</a></h2>
<p>Ludwig provides several command line interface entry points</p>
<ul>
<li><code>train</code>: Trains a model</li>
<li><code>predict</code>: Predicts using a pretrained model</li>
<li><code>evaluate</code>: Evaluate a pretrained model's performance</li>
<li><code>experiment</code>: Runs a full experiment training a model and evaluating it</li>
<li><code>serve</code>: Serves a pretrained model</li>
<li><code>visualize</code>: Visualizes experimental results</li>
<li><code>hyperopt</code>: Perform hyperparameter optimization</li>
<li><code>collect_summary</code>: Prints names of weights and layers activations to use with other collect commands</li>
<li><code>collect_weights</code>: Collects tensors containing a pretrained model weights</li>
<li><code>collect_activations</code>: Collects tensors for each datapoint using a pretrained model</li>
<li><code>export_savedmodel</code>: Exports Ludwig models to SavedModel</li>
<li><code>export_neuropod</code>: Exports Ludwig models to Neuropod</li>
<li><code>preprocess</code>: Preprocess data and saves it into HDF5 and JSON format</li>
<li><code>synthesize_dataset</code>: Creates synthetic data for tesing purposes</li>
</ul>
<p>They are described in detail below.</p>
<h3 id="train">train<a class="headerlink" href="#train" title="Permanent link">&para;</a></h3>
<p>This command lets you train a model from your data.
You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig train [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.train [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig train [options]

This script trains a model

optional arguments:
  -h, --help            show this help message and exit
  --output_directory OUTPUT_DIRECTORY
                        directory that contains the results
  --experiment_name EXPERIMENT_NAME
                        experiment name
  --model_name MODEL_NAME
                        name for the model
  --dataset DATASET     input data file path. If it has a split column, it
                        will be used for splitting (0: train, 1: validation,
                        2: test), otherwise the dataset will be randomly split
  --training_set TRAINING_SET
                        input train data file path
  --validation_set VALIDATION_SET
                        input validation data file path
  --test_set TEST_SET   input test data file path
  --training_set_metadata TRAINING_SET_METADATA
                        input metadata JSON file path. An intermediate
                        preprocessed  containing the mappings of the input
                        file created the first time a file is used, in the
                        same directory with the same name and a .json
                        extension
  --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv}
                        format of the input data
  -sspi, --skip_save_processed_input
                        skips saving intermediate HDF5 and JSON files
  -c CONFIG, --config CONFIG
                        config
  -cf CONFIG_FILE, --config_file CONFIG_FILE
                        YAML file describing the model. Ignores --config
  -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH
                        path of a pretrained model to load as initialization
  -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH
                        path of the model directory to resume training of
  -sstd, --skip_save_training_description
                        disables saving the description JSON file
  -ssts, --skip_save_training_statistics
                        disables saving training statistics JSON file
  -ssm, --skip_save_model
                        disables saving weights each time the model improves.
                        By default Ludwig saves weights after each epoch the
                        validation metric imrpvoes, but if the model is really
                        big that can be time consuming. If you do not want to
                        keep the weights and just find out what performance
                        can a model get with a set of hyperparameters, use
                        this parameter to skip it
  -ssp, --skip_save_progress
                        disables saving weights after each epoch. By default
                        ludwig saves weights after each epoch for enabling
                        resuming of training, but if the model is really big
                        that can be time consuming and will save twice as much
                        space, use this parameter to skip it
  -ssl, --skip_save_log
                        disables saving TensorBoard logs. By default Ludwig
                        saves logs for the TensorBoard, but if it is not
                        needed turning it off can slightly increase the
                        overall speed
  -rs RANDOM_SEED, --random_seed RANDOM_SEED
                        a random seed that is going to be used anywhere there
                        is a call to a random number generator: data
                        splitting, parameter initialization and training set
                        shuffling
  -g GPUS [GPUS ...], --gpus GPUS [GPUS ...]
                        list of gpus to use
  -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT
                        maximum memory in MB to allocate per GPU device
  -dpt, --disable_parallel_threads
                        disable TensorFlow from using multithreading for
                        reproducibility
  -uh, --use_horovod    uses horovod for distributed training
  -dbg, --debug         enables debugging mode
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>When Ludwig trains a model it creates two intermediate files, one HDF5 and one JSON.
The HDF5 file contains the data mapped to numpy ndarrays, while the JSON file 
contains the mappings from the values in the tensors to their original labels.</p>
<p>For instance, for a categorical feature with 3 possible values, the HDF5 file 
will contain integers from 0 to 3 (with 0 being a <code>&lt;UNK&gt;</code> category), while the 
JSON file will contain a <code>idx2str</code> list containing all tokens 
(<code>[&lt;UNK&gt;, label_1, label_2, label_3]</code>), a <code>str2idx</code> dictionary 
(<code>{"&lt;UNK&gt;": 0, "label_1": 1, "label_2": 2, "label_3": 3}</code>) and a <code>str2freq</code> 
dictionary (<code>{"&lt;UNK&gt;": 0, "label_1": 93, "label_2": 55, "label_3": 24}</code>).</p>
<p>The reason to have those  intermediate files is two-fold: on one hand, if you are going to train your model again Ludwig will try to load them instead of recomputing all tensors, which saves a considerable amount of time, and on the other hand when you want to use your model to predict, data has to be mapped to tensors in exactly the same way it was mapped during training, so you'll be required to load the JSON metadata file in the <code>predict</code> command.
The way this works is: the first time you provide a UTF-8 encoded dataset (<code>--dataset</code>), the HDF5 and JSON files are created, from the second time on Ludwig will load them instead of the dataset even if you specify the dataset (it looks in the same directory for files names in the same way but with a different extension), finally you can directly specify the HDF5 and JSON files.</p>
<p>As the mapping from raw data to tensors depends on the type of feature that you specify in your configuration, if you change type (for instance from <code>sequence</code> to <code>text</code>) you also have to redo the preprocessing, which is achieved by deleting the HDF5 and JSON files.
Alternatively you can skip saving the HDF5 and JSON files specifying <code>--skip_save_processed_input</code>.</p>
<p>Splitting between train, validation and test set can be done in several ways.
This allows for a few possible input data scenarios:</p>
<ul>
<li>one single UTF-8 encoded dataset file is provided (<code>-dataset</code>). In this case if the dataset contains a <code>split</code> column with values <code>0</code> for training, <code>1</code> for validation and <code>2</code> for test, this split will be used. If you want to ignore the split column and perform a random split, use a <code>force_split</code> argument in the configuration. In the case when there is no split column, a random <code>70-20-10</code> split will be performed. You can set the percentages and specify if you want stratified sampling in the configuration preprocessing section.</li>
<li>you can provide separate UTF-8 encoded training, validation and test sets  (<code>--training_set</code>, <code>--validation_set</code>, <code>--test_set</code>).</li>
<li>the HDF5 and JSON file indications specified in the case of a single dataset file apply also in the multiple files case, with the only difference that you need to specify only one JSON file (<code>--train_set_metadata_json</code>).</li>
</ul>
<p>The validation set is optional, but if absent the training wil continue until the end of the training epochs, while when there's a validation set the default behavior is to perform early stopping after the validation measure does not improve for a certain amount of epochs. The test set is optional too.</p>
<p>Other optional arguments are <code>--output_directory</code>, <code>--experiment_name</code> and <code>--model name</code>.
By default the output directory is <code>./results</code>.
That directory will contain a directory named <code>[experiment_name]_[model_name]_0</code> 
if model name and experiment name are specified.
If the same combination of experiment and model name is used again, the integer 
at the end of the name wil be increased.
If neither of them is specified the directory will be named <code>run_0</code>.
The directory will contain</p>
<ul>
<li><code>description.json</code> - a file containing a description of the training process with all the information to reproduce it.</li>
<li><code>training_statistics.json</code> - a file containing records of all measures and losses for each epoch.</li>
<li><code>model</code> - a directory containing model hyper-parameters, weights, checkpoints and logs (for TensorBoard).</li>
</ul>
<p>The configuration can be provided either as a string (<code>--config</code>) 
or as YAML file (<code>--config_file</code>).
Details on how to write your configuration are provided in the <a href="#configuration">Configuration</a> section.</p>
<p>During training Ludwig saves two sets of weights for the model, one that is the 
weights at the end of the epoch where the best performance on the validation 
measure was achieved and one that is the weights at the end of the latest epoch.
The reason for keeping the second set is to be able to resume training in case 
the training process gets interrupted somehow.</p>
<p>To resume training using the latest weights and the whole history of progress so far you have to specify the <code>--model_resume_path</code> argument.
You can avoid saving the latest weights and the overall progress so far by using the argument <code>--skip_save_progress</code>, but you will not be able to resume it afterwards.
Another available option is to load a previously trained model as an initialization for a new training process.
In this case Ludwig will start a new training process, without knowing any progress of the previous model, no training statistics, nor the number of epochs the model has been trained on so far.
It's not resuming training, just initializing training with a previously trained model with the same configuration, and it is accomplished through the <code>--model_load_path</code> argument.</p>
<p>You can specify a random seed to be used by the python environment, python random package, numpy and TensorFlow with the <code>--random_seed</code> argument.
This is useful for reproducibility.
Be aware that due to asynchronicity in the TensorFlow GPU execution, when training on GPU results may not be reproducible.</p>
<p>You can manage which GPUs on your machine are used with the <code>--gpus</code> argument, which accepts a string identical to the format of <code>CUDA_VISIBLE_DEVICES</code> environment variable, namely a list of integers separated by comma.
You can also specify the amount of GPU memory that will be initially assigned to TensorFlow with <code>--gpu_memory_limit</code>.
By default all of memory is allocated.
If less than all of memory is allcoated, TensorFlow will need more GPU memory it will try to increase this amount.</p>
<p>If parameter <code>--use_horovod</code> is set <code>true</code>, will use Horovod for distributed processing.</p>
<p>Finally the <code>--logging_level</code> argument lets you set the amount of logging that you want to see during training and the <code>--debug</code> argument turns on TensorFlow's <code>tfdbg</code>. Be careful when doing so, as it will help in catching errors, in particular <code>infs</code> and <code>NaNs</code> but it will consume much more memory.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code>ludwig train --dataset reuters-allcats.csv --config &quot;{input_features: [{name: text, type: text, encoder: parallel_cnn, level: word}], output_features: [{name: class, type: category}]}&quot;
</code></pre></div>

<h3 id="predict">predict<a class="headerlink" href="#predict" title="Permanent link">&para;</a></h3>
<p>This command lets you use a previously trained model to predict on new data.
You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig predict [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.predict [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig predict [options]

This script loads a pretrained model and uses it to predict

optional arguments:
  -h, --help            show this help message and exit
  --dataset DATASET     input data file path
  --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv}
                        format of the input data
  -s {training,validation,test,full}, --split {training,validation,test,full}
                        the split to test the model on
  -m MODEL_PATH, --model_path MODEL_PATH
                        model to load
  -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY
                        directory that contains the results
  -ssuo, --skip_save_unprocessed_output
                        skips saving intermediate NPY output files
  -sstp, --skip_save_predictions
                        skips saving predictions CSV files
  -bs BATCH_SIZE, --batch_size BATCH_SIZE
                        size of batches
  -g GPUS, --gpus GPUS  list of gpu to use
  -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT
                        maximum memory in MB to allocate per GPU device
  -dpt, --disable_parallel_threads
                        disable TensorFlow from using multithreading for
                        reproducibility
  -uh, --use_horovod    uses horovod for distributed training
  -dbg, --debug         enables debugging mode
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>The same distinction between UTF-8 encoded dataset files and HDF5 / JSON files explained in the <a href="#train">train</a> section also applies here.
In either case, the JSON metadata file obtained during training is needed in order to map the new data into tensors.
If the new data contains a split column, you can specify which split to use to calculate the predictions with the <code>--split</code> argument. By default it's <code>full</code> which means all the splits will be used.</p>
<p>A model to load is needed, and you can specify its path with the <code>--model_path</code> argument.
If you trained a model previously and got the results in, for instance, 
<code>./results/experiment_run_0</code>, you have to specify 
<code>./results/experiment_run_0/model</code> for using it to predict.</p>
<p>You can specify an output directory with the argument <code>--output-directory</code>, by 
default it will be <code>./result_0</code>, with increasing numbers if a directory with the same name is present.</p>
<p>The directory will contain a prediction CSV file and a probability CSV file for 
each output feature, together with raw NPY files containing raw tensors.
You can specify not to save the raw NPY output files with the argument <code>skip_save_unprocessed_output</code>.</p>
<p>A specific batch size for speeding up the prediction can be specified using the argument <code>--batch_size</code>.</p>
<p>Finally the <code>--logging_level</code>, <code>--debug</code>, <code>--gpus</code>, <code>--gpu_memory_limit</code> and <code>--disable_parallel_threads</code>  related arguments behave exactly like described in the train command section.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code>ludwig predict --dataset reuters-allcats.csv --model_path results/experiment_run_0/model/
</code></pre></div>

<h3 id="evaluate">evaluate<a class="headerlink" href="#evaluate" title="Permanent link">&para;</a></h3>
<p>This command lets you use a previously trained model to predict on new data and 
evaluate the performance of the prediction compared to ground truth.
You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig evaluate [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.evaluate [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig evaluate [options]

This script loads a pretrained model and evaluates its performance by
comparingits predictions with ground truth.

optional arguments:
  -h, --help            show this help message and exit
  --dataset DATASET     input data file path
  --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv}
                        format of the input data
  -s {training,validation,test,full}, --split {training,validation,test,full}
                        the split to test the model on
  -m MODEL_PATH, --model_path MODEL_PATH
                        model to load
  -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY
                        directory that contains the results
  -ssuo, --skip_save_unprocessed_output
                        skips saving intermediate NPY output files
  -sses, --skip_save_eval_stats
                        skips saving intermediate JSON eval statistics
  -scp, --skip_collect_predictions
                        skips collecting predictions
  -scos, --skip_collect_overall_stats
                        skips collecting overall stats
  -bs BATCH_SIZE, --batch_size BATCH_SIZE
                        size of batches
  -g GPUS, --gpus GPUS  list of gpu to use
  -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT
                        maximum memory in MB to allocate per GPU device
  -dpt, --disable_parallel_threads
                        disable TensorFlow from using multithreading for
                        reproducibility
  -uh, --use_horovod    uses horovod for distributed training
  -dbg, --debug         enables debugging mode
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>All parameters are the same of <a href="#predict">predict</a> and the behavior is the same.
The only difference isthat <code>evaluate</code> requires the dataset to contain also columns with the same name of output features.
This is needed because <code>evaluate</code> compares the predictions produced by the model with the ground truth and will save all those statistics in a <code>test_statistics.json</code> file in the result directory.</p>
<p>Note that the data must contain columns for each output feature with ground 
truth output values in order to compute the performance statistics.
If you receive an error regarding a missing output feature column in your data, 
it means that the data does not contain the columns for each output feature to use as ground truth.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code>ludwig evaluate --dataset reuters-allcats.csv --model_path results/experiment_run_0/model/
</code></pre></div>

<h3 id="experiment">experiment<a class="headerlink" href="#experiment" title="Permanent link">&para;</a></h3>
<p>This command combines training and evaluation into a single handy command.<br />
You can request a k-fold cross validation run by specifing the <code>--k_fold</code>
parameter.
You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig experiment [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.experiment [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig experiment [options]

This script trains and evaluates a model

optional arguments:
  -h, --help            show this help message and exit
  --output_directory OUTPUT_DIRECTORY
                        directory that contains the results
  --experiment_name EXPERIMENT_NAME
                        experiment name
  --model_name MODEL_NAME
                        name for the model
  --dataset DATASET     input data file path. If it has a split column, it
                        will be used for splitting (0: train, 1: validation,
                        2: test), otherwise the dataset will be randomly split
  --training_set TRAINING_SET
                        input train data file path
  --validation_set VALIDATION_SET
                        input validation data file path
  --test_set TEST_SET   input test data file path
  --training_set_metadata TRAINING_SET_METADATA
                        input metadata JSON file path. An intermediate
                        preprocessed  containing the mappings of the input
                        file created the first time a file is used, in the
                        same directory with the same name and a .json
                        extension
  --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv}
                        format of the input data
  -es {training,validation,test,full}, --eval_split {training,validation,test,full}
                        the split to evaluate the model on
  -sspi, --skip_save_processed_input
                        skips saving intermediate HDF5 and JSON files
  -ssuo, --skip_save_unprocessed_output
                        skips saving intermediate NPY output files
  -kf K_FOLD, --k_fold K_FOLD
                        number of folds for a k-fold cross validation run
  -skfsi, --skip_save_k_fold_split_indices
                        disables saving indices generated to split training
                        data set for the k-fold cross validation run, but if
                        it is not needed turning it off can slightly increase
                        the overall speed
  -c CONFIG, --config CONFIG
                        config
  -cf CONFIG_FILE, --config_file CONFIG_FILE
                        YAML file describing the model. Ignores
                        --model_hyperparameters
  -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH
                        path of a pretrained model to load as initialization
  -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH
                        path of the model directory to resume training of
  -sstd, --skip_save_training_description
                        disables saving the description JSON file
  -ssts, --skip_save_training_statistics
                        disables saving training statistics JSON file
  -sstp, --skip_save_predictions
                        skips saving test predictions CSV files
  -sstes, --skip_save_eval_stats
                        skips saving eval statistics JSON file
  -ssm, --skip_save_model
                        disables saving model weights and hyperparameters each
                        time the model improves. By default Ludwig saves model
                        weights after each epoch the validation metric
                        imprvoes, but if the model is really big that can be
                        time consuming if you do not want to keep the weights
                        and just find out what performance a model can get
                        with a set of hyperparameters, use this parameter to
                        skip it,but the model will not be loadable later on
  -ssp, --skip_save_progress
                        disables saving progress each epoch. By default Ludwig
                        saves weights and stats after each epoch for enabling
                        resuming of training, but if the model is really big
                        that can be time consuming and will uses twice as much
                        space, use this parameter to skip it, but training
                        cannot be resumed later on
  -ssl, --skip_save_log
                        disables saving TensorBoard logs. By default Ludwig
                        saves logs for the TensorBoard, but if it is not
                        needed turning it off can slightly increase the
                        overall speed
  -rs RANDOM_SEED, --random_seed RANDOM_SEED
                        a random seed that is going to be used anywhere there
                        is a call to a random number generator: data
                        splitting, parameter initialization and training set
                        shuffling
  -g GPUS [GPUS ...], --gpus GPUS [GPUS ...]
                        list of GPUs to use
  -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT
                        maximum memory in MB to allocate per GPU device
  -dpt, --disable_parallel_threads
                        disable TensorFlow from using multithreading for
                        reproducibility
  -uh, --use_horovod    uses horovod for distributed training
  -dbg, --debug         enables debugging mode
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>The parameters combine parameters from both <a href="#train">train</a> and <a href="#test">test</a> so 
refer to those sections for an in depth explanation.
The output directory will contain the outputs both commands produce.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code>ludwig experiment --dataset reuters-allcats.csv --config &quot;{input_features: [{name: text, type: text, encoder: parallel_cnn, level: word}], output_features: [{name: class, type: category}]}&quot;
</code></pre></div>

<h3 id="hyperopt">hyperopt<a class="headerlink" href="#hyperopt" title="Permanent link">&para;</a></h3>
<p>This command lets you perform an hyper-parameter search with a given sampler and parameters.
You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig hyperopt [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.hyperopt [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig hyperopt [options]

This script searches for optimal Hyperparameters

optional arguments:
  -h, --help            show this help message and exit
  -sshs, --skip_save_hyperopt_statistics
                        skips saving hyperopt statistics file
  --output_directory OUTPUT_DIRECTORY
                        directory that contains the results
  --experiment_name EXPERIMENT_NAME
                        experiment name
  --model_name MODEL_NAME
                        name for the model
  --dataset DATASET     input data file path. If it has a split column, it
                        will be used for splitting (0: train, 1: validation,
                        2: test), otherwise the dataset will be randomly split
  --training_set TRAINING_SET
                        input train data file path
  --validation_set VALIDATION_SET
                        input validation data file path
  --test_set TEST_SET   input test data file path
  --training_set_metadata TRAINING_SET_METADATA
                        input metadata JSON file path. An intermediate
                        preprocessed file containing the mappings of the input
                        file created the first time a file is used, in the
                        same directory with the same name and a .json
                        extension
  --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv}
                        format of the input data
  -sspi, --skip_save_processed_input
                        skips saving intermediate HDF5 and JSON files
  -c CONFIG, --config CONFIG
                        config
  -cf CONFIG_FILE, --config_file CONFIG_FILE
                        YAML file describing the model. Ignores
                        --model_hyperparameters
  -mlp MODEL_LOAD_PATH, --model_load_path MODEL_LOAD_PATH
                        path of a pretrained model to load as initialization
  -mrp MODEL_RESUME_PATH, --model_resume_path MODEL_RESUME_PATH
                        path of the model directory to resume training of
  -sstd, --skip_save_training_description
                        disables saving the description JSON file
  -ssts, --skip_save_training_statistics
                        disables saving training statistics JSON file
  -ssm, --skip_save_model
                        disables saving weights each time the model improves.
                        By default Ludwig saves weights after each epoch the
                        validation metric imrpvoes, but if the model is really
                        big that can be time consuming. If you do not want to
                        keep the weights and just find out what performance
                        can a model get with a set of hyperparameters, use
                        this parameter to skip it
  -ssp, --skip_save_progress
                        disables saving weights after each epoch. By default
                        ludwig saves weights after each epoch for enabling
                        resuming of training, but if the model is really big
                        that can be time consuming and will save twice as much
                        space, use this parameter to skip it
  -ssl, --skip_save_log
                        disables saving TensorBoard logs. By default Ludwig
                        saves logs for the TensorBoard, but if it is not
                        needed turning it off can slightly increase the
                        overall speed
  -rs RANDOM_SEED, --random_seed RANDOM_SEED
                        a random seed that is going to be used anywhere there
                        is a call to a random number generator: data
                        splitting, parameter initialization and training set
                        shuffling
  -g GPUS [GPUS ...], --gpus GPUS [GPUS ...]
                        list of gpus to use
  -gml GPU_MEMORY_LIMIT, --gpu_memory_limit GPU_MEMORY_LIMIT
                        maximum memory in MB to allocate per GPU device
  -uh, --use_horovod    uses horovod for distributed training
  -dbg, --debug         enables debugging mode
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>The parameters combine parameters from both <a href="#train">train</a> and <a href="#test">test</a> so refer to those sections for an in depth explanation. The output directory will contain a <code>hyperopt_statistics.json</code> file that summarizes the results obtained.</p>
<p>In order to perform an hyper-parameter optimization, the <code>hyperopt</code> section needs to be provided within the configuration.
In the <code>hyperopt</code> section you will be able to define what metric to optimize, what parameters, what sampler to use to optimize them and how to execute the optimization.
For details on the <code>hyperopt</code> section see the detailed description in the <a href="#hyper-parameter-optimization">Hyper-parameter Optimization</a> section.</p>
<h3 id="serve">serve<a class="headerlink" href="#serve" title="Permanent link">&para;</a></h3>
<p>This command lets you load a pre-trained model and serve it on an http server.</p>
<p>You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig serve [options]
</code></pre></div>

<p>or with</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.serve [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig serve [options]

This script serves a pretrained model

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL_PATH, --model_path MODEL_PATH
                        model to load
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
  -p PORT, --port PORT  port for server (default: 8000)
  -H HOST, --host HOST  host for server (default: 0.0.0.0)
</code></pre></div>

<p>The most important argument is <code>--model_path</code> where you have to specify the path of the model to load.</p>
<p>Once running, you can make a POST request on the <code>/predict</code> endpoint to run inference on the form data submitted.</p>
<h5 id="example-curl">Example curl<a class="headerlink" href="#example-curl" title="Permanent link">&para;</a></h5>
<p><strong>File</strong></p>
<p><code>curl http://0.0.0.0:8000/predict -X POST -F 'image_path=@path_to_image/example.png'</code></p>
<p><strong>Text</strong></p>
<p><code>curl http://0.0.0.0:8000/predict -X POST -F 'english_text=words to be translated'</code></p>
<p><strong>Both Text and File</strong></p>
<p><code>curl http://0.0.0.0:8000/predict -X POST -F 'text=mixed together with' -F 'image=@path_to_image/example.png'</code></p>
<p><strong>Batch prediction</strong></p>
<p>You can also make a POST request on the <code>/batch_predict</code> endpoint to run inference on multiple samples at once.</p>
<p>Requests must be submitted as form data, with one of fields being <code>dataset</code>: a JSON encoded string representation of the data to be predicted.</p>
<p>The <code>dataset</code> JSON string is expected to be in the Pandas "split" format to reduce payload size. This format divides the dataset into three parts:</p>
<ol>
<li>columns: <code>List[str]</code></li>
<li>index (optional): <code>List[Union[str, int]]</code></li>
<li>data: <code>List[List[object]]</code></li>
</ol>
<p>Additional form fields can be used to provide file resources like images that are referenced within the dataset.</p>
<p>Batch prediction example:</p>
<p><code>curl http://0.0.0.0:8000/batch_predict -X POST -F 'dataset={"columns": ["a", "b"], "data": [[1, 2], [3, 4]]}'</code></p>
<h3 id="visualize">visualize<a class="headerlink" href="#visualize" title="Permanent link">&para;</a></h3>
<p>This command lets you visualize training and prediction statistics, alongside with comparing different models performances and predictions.
You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.visualize [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig visualize [options]

This script analyzes results and shows some nice plots.

optional arguments:
  -h, --help            show this help message and exit
  -g GROUND_TRUTH, --ground_truth GROUND_TRUTH
                        ground truth file
  -gm GROUND_TRUTH_METADATA, --ground_truth_metadata GROUND_TRUTH_METADATA
                        input metadata JSON file
  -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY
                        directory where to save plots.If not specified, plots
                        will be displayed in a window
  -ff {pdf,png}, --file_format {pdf,png}
                        file format of output plots
  -v {binary_threshold_vs_metric,calibration_1_vs_all,calibration_multiclass,compare_classifiers_multiclass_multimetric,compare_classifiers_performance_changing_k,compare_classifiers_performance_from_pred,compare_classifiers_performance_from_prob,compare_classifiers_performance_subset,compare_classifiers_predictions,compare_classifiers_predictions_distribution,compare_performance,confidence_thresholding,confidence_thresholding_2thresholds_2d,confidence_thresholding_2thresholds_3d,confidence_thresholding_data_vs_acc,confidence_thresholding_data_vs_acc_subset,confidence_thresholding_data_vs_acc_subset_per_class,confusion_matrix,frequency_vs_f1,hyperopt_hiplot,hyperopt_report,learning_curves,roc_curves,roc_curves_from_test_statistics}, --visualization {binary_threshold_vs_metric,calibration_1_vs_all,calibration_multiclass,compare_classifiers_multiclass_multimetric,compare_classifiers_performance_changing_k,compare_classifiers_performance_from_pred,compare_classifiers_performance_from_prob,compare_classifiers_performance_subset,compare_classifiers_predictions,compare_classifiers_predictions_distribution,compare_performance,confidence_thresholding,confidence_thresholding_2thresholds_2d,confidence_thresholding_2thresholds_3d,confidence_thresholding_data_vs_acc,confidence_thresholding_data_vs_acc_subset,confidence_thresholding_data_vs_acc_subset_per_class,confusion_matrix,frequency_vs_f1,hyperopt_hiplot,hyperopt_report,learning_curves,roc_curves,roc_curves_from_test_statistics}
                        type of visualization
  -f OUTPUT_FEATURE_NAME, --output_feature_name OUTPUT_FEATURE_NAME
                        name of the output feature to visualize
  -gts GROUND_TRUTH_SPLIT, --ground_truth_split GROUND_TRUTH_SPLIT
                        ground truth split - 0:train, 1:validation, 2:test
                        split
  -tf THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...], --threshold_output_feature_names THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...]
                        names of output features for 2d threshold
  -pred PREDICTIONS [PREDICTIONS ...], --predictions PREDICTIONS [PREDICTIONS ...]
                        predictions files
  -prob PROBABILITIES [PROBABILITIES ...], --probabilities PROBABILITIES [PROBABILITIES ...]
                        probabilities files
  -trs TRAINING_STATISTICS [TRAINING_STATISTICS ...], --training_statistics TRAINING_STATISTICS [TRAINING_STATISTICS ...]
                        training stats files
  -tes TEST_STATISTICS [TEST_STATISTICS ...], --test_statistics TEST_STATISTICS [TEST_STATISTICS ...]
                        test stats files
  -hs HYPEROPT_STATS_PATH, --hyperopt_stats_path HYPEROPT_STATS_PATH
                        hyperopt stats file
  -mn MODEL_NAMES [MODEL_NAMES ...], --model_names MODEL_NAMES [MODEL_NAMES ...]
                        names of the models to use as labels
  -tn TOP_N_CLASSES [TOP_N_CLASSES ...], --top_n_classes TOP_N_CLASSES [TOP_N_CLASSES ...]
                        number of classes to plot
  -k TOP_K, --top_k TOP_K
                        number of elements in the ranklist to consider
  -ll LABELS_LIMIT, --labels_limit LABELS_LIMIT
                        maximum numbers of labels. If labels in dataset are
                        higher than this number, &quot;rare&quot; label
  -ss {ground_truth,predictions}, --subset {ground_truth,predictions}
                        type of subset filtering
  -n, --normalize       normalize rows in confusion matrix
  -m METRICS [METRICS ...], --metrics METRICS [METRICS ...]
                        metrics to dispay in threshold_vs_metric
  -pl POSITIVE_LABEL, --positive_label POSITIVE_LABEL
                        label of the positive class for the roc curve
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>As the <code>--visualization</code> parameters suggests, there is a vast number of visualizations readily available.
Each of them requires a different subset of this command's arguments, so they will be described one by one in the <a href="#visualizations">Visualizations</a> section.</p>
<h3 id="collect_summary">collect_summary<a class="headerlink" href="#collect_summary" title="Permanent link">&para;</a></h3>
<p>This command loads a pretrained model and prints names of weights and layers activations to use with <code>collect_weights</code> or <code>collect_activations</code>.</p>
<div class="codehilite"><pre><span></span><code>ludwig collect_summary [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.collect names [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig collect_summary [options]

This script loads a pretrained model and print names of weights and layer activations.

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL_PATH, --model_path MODEL_PATH
                        model to load
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<h3 id="collect_weights">collect_weights<a class="headerlink" href="#collect_weights" title="Permanent link">&para;</a></h3>
<p>This command lets you load a pre-trained model and collect the tensors with a specific name in order to save them in a NPY format.
This may be useful in order to visualize the learned weights (for instance collecting embedding matrices) and for some post-hoc analyses.
You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig collect_weights [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.collect weights [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig collect_weights [options]

This script loads a pretrained model and uses it collect weights.

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL_PATH, --model_path MODEL_PATH
                        model to load
  -t TENSORS [TENSORS ...], --tensors TENSORS [TENSORS ...]
                        tensors to collect
  -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY
                        directory that contains the results
  -dbg, --debug         enables debugging mode
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>The three most important arguments are <code>--model_path</code> where you have to specify the path of the model to load, <code>--tensors</code> that lets you specify a list of tensor names in the TensorFlow graph that contain the weights you want to collect, and finally <code>--output_directory</code> that lets you specify where the NPY files (one for each tensor name specified) will be saved.</p>
<p>In order to figure out the names of the tensors containing the weights you want to collect, the best way is to inspect the graph of the model with TensorBoard.</p>
<div class="codehilite"><pre><span></span><code>tensorboard --logdir /path/to/model/log
</code></pre></div>

<p>Or use the <code>collect_summary</code> command.</p>
<h3 id="collect_activations">collect_activations<a class="headerlink" href="#collect_activations" title="Permanent link">&para;</a></h3>
<p>This command lets you load a pre-trained model and input data and collects the values of activations contained in tensors with a specific name in order to save them in a NPY format.
This may be useful in order to visualize the activations (for instance collecting last layer's activations as embeddings representations of the input datapoint) and for some post-hoc analyses.
You can call it with:</p>
<div class="codehilite"><pre><span></span><code>ludwig collect_activations [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.collect activations [options]
</code></pre></div>

<p>from within Ludwig's main directory.</p>
<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig collect_activations [options]

This script loads a pretrained model and uses it collect tensors for each
datapoint in the dataset.

optional arguments:
  -h, --help            show this help message and exit
  --dataset  DATASET    filepath for input dataset
  --data_format DATA_FORMAT  format of the dataset.  Valid values are auto,
                        csv, excel, feature, fwf, hdf5, html, tables, json,
                        json, jsonl, parquet, pickle, sas, spss, stata, tsv
  -s {training,validation,test,full}, --split {training,validation,test,full}
                        the split to test the model on
  -m MODEL_PATH, --model_path MODEL_PATH
                        model to load
  -lyr LAYER [LAYER ..], --layers LAYER [LAYER ..]
                        layers to collect
  -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY
                        directory that contains the results
  -bs BATCH_SIZE, --batch_size BATCH_SIZE
                        size of batches
  -g GPUS, --gpus GPUS  list of gpu to use
  -gml GPU_MEMORY, --gpu_memory_limit GPU_MEMORY
                        maximum memory in MB of gpu memory to allocate per
                        GPU device
  -dpt, --disable_parallel_threads
                        disable Tensorflow from using multithreading
                        for reproducibility
  -uh, --use_horovod    uses horovod for distributed training
  -dbg, --debug         enables debugging mode
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>The data related and runtime related arguments (GPUs, batch size, etc.) are the same used in <a href="#predict">predict</a>, you can refer to that section for an explanation.
The collect specific arguments <code>--model_path</code>, <code>--tensors</code> and <code>--output_directory</code> are the same used in <a href="#collect_weights">collect_weights</a>, you can refer to that section for an explanation.</p>
<p>In order to figure out the names of the tensors containing the activations you want to collect, the best way is to inspect the graph of the model with TensorBoard.</p>
<div class="codehilite"><pre><span></span><code>tensorboard --logdir /path/to/model/log
</code></pre></div>

<h3 id="export_savedmodel">export_savedmodel<a class="headerlink" href="#export_savedmodel" title="Permanent link">&para;</a></h3>
<p>Exports a pre-trained model to Tensorflow <code>SavedModel</code> format.</p>
<div class="codehilite"><pre><span></span><code>ludwig export_savedmodel [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.export savedmodel [options]
</code></pre></div>

<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig export_savedmodel [options]

This script loads a pretrained model and uses it collect weights.

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL_PATH, --model_path MODEL_PATH
                        model to load
  -od OUTPUT_PATH, --output_path OUTPUT_PATH
                        path where to save the export model  
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<h3 id="export_neuropod">export_neuropod<a class="headerlink" href="#export_neuropod" title="Permanent link">&para;</a></h3>
<p>A Ludwig model can be exported as a <a href="https://github.com/uber/neuropod">Neuropod</a>, a mechanism that allows it to be executed in a framework agnostic way.</p>
<p>In order to export a Ludwig model as a Neuropod, first make sure the <code>neuropod</code> package is installed in your environment together with the approrpiate backend (only use Python 3.7+), then run the following command:</p>
<div class="codehilite"><pre><span></span><code>ludwig export_neuropod [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.export neuropod [options]
</code></pre></div>

<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig export_neuropod [options]

This script loads a pretrained model and uses it collect weights.

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL_PATH, --model_path MODEL_PATH
                        model to load
  -mn MODEL_NAME, --model_name MODEL_NAME
                        model name
  -od OUTPUT_PATH, --output_path OUTPUT_PATH
                        path where to save the export model  
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>This functionality has been tested with <code>neuropod==0.2.0</code>.</p>
<h3 id="preprocess">preprocess<a class="headerlink" href="#preprocess" title="Permanent link">&para;</a></h3>
<p>Preprocess data and saves it into HDF5 and JSON format.
The preprocessed files can be then used for performing training, prediction and evaluation.
The advantage is that, being the data already preprocessed, if multiple models have to be trained on the same data, the preprocessed files act as a cache to avoid performing preprocessing multiple times.</p>
<div class="codehilite"><pre><span></span><code>ludwig preprocess [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.preprocess [options]
</code></pre></div>

<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig preprocess [options]

This script preprocess a dataset

optional arguments:
  -h, --help            show this help message and exit
  --dataset DATASET     input data file path. If it has a split column, it
                        will be used for splitting (0: train, 1: validation,
                        2: test), otherwise the dataset will be randomly split
  --training_set TRAINING_SET
                        input train data file path
  --validation_set VALIDATION_SET
                        input validation data file path
  --test_set TEST_SET   input test data file path
  --training_set_metadata TRAINING_SET_METADATA
                        input metadata JSON file path. An intermediate
                        preprocessed  containing the mappings of the input
                        file created the first time a file is used, in the
                        same directory with the same name and a .json
                        extension
  --data_format {auto,csv,excel,feather,fwf,hdf5,htmltables,json,jsonl,parquet,pickle,sas,spss,stata,tsv}
                        format of the input data
  -pc PREPROCESSING_CONFIG, --preprocessing_config PREPROCESSING_CONFIG
                        preproceesing config. Uses the same format of config,
                        but ignores encoder specific parameters, decoder
                        specific paramters, combiner and training parameters
  -pcf PREPROCESSING_CONFIG_FILE, --preprocessing_config_file PREPROCESSING_CONFIG_FILE
                        YAML file describing the preprocessing. Ignores
                        --preprocessing_config.Uses the same format of config,
                        but ignores encoder specific parameters, decoder
                        specific paramters, combiner and training parameters
  -rs RANDOM_SEED, --random_seed RANDOM_SEED
                        a random seed that is going to be used anywhere there
                        is a call to a random number generator: data
                        splitting, parameter initialization and training set
                        shuffling
  -dbg, --debug         enables debugging mode
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<h3 id="synthesize_dataset">synthesize_dataset<a class="headerlink" href="#synthesize_dataset" title="Permanent link">&para;</a></h3>
<p>Creates synthetic data for tesing purposes depending on the feature list parameters provided in YAML format.</p>
<div class="codehilite"><pre><span></span><code>ludwig synthesize_dataset [options]
</code></pre></div>

<p>or with:</p>
<div class="codehilite"><pre><span></span><code>python -m ludwig.data.dataset_synthesizer [options]
</code></pre></div>

<p>These are the available arguments:</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig synthesize_dataset [options]

This script generates a synthetic dataset.

optional arguments:
  -h, --help            show this help message and exit
  -od OUTPUT_PATH, --output_path OUTPUT_PATH
                        output CSV file path
  -d DATASET_SIZE, --dataset_size DATASET_SIZE
                        size of the dataset
  -f FEATURES, --features FEATURES
                        list of features to generate in YAML format. Provide a
                        list containing one dictionary for each feature, each
                        dictionary must include a name, a type and can include
                        some generation parameters depending on the type

Process finished with exit code 0
</code></pre></div>

<p>The feature list file should contain one entry dictionary per feature, with its name and type, plus optional hyperparameters.</p>
<div class="codehilite"><pre><span></span><code><span class="p p-Indicator">-</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">first_feature</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">first_feature_type</span>
<span class="p p-Indicator">-</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">second_feature</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">second_feature_type</span>
<span class="nn">...</span>
</code></pre></div>

<p>The available parameters depend on the feature type.</p>
<p><strong>binary</strong></p>
<ul>
<li><code>prob</code> (float, default: <code>0.5</code>): probability of generating <code>true</code>.</li>
<li><code>cycle</code> (boolean, default: <code>false</code>): cycle through values instead of sampling.</li>
</ul>
<p><strong>numerical</strong></p>
<ul>
<li><code>min</code> (float, default: <code>0</code>): minimum value of the range of values to generate.</li>
<li><code>max</code> (float, default: <code>1</code>): maximum value of the range of values to generate.</li>
</ul>
<p><strong>category</strong></p>
<ul>
<li><code>vocab_size</code> (int, default: <code>10</code>): size of the vocabulary to sample from.</li>
<li><code>cycle</code> (boolean, default: <code>false</code>): cycle through values instead of sampling.</li>
</ul>
<p><strong>sequence</strong></p>
<ul>
<li><code>vocab_size</code> (int, default: <code>10</code>): size of the vocabulary to sample from.</li>
<li><code>max_len</code> (int, default: <code>10</code>): maximum length of the generated sequence.</li>
<li><code>min_len</code> (int, default: <code>null</code>): if <code>null</code> all sequences will be of size <code>max_len</code>. If a value is provided, the length will be randomly determined between <code>min_len</code> and <code>max_len</code>.</li>
</ul>
<p><strong>set</strong></p>
<ul>
<li><code>vocab_size</code> (int, default: <code>10</code>): size of the vocabulary to sample from.</li>
<li><code>max_len</code> (int, default: <code>10</code>): maximum length of the generated set.</li>
</ul>
<p><strong>bag</strong></p>
<ul>
<li><code>vocab_size</code> (int, default: <code>10</code>): size of the vocabulary to sample from.</li>
<li><code>max_len</code> (int, default: <code>10</code>): maximum length of the generated set.</li>
</ul>
<p><strong>text</strong></p>
<ul>
<li><code>vocab_size</code> (int, default: <code>10</code>): size of the vocabulary to sample from.</li>
<li><code>max_len</code> (int, default: <code>10</code>): maximum length of the generated sequence, lengths will be randomly sampled between <code>max_len - 20%</code> and <code>max_len</code>.</li>
</ul>
<p><strong>timeseries</strong></p>
<ul>
<li><code>max_len</code> (int, default: <code>10</code>): maximum length of the generated sequence.</li>
<li><code>min</code> (float, default: <code>0</code>): minimum value of the range of values to generate.</li>
<li><code>max</code> (float, default: <code>1</code>): maximum value of the range of values to generate.</li>
</ul>
<p><strong>audio</strong></p>
<ul>
<li><code>destination_folder</code> (str): folder where the generated audio files will be saved.</li>
<li><code>preprocessing: {audio_file_length_limit_in_s}</code> (int, default: <code>1</code>): length of the generated audio in seconds.</li>
</ul>
<p><strong>image</strong></p>
<ul>
<li><code>destination_folder</code> (str): folder where the generated image files will be saved.</li>
<li><code>preprocessing: {height}</code> (int, default: <code>28</code>): height of the generated image in pixels.</li>
<li><code>preprocessing: {width}</code> (int, default: <code>28</code>): width of the generated image in pixels.</li>
<li><code>preprocessing: {num_channels}</code> (int, default: <code>1</code>): number of channels of the generated images. Valid values are <code>1</code>, <code>3</code>, <code>4</code>.</li>
</ul>
<p><strong>date</strong></p>
<p>No parameters.</p>
<p><strong>h3</strong></p>
<p>No parameters.</p>
<p><strong>vector</strong></p>
<ul>
<li><code>vector_size</code> (int, default: <code>10</code>): size of the vectors to generate.</li>
</ul>
<h2 id="data-preprocessing">Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permanent link">&para;</a></h2>
<p>Ludwig is able to read UTF-8 encoded data from 14 file formats.
Supported formats are:</p>
<ul>
<li>Comma Separated Values (<code>csv</code>)</li>
<li>Excel Workbooks (<code>excel</code>)</li>
<li>Feather (<code>feather</code>)</li>
<li>Fixed Width Format (<code>fwf</code>)</li>
<li>Hierarchical Data Format 5 (<code>hdf5</code>)</li>
<li>Hypertext Markup Language (<code>html</code>) Note: limited to single table in the file.</li>
<li>JavaScript Object Notation (<code>json</code> and <code>jsonl</code>)</li>
<li>Parquet (<code>parquet</code>)</li>
<li>Pickled Pandas DataFrame (<code>pickle</code>)</li>
<li>SAS data sets in XPORT or SAS7BDAT format (<code>sas</code>)</li>
<li>SPSS file (<code>spss</code>)</li>
<li>Stata file (<code>stata</code>)</li>
<li>Tab Separated Values (<code>tsv</code>)</li>
</ul>
<p>Ludwig data preprocessing maps raw data in a supported dataset into an HDF5 file containing tensors and a JSON file containing mappings from strings to tensors when needed.
This mapping is performed when a UTF-8 encoded data is provided as input and both HDF5 and JSON files are saved in the same directory as the input dataset, unless the argument <code>--skip_save_processed_input</code> is used (both in <code>train</code> and <code>experiment</code> commands).
The reason to save those files is both to provide a cache and avoid performing the preprocessing again (as, depending on the type of features involved, it could be time consuming) and to provide the needed mappings to be able to map unseen data into tensors.</p>
<p>The preprocessing process is personalizable to fit the specifics of your data format, but the basic assumption is always that your UTF-8 encoded dataset contains one row for each datapoint and one column for each feature (either input or output), and that you are able to determine the type of that column among the ones supported by Ludwig.
The reason for that is that each data type is mapped into tensors in a different way and expects the content to be formatted in a specific way.
Different datatypes may have different tokenizers that format the values of a cell.</p>
<p>For instance, the value of a cell of a sequence feature column by default is managed by a <code>space</code> tokenizer, that splits the content of the value into a list of strings using space.</p>
<table>
<thead>
<tr>
<th>before tokenizer</th>
<th>after tokenizer</th>
</tr>
</thead>
<tbody>
<tr>
<td>"token3 token4 token2"</td>
<td>[token3, token4, token2]</td>
</tr>
<tr>
<td>"token3 token1"</td>
<td>[token3, token1]</td>
</tr>
</tbody>
</table>
<p>Then a list <code>idx2str</code> and two dictionaries <code>str2idx</code> and <code>str2freq</code> are created containing all the tokens in all the lists obtained by splitting all the rows of the column and an integer id is assigned to each of them (in order of frequency).</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
    <span class="nt">&quot;column_name&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;idx2str&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;&lt;PAD&gt;&quot;</span><span class="p">,</span>
            <span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">,</span>
            <span class="s2">&quot;token3&quot;</span><span class="p">,</span>
            <span class="s2">&quot;token2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;token4&quot;</span><span class="p">,</span>
            <span class="s2">&quot;token1&quot;</span>
        <span class="p">],</span>
        <span class="nt">&quot;str2idx&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">&quot;&lt;PAD&gt;&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&quot;&lt;UNK&gt;&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="nt">&quot;token3&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="nt">&quot;token2&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="nt">&quot;token4&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="nt">&quot;token1&quot;</span><span class="p">:</span> <span class="mi">5</span>
        <span class="p">},</span>
        <span class="nt">&quot;str2freq&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">&quot;&lt;PAD&gt;&quot;</span><span class="p">:</span>  <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&quot;&lt;UNK&gt;&quot;</span><span class="p">:</span>  <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&quot;token3&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="nt">&quot;token2&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="nt">&quot;token4&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="nt">&quot;token1&quot;</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p>Finally, a numpy matrix is created with sizes <code>n x l</code> where <code>n</code> is the number of rows in the column and <code>l</code> is the minimum of the longest tokenized list and a <code>max_length</code> parameter that can be set.
All sequences shorter than <code>l</code> are padded on the right (but this behavior may also be modified through a parameter).</p>
<table>
<thead>
<tr>
<th>after tokenizer</th>
<th>numpy matrix</th>
</tr>
</thead>
<tbody>
<tr>
<td>[token3, token4, token2]</td>
<td>2 4 3</td>
</tr>
<tr>
<td>[token3, token1]</td>
<td>2 5 0</td>
</tr>
</tbody>
</table>
<p>The final result matrix is saved in the HDF5 with the name of the original column in the dataset as key, while the mapping from token to integer ID (and its inverse mapping) is saved in the JSON file.</p>
<p>Each datatype is preprocessed in a different way, using different parameters and different tokenizers.
Details on how to set those parameters for each feature type and for each specific feature will be described in the <a href="#preprocessing">Configuration - Preprocessing</a> section.</p>
<p><code>Binary</code> features are directly transformed into a binary valued vector of length <code>n</code> (where <code>n</code> is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset.
No additional information about them is available in the JSON metadata file.</p>
<p><code>Numerical</code> features are directly transformed into a float valued vector of length <code>n</code> (where <code>n</code> is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset.
No additional information about them is available in the JSON metadata file.</p>
<p><code>Category</code> features are transformed into an integer valued vector of size <code>n</code> (where <code>n</code> is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset.
The way categories are mapped into integers consists in first collecting a dictionary of all the different category strings present in the column of the dataset, then rank them by frequency and then assign them an increasing integer ID from the most frequent to the most rare (with 0 being assigned to a <code>&lt;UNK&gt;</code> token).  The column name is added to the JSON file, with an associated dictionary containing:</p>
<ol>
<li>the mapping from integer to string (<code>idx2str</code>)</li>
<li>the mapping from string to id (<code>str2idx</code>)</li>
<li>the mapping from string to frequency (<code>str2freq</code>)</li>
<li>the size of the set of all tokens (<code>vocab_size</code>)</li>
<li>additional preprocessing information (by default how to fill missing values 
and what token to use to fill missing values)</li>
</ol>
<p><code>Set</code> features are transformed into a binary (int8 actually) valued matrix of size <code>n x l</code> (where <code>n</code> is the size of the dataset and <code>l</code> is the minimum of the size of the biggest set and a <code>max_size</code> parameter) and added to HDF5 with a key that reflects the name of column in the dataset.
The way sets are mapped into integers consists in first using a tokenizer to map from strings to sequences of set items (by default this is done by splitting on spaces).  Then a dictionary of all the different set item strings present in the column of the dataset is collected, then they are ranked by frequency and an increasing integer ID is assigned to them from the most frequent to the most rare (with 0 being assigned to <code>&lt;PAD&gt;</code> used for padding and 1 assigned to <code>&lt;UNK&gt;</code> item).  The column name is added to the JSON file, with an associated dictionary containing:</p>
<ol>
<li>the mapping from integer to string (<code>idx2str</code>)</li>
<li>the mapping from string to id (<code>str2idx</code>)</li>
<li>the mapping from string to frequency (<code>str2freq</code>)</li>
<li>the maximum size of all sets (<code>max_set_size</code>)</li>
<li>additional preprocessing information (by default how to fill missing values 
and what token to use to fill missing values)</li>
</ol>
<p><code>Bag</code> features are treated in the same way of set features, with the only difference being that the matrix had float values (frequencies).</p>
<p><code>Sequence</code> features are transformed into an integer valued matrix of size <code>n x l</code> (where <code>n</code> is the size of the dataset and <code>l</code> is the minimum of the length of the longest sequence and a <code>sequence_length_limit</code> parameter) and added to HDF5 with a key that reflects the name of column in the dataset.
The way sets are mapped into integers consists in first using a tokenizer to map from strings to sequences of tokens (by default this is done by splitting on spaces).
Then a dictionary of all the different token strings present in the column of the dataset is collected, then they are ranked by frequency and an increasing integer ID is assigned to them from the most frequent to the most rare (with 0 being assigned to <code>&lt;PAD&gt;</code> used for padding and 1 assigned to <code>&lt;UNK&gt;</code> item).
The column name is added to the JSON file, with an associated dictionary containing:</p>
<ol>
<li>the mapping from integer to string (<code>idx2str</code>)</li>
<li>the mapping from string to id (<code>str2idx</code>)</li>
<li>the mapping from string to frequency (<code>str2freq</code>)</li>
<li>the maximum length of all sequences (<code>sequence_length_limit</code>)</li>
<li>additional preprocessing information (by default how to fill missing values 
and what token to use to fill missing values)</li>
</ol>
<p><code>Text</code> features are treated in the same way of sequence features, with a couple differences.
Two different tokenizations happen, one that splits at every character and one that uses a spaCy based tokenizer (and removes stopwords), and two different keys are added to the HDF5 file, one for the matrix of characters and one for the matrix of words.
The same thing happens in the JSON file, where there are dictionaries for mapping characters to integers (and the inverse) and words to integers (and their inverse).
In the configuration you are able to specify which level of representation to use: the character level or the word level.</p>
<p><code>Timeseries</code> features are treated in the same way of sequence features, with the only difference being that the matrix in the HDF5 file does not have integer values, but float values.
Moreover, there is no need for any mapping in the JSON file.</p>
<p><code>Image</code> features are transformed into a int8 valued tensor of size <code>n x h x w x c</code> (where <code>n</code> is the size of the dataset and <code>h x w</code> is a specific resizing of the image that can be set, and <code>c</code> is the number of color channels) and added to HDF5 with a key that reflects the name of column in the dataset.
The column name is added to the JSON file, with an associated dictionary containing preprocessing information about the sizes of the resizing.</p>
<h3 id="dataset-format">Dataset Format<a class="headerlink" href="#dataset-format" title="Permanent link">&para;</a></h3>
<p>Ludwig uses Pandas under the hood to read the UTF-8 encoded dataset files, which allows support for CSV, Excel, Feather, fwf, HDF5, HTML (containing a <code>&lt;table&gt;</code>), JSON, JSONL, Parquet, pickle (pickled Pandas DataFrame), SAS, SPSS, Stata and TSV formats.
Ludwig tries to automatically identify the format by the extension.</p>
<p>In case a *SV file is provided, Ludwig tries to identify the separator (generally <code>,</code>) from the data.
The default escape character is <code>\</code>.
For example, if <code>,</code> is the column separator and one of your data columns has a <code>,</code> in it, Pandas would fail to load the data properly.
To handle such cases, we expect the values in the columns to be escaped with backslashes (replace <code>,</code> in the data with <code>\\,</code>).</p>
<h2 id="data-postprocessing">Data Postprocessing<a class="headerlink" href="#data-postprocessing" title="Permanent link">&para;</a></h2>
<p>The JSON file obtained from preprocessing is used also for postprocessing: Ludwig models return output predictions and, depending on their datatype they are mapped back into the original space.
Numerical and timeseries are returned as they are, while category, set, sequence, and text features output integers, those integers are mapped back into the original tokens / names using the <code>idx2str</code> in the JSON file.
When you run <code>experiment</code> or <code>predict</code> you will find both a CSV file for each output containing the mapped predictions, a probability CSV file containing the probability of that prediction, a probabilities CSV file containing the probabilities for all alternatives (for instance, the probabilities of all the categories in case of a categorical feature).  You will also find the unmapped NPY files.
If you don't need them you can use the <code>--skip_save_unprocessed_output</code> argument.</p>
<h2 id="configuration">Configuration<a class="headerlink" href="#configuration" title="Permanent link">&para;</a></h2>
<p>The configuration is the core of Ludwig.
It is a dictionary that contains all the information needed to build and train a Ludwig model.
It mixes ease of use, by means of reasonable defaults, with flexibility, by means of detailed control over the parameters of your model.
It is provided to both <code>experiment</code> and <code>train</code> commands either as a string (<code>--config</code>) or as a file (<code>--config_file</code>).
The string or the content of the file will be parsed by PyYAML into a dictionary in memory, so any style of YAML accepted by the parser is considered to be valid, so both multiline and oneline formats are accepted.
For instance a list of dictionaries can be written both as:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">mylist</span><span class="p">:</span> <span class="p p-Indicator">[{</span><span class="nt">name</span><span class="p">:</span> <span class="nv">item1</span><span class="p p-Indicator">,</span><span class="nt"> score</span><span class="p">:</span> <span class="nv">2</span><span class="p p-Indicator">},</span> <span class="p p-Indicator">{</span><span class="nt">name</span><span class="p">:</span> <span class="nv">item2</span><span class="p p-Indicator">,</span><span class="nt"> score</span><span class="p">:</span> <span class="nv">1</span><span class="p p-Indicator">},</span> <span class="p p-Indicator">{</span><span class="nt">name</span><span class="p">:</span> <span class="nv">item3</span><span class="p p-Indicator">,</span><span class="nt"> score</span><span class="p">:</span> <span class="nv">4</span><span class="p p-Indicator">}]</span>
</code></pre></div>

<p>or as:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">mylist</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">item1</span>
        <span class="nt">score</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">item2</span>
        <span class="nt">score</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">item3</span>
        <span class="nt">score</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
</code></pre></div>

<p>The structure of the configuration file is a dictionary with five keys:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">input_features</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">combiner</span><span class="p">:</span> <span class="p p-Indicator">{}</span>
<span class="nt">output_features</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">training</span><span class="p">:</span> <span class="p p-Indicator">{}</span>
<span class="nt">preprocessing</span><span class="p">:</span> <span class="p p-Indicator">{}</span>
</code></pre></div>

<p>Only <code>input_features</code> and <code>output_features</code> are required, the other three fields 
have default values, but you are free to modify them.</p>
<h3 id="input-features">Input features<a class="headerlink" href="#input-features" title="Permanent link">&para;</a></h3>
<p>The <code>input_features</code> list contains a list of dictionaries, each of them containing two required fields <code>name</code> and <code>type</code>.
<code>name</code> is the name of the feature and is the same name of the column of the dataset input file, <code>type</code> is one of the supported datatypes.
Input features may have different ways to be encoded and the parameter to decide it is <code>encoder</code>.</p>
<p>All the other parameters you specify in an input feature will be passed as parameters to the function that build the encoder, and each encoder can have different parameters.</p>
<p>For instance a <code>sequence</code> feature can be encoded by a <code>stacked_cnn</code> or by and <code>rnn</code>, but only the <code>stacked_cnn</code> will accept the parameter <code>num_filters</code> while only the <code>rnn</code> will accept the parameter <code>bidirectional</code>.</p>
<p>A list of all the encoders available for all the datatypes alongside with the description of all parameters will be provided in the datatype-specific sections.
Some datatypes have only one type of encoder, so you are not required to specify it.</p>
<p>The role of the encoders is to map inputs into tensors, usually vectors in the case of datatype without a temporal / sequential aspect, matrices in case there is a temporal / sequential aspect or higher rank tensors in case there is a spatial or a spatio-temporal aspect to the input data.</p>
<p>Different configurations of the same encoder may return a tensor with different rank, for instance a sequential encoder may return a vector of size <code>h</code> that is either the final vector of a sequence or the result of pooling over the sequence length, or it can return a matrix of size <code>l x h</code> where <code>l</code> is the length of the sequence and <code>h</code> is the hidden dimension if you specify the pooling reduce operation (<code>reduce_output</code>) to be <code>null</code>.  For the sake of simplicity you can imagine the output to be a vector in most of the cases, but there is a <code>reduce_output</code> parameter one can specify to change the default behavior.</p>
<p>An additional feature that Ludwig provides is the option to have tied weights between different encoders.
For instance if my model takes two sentences as input and return the probability of their entailment, I may want to encode both sentences with the same encoder.
The way to do it is by specifying the <code>tied-weights</code> parameter of the second feature you define to be the name of the first feature you defined.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">input_features</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sentence1</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sentence2</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text</span>
        <span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sentence1</span>
</code></pre></div>

<p>If you specify a name of an input feature that has not been defined yet, it will result in an error.
Also, in order to be able to have tied weights, all encoder parameters have to be identical between the two input features.</p>
<h3 id="combiner">Combiner<a class="headerlink" href="#combiner" title="Permanent link">&para;</a></h3>
<p>Combiners are part of the model that take all the outputs of the different input features and combine them in a single representation that is passed to the outputs.
You can specify which one to use in the <code>combiner</code> section of the configuration.
Different combiners implement different combination logic, but the default one <code>concat</code> just concatenates all outputs of input feature encoders and optionally passes the concatenation through fully connected layers, with the output of the last layer being forwarded to the outputs decoders.</p>
<div class="codehilite"><pre><span></span><code>+-----------+
|Input      |
|Feature 1  +-+
+-----------+ |            +---------+
+-----------+ | +------+   |Fully    |
|...        +---&gt;Concat+---&gt;Connected+-&gt;
+-----------+ | +------+   |Layers   |
+-----------+ |            +---------+
|Input      +-+
|Feature N  |
+-----------+
</code></pre></div>

<p>For the sake of simplicity you can imagine the both inputs and outputs are vectors in most of the cases, but there are <code>reduce_input</code> and <code>reduce_output</code> parameters to specify to change the default behavior.</p>
<h3 id="output-features">Output Features<a class="headerlink" href="#output-features" title="Permanent link">&para;</a></h3>
<p>The <code>output_features</code> list has the same structure of the <code>input_features</code> list: it is a list of dictionaries containing a <code>name</code> and a <code>type</code>.
They represent outputs / targets that you want your model to predict.
In most machine learning tasks you want to predict only one target variable, but in Ludwig you are allowed to specify as many outputs as you want and they are going to be optimized in a multi-task fashion, using a weighted sum of their losses as a combined loss to optimize.</p>
<p>Instead of having <code>encoders</code>, output features have <code>decoders</code>, but most of them have only one decoder so you don't have to specify it.</p>
<p>Decoders take the output of the combiner as input, process it further, for instance passing it through fully connected layers, and finally predict values and compute a loss and some measures (depending on the datatype different losses and measures apply).</p>
<p>Decoders have additional parameters, in particular <code>loss</code> that allows you to specify a different loss to optimize for this specific decoder, for instance numerical features support both <code>mean_squared_error</code> and <code>mean_absolute_error</code> as losses.
Details about the available decoders and losses alongside with the description of all parameters will be provided in the datatype-specific sections.</p>
<p>For the sake of simplicity you can imagine the input coming from the combiner to be a vector in most of the cases, but there is a <code>reduce_input</code> parameter one can specify to change the default behavior.</p>
<h4 id="multi-task-learning">Multi-task Learning<a class="headerlink" href="#multi-task-learning" title="Permanent link">&para;</a></h4>
<p>As Ludwig allows for multiple output features to be specified and each output feature can be seen as a task the model is learning to perform, by consequence Ludwig supports Multi-task learning natively.
When multiple output features are specified, the loss that is optimized is a weighted sum of the losses of each individual output feature.
By default each loss weight is <code>1</code>, but it can be changed by specifying a value for the <code>weight</code> parameter in the <code>loss</code> section of each output feature definition.</p>
<p>For example, given a <code>category</code> feature <code>A</code> and <code>numerical</code> feature <code>B</code>, in order to optimize the loss <code>loss_total = 1.5 * loss_A + 0.8 + loss_B</code> the <code>output_feature</code> section of the configuration should look like:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">output_features</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">A</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
        <span class="nt">loss</span><span class="p">:</span>
          <span class="nt">weight</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1.5</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">A</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
        <span class="nt">loss</span><span class="p">:</span>
          <span class="nt">weight</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>
</code></pre></div>

<h4 id="output-features-dependencies">Output Features Dependencies<a class="headerlink" href="#output-features-dependencies" title="Permanent link">&para;</a></h4>
<p>An additional feature that Ludwig provides is the concept of dependency between <code>output_features</code>.  You can specify a list of output features as dependencies when you write the dictionary of a specific feature.
At model building time Ludwig checks that no cyclic dependency exists.
If you do so Ludwig will concatenate all the final representations before the prediction of those output features to the original input of the decoder.
The reason is that if different output features have a causal dependency, knowing which prediction has been made for one can help making the prediction of the other.</p>
<p>For instance if two output features are one coarse grained category and one fine-grained category that are in a hierarchical structure with each other, knowing the prediction made for coarse grained restricts the possible categories to predict for the fine-grained.
In this case the following configuration structure can be used:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">output_features</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coarse_class</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
        <span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
        <span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">64</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">fine_class</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
        <span class="nt">dependencies</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">coarse_class</span>
        <span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
        <span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">64</span>
</code></pre></div>

<p>Assuming the input coming from the combiner has hidden dimension <code>h</code> 128, there are two fully connected layers that return a vector with hidden size 64 at the end of the <code>coarse_class</code> decoder (that vector will be used for the final layer before projecting in the output <code>coarse_class</code> space).  In the decoder of <code>fine_class</code>, the 64 dimensional vector of <code>coarse_class</code> will be concatenated to the combiner output vector, making a vector of hidden size 192 that will be passed through a fully connected layer and the 64 dimensional output will be used for the final layer before projecting in the output class space of the <code>fine_class</code>.</p>
<h3 id="training">Training<a class="headerlink" href="#training" title="Permanent link">&para;</a></h3>
<p>The <code>training</code> section of the configuration lets you specify some parameters of the training process, like for instance the number of epochs or the learning rate.</p>
<p>These are the available training parameters:</p>
<ul>
<li><code>batch_size</code> (default <code>128</code>): size of the batch used for training the model.</li>
<li><code>eval_batch_size</code> (default <code>0</code>): size of the batch used for evaluating the model. If it is <code>0</code>, the same value of <code>batch_size</code> is used. This is usefult to speedup evaluation with a much bigger batch size than training, if enough memory is available, or to decrease the batch size when <code>sampled_softmax_cross_entropy</code> is used as loss for sequential and categorical features with big vocabulary sizes (evaluation needs to be performed on the full vocabulary, so a much smaller batch size may be needed to fit the activation tensors in memory).</li>
<li><code>epochs</code> (default <code>100</code>): number of epochs the training process will run for.</li>
<li><code>early_stop</code> (default <code>5</code>): if there's a validation set, number of epochs of patience without an improvement on the validation measure before the training is stopped.</li>
<li><code>optimizer</code> (default <code>{type: adam, beta1: 0.9, beta2: 0.999, epsilon: 1e-08}</code>): which optimizer to use with the relative parameters. The available optimizers are: <code>sgd</code> (or <code>stochastic_gradient_descent</code>, <code>gd</code>, <code>gradient_descent</code>, they are all the same), <code>adam</code>, <code>adadelta</code>, <code>adagrad</code>, <code>adamax</code>, <code>ftrl</code>, <code>nadam</code>,
<code>rmsprop</code>. To know their parameters check <a href="https://www.tensorflow.org/api_docs/python/tf/train">TensorFlow's optimizer documentation</a>.</li>
<li><code>learning_rate</code> (default <code>0.001</code>): the learning rate to use.</li>
<li><code>decay</code> (default <code>false</code>): if to use exponential decay of the learning rate or not.</li>
<li><code>decay_rate</code> (default <code>0.96</code>): the rate of the exponential learning rate decay.</li>
<li><code>decay_steps</code> (default <code>10000</code>): the number of steps of the exponential learning rate decay.</li>
<li><code>staircase</code> (default <code>false</code>): decays the learning rate at discrete intervals.</li>
<li><code>regularization_lambda</code> (default <code>0</code>): the lambda parameter used for adding a l2 regularization loss to the overall loss.</li>
<li><code>reduce_learning_rate_on_plateau</code> (default <code>0</code>): if there's a validation set, how many times to reduce the learning rate when a plateau of validation measure is reached.</li>
<li><code>reduce_learning_rate_on_plateau_patience</code> (default <code>5</code>): if there's a validation set, number of epochs of patience without an improvement on the validation measure before reducing the learning rate.</li>
<li><code>reduce_learning_rate_on_plateau_rate</code> (default <code>0.5</code>): if there's a validation set, the reduction rate of the learning rate.</li>
<li><code>increase_batch_size_on_plateau</code> (default <code>0</code>): if there's a validation set, how many times to increase the batch size when a plateau of validation measure is reached.</li>
<li><code>increase_batch_size_on_plateau_patience</code> (default <code>5</code>): if there's a validation set, number of epochs of patience without an improvement on the validation measure before increasing the learning rate.</li>
<li><code>increase_batch_size_on_plateau_rate</code> (default <code>2</code>): if there's a validation set, the increase rate of the batch size.</li>
<li><code>increase_batch_size_on_plateau_max</code> (default <code>512</code>): if there's a validation set, the maximum value of batch size.</li>
<li><code>validation_field</code> (default <code>combined</code>): when there is more than one output feature, which one to use for computing if there was an improvement on validation. The measure to use to determine if there was an improvement can be set with the <code>validation_measure</code> parameter. Different datatypes have different available measures, refer to the datatype-specific section for more details. <code>combined</code> indicates the use the combination of all features. For instance the combination of <code>combined</code> and <code>loss</code> as measure uses a decrease in the combined loss of all output features to check for improvement on validation, while <code>combined</code> and <code>accuracy</code> considers on how many datapoints the predictions for all output features were correct (but consider that for some features, for instance <code>numeric</code> there is no accuracy measure, so you should use <code>accuracy</code> only if all your output features have an accuracy measure).</li>
<li><code>validation_metric:</code> (default <code>loss</code>): the metric to use to determine if there was an improvement. The metric is considered for the output feature specified in <code>validation_field</code>. Different datatypes have different available metrics, refer to the datatype-specific section for more details.</li>
<li><code>bucketing_field</code> (default <code>null</code>): when not <code>null</code>, when creating batches, instead of shuffling randomly, the length along the last dimension of the matrix of the specified input feature is used for bucketing datapoints and then randomly shuffled datapoints from the same bin are sampled. Padding is trimmed to the longest datapoint in the batch. The specified feature should be either a <code>sequence</code> or <code>text</code> feature and the encoder encoding it has to be <code>rnn</code>. When used, bucketing improves speed of <code>rnn</code> encoding up to 1.5x, depending on the length distribution of the inputs.</li>
<li><code>learning_rate_warmup_epochs</code> (default <code>1</code>): It's the number or training epochs where learning rate warmup will be used. It is calculated as described in <a href="https://arxiv.org/abs/1706.02677">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</a>. In the paper the authors suggest <code>6</code> epochs of warmup, that parameter is suggested for large datasets and big batches.</li>
</ul>
<h4 id="optimizers-details">Optimizers details<a class="headerlink" href="#optimizers-details" title="Permanent link">&para;</a></h4>
<p>The available optimizers wrap the ones available in TensorFlow.
For details about the parameters pleease refer to the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">TensorFlow documentation</a>.</p>
<p>The <code>learning_rate</code> parameter the optimizer will use come from the <code>training</code> section.
Other optimizer specific parameters, shown with their Ludwig default settings, follow:</p>
<ul>
<li><code>sgd</code> (or <code>stochastic_gradient_descent</code>, <code>gd</code>, <code>gradient_descent</code>)</li>
</ul>
<div class="codehilite"><pre><span></span><code>&#39;momentum&#39;: 0.0,
&#39;nesterov&#39;: false
</code></pre></div>

<ul>
<li><code>adam</code></li>
</ul>
<div class="codehilite"><pre><span></span><code>&#39;beta_1&#39;: 0.9,
&#39;beta_2&#39;: 0.999,
&#39;epsilon&#39;: 1e-08
</code></pre></div>

<ul>
<li><code>adadelta</code></li>
</ul>
<div class="codehilite"><pre><span></span><code>&#39;rho&#39;: 0.95,
&#39;epsilon&#39;: 1e-08
</code></pre></div>

<ul>
<li><code>adagrad</code></li>
</ul>
<div class="codehilite"><pre><span></span><code>&#39;initial_accumulator_value&#39;: 0.1,
&#39;epsilon&#39;: 1e-07
</code></pre></div>

<ul>
<li><code>adamax</code></li>
</ul>
<div class="codehilite"><pre><span></span><code>&#39;beta_1&#39;: 0.9, 
&#39;beta_2&#39;: 0.999, 
&#39;epsilon&#39;: 1e-07
</code></pre></div>

<ul>
<li><code>ftrl</code></li>
</ul>
<div class="codehilite"><pre><span></span><code>&#39;learning_rate_power&#39;: -0.5, 
&#39;initial_accumulator_value&#39;: 0.1,
&#39;l1_regularization_strength&#39;: 0.0, 
&#39;l2_regularization_strength&#39;: 0.0,
</code></pre></div>

<ul>
<li><code>nadam</code>,</li>
</ul>
<div class="codehilite"><pre><span></span><code>&#39;beta_1&#39;: 0.9, 
&#39;beta_2&#39;: 0.999, 
&#39;epsilon&#39;: 1e-07
</code></pre></div>

<ul>
<li><code>rmsprop</code></li>
</ul>
<div class="codehilite"><pre><span></span><code>&#39;decay&#39;: 0.9,
&#39;momentum&#39;: 0.0,
&#39;epsilon&#39;: 1e-10,
&#39;centered&#39;: false
</code></pre></div>

<h3 id="preprocessing">Preprocessing<a class="headerlink" href="#preprocessing" title="Permanent link">&para;</a></h3>
<p>The <code>preprocessing</code> section of the configuration makes it possible to specify datatype specific parameters to perform data preprocessing.
The preprocessing dictionary contains one key of each datatype, but you have to specify only the ones that apply to your case, the other ones will be kept as defaults.
Moreover, the preprocessing dictionary contains parameters related to how to split the data that are not feature specific.</p>
<ul>
<li><code>force_split</code> (default <code>false</code>): if <code>true</code> the <code>split</code> column in the dataset file is ignored and the dataset is randomly split. If <code>false</code> the <code>split</code> column is used if available.</li>
<li><code>split_probabilities</code> (default <code>[0.7, 0.1, 0.2]</code>): the proportion of the dataset data to end up in training, validation and test, respectively. The three values have to sum up to one.</li>
<li><code>stratify</code> (default <code>null</code>): if <code>null</code> the split is random, otherwise you can specify the name of a <code>category</code> feature and the split will be stratified on that feature.</li>
</ul>
<p>Example preprocessing dictionary (showing default values):</p>
<div class="codehilite"><pre><span></span><code><span class="nt">preprocessing</span><span class="p">:</span>
    <span class="nt">force_split</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
    <span class="nt">split_probabilities</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.7</span><span class="p p-Indicator">,</span> <span class="nv">0.1</span><span class="p p-Indicator">,</span> <span class="nv">0.2</span><span class="p p-Indicator">]</span>
    <span class="nt">stratify</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">category</span><span class="p">:</span> <span class="p p-Indicator">{</span><span class="nv">...</span><span class="p p-Indicator">}</span>
    <span class="nt">sequence</span><span class="p">:</span> <span class="p p-Indicator">{</span><span class="nv">...</span><span class="p p-Indicator">}</span>
    <span class="nt">text</span><span class="p">:</span> <span class="p p-Indicator">{</span><span class="nv">...</span><span class="p p-Indicator">}</span>
    <span class="l l-Scalar l-Scalar-Plain">...</span>
</code></pre></div>

<p>The details about the preprocessing parameters that each datatype accepts will be provided in the datatype-specific sections.</p>
<p>It is important to point out that different features with the same datatype may require different preprocessing.
For instance a document classification model may have two text input features, one for the title of the document and one for the body.</p>
<p>As the length of the title is much shorter than the length of the body, the parameter <code>word_length_limit</code> should be set to 10 for the title and 2000 for the body, but both of them share the same parameter <code>most_common_words</code> with value 10000.</p>
<p>The way to do this is adding a <code>preprocessing</code> key inside the title <code>input_feature</code> dictionary and one in the <code>body</code> input feature dictionary containing the desired parameter and value.
The configuration will look like:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">preprocessing</span><span class="p">:</span>
    <span class="nt">text</span><span class="p">:</span>
        <span class="nt">most_common_word</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10000</span>
<span class="nt">input_features</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">title</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text</span>
        <span class="nt">preprocessing</span><span class="p">:</span>
            <span class="nt">word_length_limit</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">body</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text</span>
        <span class="nt">preprocessing</span><span class="p">:</span>
            <span class="nt">word_length_limit</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2000</span>
</code></pre></div>

<h4 id="tokenizers">Tokenizers<a class="headerlink" href="#tokenizers" title="Permanent link">&para;</a></h4>
<p>Several different features perform raw data preprocessing by tokenizing strings (for instance sequence, text and set).
Here are the tokenizers options you can specify for those features:</p>
<ul>
<li><code>characters</code>: splits every character of the input string in a separate token.</li>
<li><code>space</code>: splits on space characters using the regex <code>\s+</code>.</li>
<li><code>space_punct</code>: splits on space characters and punctuation using the regex <code>\w+|[^\w\s]</code>. </li>
<li><code>underscore</code>: splits on the underscore character <code>_</code>.</li>
<li><code>comma</code>: splits on the underscore character <code>,</code>.</li>
<li><code>untokenized</code>: treats the whole string as a single token.</li>
<li><code>stripped</code>: treats the whole string as a single token after removing spaces at the beginnign and at the end of the string.</li>
<li><code>hf_tokenizer</code>: uses the Hugging Face AutoTokenizer which uses a <code>pretrained_model_name_or_path</code> parameter to decide which tokenizer to load.</li>
<li>Language specific tokenizers: <a href="https://spacy.io">spaCy</a> based language tokenizers.</li>
</ul>
<p>The <a href="https://spacy.io">spaCy</a> based tokenizers are functions that use the powerful tokenization and NLP preprocessing models provided the library.
Several languages are available: English (code <code>en</code>), Italian (code <code>it</code>), Spanish (code <code>es</code>), German (code <code>de</code>), French (code <code>fr</code>), Portuguese (code <code>pt</code>), Dutch (code <code>nl</code>), Greek (code <code>el</code>), Chinese (code <code>zh</code>), Danish (code <code>da</code>), Dutch (code <code>el</code>), Japanese (code <code>ja</code>), Lithuanian (code <code>lt</code>), Norwegian (code <code>nb</code>), Polish (code <code>pl</code>), Romanian (code <code>ro</code>) and Multi (code <code>xx</code>, useful in case you have a dataset containing different languages).
For each language different functions are available:</p>
<ul>
<li><code>tokenize</code>: uses spaCy tokenizer,</li>
<li><code>tokenize_filter</code>: uses spaCy tokenizer and filters out punctuation, numbers, stopwords and words shorter than 3 characters,</li>
<li><code>tokenize_remove_stopwords</code>: uses spaCy tokenizer and filters out stopwords,</li>
<li><code>lemmatize</code>: uses spaCy lemmatizer,</li>
<li><code>lemmatize_filter</code>: uses spaCy lemmatizer and filters out punctuation, numbers, stopwords and words shorter than 3 characters,</li>
<li><code>lemmatize_remove_stopwords</code>: uses spaCy lemmatize and filters out stopwords.</li>
</ul>
<p>In order to use these options, you have to download the the spaCy model:</p>
<div class="codehilite"><pre><span></span><code>python -m spacy download &lt;language_code&gt;
</code></pre></div>

<p>and provide <code>&lt;language&gt;_&lt;function&gt;</code> as <code>tokenizer</code> like: <code>english_tokenizer</code>, <code>italian_lemmatize_filter</code>, <code>multi_tokenize_filter</code> and so on.
More details on the models can be found in the <a href="https://spacy.io/models">spaCy documentation</a>.</p>
<h3 id="binary-features">Binary Features<a class="headerlink" href="#binary-features" title="Permanent link">&para;</a></h3>
<h4 id="binary-features-preprocessing">Binary Features Preprocessing<a class="headerlink" href="#binary-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Binary features are directly transformed into a binary valued vector of length <code>n</code> (where <code>n</code> is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset.
No additional information about them is available in the JSON metadata file.</p>
<p>The parameters available for preprocessing are</p>
<ul>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>0</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill_with_const</code>.</li>
</ul>
<h4 id="binary-input-features-and-encoders">Binary Input Features and Encoders<a class="headerlink" href="#binary-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Binary features have two encoders.
One encoder (<code>passthrough'</code>) takes the raw binary values coming from the input placeholders are just returned as outputs.
Inputs are of size <code>b</code> while outputs are of size <code>b x 1</code> where <code>b</code> is the batch size.
The other encoder (<code>'dense'</code>) passes the raw binary values through a fully connected layers.
In this case the inputs of size <code>b</code> are transformed to size <code>b x h</code>.  </p>
<p>Example binary feature entry in the input features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">binary_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">binary</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">passthrough</span>
</code></pre></div>

<p>Binary input feature parameters are</p>
<ul>
<li><code>encoder</code> (default <code>'passthrough'</code>) encodes the binary feature. Valid choices:  <code>'passthrough'</code>: binary feature is passed through as-is, <code>'dense'</code>: binary feature is fed through a fully connected layer.</li>
</ul>
<p>There are no additional parameters for the <code>passthrough</code> encoder.</p>
<h4 id="dense-encoder-parameters">Dense Encoder Parameters<a class="headerlink" href="#dense-encoder-parameters" title="Permanent link">&para;</a></h4>
<p>For the <code>dense</code> encoder these are the available parameters.</p>
<ul>
<li><code>num_layers</code> (default <code>1</code>): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): f a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<h4 id="binary-output-features-and-decoders">Binary Output Features and Decoders<a class="headerlink" href="#binary-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>Binary features can be used when a binary classification needs to be performed or when the output is a single probability.
There is only one decoder available for binary features and it is a (potentially empty) stack of fully connected layers, followed by a projection into a single number followed by a sigmoid function.</p>
<p>These are the available parameters of a binary output feature</p>
<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>dependencies</code> (default <code>[]</code>): the output features this one is dependent on. For a detailed explanation refer to <a href="#output-features-dependencies">Output Features Dependencies</a>.</li>
<li><code>reduce_dependencies</code> (default <code>sum</code>): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>loss</code> (default <code>{type: cross_entropy, confidence_penalty: 0, robust_lambda: 0, positive_class_weight: 1}</code>): is a dictionary containing a loss <code>type</code> and its hyper-parameters. The only available loss <code>type</code> is <code>cross_entropy</code> (cross entropy), and the optional parameters are <code>confidence_penalty</code> (an additional term that penalizes too confident predictions by adding a <code>a * (max_entropy - entropy) / max_entropy</code> term to the loss, where a is the value of this parameter), <code>robust_lambda</code> (replaces the loss with <code>(1 - robust_lambda) * loss + robust_lambda / 2</code> which is useful in case of noisy labels) and <code>positive_class_weight</code> (multiplies the loss for the positive class, increasing its importance).</li>
</ul>
<p>These are the available parameters of a binary output feature decoder</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>use_base</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>): initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix. Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>threshold</code> (default <code>0.5</code>): The threshold above (greater or equal) which the predicted output of the sigmoid will be mapped to 1.</li>
</ul>
<p>Example binary feature entry (with default parameters) in the output features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">binary_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">binary</span>
<span class="nt">reduce_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">dependencies</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cross_entropy</span>
    <span class="nt">confidence_penalty</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">robust_lambda</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">positive_class_weight</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.2</span>
<span class="nt">weisghts_intializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">l1</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">l1</span>
<span class="nt">threshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.5</span>
</code></pre></div>

<h4 id="binary-features-measures">Binary Features Measures<a class="headerlink" href="#binary-features-measures" title="Permanent link">&para;</a></h4>
<p>The only measures that are calculated every epoch and are available for binary features are the <code>accuracy</code> and the <code>loss</code> itself.
You can set either of them as <code>validation_measure</code> in the <code>training</code> section of the configuration if you set the <code>validation_field</code> to be the name of a binary feature.</p>
<h3 id="numerical-features">Numerical Features<a class="headerlink" href="#numerical-features" title="Permanent link">&para;</a></h3>
<h4 id="numerical-features-preprocessing">Numerical Features Preprocessing<a class="headerlink" href="#numerical-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Numerical features are directly transformed into a float valued vector of length <code>n</code> (where <code>n</code> is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset.
No additional information about them is available in the JSON metadata file.</p>
<p>Parameters available for preprocessing are</p>
<ul>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>0</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill-value</code>.</li>
<li><code>normalization</code> (default <code>null</code>): technique to be used when normalizing the numerical feature types. The available options are <code>null</code>, <code>zscore</code>, <code>minmax</code> and <code>log1p</code>. If the value is <code>null</code> no normalization is performed. If the value is <code>zscore</code>, the mean and standard deviation are computed so that values are shifted to have zero mean and 1 standard deviation. If the value is <code>minmax</code>, minimun and maximum values are computed and the minimum is subtracted from values and the result is divided by difference between maximum and minimum.  If <code>normalization</code> is <code>log1p</code> the  value returned is the natural log of 1 plus the original value.  Note: <code>log1p</code> is defined only for positive values.</li>
</ul>
<h4 id="numerical-input-features-and-encoders">Numerical Input Features and Encoders<a class="headerlink" href="#numerical-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Numerical features have two encoders.
One encoder (<code>passthrough'</code>) takes the raw binary values coming from the input placeholders are just returned as outputs.
Inputs are of size <code>b</code> while outputs are of size <code>b x 1</code> where <code>b</code> is the batch size.
The other encoder (<code>'dense'</code>) passes the raw binary values through fully connected layers.
In this case the inputs of size <code>b</code> are transformed to size <code>b x h</code>.  </p>
<p>The available encoder parameters are:</p>
<ul>
<li><code>norm'</code> (default <code>null</code>): norm to apply after the single neuron. It can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>tied_weights</code> (default <code>null</code>): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.</li>
</ul>
<p>There are no additional parameters for the <code>passthrough</code> encoder.</p>
<h4 id="dense-encoder-parameters_1">Dense Encoder Parameters<a class="headerlink" href="#dense-encoder-parameters_1" title="Permanent link">&para;</a></h4>
<p>For the <code>dense</code> encoder these are the available parameters.</p>
<ul>
<li><code>num_layers</code> (default <code>1</code>): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): f a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<p>Example numerical feature entry in the input features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">num_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</code></pre></div>

<h4 id="numerical-output-features-and-decoders">Numerical Output Features and Decoders<a class="headerlink" href="#numerical-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>Numerical features can be used when a regression needs to be performed.
There is only one decoder available for numerical features and it is a (potentially empty) stack of fully connected layers, followed by a projection into a single number.</p>
<p>These are the available parameters of a numerical output feature</p>
<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>dependencies</code> (default <code>[]</code>): the output features this one is dependent on. For a detailed explanation refer to <a href="#output-features-dependencies">Output Features Dependencies</a>.</li>
<li><code>reduce_dependencies</code> (default <code>sum</code>): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>loss</code> (default <code>{type: mean_squared_error}</code>): is a dictionary containing a loss <code>type</code>. The available losses <code>type</code> are <code>mean_squared_error</code> and <code>mean_absolute_error</code>.</li>
</ul>
<p>These are the available parameters of a numerical output feature decoder</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>clip</code> (default <code>null</code>): If not <code>null</code> it specifies a minimum and maximum value the predictions will be clipped to. The value can be either a list or a tuple of length 2, with the first value representing the minimum and the second the maximum. For instance <code>(-5,5)</code> will make it so that all predictions will be clipped in the <code>[-5,5]</code> interval.</li>
</ul>
<p>Example numerical feature entry (with default parameters) in the output features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
<span class="nt">reduce_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">dependencies</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">mean_squared_error</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">clip</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>

<h4 id="numerical-features-measures">Numerical Features Measures<a class="headerlink" href="#numerical-features-measures" title="Permanent link">&para;</a></h4>
<p>The measures that are calculated every epoch and are available for numerical features are <code>mean_squared_error</code>, <code>mean_absolute_error</code>, <code>r2</code> and the <code>loss</code> itself.
You can set either of them as <code>validation_measure</code> in the <code>training</code> section of the configuration if you set the <code>validation_field</code> to be the name of a numerical feature.</p>
<h3 id="category-features">Category Features<a class="headerlink" href="#category-features" title="Permanent link">&para;</a></h3>
<h4 id="category-features-preprocessing">Category Features Preprocessing<a class="headerlink" href="#category-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Category features are transformed into an integer valued vector of size <code>n</code> (where <code>n</code> is the size of the dataset) and added to the HDF5 with a key that reflects the name of column in the dataset.
The way categories are mapped into integers consists in first collecting a dictionary of all the different category strings present in the column of the dataset, then ranking them by frequency and then assigning them an increasing integer ID from the most frequent to the most rare (with 0 being assigned to a <code>&lt;UNK&gt;</code> token).
The column name is added to the JSON file, with an associated dictionary containing</p>
<ol>
<li>the mapping from integer to string (<code>idx2str</code>)</li>
<li>the mapping from string to id (<code>str2idx</code>)</li>
<li>the mapping from string to frequency (<code>str2freq</code>)</li>
<li>the size of the set of all tokens (<code>vocab_size</code>)</li>
<li>additional preprocessing information (by default how to fill missing values and what token to use to fill missing values)</li>
</ol>
<p>The parameters available for preprocessing are</p>
<ul>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>"&lt;UNK&gt;"</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill-value</code>.</li>
<li><code>lowercase</code> (default <code>false</code>): if the string has to be lowercased before being handled by the tokenizer.</li>
<li><code>most_common</code> (default <code>10000</code>): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown.</li>
</ul>
<h4 id="category-input-features-and-encoders">Category Input Features and Encoders<a class="headerlink" href="#category-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Category features have three encoders.
The <code>passthrough</code> encoder passes the raw integer values coming from the input placeholders to outputs of size <code>b x 1</code>.
The other two encoders map to either <code>dense</code> or <code>sparse</code> embeddings (one-hot encodings) and returned as outputs of size <code>b x h</code>, where <code>b</code> is the batch size and <code>h</code> is the dimenionsality of the embeddings.</p>
<p>Input feature parameters.</p>
<ul>
<li><code>encoder'</code> (default <code>dense</code>): the possible values are <code>passthrough</code>, <code>dense</code> and <code>sparse</code>. <code>passthrough</code> means passing the raw integer values unaltered.  <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>tied_weights</code> (default <code>null</code>): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.</li>
</ul>
<p>Example binary feature entry in the input features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
</code></pre></div>

<p>The available encoder parameters:</p>
<h5 id="dense-encoder">Dense Encoder<a class="headerlink" href="#dense-encoder" title="Permanent link">&para;</a></h5>
<ul>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate.</li>
<li><code>embedding_initializer</code> (default <code>null</code>): the initializer to use. If <code>null</code>, the default initialized of each variable is used (<code>glorot_uniform</code> in most cases). Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>embedding_regularizer</code> (default <code>null</code>): specifies the type of regularizer to use <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
</ul>
<h5 id="sparse-encoder">Sparse Encoder<a class="headerlink" href="#sparse-encoder" title="Permanent link">&para;</a></h5>
<ul>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>dropout</code> (default <code>false</code>): determines if there should be a dropout layer after embedding.</li>
<li><code>initializer</code> (default <code>null</code>): the initializer to use. If <code>null</code>, the default initialized of each variable is used (<code>glorot_uniform</code> in most cases). Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>regularize</code> (default <code>true</code>): if <code>true</code> the embedding weights are added to the set of weights that get regularized by a regularization loss (if the <code>regularization_lambda</code> in <code>training</code> is greater than 0).</li>
<li><code>tied_weights</code> (default <code>null</code>): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.</li>
</ul>
<p>Example category feature entry in the input features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sparse</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>

<h4 id="category-output-features-and-decoders">Category Output Features and Decoders<a class="headerlink" href="#category-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>Category features can be used when a multi-class classification needs to be performed.
There is only one decoder available for category features and it is a (potentially empty) stack of fully connected layers, followed by a projection into a vector of size of the number of available classes, followed by a softmax.</p>
<div class="codehilite"><pre><span></span><code>+--------------+   +---------+   +-----------+
|Combiner      |   |Fully    |   |Projection |   +-------+
|Output        +---&gt;Connected+---&gt;into Output+---&gt;Softmax|
|Representation|   |Layers   |   |Space      |   +-------+
+--------------+   +---------+   +-----------+
</code></pre></div>

<p>These are the available parameters of a category output feature</p>
<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>dependencies</code> (default <code>[]</code>): the output features this one is dependent on. For a detailed explanation refer to <a href="#output-features-dependencies">Output Features Dependencies</a>.</li>
<li><code>reduce_dependencies</code> (default <code>sum</code>): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>loss</code> (default <code>{type: softmax_cross_entropy, class_similarities_temperature: 0, class_weights: 1, confidence_penalty: 0, distortion: 1, labels_smoothing: 0, negative_samples: 0, robust_lambda: 0, sampler: null, unique: false}</code>): is a dictionary containing a loss <code>type</code>. The available losses <code>type</code> are <code>softmax_cross_entropy</code> and <code>sampled_softmax_cross_entropy</code>.</li>
<li><code>top_k</code> (default <code>3</code>): determines the parameter <code>k</code>, the number of categories to consider when computing the <code>top_k</code> measure. It computes accuracy but considering as a match if the true category appears in the first <code>k</code> predicted categories ranked by decoder's confidence.</li>
</ul>
<p>These are the <code>loss</code> parameters</p>
<ul>
<li><code>confidence_penalty</code> (default <code>0</code>): penalizes overconfident predictions (low entropy) by adding an additional term that penalizes too confident predictions by adding a <code>a * (max_entropy - entropy) / max_entropy</code> term to the loss, where a is the value of this parameter. Useful in case of noisy labels.</li>
<li><code>robust_lambda</code> (default <code>0</code>): replaces the loss with <code>(1 - robust_lambda) * loss + robust_lambda / c</code> where <code>c</code> is the number of classes, which is useful in case of noisy labels.</li>
<li><code>class_weights</code> (default <code>1</code>): the value can be a vector of weights, one for each class, that is multiplied to the loss of the datapoints that have that class as ground truth. It is an alternative to oversampling in case of unbalanced class distribution. The ordering of the vector follows the category to integer ID mapping in the JSON metadata file (the <code>&lt;UNK&gt;</code> class needs to be included too). Alternatively, the value can be a dictionary with class strings as keys and weights as values, like <code>{class_a: 0.5, class_b: 0.7, ...}</code>.</li>
<li><code>class_similarities</code> (default <code>null</code>): if not <code>null</code> it is a <code>c x c</code> matrix in the form of a list of lists that contains the mutual similarity of classes. It is used if <code>class_similarities_temperature</code> is greater than 0. The ordering of the vector follows the category to integer ID mapping in the JSON metadata file (the <code>&lt;UNK&gt;</code> class needs to be included too).</li>
<li><code>class_similarities_temperature</code> (default <code>0</code>): is the temperature parameter of the softmax that is performed on each row of <code>class_similarities</code>. The output of that softmax is used to determine the supervision vector to provide instead of the one hot vector that would be provided otherwise for each datapoint. The intuition behind it is that errors between similar classes are more tollerable than errors between really different classes.</li>
<li><code>labels_smoothing</code> (default <code>0</code>): If label_smoothing is nonzero, smooth the labels towards <code>1/num_classes</code>: <code>new_onehot_labels = onehot_labels * (1 - label_smoothing) + label_smoothing / num_classes</code>.</li>
<li><code>negative_samples</code> (default <code>0</code>): if <code>type</code> is <code>sampled_softmax_cross_entropy</code>, this parameter indicates how many negative samples to use.</li>
<li><code>sampler</code> (default <code>null</code>): options are <code>fixed_unigram</code>, <code>uniform</code>, <code>log_uniform</code>, <code>learned_unigram</code>. For a detailed description of the samplers refer to <a href="https://www.tensorflow.org/api_guides/python/nn#Candidate_Sampling">TensorFlow's documentation</a>.</li>
<li><code>distortion</code> (default <code>1</code>): when <code>loss</code> is <code>sampled_softmax_cross_entropy</code> and the sampler is either <code>unigram</code> or <code>learned_unigram</code> this is used to skew the unigram probability distribution. Each weight is first raised to the distortion's power before adding to the internal unigram distribution. As a result, distortion = 1.0 gives regular unigram sampling (as defined by the vocab file), and distortion = 0.0 gives a uniform distribution.</li>
<li><code>unique</code> (default <code>false</code>): Determines whether all sampled classes in a batch are unique.</li>
</ul>
<p>These are the available parameters of a category output feature decoder</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>weights_initializer</code> and <code>weighs_regularizer</code>. If any of those values is missing from the dictionary, the default value will be used.</li>
<li><code>num_fc_layers</code> (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>dropout</code> (default <code>false</code>): determines if there should be a dropout layer after each layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the fully connected weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the fully connected weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
</ul>
<p>Example category feature entry (with default parameters) in the output features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
<span class="nt">reduce_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">dependencies</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">softmax_cross_entropy</span>
    <span class="nt">confidence_penalty</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">robust_lambda</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">class_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">class_similarities</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">class_similarities_temperature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">labels_smoothing</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">negative_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">sampler</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">distortion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">unique</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">use_biase</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">top_k</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
</code></pre></div>

<h4 id="category-features-measures">Category Features Measures<a class="headerlink" href="#category-features-measures" title="Permanent link">&para;</a></h4>
<p>The measures that are calculated every epoch and are available for category features are <code>accuracy</code>, <code>top_k</code> (computes accuracy considering as a match if the true category appears in the first <code>k</code> predicted categories ranked by decoder's confidence) and the <code>loss</code> itself.
You can set either of them as <code>validation_measure</code> in the <code>training</code> section of the configuration if you set the <code>validation_field</code> to be the name of a category feature.</p>
<h3 id="set-features">Set Features<a class="headerlink" href="#set-features" title="Permanent link">&para;</a></h3>
<h4 id="set-features-preprocessing">Set Features Preprocessing<a class="headerlink" href="#set-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Set features are expected to be provided as a string of elements separated by whitespace, e.g. "elem5 elem9 elem6".
The string values are transformed into a binary (int8 actually) valued matrix of size <code>n x l</code> (where <code>n</code> is the size of the dataset and <code>l</code> is the minimum of the size of the biggest set and a <code>max_size</code> parameter) and added to HDF5 with a key that reflects the name of column in the dataset.
The way sets are mapped into integers consists in first using a tokenizer to map from strings to sequences of set items (by default this is done by splitting on spaces).
Then a dictionary of all the different set item strings present in the column of the dataset is collected, then they are ranked by frequency and an increasing integer ID is assigned to them from the most frequent to the most rare (with 0 being assigned to <code>&lt;PAD&gt;</code> used for padding and 1 assigned to <code>&lt;UNK&gt;</code> item).
The column name is added to the JSON file, with an associated dictionary containing</p>
<ol>
<li>the mapping from integer to string (<code>idx2str</code>)</li>
<li>the mapping from string to id (<code>str2idx</code>)</li>
<li>the mapping from string to frequency (<code>str2freq</code>)</li>
<li>the maximum size of all sets (<code>max_set_size</code>)</li>
<li>additional preprocessing information (by default how to fill missing values and what token to use to fill missing values)</li>
</ol>
<p>The parameters available for preprocessing are</p>
<ul>
<li><code>tokenizer</code> (default <code>space</code>): defines how to map from the raw string content of the dataset column to a set of elements. The default value <code>space</code> splits the string on spaces. Common options include: <code>underscore</code> (splits on underscore), <code>comma</code>(splits on comma), <code>json</code> (decodes the string into a set or a list through a JSON parser). For all the available options refer to the <a href="#tokenizers">Tokenizers</a> section.</li>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>0</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill-value</code>.</li>
<li><code>lowercase</code> (default <code>false</code>): if the string has to be lowercased before being handled by the tokenizer.</li>
<li><code>most_common</code> (default <code>10000</code>): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown.</li>
</ul>
<h4 id="set-input-features-and-encoders">Set Input Features and Encoders<a class="headerlink" href="#set-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Set features have one encoder, the raw binary values coming from the input placeholders are first transformed in sparse integer lists, then they are mapped to either dense or sparse embeddings (one-hot encodings), finally they are aggregated and returned as outputs.
Inputs are of size <code>b</code> while outputs are of size <code>b x h</code> where <code>b</code> is the batch size and <code>h</code> is the dimensionally of the embeddings.</p>
<div class="codehilite"><pre><span></span><code>+-+
|0|          +-----+
|0|   +-+    |emb 2|   +-----------+
|1|   |2|    +-----+   |Aggregation|
|0+---&gt;4+----&gt;emb 4+---&gt;Reduce     +-&gt;
|1|   |5|    +-----+   |Operation  |
|1|   +-+    |emb 5|   +-----------+
|0|          +-----+
+-+
</code></pre></div>

<p>The available encoder parameters are</p>
<ul>
<li><code>representation'</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>50</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>weights_initializer</code> and <code>weighs_regularizer</code>. If any of those values is missing from the dictionary, the default value will be used.</li>
<li><code>num_fc_layers</code> (default <code>1</code>): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>10</code>): f a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>sum</code>): describes the strategy to use to aggregate the embeddings of the items of the set. Possible values are <code>sum</code>, <code>mean</code> and <code>sqrt</code> (the weighted sum divided by the square root of the sum of the squares of the weights).</li>
<li><code>tied_weights</code> (default <code>null</code>): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.</li>
</ul>
<p>Example set feature entry in the input features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">set_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">set</span>
<span class="nt">representation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>

<h4 id="set-output-features-and-decoders">Set Output Features and Decoders<a class="headerlink" href="#set-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>Set features can be used when multi-label classification needs to be performed.
There is only one decoder available for set features and it is a (potentially empty) stack of fully connected layers, followed by a projection into a vector of size of the number of available classes, followed by a sigmoid.</p>
<div class="codehilite"><pre><span></span><code>+--------------+   +---------+   +-----------+
|Combiner      |   |Fully    |   |Projection |   +-------+
|Output        +---&gt;Connected+---&gt;into Output+---&gt;Sigmoid|
|Representation|   |Layers   |   |Space      |   +-------+
+--------------+   +---------+   +-----------+
</code></pre></div>

<p>These are the available parameters of the set output feature</p>
<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>dependencies</code> (default <code>[]</code>): the output features this one is dependent on. For a detailed explanation refer to <a href="#output-features-dependencies">Output Features Dependencies</a>.</li>
<li><code>reduce_dependencies</code> (default <code>sum</code>): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>loss</code> (default <code>{type: sigmoid_cross_entropy}</code>): is a dictionary containing a loss <code>type</code>. The available loss <code>type</code> is <code>sigmoid_cross_entropy</code>.</li>
</ul>
<p>These are the available parameters of a set output feature decoder</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): f a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>threshold</code> (default <code>0.5</code>): The threshold above (greater or equal) which the predicted output of the sigmoid will be mapped to 1.</li>
</ul>
<p>Example set feature entry (with default parameters) in the output features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">set_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">set</span>
<span class="nt">reduce_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">dependencies</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sigmoid_cross_entropy</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">threshold</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.5</span>
</code></pre></div>

<h4 id="set-features-measures">Set Features Measures<a class="headerlink" href="#set-features-measures" title="Permanent link">&para;</a></h4>
<p>The measures that are calculated every epoch and are available for category features are <code>jaccard_index</code> and the <code>loss</code> itself.
You can set either of them as <code>validation_measure</code> in the <code>training</code> section of the configuration if you set the <code>validation_field</code> to be the name of a set feature.</p>
<h3 id="bag-features">Bag Features<a class="headerlink" href="#bag-features" title="Permanent link">&para;</a></h3>
<h4 id="bag-features-preprocessing">Bag Features Preprocessing<a class="headerlink" href="#bag-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Bag features are expected to be provided as a string of elements separated by whitespace, e.g. "elem5 elem9 elem6".
Bag features are treated in the same way of set features, with the only difference being that the matrix had float values (frequencies).</p>
<h4 id="bag-input-features-and-encoders">Bag Input Features and Encoders<a class="headerlink" href="#bag-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Bag features have one encoder, the raw float values coming from the input placeholders are first transformed in sparse integer lists, then they are mapped to either dense or sparse embeddings (one-hot encodings), they are aggregated as a weighted sum, where the weights are the original float values, and finally returned as outputs.
Inputs are of size <code>b</code> while outputs are of size <code>b x h</code> where <code>b</code> is the batch size and <code>h</code> is the dimensionality of the embeddings.</p>
<p>The parameters are the same used for set input features with the exception of <code>reduce_output</code> that does not apply in this case because the weighted sum already acts as a reducer.</p>
<h4 id="bag-output-features-and-decoders">Bag Output Features and Decoders<a class="headerlink" href="#bag-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>There is no bag decoder available yet.</p>
<h4 id="bag-features-measures">Bag Features Measures<a class="headerlink" href="#bag-features-measures" title="Permanent link">&para;</a></h4>
<p>As there is no decoder there is also no measure available yet for bag feature.</p>
<h3 id="sequence-features">Sequence Features<a class="headerlink" href="#sequence-features" title="Permanent link">&para;</a></h3>
<h4 id="sequence-features-preprocessing">Sequence Features Preprocessing<a class="headerlink" href="#sequence-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Sequence features are transformed into an integer valued matrix of size <code>n x l</code> (where <code>n</code> is the size of the dataset and <code>l</code> is the minimum of the length of the longest sequence and a <code>sequence_length_limit</code> parameter) and added to HDF5 with a key that reflects the name of column in the dataset.
The way sequences are mapped into integers consists in first using a tokenizer to map from strings to sequences of tokens (by default this is done by splitting on spaces).
Then a dictionary of all the different token strings present in the column of the dataset is collected, then they are ranked by frequency and an increasing integer ID is assigned to them from the most frequent to the most rare (with 0 being assigned to <code>&lt;PAD&gt;</code> used for padding and 1 assigned to <code>&lt;UNK&gt;</code> item).
The column name is added to the JSON file, with an associated dictionary containing</p>
<ol>
<li>the mapping from integer to string (<code>idx2str</code>)</li>
<li>the mapping from string to id (<code>str2idx</code>)</li>
<li>the mapping from string to frequency (<code>str2freq</code>)</li>
<li>the maximum length of all sequences (<code>sequence_length_limit</code>)</li>
<li>additional preprocessing information (by default how to fill missing values and what token to use to fill missing values)</li>
</ol>
<p>The parameters available for preprocessing are</p>
<ul>
<li><code>sequence_length_limit</code> (default <code>256</code>): the maximum length of the sequence. Sequences that are longer than this value will be truncated, while sequences that are shorter will be padded.</li>
<li><code>most_common</code> (default <code>20000</code>): the maximum number of most common tokens to be considered. if the data contains more than this amount, the most infrequent tokens will be treated as unknown.</li>
<li><code>padding_symbol</code> (default <code>&lt;PAD&gt;</code>): the string used as a padding symbol. Is is mapped to the integer ID 0 in the vocabulary.</li>
<li><code>unknown_symbol</code> (default <code>&lt;UNK&gt;</code>): the string used as a unknown symbol. Is is mapped to the integer ID 1 in the vocabulary.</li>
<li><code>padding</code> (default <code>right</code>): the direction of the padding. <code>right</code> and <code>left</code> are available options.</li>
<li><code>tokenizer</code> (default <code>space</code>): defines how to map from the raw string content of the dataset column to a sequence of elements. For the available options refer to the <a href="#tokenizers">Tokenizers</a>section.</li>
<li><code>lowercase</code> (default <code>false</code>): if the string has to be lowercase before being handled by the tokenizer.</li>
<li><code>vocab_file</code> (default <code>null</code>)  filepath string to a UTF-8 encoded file containing the sequence's vocabulary.  On each line the first string until <code>\t</code> or <code>\n</code> is considered a word.</li>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>""</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill_value</code>.</li>
</ul>
<h4 id="sequence-input-features-and-encoders">Sequence Input Features and Encoders<a class="headerlink" href="#sequence-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Sequence features have several encoders and each of them has its own parameters.
Inputs are of size <code>b</code> while outputs are of size <code>b x h</code> where <code>b</code> is the batch size and <code>h</code> is the dimensionally of the output of the encoder.
In case a representation for each element of the sequence is needed (for example for tagging them, or for using an attention mechanism), one can specify the parameter <code>reduce_output</code> to be  <code>null</code> and the output will be a <code>b x s x h</code> tensor where <code>s</code> is the length of the sequence.
Some encoders, because of their inner workings, may require additional parameters to be specified in order to obtain one representation for each element of the sequence.
For instance the <code>parallel_cnn</code> encoder, by default pools and flattens the sequence dimension and then passes the flattened vector through fully connected layers, so in order to obtain the full tesnor one has to specify <code>reduce_output: null</code>.</p>
<p>Sequence input feature parameters are</p>
<ul>
<li><code>encoder</code> (default <code>parallel_cnn</code>): the name of the encoder to use to encode the sequence. The available ones are  <code>embed</code>, <code>parallel_cnn</code>, <code>stacked_cnn</code>, <code>stacked_parallel_cnn</code>, <code>rnn</code>, <code>cnnrnn</code>, <code>transformer</code> and <code>passthrough</code> (equivalent to specify <code>null</code> or <code>'None'</code>).</li>
<li><code>tied_weights</code> (default <code>null</code>): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.</li>
</ul>
<h5 id="embed-encoder">Embed Encoder<a class="headerlink" href="#embed-encoder" title="Permanent link">&para;</a></h5>
<p>The embed encoder simply maps each integer in the sequence to an embedding, creating a <code>b x s x h</code> tensor where <code>b</code> is the batch size, <code>s</code> is the length of the sequence and <code>h</code> is the embedding size.
The tensor is reduced along the <code>s</code> dimension to obtain a single vector of size <code>h</code> for each element of the batch.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="codehilite"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|   +-----------+
|43|   +------+   |Aggregation|
|65+---&gt;Emb 65+---&gt;Reduce     +-&gt;
|23|   +------+   |Operation  |
|4 |   |Emb 23|   +-----------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>

<p>These are the parameters available for the embed encoder</p>
<ul>
<li><code>representation'</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>reduce_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the input features list using an embed encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">embed</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">representation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
</code></pre></div>

<h5 id="parallel-cnn-encoder">Parallel CNN Encoder<a class="headerlink" href="#parallel-cnn-encoder" title="Permanent link">&para;</a></h5>
<p>The parallel cnn encoder is inspired by <a href="https://arxiv.org/abs/1408.5882">Yoon Kim's Convolutional Neural Network for Sentence Classification</a>.
It works by first mapping the input integer sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a number of parallel 1d convolutional layers with different filter size (by default 4 layers with filter size 2, 3, 4 and 5), followed by max pooling and concatenation.
This single vector concatenating the outputs of the parallel convolutional layers is then passed through a stack of fully connected layers and returned as a <code>b x h</code> tensor where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="codehilite"><pre><span></span><code>                   +-------+   +----+
                +--&gt;1D Conv+---&gt;Pool+-+
       +------+ |  |Width 2|   +----+ |
       |Emb 12| |  +-------+          |
       +------+ |                     |
+--+   |Emb 7 | |  +-------+   +----+ |
|12|   +------+ +--&gt;1D Conv+---&gt;Pool+-+
|7 |   |Emb 43| |  |Width 3|   +----+ |           +---------+
|43|   +------+ |  +-------+          | +------+  |Fully    |
|65+---&gt;Emb 65+-+                     +-&gt;Concat+--&gt;Connected+-&gt;
|23|   +------+ |  +-------+   +----+ | +------+  |Layers   |
|4 |   |Emb 23| +--&gt;1D Conv+---&gt;Pool+-+           +---------+
|1 |   +------+ |  |Width 4|   +----+ |
+--+   |Emb 4 | |  +-------+          |
       +------+ |                     |
       |Emb 1 | |  +-------+   +----+ |
       +------+ +--&gt;1D Conv+---&gt;Pool+-+
                   |Width 5|   +----+
                   +-------+
</code></pre></div>

<p>These are the available for an parallel cnn encoder:</p>
<ul>
<li><code>representation'</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>conv_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of parallel convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>filter_size</code>, <code>num_filters</code>, <code>pool</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value <code>[{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}]</code>.</li>
<li><code>num_conv_layers</code> (default <code>null</code>): if <code>conv_layers</code> is <code>null</code>, this is the number of parallel convolutional layers.</li>
<li><code>filter_size</code> (default <code>3</code>): if a <code>filter_size</code> is not already specified in <code>conv_layers</code> this is the default <code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>conv_layers</code> this is the default <code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution.</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value.  Any of these--<code>average</code>, <code>avg</code> or <code>mean</code>--will compute the mean value.</li>
<li><code>pool_size</code> (default <code>null</code>): if a <code>pool_size</code> is not already specified in <code>conv_layers</code> this is the default <code>pool_size</code> that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>,  <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the sequence dimension), <code>last</code> (returns the last vector of the sequence dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the input features list using a parallel cnn encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">parallel_cnn</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">representation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">conv_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_conv_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">filter_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="nt">num_filters</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">pool_function</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="nt">pool_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
</code></pre></div>

<h5 id="stacked-cnn-encoder">Stacked CNN Encoder<a class="headerlink" href="#stacked-cnn-encoder" title="Permanent link">&para;</a></h5>
<p>The stacked cnn encoder is inspired by <a href="https://arxiv.org/abs/1509.01626">Xiang Zhang at all's Character-level Convolutional Networks for Text Classification</a>.
It works by first mapping the input integer sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of 1d convolutional layers with different filter size (by default 6 layers with filter size 7, 7, 3, 3, 3 and 3), followed by an optional final pool and by a flatten operation.
This single flatten vector is then passed through a stack of fully connected layers and returned as a <code>b x h</code> tensor where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify the <code>pool_size</code> of all your <code>conv_layers</code> to be <code>null</code>  and <code>reduce_output: null</code>, while if <code>pool_size</code> has a value different from <code>null</code> and <code>reduce_output: null</code> the returned tensor will be of shape <code>b x s' x h</code>, where <code>s'</code> is width of the output of the last convolutional layer.</p>
<div class="codehilite"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|   +----------------+  +---------+
|43|   +------+   |1D Conv         |  |Fully    |
|65+---&gt;Emb 65+---&gt;Layers          +--&gt;Connected+-&gt;
|23|   +------+   |Different Widths|  |Layers   |
|4 |   |Emb 23|   +----------------+  +---------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>

<p>These are the parameters available for the stack cnn encoder:</p>
<ul>
<li><code>representation'</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>conv_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>filter_size</code>, <code>num_filters</code>, <code>pool_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value <code>[{filter_size: 7, pool_size: 3, regularize: false}, {filter_size: 7, pool_size: 3, regularize: false}, {filter_size: 3, pool_size: null, regularize: false}, {filter_size: 3, pool_size: null, regularize: false}, {filter_size: 3, pool_size: null, regularize: true}, {filter_size: 3, pool_size: 3, regularize: true}]</code>.</li>
<li><code>num_conv_layers</code> (default <code>null</code>): if <code>conv_layers</code> is <code>null</code>, this is the number of stacked convolutional layers.</li>
<li><code>filter_size</code> (default <code>3</code>): if a <code>filter_size</code> is not already specified in <code>conv_layers</code> this is the default <code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>conv_layers</code> this is the default <code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution.</li>
<li><code>strides</code> (default <code>1</code>): stride length of the convolution</li>
<li><code>padding</code> (default <code>same</code>):  one of <code>valid</code> or <code>same</code>.</li>
<li><code>dilation_rate</code> (default <code>1</code>): dilation rate to use for dilated convolution</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value.  Any of these--<code>average</code>, <code>avg</code> or <code>mean</code>--will compute the mean value.</li>
<li><code>pool_size</code> (default <code>null</code>): if a <code>pool_size</code> is not already specified in <code>conv_layers</code> this is the default <code>pool_size</code> that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><code>pool_strides</code> (default <code>null</code>): factor to scale down</li>
<li><code>pool_padding</code> (default <code>same</code>): one of <code>valid</code> or <code>same</code></li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>max</code>): defines how to reduce the output tensor of the convolutional layers along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the input features list using a parallel cnn encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">stacked_cnn</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">representation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">conv_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_conv_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">filter_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="nt">num_filters</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">strides</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">padding</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">same</span>
<span class="nt">dilation_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">pool_function</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="nt">pool_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">pool_strides</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">pool_padding</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">same</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">max</span>
</code></pre></div>

<h5 id="stacked-parallel-cnn-encoder">Stacked Parallel CNN Encoder<a class="headerlink" href="#stacked-parallel-cnn-encoder" title="Permanent link">&para;</a></h5>
<p>The stacked parallel cnn encoder is a combination of the Parallel CNN and the Stacked CNN encoders where each layer of the stack is a composed of parallel convolutional layers.
It works by first mapping the input integer sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of several parallel 1d convolutional layers with different filter size, followed by an optional final pool and by a flatten operation.
This single flatten vector is then passed through a stack of fully connected layers and returned as a <code>b x h</code> tensor where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="codehilite"><pre><span></span><code>                   +-------+                      +-------+
                +--&gt;1D Conv+-+                 +--&gt;1D Conv+-+
       +------+ |  |Width 2| |                 |  |Width 2| |
       |Emb 12| |  +-------+ |                 |  +-------+ |
       +------+ |            |                 |            |
+--+   |Emb 7 | |  +-------+ |                 |  +-------+ |
|12|   +------+ +--&gt;1D Conv+-+                 +--&gt;1D Conv+-+
|7 |   |Emb 43| |  |Width 3| |                 |  |Width 3| |                   +---------+
|43|   +------+ |  +-------+ | +------+  +---+ |  +-------+ | +------+  +----+  |Fully    |
|65+---&gt;Emb 65+-+            +-&gt;Concat+--&gt;...+-+            +-&gt;Concat+--&gt;Pool+--&gt;Connected+-&gt;
|23|   +------+ |  +-------+ | +------+  +---+ |  +-------+ | +------+  +----+  |Layers   |
|4 |   |Emb 23| +--&gt;1D Conv+-+                 +--&gt;1D Conv+-+                   +---------+
|1 |   +------+ |  |Width 4| |                 |  |Width 4| |
+--+   |Emb 4 | |  +-------+ |                 |  +-------+ |
       +------+ |            |                 |            |
       |Emb 1 | |  +-------+ |                 |  +-------+ |
       +------+ +--&gt;1D Conv+-+                 +--&gt;1D Conv+-+
                   |Width 5|                      |Width 5|
                   +-------+                      +-------+
</code></pre></div>

<p>These are the available parameters for the stack parallel cnn encoder:</p>
<ul>
<li><code>representation'</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>stacked_layers</code> (default <code>null</code>): it is a of lists of list of dictionaries containing the parameters of the stack of parallel convolutional layers. The length of the list determines the number of stacked parallel convolutional layers, length of the sub-lists determines the number of parallel conv layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>filter_size</code>, <code>num_filters</code>, <code>pool_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>stacked_layers</code> and <code>num_stacked_layers</code> are <code>null</code>, a default list will be assigned to <code>stacked_layers</code> with the value <code>[[{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}], [{filter_size: 2}, {filter_size: 3}, {filter_size: 4}, {filter_size: 5}]]</code>.</li>
<li><code>num_stacked_layers</code> (default <code>null</code>): if <code>stacked_layers</code> is <code>null</code>, this is the number of elements in the stack of parallel convolutional layers.</li>
<li><code>filter_size</code> (default <code>3</code>): if a <code>filter_size</code> is not already specified in <code>conv_layers</code> this is the default <code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>conv_layers</code> this is the default <code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution.</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value.  Any of these--<code>average</code>, <code>avg</code> or <code>mean</code>--will compute the mean value.</li>
<li><code>pool_size</code> (default <code>null</code>): if a <code>pool_size</code> is not already specified in <code>conv_layers</code> this is the default <code>pool_size</code> that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the input features list using a parallel cnn encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">stacked_parallel_cnn</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">representation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">stacked_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_stacked_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">filter_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="nt">num_filters</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">pool_function</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="nt">pool_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">max</span>
</code></pre></div>

<h5 id="rnn-encoder">RNN Encoder<a class="headerlink" href="#rnn-encoder" title="Permanent link">&para;</a></h5>
<p>The rnn encoder works by first mapping the input integer sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of recurrent layers (by default 1 layer), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions.
If you want to output the full <code>b x s x h</code> where <code>h</code> is the size of the output of the last rnn layer, you can specify <code>reduce_output: null</code>.</p>
<div class="codehilite"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|                 +---------+
|43|   +------+   +----------+  |Fully    |
|65+---&gt;Emb 65+---&gt;RNN Layers+--&gt;Connected+-&gt;
|23|   +------+   +----------+  |Layers   |
|4 |   |Emb 23|                 +---------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>

<p>These are the available parameters for the rnn encoder:</p>
<ul>
<li><code>representation'</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>num_layers</code> (default <code>1</code>): the number of stacked recurrent layers.</li>
<li><code>state_size</code> (default <code>256</code>): the size of the state of the rnn.</li>
<li><code>cell_type</code> (default <code>rnn</code>): the type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>lstm_block</code>, <code>lstm</code>, <code>ln</code>, <code>lstm_cudnn</code>, <code>gru</code>, <code>gru_block</code>, <code>gru_cudnn</code>. For reference about the differences between the cells please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell">TensorFlow's documentation</a>. We suggest to use the <code>block</code> variants on CPU and the <code>cudnn</code> variants on GPU because of their increased speed.</li>
<li><code>bidirectional</code> (default <code>false</code>): if <code>true</code> two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated.</li>
<li><code>activation</code> (default <code>'tanh'</code>): activation function to use</li>
<li><code>recurrent_activation</code> (default <code>'sigmoid'</code>): activation function to use in the recurrent step</li>
<li><code>unit_forget_bias</code> (default <code>true</code>): If <code>true</code>, add 1 to the bias of the forget gate at initialization</li>
<li><code>recurrent_initializer</code> (default <code>'orthogonal'</code>): initializer for recurrent matrix weights</li>
<li><code>recurrent_regularizer</code> (default <code>null</code>): regularizer function applied to recurrent matrix weights</li>
<li><code>dropout</code> (default <code>0.0</code>): dropout rate</li>
<li><code>recurrent_dropout</code> (default <code>0.0</code>): dropout rate for recurrent state</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>,  <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>fc_activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>fc_dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>last</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the input features list using a parallel cnn encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="l l-Scalar l-Scalar-Plain">representation&#39;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">num_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">state_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">cell_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="nt">bidirectional</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tanh</span>
<span class="nt">recurrent_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sigmoid</span>
<span class="nt">unit_forget_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">recurrent_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">orthogonal</span>
<span class="nt">recurrent_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">recurrent_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">fc_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">last</span>
</code></pre></div>

<h5 id="cnn-rnn-encoder">CNN RNN Encoder<a class="headerlink" href="#cnn-rnn-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>cnnrnn</code> encoder works by first mapping the input integer sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of convolutional layers (by default 2), that is followed by a stack of recurrent layers (by default 1), followed by a reduce operation that by default only returns the last output, but can perform other reduce functions.
If you want to output the full <code>b x s x h</code> where <code>h</code> is the size of the output of the last rnn layer, you can specify <code>reduce_output: null</code>.</p>
<div class="codehilite"><pre><span></span><code>       +------+
       |Emb 12|
       +------+
+--+   |Emb 7 |
|12|   +------+
|7 |   |Emb 43|                                +---------+
|43|   +------+   +----------+   +----------+  |Fully    |
|65+---&gt;Emb 65+---&gt;CNN Layers+---&gt;RNN Layers+--&gt;Connected+-&gt;
|23|   +------+   +----------+   +----------+  |Layers   |
|4 |   |Emb 23|                                +---------+
|1 |   +------+
+--+   |Emb 4 |
       +------+
       |Emb 1 |
       +------+
</code></pre></div>

<p>These are the available parameters of the cnn rnn encoder:</p>
<ul>
<li><code>representation'</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>conv_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>filter_size</code>, <code>num_filters</code>, <code>pool_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value <code>[{filter_size: 7, pool_size: 3, regularize: false}, {filter_size: 7, pool_size: 3, regularize: false}, {filter_size: 3, pool_size: null, regularize: false}, {filter_size: 3, pool_size: null, regularize: false}, {filter_size: 3, pool_size: null, regularize: true}, {filter_size: 3, pool_size: 3, regularize: true}]</code>.</li>
<li><code>num_conv_layers</code> (default <code>1</code>): the number of stacked convolutional layers.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>conv_layers</code> this is the default <code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 1d convolution.</li>
<li><code>filter_size</code> (default <code>5</code>): if a <code>filter_size</code> is not already specified in <code>conv_layers</code> this is the default <code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>strides</code> (default <code>1</code>): stride length of the convolution</li>
<li><code>padding</code> (default <code>same</code>):  one of <code>valid</code> or <code>same</code>.</li>
<li><code>dilation_rate</code> (default <code>1</code>): dilation rate to use for dilated convolution</li>
<li><code>conv_activation</code> (default <code>relu</code>): activation for the convolution layer</li>
<li><code>conv_dropout</code> (default <code>0.0</code>): dropout rate for the convolution layer</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value.  Any of these--<code>average</code>, <code>avg</code> or <code>mean</code>--will compute the mean value.</li>
<li><code>pool_size</code> (default 2 ): if a <code>pool_size</code> is not already specified in <code>conv_layers</code> this is the default <code>pool_size</code> that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><code>pool_strides</code> (default <code>null</code>): factor to scale down</li>
<li><code>pool_padding</code> (default <code>same</code>): one of <code>valid</code> or <code>same</code></li>
<li><code>num_rec_layers</code> (default <code>1</code>): the number of recurrent layers</li>
<li><code>state_size</code> (default <code>256</code>): the size of the state of the rnn.</li>
<li><code>cell_type</code> (default <code>rnn</code>): the type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>lstm_block</code>, <code>lstm</code>, <code>ln</code>, <code>lstm_cudnn</code>, <code>gru</code>, <code>gru_block</code>, <code>gru_cudnn</code>. For reference about the differences between the cells please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell">TensorFlow's documentation</a>. We suggest to use the <code>block</code> variants on CPU and the <code>cudnn</code> variants on GPU because of their increased speed.</li>
<li><code>bidirectional</code> (default <code>false</code>): if <code>true</code> two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated.</li>
<li><code>activation</code> (default <code>'tanh'</code>): activation function to use</li>
<li><code>recurrent_activation</code> (default <code>'sigmoid'</code>): activation function to use in the recurrent step</li>
<li><code>unit_forget_bias</code> (default <code>true</code>): If <code>true</code>, add 1 to the bias of the forget gate at initialization</li>
<li><code>recurrent_initializer</code> (default <code>'orthogonal'</code>): initializer for recurrent matrix weights</li>
<li><code>recurrent_regularizer</code> (default <code>null</code>): regularizer function applied to recurrent matrix weights</li>
<li><code>dropout</code> (default <code>0.0</code>): dropout rate</li>
<li><code>recurrent_dropout</code> (default <code>0.0</code>): dropout rate for recurrent state</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>,  <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>null</code>): if <code>fc_layers</code> is <code>null</code>, this is the number of stacked fully connected layers (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>fc_activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>fc_dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>last</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the inputs features list using a cnn rnn encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cnnrnn</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">representation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">conv_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_conv_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">num_filters</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">filter_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="nt">strides</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">padding</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">same</span>
<span class="nt">dilation_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">conv_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">conv_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">pool_function</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="nt">pool_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="nt">pool_strides</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">pool_padding</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">same</span>
<span class="nt">num_rec_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">state_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">cell_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="nt">bidirectional</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tanh</span>
<span class="nt">recurrent_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sigmoid</span>
<span class="nt">unit_forget_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">recurrent_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">orthogonal</span>
<span class="nt">recurrent_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">recurrent_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">fc_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">last</span>
</code></pre></div>

<h5 id="transformer-encoder">Transformer Encoder<a class="headerlink" href="#transformer-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>transformer</code> encoder implements a stack of transformer blocks, replicating the architecture introduced in the <a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a> paper, and adds am optional stack of fully connected layers at the end.</p>
<div class="codehilite"><pre><span></span><code>       +------+                     
       |Emb 12|                     
       +------+                     
+--+   |Emb 7 |                     
|12|   +------+                     
|7 |   |Emb 43|   +-------------+   +---------+ 
|43|   +------+   |             |   |Fully    |
|65+---+Emb 65+---&gt; Transformer +---&gt;Connected+-&gt;
|23|   +------+   | Blocks      |   |Layers   |
|4 |   |Emb 23|   +-------------+   +---------+
|1 |   +------+                     
+--+   |Emb 4 |                     
       +------+                     
       |Emb 1 |                     
       +------+                     
</code></pre></div>

<ul>
<li><code>representation'</code> (default <code>dense</code>): the possible values are <code>dense</code> and <code>sparse</code>. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings.</li>
<li><code>embedding_size</code> (default <code>256</code>): it is the maximum embedding size, the actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of different strings appearing in the training set in the column the feature is named after (plus 1 for <code>&lt;UNK&gt;</code>).</li>
<li><code>embeddings_trainable</code> (default <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code> as <code>sparse</code> one-hot encodings are not trainable.</li>
<li><code>pretrained_embeddings</code> (default <code>null</code>): by default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>num_layers</code> (default <code>1</code>): number of transformer blocks.</li>
<li><code>hidden_size</code> (default <code>256</code>): the size of the hidden representation within the transformer block. It is usually the same of the <code>embedding_size</code>, but if the two values are different, a projection layer will be added before the first transformer block.</li>
<li><code>num_heads</code> (default <code>8</code>): number of heads of the self attention in the transformer block.</li>
<li><code>transformer_fc_size</code> (default <code>256</code>): Size of the fully connected layer after self attention in the transformer block. This is usually the same as <code>hidden_size</code> and <code>embedding_size</code>.</li>
<li><code>dropout</code> (default <code>0.1</code>): dropout rate for the transformer block</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>,  <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>0</code>): This is the number of stacked fully connected layers (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>fc_activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>fc_dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>last</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the inputs features list using a Transformer encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">transformer</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">representation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embeddings_trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">pretrained_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">num_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">hidden_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">num_heads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="nt">transformer_fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">fc_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">last</span>
</code></pre></div>

<h5 id="passthrough-encoder">Passthrough Encoder<a class="headerlink" href="#passthrough-encoder" title="Permanent link">&para;</a></h5>
<p>The passthrough decoder simply transforms each input value into a float value and adds a dimension to the input tensor, creating a <code>b x s x 1</code> tensor where <code>b</code> is the batch size and <code>s</code> is the length of the sequence.
The tensor is reduced along the <code>s</code> dimension to obtain a single vector of size <code>h</code> for each element of the batch.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.
This encoder is not really useful for <code>sequence</code> or <code>text</code> features, but may be useful for <code>timeseries</code> features, as it allows for using them without any processing in later stages of the model, like in a sequence combiner for instance.</p>
<div class="codehilite"><pre><span></span><code>+--+   
|12|   
|7 |                    +-----------+
|43|   +------------+   |Aggregation|
|65+---&gt;Cast float32+---&gt;Reduce     +-&gt;
|23|   +------------+   |Operation  |
|4 |                    +-----------+
|1 |   
+--+   
</code></pre></div>

<p>These are the parameters available for the passthrough encoder</p>
<ul>
<li><code>reduce_output</code> (default <code>null</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example sequence feature entry in the input features list using a passthrough encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">passthrough</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>

<h4 id="sequence-output-features-and-decoders">Sequence Output Features and Decoders<a class="headerlink" href="#sequence-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>Sequential features can be used when sequence tagging (classifying each element of an input sequence) or sequence generation needs to be performed.
There are two decoders available for those to tasks names <code>tagger</code> and <code>generator</code>.</p>
<p>These are the available parameters of a sequence output feature</p>
<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>dependencies</code> (default <code>[]</code>): the output features this one is dependent on. For a detailed explanation refer to <a href="#output-features-dependencies">Output Features Dependencies</a>.</li>
<li><code>reduce_dependencies</code> (default <code>sum</code>): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>loss</code> (default <code>{type: softmax_cross_entropy, class_similarities_temperature: 0, class_weights: 1, confidence_penalty: 0, distortion: 1, labels_smoothing: 0, negative_samples: 0, robust_lambda: 0, sampler: null, unique: false}</code>): is a dictionary containing a loss <code>type</code>. The available losses <code>type</code> are <code>softmax_cross_entropy</code> and <code>sampled_softmax_cross_entropy</code>. For details on both losses, please refer to the <a href="#category-output-features-and-encoders">category feature output feature section</a>.</li>
</ul>
<h5 id="tagger-decoder">Tagger Decoder<a class="headerlink" href="#tagger-decoder" title="Permanent link">&para;</a></h5>
<p>In the case of <code>tagger</code> the decoder is a (potentially empty) stack of fully connected layers, followed by a projection into a tensor of size <code>b x s x c</code>, where <code>b</code> is the batch size, <code>s</code> is the length of the sequence and <code>c</code> is the number of classes, followed by a softmax_cross_entropy.
This decoder requires its input to be shaped as <code>b x s x h</code>, where <code>h</code> is an hidden dimension, which is the output of a sequence, text or timeseries input feature without reduced outputs or the output of a sequence-based combiner.
If a <code>b x h</code> input is provided instead, an error will be raised during model building.</p>
<div class="codehilite"><pre><span></span><code>Combiner
Output

+---+                 +----------+   +-------+
|emb|   +---------+   |Projection|   |Softmax|
+---+   |Fully    |   +----------+   +-------+
|...+---&gt;Connected+---&gt;...       +---&gt;...    |
+---+   |Layers   |   +----------+   +-------+
|emb|   +---------+   |Projection|   |Softmax|
+---+                 +----------+   +-------+
</code></pre></div>

<p>These are the available parameters of a tagger decoder:</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>attention</code> (default <code>false</code>): If <code>true</code>, applies a multi-head self attention layer befre prediction.</li>
<li><code>attention_embedding_size</code> (default <code>256</code>): the embedding size of the multi-head self attention layer.</li>
<li><code>attention_num_heads</code> (default <code>8</code>): number of attention heads in the multi-head self attention layer.</li>
</ul>
<p>Example sequence feature entry using a tagger decoder (with default parameters) in the output features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">decoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tagger</span>
<span class="nt">reduce_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">dependencies</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">softmax_cross_entropy</span>
    <span class="nt">confidence_penalty</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">robust_lambda</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">class_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">class_similarities</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">class_similarities_temperature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">labels_smoothing</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">negative_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">sampler</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">distortion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">unique</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">attention</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">attention_embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">attention_num_heads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8</span>
</code></pre></div>

<h5 id="generator-decoder">Generator Decoder<a class="headerlink" href="#generator-decoder" title="Permanent link">&para;</a></h5>
<p>In the case of <code>generator</code> the decoder is a (potentially empty) stack of fully connected layers, followed by an rnn that generates outputs feeding on its own previous predictions and generates a tensor of size <code>b x s' x c</code>, where <code>b</code> is the batch size, <code>s'</code> is the length of the generated sequence and <code>c</code> is the number of classes, followed by a softmax_cross_entropy.
During training teacher forcing is adopted, meaning the list of targets is provided as both inputs and outputs (shifted by 1), while at evaluation time greedy decoding (generating one token at a time and feeding it as input for the next step) is performed by beam search, using a beam of 1 by default.
By default a generator expects a <code>b x h</code> shaped input tensor, where <code>h</code> is a hidden dimension.
The <code>h</code> vectors are (after an optional stack of fully connected layers) fed into the rnn generator.
One exception is when the generator uses attention, as in that case the expected size of the input tensor is <code>b x s x h</code>, which is the output of a sequence, text or timeseries input feature without reduced outputs or the output of a sequence-based combiner.
If a <code>b x h</code> input is provided to a generator decoder using an rnn with attention instead, an error will be raised during model building.</p>
<div class="codehilite"><pre><span></span><code>                            Output     Output
                               1  +-+    ... +--+    END
                               ^    |     ^     |     ^
+--------+   +---------+       |    |     |     |     |
|Combiner|   |Fully    |   +---+--+ | +---+---+ | +---+--+
|Output  +---&gt;Connected+---+RNN   +---&gt;RNN... +---&gt;RNN   |
|        |   |Layers   |   +---^--+ | +---^---+ | +---^--+
+--------+   +---------+       |    |     |     |     |
                              GO    +-----+     +-----+
</code></pre></div>

<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
</ul>
<p>These are the available parameters of a Generator decoder:</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>cell_type</code> (default <code>rnn</code>): the type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>lstm_block</code>, <code>lstm</code>, <code>ln</code>, <code>lstm_cudnn</code>, <code>gru</code>, <code>gru_block</code>, <code>gru_cudnn</code>. For reference about the differences between the cells please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell">TensorFlow's documentation</a>. We suggest to use the <code>block</code> variants on CPU and the <code>cudnn</code> variants on GPU because of their increased speed.</li>
<li><code>state_size</code> (default <code>256</code>): the size of the state of the rnn.</li>
<li><code>embedding_size</code> (default <code>256</code>): if <code>tied_target_embeddings</code> is <code>false</code>, the input embeddings and the weights of the softmax_cross_entropy weights before the softmax_cross_entropy are not tied together and can have different sizes, this parameter describes the size of the embeddings of the inputs of the generator.</li>
<li><code>beam_width</code> (default <code>1</code>): sampling from the rnn generator is performed using beam search. By default, with a beam of one, only a greedy sequence using always the most probably next token is generated, but the beam size can be increased. This usually leads to better performance at the expense of more computation and slower generation.</li>
<li><code>attention</code> (default <code>null</code>): the recurrent generator may use an attention mechanism. The available ones are <code>bahdanau</code> and <code>luong</code> (for more information refer to <a href="https://www.tensorflow.org/api_guides/python/contrib.seq2seq#Attention">TensorFlow's documentation</a>). When <code>attention</code> is not <code>null</code> the expected size of the input tensor is <code>b x s x h</code>, which is the output of a sequence, text or timeseries input feature without reduced outputs or the output of a sequence-based combiner. If a <code>b x h</code> input is provided to a generator decoder using an rnn with attention instead, an error will be raised during model building.</li>
<li><code>tied_embeddings</code> (default <code>null</code>): if <code>null</code> the embeddings of the targets are initialized randomly, while if the values is the name of an input feature, the embeddings of that input feature will be used as embeddings of the target. The <code>vocabulary_size</code> of that input feature has to be the same of the output feature one and it has to have an embedding matrix (binary and numerical features will not have one, for instance). In this case the <code>embedding_size</code> will be the same as the <code>state_size</code>. This is useful for implementing autoencoders where the encoding and decoding part of the model share parameters.</li>
<li><code>max_sequence_length</code> (default <code>0</code>):</li>
</ul>
<p>Example sequence feature entry using a generator decoder (with default parameters) in the output features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">decoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">generator</span>
<span class="nt">reduce_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">dependencies</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">softmax_cross_entropy</span>
    <span class="nt">confidence_penalty</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">robust_lambda</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">class_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">class_similarities</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">class_similarities_temperature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">labels_smoothing</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">negative_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">sampler</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">distortion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">unique</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">cell_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="nt">state_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">beam_width</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">attention</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">tied_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">max_sequence_length</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</code></pre></div>

<h4 id="sequence-features-measures">Sequence Features Measures<a class="headerlink" href="#sequence-features-measures" title="Permanent link">&para;</a></h4>
<p>The measures that are calculated every epoch and are available for category features are <code>accuracy</code> (counts the number of datapoints where all the elements of the predicted sequence are correct over the number of all datapoints), <code>token_accuracy</code> (computes the number of elements in all the sequences that are correctly predicted over the number of all the elements in all the sequences), <code>last_accuracy</code> (accuracy considering only the last element of the sequence, it is useful for being sure special end-of-sequence tokens are generated or tagged), <code>edit_distance</code> (the levenshtein distance between the predicted and ground truth sequence), <code>perplexity</code> (the perplexity of the ground truth sequence according to the model) and the <code>loss</code> itself.
You can set either of them as <code>validation_measure</code> in the <code>training</code> section of the configuration if you set the <code>validation_field</code> to be the name of a sequence feature.</p>
<h3 id="text-features">Text Features<a class="headerlink" href="#text-features" title="Permanent link">&para;</a></h3>
<h4 id="text-features-preprocessing">Text Features Preprocessing<a class="headerlink" href="#text-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Text features are treated in the same way of sequence features, with a couple differences.
Two different tokenizations happen, one that splits at every character and one that splits on whitespace and punctuation are used, and two different keys are added to the HDF5 file, one containing the matrix of characters and one containing the matrix of words.
The same thing happens in the JSON file, which contains dictionaries for mapping characters to integers (and the inverse) and words to integers (and their inverse).
In the configuration you are able to specify which level of representation to use, if the character level or the word level.</p>
<p>The parameters available for preprocessing are:</p>
<ul>
<li><code>char_tokenizer</code> (default <code>characters</code>): defines how to map from the raw string content of the dataset column to a sequence of characters. The default value and only available option is <code>characters</code> and the behavior is to split the string at each character.</li>
<li><code>char_vocab_file</code> (default <code>null</code>):</li>
<li><code>char_sequence_length_limit</code> (default <code>1024</code>): the maximum length of the text in characters. Texts that are longer than this value will be truncated, while sequences that are shorter will be padded.</li>
<li><code>char_most_common</code> (default <code>70</code>): the maximum number of most common characters to be considered. if the data contains more than this amount, the most infrequent characters will be treated as unknown.</li>
<li><code>word_tokenizer</code> (default <code>space_punct</code>): defines how to map from the raw string content of the dataset column to a sequence of elements. For the available options refer to the <a href="#tokenizers">Tokenizers</a>section.</li>
<li><code>pretrained_model_name_or_path</code> (default <code>null</code>):</li>
<li><code>word_vocab_file</code> (default <code>null</code>):</li>
<li><code>word_sequence_length_limit</code> (default <code>256</code>): the maximum length of the text in words. Texts that are longer than this value will be truncated, while texts that are shorter will be padded.</li>
<li><code>word_most_common</code> (default <code>20000</code>): the maximum number of most common words to be considered. If the data contains more than this amount, the most infrequent words will be treated as unknown.</li>
<li><code>padding_symbol</code> (default <code>&lt;PAD&gt;</code>): the string used as a padding symbol. Is is mapped to the integer ID 0 in the vocabulary.</li>
<li><code>unknown_symbol</code> (default <code>&lt;UNK&gt;</code>): the string used as a unknown symbol. Is is mapped to the integer ID 1 in the vocabulary.</li>
<li><code>padding</code> (default <code>right</code>): the direction of the padding. <code>right</code> and <code>left</code> are available options.</li>
<li><code>lowercase</code> (default <code>false</code>): if the string has to be lowercased before being handled by the tokenizer.</li>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>""</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill-value</code>.</li>
</ul>
<p>Example of text preprocessing.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text</span>
<span class="nt">level</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">word</span>
<span class="nt">preprocessing</span><span class="p">:</span>
    <span class="nt">char_tokenizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">characters</span>
    <span class="nt">char_vocab_file</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">char_sequence_length_limit</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1024</span>
    <span class="nt">char_most_common</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">70</span>
    <span class="nt">word_tokenizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">space_punct</span>
    <span class="nt">pretrained_model_name_or_path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">word_vocab_file</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">word_sequence_length_limit</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
    <span class="nt">word_most_common</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20000</span>
    <span class="nt">padding_symbol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;PAD&gt;</span>
    <span class="nt">unknown_symbol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;UNK&gt;</span>
    <span class="nt">padding</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">right</span>
    <span class="nt">lowercase</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
    <span class="nt">missing_value_strategy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">fill_with_const</span>
    <span class="nt">fill_value</span><span class="p">:</span> <span class="s">&quot;&quot;</span>
</code></pre></div>

<h4 id="text-input-features-and-encoders">Text Input Features and Encoders<a class="headerlink" href="#text-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Text input feature parameters are</p>
<ul>
<li><code>encoder</code> (default <code>parallel_cnn</code>): encoder to use for the input text feature. The available encoders come from <a href="#sequence-input-features-and-encoders">Sequence Features</a> and these text specific encoders: <code>bert</code>, <code>gpt</code>, <code>gpt2</code>, <code>xlnet</code>, <code>xlm</code>, <code>roberta</code>, <code>distilbert</code>, <code>ctrl</code>, <code>camembert</code>, <code>albert</code>, <code>t5</code>, <code>xlmroberta</code>, <code>flaubert</code>, <code>electra</code>, <code>longformer</code> and <code>auto-transformer</code>.</li>
<li><code>level</code> (default <code>word</code>): <code>word</code> specifies using text words, <code>char</code> use individual characters.</li>
<li><code>tied_weights</code> (default <code>null</code>): name of the input feature to tie the weights of the encoder with. It needs to be the name of a feature of the same type and with the same encoder parameters.</li>
</ul>
<h5 id="bert-encoder">BERT Encoder<a class="headerlink" href="#bert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>bert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1810.04805">BERT</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>bert-base-uncased</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/bert.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>cls_pooled</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>cls_pool</code>, <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="gpt-encoder">GPT Encoder<a class="headerlink" href="#gpt-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>gpt</code> encoder loads a pretrained <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>openai-gpt</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/gpt.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="gpt-2-encoder">GPT-2 Encoder<a class="headerlink" href="#gpt-2-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>gpt2</code> encoder loads a pretrained <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>gpt2</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/gpt2.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="xlnet-encoder">XLNet Encoder<a class="headerlink" href="#xlnet-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>xlnet</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1906.08237">XLNet</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>xlnet-base-cased</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/xlnet.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="xlm-encoder">XLM Encoder<a class="headerlink" href="#xlm-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>xlm</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1901.07291">XLM</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>xlm-mlm-en-2048</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/xlm.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="roberta-encoder">RoBERTa Encoder<a class="headerlink" href="#roberta-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>roberta</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>roberta-base</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/roberta.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>cls_pooled</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>cls_pool</code>, <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="distilbert-encoder">DistilBERT Encoder<a class="headerlink" href="#distilbert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>distilbert</code> encoder loads a pretrained <a href="https://medium.com/huggingface/distilbert-8cf3380435b5">DistilBERT</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>istilbert-base-uncased</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/distilbert.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="ctrl-encoder">CTRL Encoder<a class="headerlink" href="#ctrl-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>ctrl</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1909.05858">CTRL</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>ctrl</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/ctrl.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="camembert-encoder">CamemBERT Encoder<a class="headerlink" href="#camembert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>camembert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1911.03894">CamemBERT</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>jplu/tf-camembert-base</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/camembert.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>cls_pooled</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>cls_pool</code>, <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="albert-encoder">ALBERT Encoder<a class="headerlink" href="#albert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>albert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1909.11942">ALBERT</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>albert-base-v2</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/albert.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>cls_pooled</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>cls_pool</code>, <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="t5-encoder">T5 Encoder<a class="headerlink" href="#t5-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>t5</code> encoder loads a pretrained <a href="https://arxiv.org/pdf/1910.10683.pdf">T5</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>t5-small</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/t5.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="xlm-roberta-encoder">XLM-RoBERTa Encoder<a class="headerlink" href="#xlm-roberta-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>xlmroberta</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1911.02116">XLM-RoBERTa</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>jplu/tf-xlm-reoberta-base</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/xlmroberta.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>cls_pooled</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>cls_pool</code>, <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="flaubert-encoder">FlauBERT Encoder<a class="headerlink" href="#flaubert-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>flaubert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1912.05372">FlauBERT</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>jplu/tf-flaubert-base-uncased</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/flaubert.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="electra-encoder">ELECTRA Encoder<a class="headerlink" href="#electra-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>electra</code> encoder loads a pretrained <a href="https://openreview.net/pdf?id=r1xMH1BtvB">ELECTRA</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>google/electra-small-discriminator</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/electra.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="longformer-encoder">Longformer Encoder<a class="headerlink" href="#longformer-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>longformer</code> encoder loads a pretrained <a href="https://arxiv.org/pdf/2004.05150.pdf">Longformer</a> model using the Hugging Face transformers package.</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default <code>allenai/longformer-base-4096</code>): it can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/transformers/model_doc/longformer.html">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>cls_pooled</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>cls_pool</code>, <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="auto-transformer-encoder">Auto-Transformer Encoder<a class="headerlink" href="#auto-transformer-encoder" title="Permanent link">&para;</a></h5>
<p>The <code>auto_transformer</code> encoder loads a pretrained model using the Hugging Face transformers package.
It's the best option for customly trained models that don't fit into the other pretrained transformers encoders.</p>
<ul>
<li><code>pretrained_model_name_or_path</code>: it can be either the name of a model or a path where it was downloaded. For details on the available models to the <a href="https://huggingface.co/transformers/model_doc/auto.html#tfautomodel">Hugging Face documentation</a>.</li>
<li><code>reduced_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen. </li>
</ul>
<h5 id="example-usage">Example usage<a class="headerlink" href="#example-usage" title="Permanent link">&para;</a></h5>
<p>Example text input feature encoder usage:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text</span>
<span class="nt">level</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">word</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bert</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">pretrained_model_name_or_path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bert-base-uncased</span>
<span class="nt">reduced_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cls_pooled</span>
<span class="nt">trainable</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
</code></pre></div>

<h4 id="text-output-features-and-decoders">Text Output Features and Decoders<a class="headerlink" href="#text-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>The decoders are the same used for the <a href="#sequence-output-features-and-decoders">Sequence Features</a>.
The only difference is that you can specify an additional <code>level</code> parameter with possible values <code>word</code> or <code>char</code> to force to use the text words or characters as inputs (by default the encoder will use <code>word</code>).</p>
<p>Example text input feature using default values:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text</span>
<span class="nt">level</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">word</span>
<span class="nt">decoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">generator</span>
<span class="nt">reduce_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">dependencies</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">softmax_cross_entropy</span>
    <span class="nt">confidence_penalty</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">robust_lambda</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">class_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">class_similarities</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">class_similarities_temperature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">labels_smoothing</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">negative_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">sampler</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
    <span class="nt">distortion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">unique</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">cell_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="nt">state_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">beam_width</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">attention</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">tied_embeddings</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">max_sequence_length</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</code></pre></div>

<h4 id="text-features-measures">Text Features Measures<a class="headerlink" href="#text-features-measures" title="Permanent link">&para;</a></h4>
<p>The measures are the same used for the <a href="#sequence-features-measures">Sequence Features</a>.</p>
<h3 id="time-series-features">Time Series Features<a class="headerlink" href="#time-series-features" title="Permanent link">&para;</a></h3>
<h4 id="time-series-features-preprocessing">Time Series Features Preprocessing<a class="headerlink" href="#time-series-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Timeseries features are treated in the same way of sequence features, with the only difference being that the matrix in the HDF5 file does not have integer values, but float values.
Moreover, there is no need for any mapping in the JSON file.</p>
<h4 id="time-series-input-features-and-encoders">Time Series Input Features and Encoders<a class="headerlink" href="#time-series-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>The encoders are the same used for the <a href="#sequence-input-features-and-encoders">Sequence Features</a>.
The only difference is that time series features don't have an embedding layer at the beginning, so the <code>b x s</code> placeholders (where <code>b</code> is the batch size and <code>s</code> is the sequence length) are directly mapped to a <code>b x s x 1</code> tensor and then passed to the different sequential encoders.</p>
<h4 id="time-series-output-features-and-decoders">Time Series Output Features and Decoders<a class="headerlink" href="#time-series-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>There are no time series decoders at the moment (WIP), so time series cannot be used as output features.</p>
<h4 id="time-series-features-measures">Time Series Features Measures<a class="headerlink" href="#time-series-features-measures" title="Permanent link">&para;</a></h4>
<p>As no time series decoders are available at the moment, there are also no time series measures.</p>
<h3 id="audio-features">Audio Features<a class="headerlink" href="#audio-features" title="Permanent link">&para;</a></h3>
<h4 id="audio-features-preprocessing">Audio Features Preprocessing<a class="headerlink" href="#audio-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Ludwig supports reads in audio files using Python's library <a href="https://pypi.org/project/SoundFile/">SoundFile</a> therefore supporting WAV, FLAC, OGG and MAT files.</p>
<ul>
<li><code>audio_file_length_limit_in_s</code>: (default <code>7.5</code>): float value that defines the maximum limit of the audio file in seconds. All files longer than this limit are cut off. All files shorter than this limit are padded with <code>padding_value</code></li>
<li><code>missing_value_strategy</code> (default: <code>backfill</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>in_memory</code> (default <code>true</code>): defines whether image dataset will reside in memory during the training process or will be dynamically fetched from disk (useful for large datasets). In the latter case a training batch of input images will be fetched from disk each training iteration. At the moment only <code>in_memory</code> = true is supported.</li>
<li><code>padding_value</code>: (default 0): float value that is used for padding. </li>
<li><code>norm</code>: (default <code>null</code>) the normalization method that can be used for the input data. Supported methods: <code>null</code> (data is not normalized), <code>per_file</code> (z-norm is applied on a “per file” level)</li>
<li><code>audio_feature</code>: (default <code>{ type: raw }</code>) dictionary that takes as input the audio feature <code>type</code> as well as additional parameters if <code>type != raw</code>. The following parameters can/should be defined in the dictionary:<ul>
<li><code>type</code> (default <code>raw</code>): defines the type of audio features to be used. Supported types at the moment are <code>raw</code>, <code>stft</code>, <code>stft_phase</code>, <code>group_delay</code>. For more detail, check <a href="#audio-input-features-and-encoders">Audio Input Features and Encoders</a>.</li>
<li><code>window_length_in_s</code>: defines the window length used for the short time Fourier transformation (only needed if <code>type != raw</code>).</li>
<li><code>window_shift_in_s</code>: defines the window shift used for the short time Fourier transformation (also called hop_length) (only needed if <code>type != raw</code>).</li>
<li><code>num_fft_points</code>: (default <code>window_length_in_s * sample_rate</code> of audio file) defines the number of fft points used for the short time Fourier transformation. If <code>num_fft_points &gt; window_length_in_s * sample_rate</code>, then the signal is zero-padded at the end. <code>num_fft_points</code> has to be <code>&gt;= window_length_in_s * sample_rate</code> (only needed if <code>type != raw</code>).</li>
<li><code>window_type</code>: (default <code>hamming</code>): defines the type window the signal is weighted before the short time Fourier transformation. All windows provided by <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.get_window.html">scipy’s window function</a> can be used (only needed if <code>type != raw</code>).</li>
<li><code>num_filter_bands</code>: defines the number of filters used in the filterbank (only needed if <code>type == fbank</code>).</li>
</ul>
</li>
</ul>
<p>Example of a preprocessing specification (assuming the audio files have a sample rate of 16000):</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">audio_path</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">audio</span>
<span class="nt">preprocessing</span><span class="p">:</span>
  <span class="nt">audio_file_length_limit_in_s</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">7.5</span>
  <span class="nt">audio_feature</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">stft</span>
    <span class="nt">window_length_in_s</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.04</span>
    <span class="nt">window_shift_in_s</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.02</span>
    <span class="nt">num_fft_points</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">800</span>
    <span class="nt">window_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">boxcar</span>
</code></pre></div>

<h4 id="audio-input-features-and-encoders">Audio Input Features and Encoders<a class="headerlink" href="#audio-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Audio files are transformed into one of the following types according to <code>type</code> in <code>audio_feature</code> in <code>preprocessing</code>.</p>
<ul>
<li><code>raw</code>: audio file is transformed into a float valued tensor of size <code>N x L x W</code> (where <code>N</code> is the size of the dataset and <code>L</code> corresponds to <code>audio_file_length_limit_in_s * sample_rate</code> and <code>W = 1</code>).</li>
<li><code>stft</code>: audio is transformed to the <code>stft</code> magnitude. Audio file is transformed into a float valued tensor of size <code>N x L x W</code> (where <code>N</code> is the size of the dataset, <code>L</code> corresponds to <code>ceil(audio_file_length_limit_in_s * sample_rate - window_length_in_s * sample_rate + 1/ window_shift_in_s * sample_rate) + 1</code> and <code>W</code> corresponds to <code>num_fft_points / 2</code>).</li>
<li><code>fbank</code>: audio file is transformed to FBANK features (also called log Mel-filter bank values). FBANK features are implemented according to their definition in the <a href="http://www.inf.u-szeged.hu/~tothl/speech/htkbook.pdf">HTK Book</a>: Raw Signal -&gt; Preemphasis -&gt; DC mean removal -&gt; <code>stft</code> magnitude -&gt; Power spectrum: <code>stft^2</code> -&gt; mel-filter bank values: triangular filters equally spaced on a Mel-scale are applied -&gt; log-compression: <code>log()</code>. Overall the audio file is transformed into a float valued tensor of size <code>N x L x W</code> with <code>N,L</code> being equal to the ones in <code>stft</code> and <code>W</code> being equal to <code>num_filter_bands</code>.</li>
<li><code>stft_phase</code>: the phase information for each stft bin is appended to the <code>stft</code> magnitude so that the audio file is transformed into a float valued tensor of size <code>N x L x 2W</code> with <code>N,L,W</code> being equal to the ones in <code>stft</code>.</li>
<li><code>group_delay</code>: audio is transformed to group delay features according to Equation (23) in this <a href="https://www.ias.ac.in/article/fullyext/sadh/036/05/0745-0782">paper</a>. Group_delay features has the same tensor size as <code>stft</code>.</li>
</ul>
<p>The encoders are the same used for the <a href="#sequence-input-features-and-encoders">Sequence Features</a>.
The only difference is that time series features don't have an embedding layer at the beginning, so the <code>b x s</code> placeholders (where <code>b</code> is the batch size and <code>s</code> is the sequence length) are directly mapped to a <code>b x s x w</code> (where <code>w</code> is <code>W</code> as described above) tensor and then passed to the different sequential encoders.</p>
<h4 id="audio-output-features-and-decoders">Audio Output Features and Decoders<a class="headerlink" href="#audio-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>There are no audio decoders at the moment (WIP), so audio cannot be used as output features.</p>
<h4 id="audio-features-measures">Audio Features Measures<a class="headerlink" href="#audio-features-measures" title="Permanent link">&para;</a></h4>
<p>As no audio decoders are available at the moment, there are also no audio measures.</p>
<h3 id="image-features">Image Features<a class="headerlink" href="#image-features" title="Permanent link">&para;</a></h3>
<h4 id="image-features-preprocessing">Image Features Preprocessing<a class="headerlink" href="#image-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Ludwig supports both grayscale and color images.
The number of channels is inferred, but make sure all your images have the same number of channels.
During preprocessing, raw image files are transformed into numpy ndarrays and saved in the hdf5 format.
All images in the dataset should have the same size.
If they have different sizes, a <code>resize_method</code>, together with a target <code>width</code> and <code>height</code>, must be specified in the feature preprocessing parameters.</p>
<ul>
<li><code>missing_value_strategy</code> (default: <code>backfill</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>in_memory</code> (default <code>true</code>): defines whether image dataset will reside in memory during the training process or will be dynamically fetched from disk (useful for large datasets). In the latter case a training batch of input images will be fetched from disk each training iteration.</li>
<li><code>num_processes</code> (default 1): specifies the number of processes to run for preprocessing images.</li>
<li><code>resize_method</code> (default <code>crop_or_pad</code>): available options: <code>crop_or_pad</code> - crops images larger than the specified <code>width</code> and <code>height</code> to the desired size or pads smalled images using edge padding; <code>interpolate</code> - uses interpolation to resize images to the specified <code>width</code> and <code>height</code>.</li>
<li><code>height</code> (default <code>null</code>): image height in pixels, must be set if resizing is required</li>
<li><code>width</code> (default <code>null</code>): image width in pixels, must be set if resizing is required</li>
<li><code>num_channels</code> (default <code>null</code>): number of channels in the images. By default, if the value is <code>null</code>, the number of channels of the first image of the dataset will be used and if there is an image in the dataset with a different number of channels, an error will be reported. If the value specified is not <code>null</code>, images in the dataset will be adapted to the specified size. If the value is <code>1</code>, all images with more then one channel will be greyscaled and reduced to one channel (trasparecy will be lost). If the value is <code>3</code> all images with 1 channel will be repeated 3 times to obtain 3 channels, while images with 4 channels will lose the transparecy channel. If the value is <code>4</code>, all the images with less than 4 channels will have the remaining channels filled with zeros.</li>
<li><code>scaling</code> (default <code>pixel_normalization</code>): what scaling to perform on images. By default <code>pixel_normalization</code> is performed, which consists in dividing each pixel values by 255, but <code>pixel_standardization</code> is also available, whic uses <a href="https://www.tensorflow.org/api_docs/python/tf/image/per_image_standardization">TensorFlow's per image standardization</a>.</li>
</ul>
<p>Depending on the application, it is preferrable not to exceed a size of <code>256 x 256</code>, as bigger sizes will, in most cases, not provide much advantage in terms of performance, while they will considerably slow down training and inference and also make both forward and backward passes consume considerably more memory, leading to memory overflows on machines with limited amounts of RAM or on GPUs with limited amounts of VRAM.</p>
<p>Example of a preprocessing specification:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">image_feature_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">image</span>
<span class="nt">preprocessing</span><span class="p">:</span>
  <span class="nt">height</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">128</span>
  <span class="nt">width</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">128</span>
  <span class="nt">resize_method</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">interpolate</span>
  <span class="nt">scaling</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pixel_normalization</span>
</code></pre></div>

<h4 id="image-input-features-and-encoders">Image Input Features and Encoders<a class="headerlink" href="#image-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Input image features are transformed into a float valued tensors of size <code>N x H x W x C</code> (where <code>N</code> is the size of the dataset and <code>H x W</code> is a specific resizing of the image that can be set, and <code>C</code> is the number of channels) and added to HDF5 with a key that reflects the name of column in the dataset.
The column name is added to the JSON file, with an associated dictionary containing preprocessing information about the sizes of the resizing.</p>
<p>Currently there are two encoders supported for images: Convolutional Stack Encoder and ResNet encoder which can be set by setting <code>encoder</code> parameter to <code>stacked_cnn</code> or <code>resnet</code> in the input feature dictionary in the configuration (<code>stacked_cnn</code> is the default one).</p>
<h5 id="convolutional-stack-encoder">Convolutional Stack Encoder<a class="headerlink" href="#convolutional-stack-encoder" title="Permanent link">&para;</a></h5>
<p>Convolutional Stack Encoder takes the following optional parameters:</p>
<ul>
<li><code>conv_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the convolutional layers. The length of the list determines the number of stacked convolutional layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>filter_size</code>, <code>num_filters</code>, <code>pool_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value <code>[{filter_size: 7, pool_size: 3, regularize: false}, {filter_size: 7, pool_size: 3, regularize: false}, {filter_size: 3, pool_size: null, regularize: false}, {filter_size: 3, pool_size: null, regularize: false}, {filter_size: 3, pool_size: null, regularize: true}, {filter_size: 3, pool_size: 3, regularize: true}]</code>.</li>
<li><code>num_conv_layers</code> (default <code>null</code>): if <code>conv_layers</code> is <code>null</code>, this is the number of stacked convolutional layers.</li>
<li><code>filter_size</code> (default <code>3</code>): if a <code>filter_size</code> is not already specified in <code>conv_layers</code> this is the default <code>filter_size</code> that will be used for each layer. It indicates how wide is the 1d convolutional filter.</li>
<li><code>num_filters</code> (default <code>256</code>): if a <code>num_filters</code> is not already specified in <code>conv_layers</code> this is the default <code>num_filters</code> that will be used for each layer. It indicates the number of filters, and by consequence the output channels of the 2d convolution.</li>
<li><code>strides</code> (default <code>(1, 1)</code>): specifying the strides of the convolution along the height and width</li>
<li><code>padding</code> (default <code>valid</code>): one of <code>valid</code> or <code>same</code>.</li>
<li><code>dilation_rate</code> (default <code>(1, 1)</code>): specifying the dilation rate to use for dilated convolution.</li>
<li><code>conv_use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>conv_weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>conv_bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>conv_bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>conv_activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>conv_norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>conv_norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>conv_activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>conv_dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>pool_function</code> (default <code>max</code>):  pooling function: <code>max</code> will select the maximum value.  Any of these--<code>average</code>, <code>avg</code> or <code>mean</code>--will compute the mean value.</li>
<li><code>pool_size</code> (default <code>(2, 2)</code>): if a <code>pool_size</code> is not already specified in <code>conv_layers</code> this is the default <code>pool_size</code> that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><code>pool_strides</code> (default <code>null</code>): factor to scale down</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>1</code>): This is the number of stacked fully connected layers.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>fc_use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>fc_weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>fc_bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>fc_weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>fc_bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>fc_activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>fc_norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>fc_norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>fc_activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>fc_dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<p>Example image feature entry using a convolutional stack encoder (with default parameters) in the input features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">image_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">image</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">stacked_cnn</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">conv_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_conv_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">filter_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="nt">num_filters</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">strides</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">(1, 1)</span>
<span class="nt">padding</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">valid</span>
<span class="nt">dilation_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">(1, 1)</span>
<span class="nt">conv_use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">conv_weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">conv_bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">conv_bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">conv_activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">conv_norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">conv_norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">conv_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">conv_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">pool_function</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="nt">pool_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">(2, 2)</span>
<span class="nt">pool_strides</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">fc_use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">fc_weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">fc_bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">fc_weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">fc_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">fc_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">preprocessing</span><span class="p">:</span>  <span class="c1"># example pre-processing</span>
    <span class="nt">height</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">28</span>
    <span class="nt">width</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">28</span>
    <span class="nt">num_channels</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
</code></pre></div>

<h5 id="resnet-encoder">ResNet Encoder<a class="headerlink" href="#resnet-encoder" title="Permanent link">&para;</a></h5>
<p><a href="https://arxiv.org/abs/1603.05027">ResNet</a> Encoder takes the following optional parameters:</p>
<ul>
<li><code>resnet_size</code> (default <code>50</code>): A single integer for the size of the ResNet model. If has to be one of the following values: <code>8</code>, <code>14</code>, <code>18</code>, <code>34</code>, <code>50</code>, <code>101</code>, <code>152</code>, <code>200</code>.</li>
<li><code>num_filters</code> (default <code>16</code>): It indicates the number of filters, and by consequence the output channels of the 2d convolution.</li>
<li><code>kernel_size</code> (default <code>3</code>): The kernel size to use for convolution.</li>
<li><code>conv_stride</code> (default <code>1</code>): Stride size for the initial convolutional layer.</li>
<li><code>first_pool_size</code> (default <code>null</code>): Pool size to be used for the first pooling layer. If none, the first pooling layer is skipped.</li>
<li><code>batch_norm_momentum</code> (default <code>0.9</code>): Momentum of the batch norm running statistics. The suggested parameter in <a href="https://github.com/tensorflow/models/blob/master/official/resnet/resnet_model.py#L36">TensorFlow's implementation</a> is <code>0.997</code>, but that leads to a big discrepancy between the normalization at training time and test time, so the default value is a more conservative <code>0.9</code>.</li>
<li><code>batch_norm_epsilon</code> (default <code>0.001</code>): Epsilon of the batch norm. The suggested parameter in <a href="https://github.com/tensorflow/models/blob/master/official/resnet/resnet_model.py#L37">TensorFlow's implementation</a> is <code>1e-5</code>, but that leads to a big discrepancy between the normalization at training time and test time, so the default value is a more conservative <code>0.001</code>.</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>1</code>): This is the number of stacked fully connected layers.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<p>Example image feature entry using a ResNet encoder (with default parameters) in the input features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">image_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">image</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">resnet</span>
<span class="nt">tied_weights</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">resnet_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
<span class="nt">num_filters</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="nt">kernel_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="nt">conv_stride</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">first_pool_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">batch_norm_momentum</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.9</span>
<span class="nt">batch_norm_epsilon</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.001</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">preprocessing</span><span class="p">:</span>
    <span class="nt">height</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">224</span>
    <span class="nt">width</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">224</span>
    <span class="nt">num_channels</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
</code></pre></div>

<h4 id="image-output-features-and-decoders">Image Output Features and Decoders<a class="headerlink" href="#image-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>There are no image decoders at the moment (WIP), so image cannot be used as output features.</p>
<h4 id="image-features-measures">Image Features Measures<a class="headerlink" href="#image-features-measures" title="Permanent link">&para;</a></h4>
<p>As no image decoders are available at the moment, there are also no image measures.</p>
<h3 id="date-features">Date Features<a class="headerlink" href="#date-features" title="Permanent link">&para;</a></h3>
<h4 id="date-features-preprocessing">Date Features Preprocessing<a class="headerlink" href="#date-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Ludwig will try to infer the date format automatically, but a specific fomrat can be provided. 
The format is the same one described in the <a href="https://docs.python.org/2/library/time.html#time.strptime">datetime package documentation</a>.</p>
<ul>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>""</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill_value</code>. This can be a datetime string, if left empty the current datetime will be used.</li>
<li><code>datetime_format</code> (default <code>null</code>): this parameter can be either <code>null</code>, which implies the datetime format is inferred automaticall, or a datetime format string.</li>
</ul>
<p>Example of a preprocessing specification:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">date_feature_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">date</span>
<span class="nt">preprocessing</span><span class="p">:</span>
  <span class="nt">missing_value_strategy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">fill_with_const</span>
  <span class="nt">fill_value</span><span class="p">:</span> <span class="s">&#39;&#39;</span>
  <span class="nt">datetime_format</span><span class="p">:</span> <span class="s">&quot;%d</span><span class="nv"> </span><span class="s">%b</span><span class="nv"> </span><span class="s">%Y&quot;</span>
</code></pre></div>

<h4 id="date-input-features-and-encoders">Date Input Features and Encoders<a class="headerlink" href="#date-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Input date features are transformed into a int valued tensors of size <code>N x 8</code> (where <code>N</code> is the size of the dataset and the 8 dimensions contain year, month, day, weekday, yearday, hour, minute and second) and added to HDF5 with a key that reflects the name of column in the dataset.</p>
<p>Currently there are two encoders supported for dates: Embed Encoder and Wave encoder which can be set by setting <code>encoder</code> parameter to <code>embed</code> or <code>wave</code> in the input feature dictionary in the configuration (<code>embed</code> is the default one).</p>
<h5 id="embed-encoder_1">Embed Encoder<a class="headerlink" href="#embed-encoder_1" title="Permanent link">&para;</a></h5>
<p>This encoder passes the year through a fully connected layer of one neuron and embeds all other elements for the date, concatenates them and passes the concatenated representation through fully connected layers.
It takes the following optional parameters:</p>
<ul>
<li><code>embedding_size</code> (default <code>10</code>): it is the maximum embedding size adopted..</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>dropout</code> (default <code>false</code>): determines if there should be a dropout layer before returning the encoder output.</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>0</code>): This is the number of stacked fully connected layers.</li>
<li><code>fc_size</code> (default <code>10</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<p>Example date feature entry in the input features list using an embed encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">date_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">date</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">embed</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</code></pre></div>

<h5 id="wave-encoder">Wave Encoder<a class="headerlink" href="#wave-encoder" title="Permanent link">&para;</a></h5>
<p>This encoder passes the year through a fully connected layer of one neuron and represents all other elements for the date by taking the sine of their value with a different period (12 for months, 31 for days, etc.), concatenates them and passes the concatenated representation through fully connected layers.
It takes the following optional parameters:</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_fc_layers</code> (default <code>0</code>): This is the number of stacked fully connected layers.</li>
<li><code>fc_size</code> (default <code>10</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<p>Example date feature entry in the input features list using a wave encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">date_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">date</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">wave</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</code></pre></div>

<h4 id="date-output-features-and-decoders">Date Output Features and Decoders<a class="headerlink" href="#date-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>There are no date decoders at the moment (WIP), so date cannot be used as output features.</p>
<h4 id="date-features-measures">Date Features Measures<a class="headerlink" href="#date-features-measures" title="Permanent link">&para;</a></h4>
<p>As no date decoders are available at the moment, there are also no date measures.</p>
<h3 id="h3-features">H3 Features<a class="headerlink" href="#h3-features" title="Permanent link">&para;</a></h3>
<p>H3 is a indexing system for representing geospatial data.
For more details about it refer to: https://eng.uber.com/h3/ .</p>
<h4 id="h3-features-preprocessing">H3 Features Preprocessing<a class="headerlink" href="#h3-features-preprocessing" title="Permanent link">&para;</a></h4>
<p>Ludwig will parse the H3 64bit encoded format automatically. 
The parameters for preprocessing are:</p>
<ul>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value in a binary column. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default <code>576495936675512319</code>): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill_value</code>. This is a 64bit integer comaptible with the H3 bit layout. The default value encodes mode 1, edge 0, resolution 0, base_cell 0.</li>
</ul>
<p>Example of a preprocessing specification:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">h3_feature_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">h3</span>
<span class="nt">preprocessing</span><span class="p">:</span>
  <span class="nt">missing_value_strategy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">fill_with_const</span>
  <span class="nt">fill_value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">576495936675512319</span>
</code></pre></div>

<h4 id="h3-input-features-and-encoders">H3 Input Features and Encoders<a class="headerlink" href="#h3-input-features-and-encoders" title="Permanent link">&para;</a></h4>
<p>Input date features are transformed into a int valued tensors of size <code>N x 8</code> (where <code>N</code> is the size of the dataset and the 8 dimensions contain year, month, day, weekday, yearday, hour, minute and second) and added to HDF5 with a key that reflects the name of column in the dataset.</p>
<p>Currently there are two encoders supported for dates: Embed Encoder and Wave encoder which can be set by setting <code>encoder</code> parameter to <code>embed</code> or <code>wave</code> in the input feature dictionary in the configuration (<code>embed</code> is the default one).</p>
<h5 id="embed-encoder_2">Embed Encoder<a class="headerlink" href="#embed-encoder_2" title="Permanent link">&para;</a></h5>
<p>This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and childern cells) with embeddings.
Chidren cells with value <code>0</code> will be masked out.
After the embedding, all embeddings are summed and optionally passed through a stack of fully connected layers.
It takes the following optional parameters:</p>
<ul>
<li><code>embedding_size</code> (default <code>10</code>): it is the maximum embedding size adopted..</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead.</li>
<li><code>num_fc_layers</code> (default <code>0</code>): This is the number of stacked fully connected layers.</li>
<li><code>fc_size</code> (default <code>10</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<p>Example date feature entry in the input features list using an embed encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">h3_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">h3</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">embed</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</code></pre></div>

<h5 id="weighted-sum-embed-encoder">Weighted Sum Embed Encoder<a class="headerlink" href="#weighted-sum-embed-encoder" title="Permanent link">&para;</a></h5>
<p>This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and childern cells) with embeddings.
Chidren cells with value <code>0</code> will be masked out.
After the embedding, all embeddings are summed with a weighted sum (with learned weights) and optionally passed through a stack of fully connected layers.
It takes the following optional parameters:</p>
<ul>
<li><code>embedding_size</code> (default <code>10</code>): it is the maximum embedding size adopted..</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>should_softmax</code> (default <code>false</code>): determines if the weights of the weighted sum should be passed though a softmax layer before being used.</li>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead.</li>
<li><code>num_fc_layers</code> (default <code>0</code>): This is the number of stacked fully connected layers.</li>
<li><code>fc_size</code> (default <code>10</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
<li><code>reduce_output</code> (default <code>sum</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example date feature entry in the input features list using an embed encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">h3_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">h3</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">weighted_sum</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">should_softmax</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
</code></pre></div>

<h5 id="rnn-encoder_1">RNN Encoder<a class="headerlink" href="#rnn-encoder_1" title="Permanent link">&para;</a></h5>
<p>This encoder encodes each components of the H3 representation (mode, edge, resolution, base cell and childern cells) with embeddings.
Chidren cells with value <code>0</code> will be masked out.
After the embedding, all embeddings are passed through an RNN encoder.
The intuition behind this is that, starting from the base cell, the sequence of children cells can be seen as a sequence encoding the path in the tree of all H3 hexes, thus the encoding with  recurrent model.
It takes the following optional parameters:</p>
<ul>
<li><code>embedding_size</code> (default <code>10</code>): it is the maximum embedding size adopted..</li>
<li><code>embeddings_on_cpu</code> (default <code>false</code>): by default embeddings matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be really big and this parameter forces the placement of the embedding matrix in regular memory and the CPU is used to resolve them, slightly slowing down the process as a result of data transfer between CPU and GPU memory.</li>
<li><code>num_layers</code> (default <code>1</code>): the number of stacked recurrent layers.</li>
<li><code>state_size</code> (default <code>256</code>): the size of the state of the rnn.</li>
<li><code>cell_type</code> (default <code>rnn</code>): the type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>lstm_block</code>, <code>lstm</code>, <code>ln</code>, <code>lstm_cudnn</code>, <code>gru</code>, <code>gru_block</code>, <code>gru_cudnn</code>. For reference about the differences between the cells please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell">TensorFlow's documentation</a>. We suggest to use the <code>block</code> variants on CPU and the <code>cudnn</code> variants on GPU because of their increased speed.</li>
<li><code>bidirectional</code> (default <code>false</code>): if <code>true</code> two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated.</li>
<li><code>activation</code> (default <code>'tanh'</code>): activation function to use</li>
<li><code>recurrent_activation</code> (default <code>'sigmoid'</code>): activation function to use in the recurrent step</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>unit_forget_bias</code> (default <code>true</code>): If <code>true</code>, add 1 to the bias of the forget gate at initialization</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>recurrent_initializer</code> (default <code>'orthogonal'</code>): initializer for recurrent matrix weights</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>recurrent_regularizer</code> (default <code>null</code>): regularizer function applied to recurrent matrix weights</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>dropout</code> (default <code>0.0</code>): dropout rate</li>
<li><code>recurrent_dropout</code> (default <code>0.0</code>): dropout rate for recurrent state</li>
<li><code>initializer</code> (default <code>null</code>): the initializer to use. If <code>null</code>, the default initialized of each variable is used (<code>glorot_uniform</code> in most cases). Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>regularize</code> (default <code>true</code>): if <code>true</code> the embedding weights are added to the set of weights that get regularized by a regularization loss (if the <code>regularization_lambda</code> in <code>training</code> is greater than 0).</li>
<li><code>reduce_output</code> (default <code>last</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
</ul>
<p>Example date feature entry in the input features list using an embed encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">h3_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">h3</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">embeddings_on_cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">num_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">cell_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="nt">state_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">bidirectional</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tanh</span>
<span class="nt">recurrent_activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sigmoid</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">unit_forget_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">recurrent_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">orthogonal</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">recurrent_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">recurrent_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">regularize</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">last</span>
</code></pre></div>

<h4 id="h3-output-features-and-decoders">H3 Output Features and Decoders<a class="headerlink" href="#h3-output-features-and-decoders" title="Permanent link">&para;</a></h4>
<p>There are no date decoders at the moment (WIP), so H3 cannot be used as output features.</p>
<h4 id="h3-features-measures">H3 Features Measures<a class="headerlink" href="#h3-features-measures" title="Permanent link">&para;</a></h4>
<p>As no H3 decoders are available at the moment, there are also no date measures.</p>
<h3 id="vector-features">Vector Features<a class="headerlink" href="#vector-features" title="Permanent link">&para;</a></h3>
<p>Vector features allow to provide an ordered set of numerical values all at once.
This is useful for providing pre-trained representations or activations obtained from other models or for providing multivariate inputs and outputs.
An interesting use of vector features is the possibility to provide a probability distribution as output for a multiclass classification problem instead of just the correct class like it is possible to do with category features.
This is useful for distillation and noise-aware losses.</p>
<h4 id="vector-feature-preprocessing">Vector Feature Preprocessing<a class="headerlink" href="#vector-feature-preprocessing" title="Permanent link">&para;</a></h4>
<p>The data is expected as whitespace separated numerical values. Example: "1.0 0.0 1.04 10.49".  All vectors are expected to be of the same size.</p>
<p>Preprocessing parameters:</p>
<ul>
<li><code>vector_size</code> (default <code>null</code>): size of the vector. If not provided, it will be inferred from the data.</li>
<li><code>missing_value_strategy</code> (default <code>fill_with_const</code>): what strategy to follow when there's a missing value. The value should be one of <code>fill_with_const</code> (replaces the missing value with a specific value specified with the <code>fill_value</code> parameter), <code>fill_with_mode</code> (replaces the missing values with the most frequent value in the column), <code>fill_with_mean</code> (replaces the missing values with the mean of the values in the column), <code>backfill</code> (replaces the missing values with the next valid value).</li>
<li><code>fill_value</code> (default ""): the value to replace the missing values with in case the <code>missing_value_strategy</code> is <code>fill_value</code>. </li>
</ul>
<h4 id="vector-feature-encoders">Vector Feature Encoders<a class="headerlink" href="#vector-feature-encoders" title="Permanent link">&para;</a></h4>
<p>The vector feature supports two encoders: <code>dense</code> and <code>passthrough</code>.  Only the <code>dense</code> encoder has additional parameters, which is shown next.</p>
<h5 id="dense-encoder_1">Dense Encoder<a class="headerlink" href="#dense-encoder_1" title="Permanent link">&para;</a></h5>
<p>For vector features, you can use a dense encoder (stack of fully connected layers).
It takes the following parameters:</p>
<ul>
<li><code>layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both <code>fc_layers</code> and <code>num_fc_layers</code> are <code>null</code>, a default list will be assigned to <code>fc_layers</code> with the value <code>[{fc_size: 512}, {fc_size: 256}]</code> (only applies if <code>reduce_output</code> is not <code>null</code>).</li>
<li><code>num_layers</code> (default <code>0</code>): This is the number of stacked fully connected layers.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<p>Example vector feature entry in the input features list using an dense encoder:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vector_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vector</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="nt">layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</code></pre></div>

<h4 id="vector-feature-decoders">Vector Feature Decoders<a class="headerlink" href="#vector-feature-decoders" title="Permanent link">&para;</a></h4>
<p>Vector features can be used when multi-class classification needs to be performed with a noise-aware loss or when the task is multivariate regression.
There is only one decoder available for set features and it is a (potentially empty) stack of fully connected layers, followed by a projection into a vector of size (optionally followed by a softmax in the case of multi-class classification).</p>
<div class="codehilite"><pre><span></span><code>+--------------+   +---------+   +-----------+
|Combiner      |   |Fully    |   |Projection |   +------------------+
|Output        +---&gt;Connected+---&gt;into Output+---&gt;Softmax (optional)|
|Representation|   |Layers   |   |Space      |   +------------------+
+--------------+   +---------+   +-----------+
</code></pre></div>

<p>These are the available parameters of the set output feature</p>
<ul>
<li><code>reduce_input</code> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>dependencies</code> (default <code>[]</code>): the output features this one is dependent on. For a detailed explanation refer to <a href="#output-features-dependencies">Output Features Dependencies</a>.</li>
<li><code>reduce_dependencies</code> (default <code>sum</code>): defines how to reduce the output of a dependent feature that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension).</li>
<li><code>softmax</code> (default <code>false</code>): determines if to apply a softmax at the end of the decoder. It is useful for predicting a vector of values that sum up to 1 and can be interpreted as probabilities.</li>
<li><code>loss</code> (default <code>{type: mean_squared_error}</code>): is a dictionary containing a loss <code>type</code>. The available loss <code>type</code> are <code>mean_squared_error</code>, <code>mean_absolute_error</code> and <code>softmax_cross_entropy</code> (use it only if <code>softmax</code> is <code>true</code>).</li>
</ul>
<p>These are the available parameters of a set output feature decoder</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>clip</code> (default <code>null</code>): If not <code>null</code> it specifies a minimum and maximum value the predictions will be clipped to. The value can be either a list or a tuple of length 2, with the first value representing the minimum and the second the maximum. For instance <code>(-5,5)</code> will make it so that all predictions will be clipped in the <code>[-5,5]</code> interval.</li>
</ul>
<p>Example vector feature entry (with default parameters) in the output features list:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vector_column_name</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vector</span>
<span class="nt">reduce_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">dependencies</span><span class="p">:</span> <span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sigmoid_cross_entropy</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">glorot_uniform</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">clip</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>

<h4 id="vector-features-measures">Vector Features Measures<a class="headerlink" href="#vector-features-measures" title="Permanent link">&para;</a></h4>
<p>The measures that are calculated every epoch and are available for numerical features are <code>mean_squared_error</code>, <code>mean_absolute_error</code>, <code>r2</code> and the <code>loss</code> itself.
You can set either of them as <code>validation_measure</code> in the <code>training</code> section of the configuration if you set the <code>validation_field</code> to be the name of a numerical feature.</p>
<h3 id="combiners">Combiners<a class="headerlink" href="#combiners" title="Permanent link">&para;</a></h3>
<p>Combiners are the part of the model that take the outputs of the encoders of all input features and combine them before providing the combined representation to the different output decoders.
If you don't specify a combiner, the <code>concat</code> combiner will be used.</p>
<h4 id="concat-combiner">Concat Combiner<a class="headerlink" href="#concat-combiner" title="Permanent link">&para;</a></h4>
<p>The concat combiner assumes all outputs from encoders are tensors of size <code>b x h</code> where <code>b</code> is the batch size and <code>h</code> is the hidden dimension, which can be different for each input.
It concatenates along the <code>h</code> dimension, and then (optionally) passes the concatenated tensor through a stack of fully connected layers.
It returns the final <code>b x h'</code> tensor where <code>h'</code> is the size of the last fully connected layer or the sum of the sizes of the <code>h</code> of all inputs in the case there are no fully connected layers.
If there's only one input feature and no fully connected layers are specified, the output of the input feature is just passed through as output.</p>
<div class="codehilite"><pre><span></span><code>+-----------+
|Input      |
|Feature 1  +-+
+-----------+ |            +---------+
+-----------+ | +------+   |Fully    |
|...        +---&gt;Concat+---&gt;Connected+-&gt;
+-----------+ | +------+   |Layers   |
+-----------+ |            +---------+
|Input      +-+
|Feature N  |
+-----------+
</code></pre></div>

<p>These are the available parameters of a concat combiner</p>
<ul>
<li><code>fc_layers</code> (default <code>null</code>): it is a list of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>fc_size</code>, <code>norm</code>, <code>activation</code>, <code>dropout</code>, <code>initializer</code> and <code>regularize</code>. If any of those values is missing from the dictionary, the default one specified as a parameter of the decoder will be used instead.</li>
<li><code>num_fc_layers</code> (default 0): this is the number of stacked fully connected layers that the input to the feature passes through. Their output is projected in the feature's output space.</li>
<li><code>fc_size</code> (default <code>256</code>): if a <code>fc_size</code> is not already specified in <code>fc_layers</code> this is the default <code>fc_size</code> that will be used for each layer. It indicates the size of the output of a fully connected layer.</li>
<li><code>use_bias</code> (default <code>true</code>): boolean, whether the layer uses a bias vector.</li>
<li><code>weights_initializer</code> (default <code>'glorot_uniform'</code>): initializer for the weights matrix. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>bias_initializer</code> (default <code>'zeros'</code>):  initializer for the bias vector. Options are: <code>constant</code>, <code>identity</code>, <code>zeros</code>, <code>ones</code>, <code>orthogonal</code>, <code>normal</code>, <code>uniform</code>, <code>truncated_normal</code>, <code>variance_scaling</code>, <code>glorot_normal</code>, <code>glorot_uniform</code>, <code>xavier_normal</code>, <code>xavier_uniform</code>, <code>he_normal</code>, <code>he_uniform</code>, <code>lecun_normal</code>, <code>lecun_uniform</code>. Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. To know the parameters of each initializer, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">TensorFlow's documentation</a>.</li>
<li><code>weights_regularizer</code> (default <code>null</code>): regularizer function applied to the weights matrix.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>bias_regularizer</code> (default <code>null</code>): regularizer function applied to the bias vector.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>activity_regularizer</code> (default <code>null</code>): regurlizer function applied to the output of the layer.  Valid values are <code>l1</code>, <code>l2</code> or <code>l1_l2</code>.</li>
<li><code>norm</code> (default <code>null</code>): if a <code>norm</code> is not already specified in <code>fc_layers</code> this is the default <code>norm</code> that will be used for each layer. It indicates the norm of the output and it can be <code>null</code>, <code>batch</code> or <code>layer</code>.</li>
<li><code>norm_params</code> (default <code>null</code>): parameters used if <code>norm</code> is either <code>batch</code> or <code>layer</code>.  For information on parameters used with <code>batch</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">Tensorflow's documentation on batch normalization</a> or for <code>layer</code> see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">Tensorflow's documentation on layer normalization</a>.</li>
<li><code>activation</code> (default <code>relu</code>): if an <code>activation</code> is not already specified in <code>fc_layers</code> this is the default <code>activation</code> that will be used for each layer. It indicates the activation function applied to the output.</li>
<li><code>dropout</code> (default <code>0</code>): dropout rate</li>
</ul>
<p>Example concat combiner in the configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">concat</span>
<span class="nt">fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">fc_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">use_bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">weights_initializer</span><span class="p">:</span> <span class="s">&#39;glorot_uniform&#39;</span>
<span class="nt">bias_initializer</span><span class="p">:</span> <span class="s">&#39;zeros&#39;</span>
<span class="nt">weights_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">bias_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activity_regularizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">norm_params</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">activation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="nt">dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</code></pre></div>

<h4 id="sequence-concat-combiner">Sequence Concat Combiner<a class="headerlink" href="#sequence-concat-combiner" title="Permanent link">&para;</a></h4>
<p>The sequence concat combiner assumes at least one output from encoders is a tensors of size <code>b x s x h</code> where <code>b</code> is the batch size, <code>s</code> is the length of the sequence and <code>h</code> is the hidden dimension.
The sequence / text / sequential input can be specified with the <code>main_sequence_feature</code> parameter that should have the name of the sequential feature as value.
If no <code>main_sequence_feature</code> is specified, the combiner will look through all the features in the order they are defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text or time series).
If it cannot find one it will raise an exception, otherwise the output of that feature will be used for concatenating the other features along the sequence <code>s</code> dimension.</p>
<p>If there are other input features with a rank 3 output tensor, the combiner will concatenate them alongside the <code>s</code> dimension, which means that all of them must have identical <code>s</code> dimension, otherwise an error will be thrown.
Specifically, as the placeholders of the sequential features are of dimension <code>[None, None]</code> in order to make the <code>BucketedBatcher</code> trim longer sequences to their actual length, the check if the sequences are of the same length cannot be performed at model building time, and a dimension mismatch error will be returned during training when a datapoint with two sequential features of different lengths are provided.</p>
<p>Other features that have a <code>b x h</code> rank 2 tensor output will be replicated <code>s</code> times and concatenated to the <code>s</code> dimension.
The final output is a <code>b x s x h'</code> tensor where <code>h'</code> is the size of the concatenation of the <code>h</code> dimensions of all input features.</p>
<div class="codehilite"><pre><span></span><code>Sequence
Feature
Output

+---------+
|emb seq 1|
+---------+
|...      +--+
+---------+  |  +-----------------+
|emb seq n|  |  |emb seq 1|emb oth|   +------+
+---------+  |  +-----------------+   |      |
             +--&gt;...      |...    +--&gt;+Reduce+-&gt;
Other        |  +-----------------+   |      |
Feature      |  |emb seq n|emb oth|   +------+
Output       |  +-----------------+
             |
+-------+    |
|emb oth+----+
+-------+
</code></pre></div>

<p>These are the available parameters of a sequence concat combiner</p>
<ul>
<li><code>main_sequence_feature</code> (default <code>null</code>): name of the sequence / text/ time series feature to concatenate the outputs of the other features to. If no <code>main_sequence_feature</code> is specified, the combiner will look through all the features in the order they are defined in the configuration and will look for a feature with a rank 3 tensor output (sequence, text or time series). If it cannot find one it will raise an exception, otherwise the output of that feature will be used for concatenating the other features along the sequence <code>s</code> dimension. If there are other input features with a rank 3 output tensor, the combiner will concatenate them alongside the <code>s</code> dimension, which means that all of them must have identical <code>s</code> dimension, otherwise an error will be thrown.</li>
<li><code>reduce_output</code> (default <code>null</code>): describes the strategy to use to aggregate the embeddings of the items of the set. Possible values are <code>null</code>, <code>sum</code>, <code>mean</code> and <code>sqrt</code> (the weighted sum divided by the square root of the sum of the squares of the weights).</li>
</ul>
<p>Example sequence concat combiner in the configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence_concat</span>
<span class="nt">main_sequence_feature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">reduce_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>

<h4 id="sequence-combiner">Sequence Combiner<a class="headerlink" href="#sequence-combiner" title="Permanent link">&para;</a></h4>
<p>The sequence combiner stacks a sequence concat combiner with a sequence encoder one on top of each other.
All the considerations about inputs tensor ranks describer for the <a href="#sequence-concat-combiner">sequence concat combiner</a> apply also in this case, but the main difference is that this combiner uses the <code>b x s x h'</code> output of the sequence concat combiner, where <code>b</code> is the batch size, <code>s</code> is the sequence length and <code>h'</code> is the sum of the hidden dimensions of all input features, as input for any of the sequence encoders described in the <a href="#sequence-inpit-features-and-encoders">sequence features encoders section</a>.
Refer to that section for more detailed information about the sequence encoders and their parameters.
Also all the considerations on the shape of the outputs done for the sequence encoders apply in this case too.</p>
<div class="codehilite"><pre><span></span><code>Sequence
Feature
Output

+---------+
|emb seq 1|
+---------+
|...      +--+
+---------+  |  +-----------------+
|emb seq n|  |  |emb seq 1|emb oth|   +--------+
+---------+  |  +-----------------+   |Sequence|
             +--&gt;...      |...    +--&gt;+Encoder +-&gt;
Other        |  +-----------------+   |        |
Feature      |  |emb seq n|emb oth|   +--------+
Output       |  +-----------------+
             |
+-------+    |
|emb oth+----+
+-------+
</code></pre></div>

<p>Example sequence combiner in the configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">sequence</span>
<span class="nt">main_sequence_feature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">parallel_cnn</span>
<span class="nn">...</span> <span class="l l-Scalar l-Scalar-Plain">encoder parameters ...</span>
</code></pre></div>

<h2 id="distributed-training">Distributed Training<a class="headerlink" href="#distributed-training" title="Permanent link">&para;</a></h2>
<p>You can distribute the training and prediction of your models using <a href="https://github.com/uber/horovod">Horovod</a>, which allows to train on a single machine with multiple GPUs as well as on multiple machines with multiple GPUs.</p>
<p>In order to use distributed training you have to install Horovod as detailed in <a href="https://github.com/uber/horovod#install">Horovod's installation instructions</a> (which include installing <a href="https://www.open-mpi.org">OpenMPI</a> or other <a href="https://en.wikipedia.org/wiki/Message_Passing_Interface">MPI</a> implementations or <a href="https://github.com/facebookincubator/gloo">Gloo</a>) and then install the two packages:</p>
<div class="codehilite"><pre><span></span><code>pip install horovod mpi4py
</code></pre></div>

<p>Horovod works by, in practice, increasing the batch size and distributing a part of each batch to a different node and collecting the gradients from all the nodes in a smart and scalable way.
It also adjusts the learning rate to counter balance the increase in the batch size.
The advantage is that training speed scales almost linearly with the number of nodes.</p>
<p><code>experiment</code>, <code>train</code> and <code>predict</code> commands accept a <code>--use_horovod</code> argument that instructs the model building, training and prediction phases to be conducted using Horovod in a distributed way.
A <code>horovodrun</code> command specifying which machines and / or GPUs to use, together with a few more parameters, must be provided before the call to Ludwig's command.
For instance, in order to train a Ludwig model on a local machine with four GPUs one you can run:</p>
<div class="codehilite"><pre><span></span><code>horovodrun -np 4 \
    ludwig train --use_horovod ...other Ludwig parameters...
</code></pre></div>

<p>While for training on four remote machines with four GPUs each you can run:</p>
<div class="codehilite"><pre><span></span><code>horovodrun -np 16 \
    -H server1:4,server2:4,server3:4,server4:4 \
    ludwig train --use_horovod ...other Ludwig parameters...
</code></pre></div>

<p>The same applies to <code>experiment</code>, <code>predict</code> and <code>test</code>.</p>
<p>More details on Horovod installation and run parameters can be found in <a href="https://github.com/uber/horovod">Horovod's documentation</a>.</p>
<h2 id="hyper-parameter-optimization">Hyper-parameter optimization<a class="headerlink" href="#hyper-parameter-optimization" title="Permanent link">&para;</a></h2>
<p>In order to perform hyper-parameter optimization, its configuration has to be provided inside the Ludwig configuration as a root key <code>hyperopt</code>.
Its configuration contains what metric to optimize, which parameters to optimize, which sampler to use, and how to execute the optimization.</p>
<p>The different parameters that could be defined in the <code>hyperopt</code> configuration are:
- <code>goal</code> which indicates if to minimize or maximize a metric or a loss of any of the output features on any of the dataset splits. Available values are: <code>minimize</code> (default) or <code>maximize</code>.
- <code>output_feature</code> is a <code>str</code> containing the name of the output feature that we want to optimize the metric or loss of. Available values are <code>combined</code> (default) or the name of any output feature provided in the configuration. <code>combined</code> is a special output feature that allows to optimize for the aggregated loss and metrics of all output features.
- <code>metric</code> is the metric that we want to optimize for. The default one is <code>loss</code>, but depending on the type of the feature defined in <code>output_feature</code>, different metrics and losses are available. Check the metrics section of the specific output feature type to figure out what metrics are available to use.
- <code>split</code> is the split of data that we want to compute our metric on. By default it is the <code>validation</code> split, but you have the flexibility to specify also <code>train</code> or <code>test</code> splits.
- <code>parameters</code> section consists of a set of hyper-parameters to optimize. They are provided as keys (the names of the parameters) and values associated with them (that define the search space). The values vary depending on the type of the hyper-parameter. Types can be <code>float</code>, <code>int</code> and <code>category</code>.
- <code>sampler</code> section contains the sampler type to be used for sampling hyper-paramters values and its configuration. Currently available sampler types are <code>grid</code> and <code>random</code>. The sampler configuration parameters modify the sampler behavior, for instance for <code>random</code> you can set how many random samples to draw. 
- <code>executor</code> section specifies how to execute the hyper-parameter optimization. The execution could happen locally in a serial manner or in parallel across multiple workers and with GPUs as well if available.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">hyperopt</span><span class="p">:</span>
  <span class="nt">goal</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">minimize</span>
  <span class="nt">output_feature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">combined</span>
  <span class="nt">metric</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">loss</span>
  <span class="nt">split</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">validation</span>
  <span class="nt">parameters</span><span class="p">:</span>
    <span class="nt">utterance.cell_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="nt">utterance.num_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="nt">combiner.num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="nt">section.embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="nt">preprocessing.text.vocab_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="nt">training.learning_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="nt">training.optimizer.type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="l l-Scalar l-Scalar-Plain">...</span>
  <span class="nt">sampler</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grid</span>  <span class="c1"># random, ...</span>
    <span class="c1"># sampler parameters...</span>
  <span class="nt">executor</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">serial</span>  <span class="c1"># parallel, ...</span>
    <span class="c1"># executor parameters...</span>
</code></pre></div>

<p>In the <code>parameters</code> section, <code>.</code> is used to reference an parameter nested inside a section of the configuration.
For instance, to reference the <code>learning_rate</code>, one would have to use the name <code>training.learning_rate</code>.
If the parameter to reference is inside an input or output feature, the name of that feature will be be used as starting point.
For instance, for referencing the <code>cell_type</code> of the <code>utterance</code> feature, use the name <code>utterance.cell_type</code>.</p>
<h3 id="hyper-parameters">Hyper-parameters<a class="headerlink" href="#hyper-parameters" title="Permanent link">&para;</a></h3>
<h4 id="float-parameters">Float parameters<a class="headerlink" href="#float-parameters" title="Permanent link">&para;</a></h4>
<p>For a <code>float</code> value, the parameters to specify are:</p>
<ul>
<li><code>low</code>: the minimum value the parameter can have</li>
<li><code>high</code>: the maximum value the parameter can have</li>
<li><code>scale</code>: <code>linear</code> (default) or <code>log</code></li>
<li><code>steps</code>: OPTIONAL number of steps.</li>
</ul>
<p>For instance <code>range: (0.0, 1.0), steps: 3</code> would yield <code>[0.0, 0.5, 1.0]</code> as potential values to sample from, while if <code>steps</code> is not specified, the full range between <code>0.0</code> and <code>1.0</code> will be used.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">training.learning_rate</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">real</span>
  <span class="nt">low</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.001</span>
  <span class="nt">high</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="nt">steps</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">scale</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">linear</span>
</code></pre></div>

<h4 id="int-parameters">Int parameters<a class="headerlink" href="#int-parameters" title="Permanent link">&para;</a></h4>
<p>For an <code>int</code> value, the parameters to specify are:</p>
<ul>
<li><code>low</code>: the minimum value the parameter can have</li>
<li><code>high</code>: the maximum value the parameter can have</li>
<li><code>steps</code>: OPTIONAL number of steps. </li>
</ul>
<p>For instance <code>range: (0, 10), steps: 3</code> would yield <code>[0, 5, 10]</code> for the search, while if <code>steps</code> is not specified, <code>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</code> will be used.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">combiner.num_fc_layers</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">int</span>
  <span class="nt">low</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">high</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
</code></pre></div>

<h4 id="category-parameters">Category parameters<a class="headerlink" href="#category-parameters" title="Permanent link">&para;</a></h4>
<p>For a <code>category</code> value, the parameters to specify are:
- <code>values</code>: a list of possible values. The type of each value of the list is not important (they could be strings, integers, floats and anything else, even entire dictionaries).</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">utterance.cell_type</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
  <span class="nt">values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">rnn</span><span class="p p-Indicator">,</span> <span class="nv">gru</span><span class="p p-Indicator">,</span> <span class="nv">lstm</span><span class="p p-Indicator">]</span>
</code></pre></div>

<h3 id="sampler">Sampler<a class="headerlink" href="#sampler" title="Permanent link">&para;</a></h3>
<h4 id="grid-sampler">Grid sampler<a class="headerlink" href="#grid-sampler" title="Permanent link">&para;</a></h4>
<p>The <code>grid</code> sampler creates a search space by exhaustively selecting all elements from the outer product of all possible values of the hyper-parameters provided in the <code>parameters</code> section.
For <code>float</code> parameters, it is required to specify the number of <code>steps</code>.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">sampler</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grid</span>
</code></pre></div>

<h4 id="random-sampler">Random sampler<a class="headerlink" href="#random-sampler" title="Permanent link">&para;</a></h4>
<p>The <code>random</code> sampler samples hyper-parameter values randomly from the parameters search space.
<code>num_samples</code> (default: <code>10</code>) can be specified in the <code>sampler</code> section.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">sampler</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">random</span>
  <span class="nt">num_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
</code></pre></div>

<h4 id="pysot-sampler">PySOT sampler<a class="headerlink" href="#pysot-sampler" title="Permanent link">&para;</a></h4>
<p>The <code>pysot</code> sampler uses the <a href="https://arxiv.org/pdf/1908.00420.pdf">pySOT</a> package for asynchronous surrogate optimization.
This package implements many popular methods from Bayesian optimization and surrogate optimization.
By default, pySOT uses the Stochastic RBF (SRBF) method by <a href="https://pubsonline.informs.org/doi/10.1287/ijoc.1060.0182">Regis and Shoemaker</a>.
SRBF starts by evaluating a symmetric Latin hypercube design of size <code>2 * d + 1</code>, where d is the number of hyperparameters that are optimized.
When these points have been evaluated, SRBF fits a radial basis function surrogate and uses this surrogate together with an acquisition function to select the next sample(s).
We recommend using at least <code>10 * d</code> total samples to allow the algorithm to converge.</p>
<p>More details are available on the GitHub page: https://github.com/dme65/pySOT.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">sampler</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pysot</span>
  <span class="nt">num_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
</code></pre></div>

<h3 id="executor">Executor<a class="headerlink" href="#executor" title="Permanent link">&para;</a></h3>
<h4 id="serial-executor">Serial Executor<a class="headerlink" href="#serial-executor" title="Permanent link">&para;</a></h4>
<p>The <code>serial</code>executor performs hyper-parameter optimization locally in a serial manner, executing the elements in the set of sampled parameters obtained by the selected sampler one at a time.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">executor</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">serial</span>
</code></pre></div>

<h4 id="parallel-executor">Parallel Executor<a class="headerlink" href="#parallel-executor" title="Permanent link">&para;</a></h4>
<p>The <code>parallel</code> executor performs hyper-parameter optimization in parallel, executing the elements in the set of sampled parameters obtained by the selected sampler at the same time.
The maximum numer of parallel workers that train and evaluate models is defined by the parameter <code>num_workers</code> (default: <code>2</code>).</p>
<p>In case of training with GPUs, the <code>gpus</code> argument provided to the command line interface contains the list of GPUs to use, while if no <code>gpus</code> parameter is provided, all available GPUs will be used.
The <code>gpu_fraction</code> argument can be provided as well, but it gets modified according to the <code>num_workers</code> to execute tasks parallely.
For example, if <code>num_workers: 4</code> and 2 GPUs are available, if the provided <code>gpu_fraction</code> is above <code>0.5</code>, if will be replaced by <code>0.5</code>.
An <code>epsilon</code> (default: <code>0.01</code>) parameter is also provided to allow for additional free GPU memory: the GPU franction to use is defined as <code>(#gpus / #workers) - epsilon</code>.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">executor</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">parallel</span>
  <span class="nt">num_workers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
  <span class="nt">epsilon</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.01</span>
</code></pre></div>

<h4 id="fiber-executor">Fiber Executor<a class="headerlink" href="#fiber-executor" title="Permanent link">&para;</a></h4>
<p><a href="https://github.com/uber/fiber">Fiber</a> is a Python distributed computing library for modern computer clusters.
The <code>fiber</code> executor performs hyper-parameter optimization in parallel on a computer cluster so that massive parallelism can be achieved.
Check <a href="https://uber.github.io/fiber/platforms/">this</a> for supported cluster types.</p>
<p>Fiber Executor requires <code>fiber</code> to be installed:</p>
<div class="codehilite"><pre><span></span><code>pip install fiber
</code></pre></div>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>num_workers</code>: The number of parallel workers that is used to train and evaluate models. The default value is <code>2</code>.</li>
<li><code>num_cpus_per_worker</code>: How many CPU cores are allocated per worker.</li>
<li><code>num_gpus_per_worker</code>: How many GPUs are allocated per worker.</li>
<li><code>fiber_backend</code>: Fiber backend to use. This needs to be set if you want to run hyper-parameter optimization on a cluster. The default value is <code>local</code>. Available values are <code>local</code>, <code>kubernetes</code>, <code>docker</code>. Check <a href="https://uber.github.io/fiber/platforms/">Fiber's documentation</a> for details on the supported platforms.</li>
</ul>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">executor</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">fiber</span>
  <span class="nt">num_workers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
  <span class="nt">fiber_backend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes</span>
  <span class="nt">num_cpus_per_worker</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
  <span class="nt">num_gpus_per_worker</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
</code></pre></div>

<p><strong>Running Fiber Executor:</strong></p>
<p>Fiber runs on a computer cluster and uses Docker to encapsulate all the code and dependencies.
To run a hyper-parameter search powered by Fiber, you have to create a Docker file to encapsulate your code and dependencies.</p>
<p>Example Dockerfile:</p>
<div class="codehilite"><pre><span></span><code><span class="k">FROM</span> <span class="s">tensorflow/tensorflow:1.15.2-gpu-py3</span>

<span class="k">RUN</span> apt-get -y update <span class="o">&amp;&amp;</span> apt-get -y install git libsndfile1

<span class="k">RUN</span> git clone --depth<span class="o">=</span><span class="m">1</span> https://github.com/ludwig-ai/ludwig.git
<span class="k">RUN</span> <span class="nb">cd</span> ludwig/ <span class="se">\</span>
    <span class="o">&amp;&amp;</span> pip install -r requirements.txt -r requirements_text.txt <span class="se">\</span>
          -r requirements_image.txt -r requirements_audio.txt <span class="se">\</span>
          -r requirements_serve.txt -r requirements_viz.txt <span class="se">\</span>
    <span class="o">&amp;&amp;</span> python setup.py install

<span class="k">RUN</span> pip install fiber

<span class="k">RUN</span> mkdir /data
<span class="k">ADD</span> train.csv /data/data.csv
<span class="k">ADD</span> hyperopt.yaml /data/hyperopt.yaml

<span class="k">WORKDIR</span><span class="s"> /data</span>
</code></pre></div>

<p>In this Dockerfile, the data <code>data.csv</code> is embedded in the docker together with <code>hyperopt.yaml</code> that specifies the model and hyper-parameter optimization parameters.
If your data is too big to be added directly in the docker image, refer to the <a href="https://uber.github.io/fiber/advanced/#working-with-persistent-storage">Fiber's documentation</a> for instructions on how to work with shared persistent storage for Fiber workers.
An example <code>hyperopt.yaml</code> looks like:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">input_features</span><span class="p">:</span>
  <span class="p p-Indicator">-</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">x</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
<span class="nt">output_features</span><span class="p">:</span>
  <span class="p p-Indicator">-</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">y</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
<span class="nt">training</span><span class="p">:</span>
  <span class="nt">epochs</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">hyperopt</span><span class="p">:</span>
  <span class="nt">sampler</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">random</span>
    <span class="nt">num_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
  <span class="nt">executor</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">fiber</span>
    <span class="nt">num_workers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
    <span class="nt">fiber_backend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes</span>
    <span class="nt">num_cpus_per_worker</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
    <span class="nt">num_gpus_per_worker</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">parameters</span><span class="p">:</span>
    <span class="nt">training.learning_rate</span><span class="p">:</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">float</span>
      <span class="nt">low</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0001</span>
      <span class="nt">high</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
    <span class="nt">y.num_fc_layers</span><span class="p">:</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">int</span>
      <span class="nt">low</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
      <span class="nt">high</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
</code></pre></div>

<p>Running hyper-parameter optimization with Fiber is a little bit different from other executors because there is docker building and pushing involved, so the <code>fiber run</code> command, which takes care of those aspects, is used to run hyper-parameter optimization on a cluster:</p>
<p><code>fiber run ludwig hyperopt --dataset train.csv -cf hyperopt.yaml</code></p>
<p>Check out <a href="https://uber.github.io/fiber/getting-started/#running-on-a-computer-cluster">Fiber's documentation</a> for more details on running on clusters.</p>
<h3 id="full-hyper-parameter-optimization-example">Full hyper-parameter optimization example<a class="headerlink" href="#full-hyper-parameter-optimization-example" title="Permanent link">&para;</a></h3>
<p>Example YAML:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">input_features</span><span class="p">:</span>
  <span class="p p-Indicator">-</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">utterance</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">text</span>
    <span class="nt">encoder</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rnn</span>
    <span class="nt">cell_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">lstm</span>
    <span class="nt">num_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
  <span class="p p-Indicator">-</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">section</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
    <span class="nt">representation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dense</span>
    <span class="nt">embedding_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">100</span>
<span class="nt">combiner</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">concat</span>
  <span class="nt">num_fc_layers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">output_features</span><span class="p">:</span>
  <span class="p p-Indicator">-</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">class</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
<span class="nt">preprocessing</span><span class="p">:</span>
  <span class="nt">text</span><span class="p">:</span>
    <span class="nt">word_vocab_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10000</span>
<span class="nt">training</span><span class="p">:</span>
  <span class="nt">learning_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.001</span>
  <span class="nt">optimizer</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">adam</span>
<span class="nt">hyperopt</span><span class="p">:</span>
  <span class="nt">goal</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">maximize</span>
  <span class="nt">output_feature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">class</span>
  <span class="nt">metric</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">accuracy</span>
  <span class="nt">split</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">validation</span>
  <span class="nt">parameters</span><span class="p">:</span>
    <span class="nt">training.learning_rate</span><span class="p">:</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">float</span>
      <span class="nt">low</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0001</span>
      <span class="nt">high</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
      <span class="nt">steps</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
      <span class="nt">scale</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">log</span>
    <span class="nt">training.optimizaer.type</span><span class="p">:</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
      <span class="nt">values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">sgd</span><span class="p p-Indicator">,</span> <span class="nv">adam</span><span class="p p-Indicator">,</span> <span class="nv">adagrad</span><span class="p p-Indicator">]</span>
    <span class="nt">preprocessing.text.word_vocab_size</span><span class="p">:</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">int</span>
      <span class="nt">low</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">700</span>
      <span class="nt">high</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1200</span>
      <span class="nt">steps</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
    <span class="nt">combiner.num_fc_layers</span><span class="p">:</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">int</span>
      <span class="nt">low</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
      <span class="nt">high</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
    <span class="nt">utterance.cell_type</span><span class="p">:</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
      <span class="nt">values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">rnn</span><span class="p p-Indicator">,</span> <span class="nv">gru</span><span class="p p-Indicator">,</span> <span class="nv">lstm</span><span class="p p-Indicator">]</span>
  <span class="nt">sampler</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">random</span>
    <span class="nt">num_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">12</span>
  <span class="nt">executor</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">parallel</span>
    <span class="nt">num_workers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
</code></pre></div>

<p>Example CLI command:</p>
<div class="codehilite"><pre><span></span><code>ludwig hyperopt --dataset reuters-allcats.csv --config &quot;{input_features: [{name: utterance, type: text, encoder: rnn, cell_type: lstm, num_layers: 2}], output_features: [{name: class, type: category}], training: {learning_rate: 0.001}, hyperopt: {goal: maximize, output_feature: class, metric: accuracy, split: validation, parameters: {training.learning_rate: {type: float, low: 0.0001, high: 0.1, steps: 4, scale: log}, utterance.cell_type: {type: category, values: [rnn, gru, lstm]}}, sampler: {type: grid}, executor: {type: serial}}}&quot;
</code></pre></div>

<h2 id="integrations">Integrations<a class="headerlink" href="#integrations" title="Permanent link">&para;</a></h2>
<p>Ludwig provides an extendable interface to integrate with third-party
systems. To activate a particular integration, simply insert its flag
into the command line. Each integration may have specific requirements
and use.</p>
<p>Ludwig supports the following integrations:</p>
<ul>
<li>
<p><code>--comet</code> - logs training metrics, environment details, test results, visualizations, and more to <a href="https://comet.ml">Comet.ML</a>. Requires a freely available account. For more details, see Comet's <a href="https://www.comet.ml/docs/python-sdk/ludwig/#running-ludwig-with-comet">Running Ludwig with Comet</a>.</p>
</li>
<li>
<p><code>--wandb</code> - logs training metrics, configuration parameters, environment details, and trained model to <a href="https://www.wandb.com/">Weights &amp; Biases</a>. For more details, refer to <a href="https://docs.wandb.com/quickstart">W&amp;B Quickstart</a>.</p>
</li>
</ul>
<p>For more information about integration contributions, please see the <a href="../developer_guide/">Developer Guide</a>.</p>
<h2 id="programmatic-api">Programmatic API<a class="headerlink" href="#programmatic-api" title="Permanent link">&para;</a></h2>
<p>Ludwig functionalities can also be accessed through a programmatic API.
The API consists of one <code>LudwigModel</code> class that can be initialized with a configuration dictionary and then can be trained with a dataset (either in memory or loaded from file).
Pretrained models can be loaded and can be used to obtain predictions on s new dataset (either in memory or loaded from file).</p>
<p>A detailed documentation of all the functions available in <code>LudwigModel</code> is provided in the <a href="../api/">API documentation</a>.</p>
<h3 id="training-a-model">Training a Model<a class="headerlink" href="#training-a-model" title="Permanent link">&para;</a></h3>
<p>To train a model one has first to initialize it using the initializer <code>LudwigModel()</code> and a configuration dictionary, and then calling the <code>train()</code> function using either a dataframe or a dataset file.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">ludwig.api</span> <span class="kn">import</span> <span class="n">LudwigModel</span>

<span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LudwigModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">training_statistics</span><span class="p">,</span> <span class="n">preprocessed_data</span><span class="p">,</span> <span class="n">output_directory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset_file_path</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">training_statistics</span><span class="p">,</span> <span class="n">preprocessed_data</span><span class="p">,</span> <span class="n">output_directory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataframe</span><span class="p">)</span>
</code></pre></div>

<p><code>config</code> is a dictionary that has the same key-value structure of a configuration YAML file, as it's technically equivalent as parsing the YAML file into a Python dictionary.
Note that all null values should be provided as Python <code>None</code> instead of the YAML <code>null</code>, and the same applies for <code>True/False</code> instead of <code>true/false</code>. 
<code>train_statistics</code> is a dictionary of training statistics
for each output feature containing loss and metrics values
for each epoch.
The contents are exactly the same of the <code>training_statistics.json</code> file produced by the <code>experiment</code> and <code>train</code> commands.
<code>preprocessed_data</code> is the tuple containing these three data sets
<code>(training_set, validation_set, test_set)</code>.
<code>output_directory</code> is the filepath where training results are stored.</p>
<h3 id="loading-a-pre-trained-model">Loading a Pre-trained Model<a class="headerlink" href="#loading-a-pre-trained-model" title="Permanent link">&para;</a></h3>
<p>In order to load a pre-trained Ludwig model you have to call the static function <code>load()</code> of the <code>LudwigModel</code> class providing the path containing the model.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">ludwig.api</span> <span class="kn">import</span> <span class="n">LudwigModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LudwigModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
</code></pre></div>

<h3 id="predicting">Predicting<a class="headerlink" href="#predicting" title="Permanent link">&para;</a></h3>
<p>Either a newly trained model or a pre-trained loaded model can be used for predicting on new data using the <code>predict()</code> function of the model object.
The dataset has to contain columns with the same names of all the input features of the model.</p>
<div class="codehilite"><pre><span></span><code><span class="n">predictions</span><span class="p">,</span> <span class="n">output_directory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset_file_path</span><span class="p">)</span>
<span class="c1">#or</span>
<span class="n">predictions</span><span class="p">,</span> <span class="n">output_directory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataframe</span><span class="p">)</span>
</code></pre></div>

<p><code>predictions</code> will be a dataframe containing the prediction and confidence score / probability of all output features.  <code>output_directory</code> filepath to prediction interim files.</p>
<p>If you want to compute also measures on the quality of the predictions you can run:</p>
<div class="codehilite"><pre><span></span><code><span class="n">evaluation_statistics</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">output_directory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset_file_path</span><span class="p">)</span>
<span class="c1">#or</span>
<span class="n">evaluation_statistics</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">output_directory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataframe</span><span class="p">)</span>
</code></pre></div>

<p>In this case the dataset should also contain columns with the same names of all the output features, as their content is going to be used as ground truth to compare the predictions against and compute the measures and <code>evaluation_statistics</code> will be a dictionary containing several measures of quality depending on the type of each output feature (e.g. <code>category</code> features will have an accuracy measure and a confusion matrix, among other measures, associated to them, while <code>numerical</code> features will have measures like mean squared loss and R2 among others).</p>
<h2 id="visualizations">Visualizations<a class="headerlink" href="#visualizations" title="Permanent link">&para;</a></h2>
<p>Several visualization can be obtained from the result files from both <code>train</code>, <code>predict</code> and <code>experiment</code> by using the <code>visualize</code> command.
The command has several parameters, but not all the visualizations use all of them.
Let's first present the parameters of the general script, and then, for each available visualization, we will discuss about the specific parameters needed and what visualization they produce.</p>
<div class="codehilite"><pre><span></span><code>usage: ludwig visualize [options]

This script analyzes results and shows some nice plots.

optional arguments:
  -h, --help            show this help message and exit
  -g GROUND_TRUTH, --ground_truth GROUND_TRUTH
                        ground truth file
  -sf SPLIT_FILE, --split_file SPLIT_FILE
                        file containing split values used in conjunction with ground truth file
  -gm GROUND_TRUTH_METADATA, --ground_truth_metadata GROUND_TRUTH_METADATA
                        input metadata JSON file
  -od OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY
                        directory where to save plots.If not specified, plots
                        will be displayed in a window
  -ff {pdf,png}, --file_format {pdf,png}
                        file format of output plots
  -v {binary_threshold_vs_metric,calibration_1_vs_all,calibration_multiclass,compare_classifiers_multiclass_multimetric,compare_classifiers_performance_changing_k,compare_classifiers_performance_from_pred,compare_classifiers_performance_from_prob,compare_classifiers_performance_subset,compare_classifiers_predictions,compare_classifiers_predictions_distribution,compare_performance,confidence_thresholding,confidence_thresholding_2thresholds_2d,confidence_thresholding_2thresholds_3d,confidence_thresholding_data_vs_acc,confidence_thresholding_data_vs_acc_subset,confidence_thresholding_data_vs_acc_subset_per_class,confusion_matrix,frequency_vs_f1,hyperopt_hiplot,hyperopt_report,learning_curves,roc_curves,roc_curves_from_test_statistics}, --visualization {binary_threshold_vs_metric,calibration_1_vs_all,calibration_multiclass,compare_classifiers_multiclass_multimetric,compare_classifiers_performance_changing_k,compare_classifiers_performance_from_pred,compare_classifiers_performance_from_prob,compare_classifiers_performance_subset,compare_classifiers_predictions,compare_classifiers_predictions_distribution,compare_performance,confidence_thresholding,confidence_thresholding_2thresholds_2d,confidence_thresholding_2thresholds_3d,confidence_thresholding_data_vs_acc,confidence_thresholding_data_vs_acc_subset,confidence_thresholding_data_vs_acc_subset_per_class,confusion_matrix,frequency_vs_f1,hyperopt_hiplot,hyperopt_report,learning_curves,roc_curves,roc_curves_from_test_statistics}
                        type of visualization
  -ofn OUTPUT_FEATURE_NAME, --output_feature_name OUTPUT_FEATURE_NAME
                        name of the output feature to visualize
  -gts GROUND_TRUTH_SPLIT, --ground_truth_split GROUND_TRUTH_SPLIT
                        ground truth split - 0:train, 1:validation, 2:test
                        split
  -tf THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...], --threshold_output_feature_names THRESHOLD_OUTPUT_FEATURE_NAMES [THRESHOLD_OUTPUT_FEATURE_NAMES ...]
                        names of output features for 2d threshold
  -pred PREDICTIONS [PREDICTIONS ...], --predictions PREDICTIONS [PREDICTIONS ...]
                        predictions files
  -prob PROBABILITIES [PROBABILITIES ...], --probabilities PROBABILITIES [PROBABILITIES ...]
                        probabilities files
  -trs TRAINING_STATISTICS [TRAINING_STATISTICS ...], --training_statistics TRAINING_STATISTICS [TRAINING_STATISTICS ...]
                        training stats files
  -tes TEST_STATISTICS [TEST_STATISTICS ...], --test_statistics TEST_STATISTICS [TEST_STATISTICS ...]
                        test stats files
  -hs HYPEROPT_STATS_PATH, --hyperopt_stats_path HYPEROPT_STATS_PATH
                        hyperopt stats file
  -mn MODEL_NAMES [MODEL_NAMES ...], --model_names MODEL_NAMES [MODEL_NAMES ...]
                        names of the models to use as labels
  -tn TOP_N_CLASSES [TOP_N_CLASSES ...], --top_n_classes TOP_N_CLASSES [TOP_N_CLASSES ...]
                        number of classes to plot
  -k TOP_K, --top_k TOP_K
                        number of elements in the ranklist to consider
  -ll LABELS_LIMIT, --labels_limit LABELS_LIMIT
                        maximum numbers of labels. If labels in dataset are
                        higher than this number, &quot;rare&quot; label
  -ss {ground_truth,predictions}, --subset {ground_truth,predictions}
                        type of subset filtering
  -n, --normalize       normalize rows in confusion matrix
  -m METRICS [METRICS ...], --metrics METRICS [METRICS ...]
                        metrics to dispay in threshold_vs_metric
  -pl POSITIVE_LABEL, --positive_label POSITIVE_LABEL
                        label of the positive class for the roc curve
  -l {critical,error,warning,info,debug,notset}, --logging_level {critical,error,warning,info,debug,notset}
                        the level of logging to use
</code></pre></div>

<p>Some additional information on the parameters:</p>
<ul>
<li>The list parameters are considered to be aligned, meaning <code>predictions</code>, <code>probabilities</code>, <code>training_statistics</code>, <code>test_statistics</code> and <code>model_names</code> are indexed altogether, for instance the name of the model producing the second predictions in the list will be the second in the model names.</li>
<li><code>ground_truth</code> and <code>ground_truth_metadata</code> are respectively the <code>HDF5</code> and <code>JSON</code> file obtained during training preprocessing. If you plan to use the visualizations then be sure not to use the <code>skip_save_preprocessing</code> when training. Those files are needed because they contain the split performed at preprocessing time, so it is easy to extract the test set from them.</li>
<li><code>output_feature_name</code> is the output feature to use for creating the visualization.</li>
</ul>
<p>Other parameters will be detailed for each visualization as different ones use them differently.</p>
<p>Example commands to generate the visualizations are based on running two experiments and comparing them.
The experiments themselves are run with the following:</p>
<div class="codehilite"><pre><span></span><code>ludwig experiment --experiment_name titanic --model_name Model1 --dataset train.csv -cf titanic_model1.yaml
ludwig experiment --experiment_name titanic --model_name Model2 --dataset train.csv -cf titanic_model2.yaml
</code></pre></div>

<p>For this, you need to download the <a href="https://www.kaggle.com/c/titanic/">Titanic Kaggle competition dataset</a> to get <code>train.csv</code>.
Note that the images associated with each visualization below are not from the Titanic dataset.
The two models are defined with <code>titanic_model1.yaml</code></p>
<div class="codehilite"><pre><span></span><code><span class="nt">input_features</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pclass</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Sex</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Age</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
        <span class="nt">preprocessing</span><span class="p">:</span>
          <span class="nt">missing_value_strategy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">fill_with_mean</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">SibSp</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Parch</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Fare</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
        <span class="nt">preprocessing</span><span class="p">:</span>
          <span class="nt">missing_value_strategy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">fill_with_mean</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Embarked</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>

<span class="nt">output_features</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Survived</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">binary</span>
</code></pre></div>

<p>and with <code>titanic_model2.yaml</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="nt">input_features</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pclass</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Sex</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">SibSp</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Parch</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">numerical</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Embarked</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">category</span>

<span class="nt">output_features</span><span class="p">:</span>
    <span class="p p-Indicator">-</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Survived</span>
        <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">binary</span>
</code></pre></div>

<h3 id="learning-curves">Learning Curves<a class="headerlink" href="#learning-curves" title="Permanent link">&para;</a></h3>
<h4 id="learning_curves">learning_curves<a class="headerlink" href="#learning_curves" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code> </li>
<li><code>training_statistics</code></li>
<li><code>model_names</code></li>
</ul>
<p>For each model (in the aligned lists of <code>training_statistics</code> and <code>model_names</code>) and for each output feature and measure of the model, it produces a line plot showing how that measure changed over the course of the epochs of training on the training and validation sets.  If <code>output_feature_name</code> is not specified, then all output features are plotted.</p>
<p>Example command:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize --visualization learning_curves \
  --output_feature_name Survived \
  --training_statistics results/titanic_Model1_0/training_statistics.json \
       results/titanic_Model2_0/training_statistics.json \
  --model_names Model1 Model2
</code></pre></div>

<p><img alt="Learning Curves Loss" src="../images/learning_curves_loss.png" title="Learning Curves Loss" /></p>
<p><img alt="Learning Curves Accuracy" src="../images/learning_curves_accuracy.png" title="Learning Curves Accuracy" /></p>
<h3 id="confusion-matrix">Confusion Matrix<a class="headerlink" href="#confusion-matrix" title="Permanent link">&para;</a></h3>
<h4 id="confusion_matrix">confusion_matrix<a class="headerlink" href="#confusion_matrix" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>test_statistics</code></li>
<li><code>model_names</code></li>
<li><code>top_n_classes</code></li>
<li><code>normalize</code></li>
</ul>
<p>For each model (in the aligned lists of <code>test_statistics</code> and <code>model_names</code>) it produces a heatmap of the confusion matrix in the predictions for each field that has a confusion matrix in <code>test_statistics</code>.
The value of <code>top_n_classes</code> limits the heatmap to the <code>n</code> most frequent classes.</p>
<p>Example command:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize --visualization confusion_matrix \
  --ground_truth_metadata results/titanic_Model1_0/model/train_set_metadata.json \
  --test_statistics results/titanic_Model1_0/test_statistics.json \
  --top_n_classes 2 
</code></pre></div>

<p><img alt="Confusion Matrix" src="../images/confusion_matrix.png" title="Confusion Matrix" /></p>
<p>The second plot produced, is a barplot showing the entropy of each class, ranked from most entropic to least entropic.</p>
<p><img alt="Confusion Matrix Entropy" src="../images/confusion_matrix_entropy.png" title="Confusion Matrix Entropy" /></p>
<h3 id="compare-performance">Compare Performance<a class="headerlink" href="#compare-performance" title="Permanent link">&para;</a></h3>
<h4 id="compare_performance">compare_performance<a class="headerlink" href="#compare_performance" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>test_statistics</code></li>
<li><code>model_names</code></li>
</ul>
<p>For each model (in the aligned lists of <code>test_statistics</code> and <code>model_names</code>) it produces bars in a bar plot, one for each overall metric available in the <code>test_statistics</code> file for the specified <code>output_feature_name</code>.</p>
<p>Example command:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize --visualization compare_performance \
  --output_feature_name Survived \
  --test_statistics results/titanic_Model1_0/test_statistics.json \
       results/titanic_Model2_0/test_statistics.json \
  --model_names Model1 Model2 
</code></pre></div>

<p><img alt="Compare Classifiers Performance" src="../images/compare_performance.png" title="Compare Classifiers Performance" /></p>
<h4 id="compare_classifiers_performance_from_prob">compare_classifiers_performance_from_prob<a class="headerlink" href="#compare_classifiers_performance_from_prob" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code> </li>
<li><code>split_file</code> </li>
<li><code>ground_truth_metadata</code> </li>
<li><code>output_directory</code> </li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code> </li>
<li><code>ground_truth_split</code> </li>
<li><code>probabilities</code> </li>
<li><code>model_names</code> </li>
<li><code>top_n_classes</code> </li>
<li><code>labels_limit</code> </li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>) it produces bars in a bar plot, one for each overall metric computed on the fly from the probabilities of predictions for the specified <code>output_feature_name</code>.</p>
<p>Example command:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize --visualization compare_classifiers_performance_from_prob \
  --ground_truth train.hdf5 \
  --output_feature_name Survived \
  --probabilities results/titanic_Model1_0/Survived_probabilities.csv \
        results/titanic_Model2_0/Survived_probabilities.csv \
  --model_names Model1 Model2 
</code></pre></div>

<p><img alt="Compare Classifiers Performance from Probabilities" src="../images/compare_classifiers_performance_from_prob.png" title="Compare Classifiers Performance from probabilities" /></p>
<h4 id="compare_classifiers_performance_from_pred">compare_classifiers_performance_from_pred<a class="headerlink" href="#compare_classifiers_performance_from_pred" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>predictions</code></li>
<li><code>model_names</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>predictions</code> and <code>model_names</code>) it produces bars in a bar plot, one for each overall metric computed on the fly from the predictions for the specified <code>output_feature_name</code>.</p>
<p>Example command:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize --visualization compare_classifiers_performance_from_pred \
  --ground_truth train.hdf5 \
  --ground_truth_metadata train.json \
  --output_feature_name Survived \
  --predictions results/titanic_Model1_0/Survived_predictions.csv \
        results/titanic_Model2_0/Survived_predictions.csv \
  --model_names Model1 Model2 
</code></pre></div>

<p><img alt="Compare Classifiers Performance from Predictions" src="../images/compare_classifiers_performance_from_pred.png" title="Compare Classifiers Performance from Predictions" /></p>
<h4 id="compare_classifiers_performance_subset">compare_classifiers_performance_subset<a class="headerlink" href="#compare_classifiers_performance_subset" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code> </li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>top_n_classes</code></li>
<li><code>labels_limit</code></li>
<li><code>subset</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>predictions</code> and <code>model_names</code>) it produces bars in a bar plot, one for each overall metric computed on the fly from the probabilities predictions for the specified <code>output_feature_name</code>, considering only a subset of the full training set.
The way the subset is obtained is using the <code>top_n_classes</code> and <code>subset</code> parameters.</p>
<p>If the values of <code>subset</code> is <code>ground_truth</code>, then only datapoints where the ground truth class is within the top <code>n</code> most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed.</p>
<p>Example command:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize --visualization compare_classifiers_performance_subset \
  --ground_truth train.hdf5 \
  --ground_truth_metadata train.json \
  --output_feature_name Survived \
  --probabilities results/titanic_Model1_0/Survived_probabilities.csv \
           results/titanic_Model2_0/Survived_probabilities.csv \
  --model_names Model1 Model2 \
  --top_n_classes 2 \
  --subset ground_truth 
</code></pre></div>

<p><img alt="Compare Classifiers Performance Subset Ground Truth" src="../images/compare_classifiers_performance_subset_gt.png" title="Compare Classifiers Performance Subset Ground Truth" /></p>
<p>If the values of <code>subset</code> is <code>predictions</code>, then only datapoints where the the model predicts a class that is within the top <code>n</code> most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model.</p>
<p><img alt="Compare Classifiers Performance Subset Ground Predictions" src="../images/compare_classifiers_performance_subset_pred.png" title="Compare Classifiers Performance Subset Ground Predictions" /></p>
<h4 id="compare_classifiers_performance_changing_k">compare_classifiers_performance_changing_k<a class="headerlink" href="#compare_classifiers_performance_changing_k" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code> </li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>top_k</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>) it produces a line plot that shows the Hits@K measure (that counts a prediction as correct if the model produces it among the first <code>k</code>) while changing <code>k</code> from 1 to <code>top_k</code> for the specified <code>output_feature_name</code>.</p>
<p>Example command:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize --visualization compare_classifiers_performance_changing_k \
  --ground_truth train.hdf5 \
  --output_feature_name Survived \
  --probabilities results/titanic_Model1_0/Survived_probabilities.csv \
         results/titanic_Model2_0/Survived_probabilities.csv \
  --model_names Model1 Model2 \
  --top_k 5 
</code></pre></div>

<p><img alt="Compare Classifiers Performance Changing K" src="../images/compare_classifiers_performance_changing_k.png" title="Compare Classifiers Performance Changing K" /></p>
<h4 id="compare_classifiers_multiclass_multimetric">compare_classifiers_multiclass_multimetric<a class="headerlink" href="#compare_classifiers_multiclass_multimetric" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>test_statistics</code></li>
<li><code>model_names</code></li>
<li><code>top_n_classes</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>test_statistics</code> and <code>model_names</code>) it produces four plots that show the precision, recall and F1 of the model on several classes for the specified <code>output_feature_name</code>.</p>
<p>The first one show the measures on the <code>n</code> most frequent classes.</p>
<p><img alt="Multiclass Multimetric top k" src="../images/compare_classifiers_multiclass_multimetric_topk.png" title="Multiclass Multimetric most frequent classes" /></p>
<p>The second one shows the measures on the <code>n</code> classes where the model performs the best.</p>
<p><img alt="Multiclass Multimetric best k" src="../images/compare_classifiers_multiclass_multimetric_bestk.png" title="Multiclass Multimetric best classes" /></p>
<p>The third one shows the measures on the <code>n</code> classes where the model performs the worst.</p>
<p><img alt="Multiclass Multimetric worst k" src="../images/compare_classifiers_multiclass_multimetric_worstk.png" title="Multiclass Multimetric worst classes" /></p>
<p>The fourth one shows the measures on all the classes, sorted by their frequency. This could become unreadable in case the number of classes is really high.</p>
<p><img alt="Multiclass Multimetric sorted" src="../images/compare_classifiers_multiclass_multimetric_sorted.png" title="Multiclass Multimetric sorted classes" /></p>
<h3 id="compare-classifier-predictions">Compare Classifier Predictions<a class="headerlink" href="#compare-classifier-predictions" title="Permanent link">&para;</a></h3>
<h4 id="compare_classifiers_predictions">compare_classifiers_predictions<a class="headerlink" href="#compare_classifiers_predictions" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code> </li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>predictions</code></li>
<li><code>model_names</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category and there must be two and only two models (in the aligned lists of <code>predictions</code> and <code>model_names</code>).
This visualization produces a pie chart comparing the predictions of the two models for the specified <code>output_feature_name</code>.</p>
<p>Example command:</p>
<div class="codehilite"><pre><span></span><code>ludwig visualize --visualization compare_classifiers_predictions \
  --ground_truth train.hdf5 \
  --output_feature_name Survived \
  --predictions results/titanic_Model1_0/Survived_predictions.csv \
          results/titanic_Model2_0/Survived_predictions.csv \
  --model_names Model1 Model2 
</code></pre></div>

<p><img alt="Compare Classifiers Predictions" src="../images/compare_classifiers_predictions.png" title="Compare Classifiers Predictions" /></p>
<h4 id="compare_classifiers_predictions_distribution">compare_classifiers_predictions_distribution<a class="headerlink" href="#compare_classifiers_predictions_distribution" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>predictions</code></li>
<li><code>model_names</code></li>
<li><code>label_limits</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
This visualization produces a radar plot comparing the distributions of predictions of the models for the first 10 classes of the specified <code>output_feature_name</code>.</p>
<p><img alt="Compare Classifiers Predictions Distribution" src="../images/compare_classifiers_predictions_distribution.png" title="Compare Classifiers Predictions Distribution" /></p>
<h3 id="confidence_thresholding">Confidence_Thresholding<a class="headerlink" href="#confidence_thresholding" title="Permanent link">&para;</a></h3>
<h4 id="confidence_thresholding_1">confidence_thresholding<a class="headerlink" href="#confidence_thresholding_1" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>) it produces a pair of lines indicating the accuracy of the model and the data coverage while increasing a threshold (x axis) on the probabilities of predictions for the specified <code>output_feature_name</code>.</p>
<p><img alt="Confidence_Thresholding" src="../images/confidence_thresholding.png" title="Confidence_Thresholding" /></p>
<h4 id="confidence_thresholding_data_vs_acc">confidence_thresholding_data_vs_acc<a class="headerlink" href="#confidence_thresholding_data_vs_acc" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified <code>output_feature_name</code>.
The difference with <code>confidence_thresholding</code> is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold.</p>
<p><img alt="Confidence_Thresholding Data vs Accuracy" src="../images/confidence_thresholding_data_vs_acc.png" title="Confidence_Thresholding Data vs Accuracy" /></p>
<h4 id="confidence_thresholding_data_vs_acc_subset">confidence_thresholding_data_vs_acc_subset<a class="headerlink" href="#confidence_thresholding_data_vs_acc_subset" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>top_n_classes</code></li>
<li><code>labels_limit</code></li>
<li><code>subset</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified <code>output_feature_name</code>, considering only a subset of the full training set.
The way the subset is obtained is using the <code>top_n_classes</code> and <code>subset</code> parameters..
The difference with <code>confidence_thresholding</code> is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold.</p>
<p>If the values of <code>subset</code> is <code>ground_truth</code>, then only datapoints where the ground truth class is within the top <code>n</code> most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed.
If the values of <code>subset</code> is <code>predictions</code>, then only datapoints where the the model predicts a class that is within the top <code>n</code> most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model.</p>
<p><img alt="Confidence_Thresholding Data vs Accuracy Subset" src="../images/confidence_thresholding_data_vs_acc_subset.png" title="Confidence_Thresholding Data vs Accuracy Subset" /></p>
<h4 id="confidence_thresholding_data_vs_acc_subset_per_class">confidence_thresholding_data_vs_acc_subset_per_class<a class="headerlink" href="#confidence_thresholding_data_vs_acc_subset_per_class" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>top_n_classes</code></li>
<li><code>labels_limit</code></li>
<li><code>subset</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>) it produces a line indicating the accuracy of the model and the data coverage while increasing a threshold on the probabilities of predictions for the specified <code>output_feature_name</code>, considering only a subset of the full training set.
The way the subset is obtained is using the <code>top_n_classes</code> and <code>subset</code> parameters..
The difference with <code>confidence_thresholding</code> is that it uses two axes instead of three, not visualizing the threshold and having coverage as x axis instead of the threshold.</p>
<p>If the values of <code>subset</code> is <code>ground_truth</code>, then only datapoints where the ground truth class is within the top <code>n</code> most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed.
If the values of <code>subset</code> is <code>predictions</code>, then only datapoints where the the model predicts a class that is within the top <code>n</code> most frequent ones will be considered as test set, and the percentage of datapoints that have been kept from the original set will be displayed for each model.</p>
<p>The difference with <code>confidence_thresholding_data_vs_acc_subset</code> is that it produces one plot per class within the <code>top_n_classes</code>.</p>
<p><img alt="Confidence_Thresholding Data vs Accuracy Subset per class 1" src="../images/confidence_thresholding_data_vs_acc_subset_per_class_1.png" title="Confidence_Thresholding Data vs Accuracy Subset per class 1" /></p>
<p><img alt="Confidence_Thresholding Data vs Accuracy Subset per class 4" src="../images/confidence_thresholding_data_vs_acc_subset_per_class_4.png" title="Confidence_Thresholding Data vs Accuracy Subset per class 4" /></p>
<h4 id="confidence_thresholding_2thresholds_2d">confidence_thresholding_2thresholds_2d<a class="headerlink" href="#confidence_thresholding_2thresholds_2d" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>ground_truth_split</code></li>
<li><code>threshold_output_feature_names</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>threshold_output_feature_names</code> need to be exactly two, either category or binary.
<code>probabilities</code> need to be exactly two, aligned with <code>threshold_output_feature_names</code>.
<code>model_names</code> has to be exactly one.
Three plots are produced.</p>
<p>The first plot shows several semi transparent lines.
They summarize the 3d surfaces displayed by <code>confidence_thresholding_2thresholds_3d</code> that have thresholds on the confidence of the predictions of the two <code>threshold_output_feature_names</code> as x and y axes and either the data coverage percentage or the accuracy as z axis.
Each line represents a slice of the data coverage surface projected onto the accuracy surface.</p>
<p><img alt="Confidence_Thresholding two thresholds 2D Multiline" src="../images/confidence_thresholding_2thresholds_2d_multiline.png" title="Confidence_Thresholding two thresholds 2D Multiline" /></p>
<p>The second plot shows the max of all the lines displayed in the first plot.</p>
<p><img alt="Confidence_Thresholding two thresholds 2D Maxline" src="../images/confidence_thresholding_2thresholds_2d_maxline.png" title="Confidence_Thresholding two thresholds 2D Maxline" /></p>
<p>The third plot shows the max line and the values of the thresholds that obtained a specific data coverage vs accuracy pair of values.</p>
<p><img alt="Confidence_Thresholding two thresholds 2D Accuracy and Thresholds" src="../images/confidence_thresholding_2thresholds_2d_accthr.png" title="Confidence_Thresholding two thresholds 2D Accuracy and Thresholds" /></p>
<h4 id="confidence_thresholding_2thresholds_3d">confidence_thresholding_2thresholds_3d<a class="headerlink" href="#confidence_thresholding_2thresholds_3d" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>ground_truth_split</code></li>
<li><code>threshold_output_feature_names</code></li>
<li><code>probabilities</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>threshold_output_feature_names</code> need to be exactly two, either category or binary.
<code>probabilities</code> need to be exactly two, aligned with <code>threshold_output_feature_names</code>.
The plot shows the 3d surfaces displayed by <code>confidence_thresholding_2thresholds_3d</code> that have thresholds on the confidence of the predictions of the two <code>threshold_output_feature_names</code> as x and y axes and either the data coverage percentage or the accuracy as z axis.</p>
<p><img alt="Confidence_Thresholding two thresholds 3D" src="../images/confidence_thresholding_2thresholds_3d.png" title="Confidence_Thresholding two thresholds 3D" /></p>
<h3 id="binary-threshold-vs-metric">Binary Threshold vs. Metric<a class="headerlink" href="#binary-threshold-vs-metric" title="Permanent link">&para;</a></h3>
<h4 id="binary_threshold_vs_metric">binary_threshold_vs_metric<a class="headerlink" href="#binary_threshold_vs_metric" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>metrics</code></li>
<li><code>positive_label</code></li>
</ul>
<p><code>output_feature_name</code> can be a category or binary feature.
For each metric specified in <code>metrics</code> (options are <code>f1</code>, <code>precision</code>, <code>recall</code>, <code>accuracy</code>), this visualization produces a line chart plotting a threshold on the confidence of the model against the metric for the specified <code>output_feature_name</code>.
If <code>output_feature_name</code> is a category feature, <code>positive_label</code> indicates which is the class to be considered positive class and all the others will be considered negative.
It needs to be an integer, to figure out the association between classes and integers check the <code>ground_truth_metadata</code> JSON file.</p>
<p><img alt="Binary_Threshold_vs_Metric" src="../images/binary_threshold_vs_metric.png" title="Binary_Threshold_vs_Metric" /></p>
<h3 id="roc-curves">ROC Curves<a class="headerlink" href="#roc-curves" title="Permanent link">&para;</a></h3>
<h4 id="roc_curves">roc_curves<a class="headerlink" href="#roc_curves" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>positive_label</code></li>
</ul>
<p><code>output_feature_name</code> can be a category or binary feature.
This visualization produces a line chart plotting the roc curves for the specified <code>output_feature_name</code>.
If <code>output_feature_name</code> is a category feature, <code>positive_label</code> indicates which is the class to be considered positive class and all the others will be considered negative.
It needs to be an integer, to figure out the association between classes and integers check the <code>ground_truth_metadata</code> JSON file.</p>
<p><img alt="ROC Curves" src="../images/roc_curves.png" title="ROC Curves" /></p>
<h4 id="roc_curves_from_test_statistics">roc_curves_from_test_statistics<a class="headerlink" href="#roc_curves_from_test_statistics" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>test_statistics</code></li>
<li><code>model_names</code></li>
</ul>
<p><code>output_feature_name</code> needs to be binary feature.
This visualization produces a line chart plotting the roc curves for the specified <code>output_feature_name</code>.</p>
<p><img alt="ROC Curves from Prediction Statistics" src="../images/roc_curves_from_test_statistics.png" title="ROC Curves from Prediction Statistics" /></p>
<h3 id="calibration-plot">Calibration Plot<a class="headerlink" href="#calibration-plot" title="Permanent link">&para;</a></h3>
<h4 id="calibration_1_vs_all">calibration_1_vs_all<a class="headerlink" href="#calibration_1_vs_all" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>top_n_classes</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category or binary.
For each class or each of the <code>n</code> most frequent classes if <code>top_n_classes</code> is specified, it produces two plots computed on the fly from the probabilities of predictions for the specified <code>output_feature_name</code>.</p>
<p>The first plot is a calibration curve that shows the calibration of the predictions considering the current class to be the true one and all others to be a false one, drawing one line for each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>).</p>
<p><img alt="Calibration 1 vs All Curve" src="../images/calibration_1_vs_all_curve.png" title="Calibration 1 vs All Curve" /></p>
<p>The second plot shows the distributions of the predictions considering the current class to be the true one and all others to be a false one, drawing the distribution for each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>).</p>
<p><img alt="Calibration 1 vs All Counts" src="../images/calibration_1_vs_all_counts.png" title="Calibration 1 vs All Counts" /></p>
<h4 id="calibration_multiclass">calibration_multiclass<a class="headerlink" href="#calibration_multiclass" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth</code></li>
<li><code>split_file</code></li>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>ground_truth_split</code></li>
<li><code>probabilities</code></li>
<li><code>model_names</code></li>
<li><code>labels_limit</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each class, produces two plots computed on the fly from the probabilities of predictions for the specified <code>output_feature_name</code>.</p>
<p>The first plot is a calibration curve that shows the calibration of the predictions considering al classes, drawing one line for each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>).</p>
<p><img alt="Calibration Multiclass Curve" src="../images/calibration_multiclass_curve.png" title="Calibration Multiclass Curve" /></p>
<p>The second plot shows a bar plot of the brier score (that calculates how calibrated are the probabilities of the predictions of a model), drawing one bar for each model (in the aligned lists of <code>probabilities</code> and <code>model_names</code>).</p>
<p><img alt="Calibration Multiclass Brier" src="../images/calibration_multiclass_brier.png" title="Calibration Multiclass Brier" /></p>
<h3 id="class-frequency-vs-f1-score">Class Frequency vs. F1 score<a class="headerlink" href="#class-frequency-vs-f1-score" title="Permanent link">&para;</a></h3>
<h4 id="frequency_vs_f1">frequency_vs_f1<a class="headerlink" href="#frequency_vs_f1" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>ground_truth_metadata</code></li>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>output_feature_name</code></li>
<li><code>test_statistics</code></li>
<li><code>model_names</code></li>
<li><code>top_n_classes</code></li>
</ul>
<p><code>output_feature_name</code> needs to be a category.
For each model (in the aligned lists of <code>test_statistics</code> and <code>model_names</code>), produces two plots statistics of predictions for the specified <code>output_feature_name</code>.</p>
<p>Generates plots for <code>top_n_classes</code>.  The first plot is a line plot with one x axis representing the different classes and two vertical axes colored in orange and blue respectively.
The orange one is the frequency of the class and an orange line is plotted to show the trend.
The blue one is the F1 score for that class and a blue line is plotted to show the trend. 
The classes on the x axis are sorted by f1 score.</p>
<p><img alt="Frequency vs F1 sorted by F1" src="../images/freq_vs_f1_sorted_f1.png" title="Frequency vs F1 sorted by F1" /></p>
<p>The second plot has the same structure of the first one, but the axes are flipped and the classes on the x axis are sorted by frequency.</p>
<p><img alt="Frequency vs F1 sorted by Frequency" src="../images/freq_vs_f1_sorted_freq.png" title="Frequency vs F1 sorted by Frequency" /></p>
<h3 id="hyper-parameter-optimization-visualization">Hyper-parameter optimization visualization<a class="headerlink" href="#hyper-parameter-optimization-visualization" title="Permanent link">&para;</a></h3>
<p>The examples of the hyper-parameter visualizations shown here are obtained by running a random search with 100 samples on the <a href="https://www.kaggle.com/siddhadev/ms-cntk-atis">ATIS dataset</a> used for classifying intents given user utterances.</p>
<h4 id="hyperopt_report">hyperopt_report<a class="headerlink" href="#hyperopt_report" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>hyperopt_stats_path</code></li>
</ul>
<p>The visualization creates one plot for each hyper-parameter in the file at <code>hyperopt_stats_path</code>, plus an additional one containing a pair plot of hyper-parameters interactions.</p>
<p>Each plot will show the distribution of the parameters with respect to the metric to optimize.
For <code>float</code> and <code>int</code> parameters, a scatter plot is used, while for <code>category</code> parameters, a violin plot is used instead. </p>
<p><img alt="Float hyperopt plot" src="../images/hyperopt_float.png" title="Float hyperopt plot" /></p>
<p><img alt="Int hyperopt plot" src="../images/hyperopt_int.png" title="Int hyperopt plot" /></p>
<p><img alt="Category hyperopt plot" src="../images/hyperopt_category.png" title="Category hyperopt plot" /></p>
<p>The pair plot shows a heatmap of how the values of pairs of hyper-parameters correlate with the metric to optimize.</p>
<p><img alt="Pait hyperopt plot" src="../images/hyperopt_pair.png" title="Pait hyperopt plot" /></p>
<h4 id="hyperopt_hiplot">hyperopt_hiplot<a class="headerlink" href="#hyperopt_hiplot" title="Permanent link">&para;</a></h4>
<p>Parameters for this visualization: </p>
<ul>
<li><code>output_directory</code></li>
<li><code>file_format</code></li>
<li><code>hyperopt_stats_path</code></li>
</ul>
<p>The visualization creates an interactive HTML page visualizing all the results from the hyper-parameter optimization at once, using a parallel coordinate plot.</p>
<p><img alt="Hiplot hyperopt plot" src="../images/hyperopt_hiplot.jpeg" title="Hiplot hyperopt plot" /></p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

<!-- Application footer -->
<footer class="md-footer">

    <!-- Link to previous and/or next page -->
    
    <div class="md-footer-nav">
        <nav aria-label="Footer"
             class="md-footer-nav__inner md-grid">
            
            <a class="md-footer-nav__link md-footer-nav__link--prev"
               href="../examples/" rel="prev"
               title="Examples">
                <div class="md-footer-nav__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
                </div>
                <div class="md-footer-nav__title">
                    <div class="md-ellipsis">
                 <span class="md-footer-nav__direction">
                   Previous
                 </span>
                        Examples
                    </div>
                </div>
            </a>
            
            
            <a class="md-footer-nav__link md-footer-nav__link--next"
               href="../developer_guide/" rel="next"
               title="Developer Guide">
                <div class="md-footer-nav__title">
                    <div class="md-ellipsis">
                 <span class="md-footer-nav__direction">
                   Next
                 </span>
                        Developer Guide
                    </div>
                </div>
                <div class="md-footer-nav__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
                </div>
            </a>
            
        </nav>
    </div>
    

    <!-- Further information -->
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">

            <!-- Copyright and theme information -->
            <div class="md-footer-copyright">
                <div class="footer-logo-smallpad"></div>
                
                <div class="md-footer-copyright__highlight">
                    Copyright &copy; 2018 - 2020 Uber Technologies Inc.
                </div>
                
                Website by <a href="http://w4nderlu.st">w4nderlust</a> powered by
                <a href="https://www.mkdocs.org">MkDocs</a>,
                <a href="https://squidfunk.github.io/mkdocs-material/">Material for MkDocs</a>,
                <a href="http://www.styleshout.com/">styleshout</a> and
                <a href="http://cables.gl/">cables</a>.
            </div>

            <!-- Social links -->
            
            
            
        </div>
    </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.77e55a48.min.js"></script>
      <script src="../assets/javascripts/bundle.9554a270.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>