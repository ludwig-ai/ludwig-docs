
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
  
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Declarative machine learning: End-to-end machine learning pipelines using data-driven configurations.">
      
      
        <meta name="author" content="Piero Molino">
      
      
        <link rel="canonical" href="https://ludwig.ai/latest/configuration/features/text_features/">
      
      
        <link rel="prev" href="../sequence_features/">
      
      
        <link rel="next" href="../vector_features/">
      
      <link rel="icon" href="../../../favicon.ico">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.14">
    
  <meta content="http://raw.githubusercontent.com/ludwig-ai/ludwig-docs/master/docs/images/og-image.jpg"
    property="og:image">
  <meta content="https://raw.githubusercontent.com/ludwig-ai/ludwig-docs/master/docs/images/og-image.jpg"
    property="og:image:secure_url">

    
      
        <title>⇅ Text Features - Ludwig</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.113286f1.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../../stylesheets/monokai.css">
    
      <link rel="stylesheet" href="../../../stylesheets/colorful.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-H8VVJF9L6G"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-H8VVJF9L6G",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-H8VVJF9L6G",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>

  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="deep-orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#preprocessing" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Ludwig" class="md-header__button md-logo" aria-label="Ludwig" data-md-component="logo">
      
<img alt="logo" src="../../../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ludwig
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ⇅ Text Features
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
            </label>
          
        
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="grey" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ludwig-ai/ludwig" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ludwig-ai/ludwig
  </div>
</a>
      </div>
    
  </nav>
  
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Ludwig" class="md-nav__button md-logo" aria-label="Ludwig" data-md-component="logo">
      
<img alt="logo" src="../../../images/ludwig_logo.svg"
     style="height:1rem;width:4rem;">

    </a>
    Ludwig
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ludwig-ai/ludwig" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ludwig-ai/ludwig
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Ludwig
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../getting_started/">Getting Started</a>
          
            <label for="__nav_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Getting Started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/installation/" class="md-nav__link">
        Installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/prepare_data/" class="md-nav__link">
        Dataset preparation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/train/" class="md-nav__link">
        Training
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/evaluate/" class="md-nav__link">
        Prediction and Evaluation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/hyperopt/" class="md-nav__link">
        Hyperopt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/serve/" class="md-nav__link">
        Serving
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/ray/" class="md-nav__link">
        Distributed training on Ray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting_started/docker/" class="md-nav__link">
        Ludwig with Docker
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../user_guide/">User Guide</a>
          
            <label for="__nav_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/what_is_ludwig/" class="md-nav__link">
        What is Ludwig?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/how_ludwig_works/" class="md-nav__link">
        How Ludwig Works
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/command_line_interface/" class="md-nav__link">
        Command Line Interface
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
          Python API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          Python API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/api/LudwigModel/" class="md-nav__link">
        LudwigModel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/api/visualization/" class="md-nav__link">
        Visualization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
      
      
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
          Datasets
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_6">
          <span class="md-nav__icon md-icon"></span>
          Datasets
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/datasets/supported_formats/" class="md-nav__link">
        Supported Formats
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/datasets/data_preprocessing/" class="md-nav__link">
        Data Preprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/datasets/data_postprocessing/" class="md-nav__link">
        Data Postprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/datasets/dataset_zoo/" class="md-nav__link">
        Dataset Zoo
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/gpus/" class="md-nav__link">
        GPUs
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_8" >
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../user_guide/distributed_training/">Distributed Training</a>
          
            <label for="__nav_3_8">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_8">
          <span class="md-nav__icon md-icon"></span>
          Distributed Training
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/distributed_training/finetuning/" class="md-nav__link">
        Fine-Tuning Pretrained Models
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/hyperopt/" class="md-nav__link">
        Hyperparameter Optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/cloud_storage/" class="md-nav__link">
        Cloud Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/automl/" class="md-nav__link">
        AutoML
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/visualizations/" class="md-nav__link">
        Visualizations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/model_export/" class="md-nav__link">
        Model Export
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/serving/" class="md-nav__link">
        Serving
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../user_guide/integrations/" class="md-nav__link">
        Third-Party Integrations
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../">Configuration</a>
          
            <label for="__nav_4">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Configuration
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../model_type/" class="md-nav__link">
        Model Types
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../preprocessing/" class="md-nav__link">
        Preprocessing
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" checked>
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
          Features
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          Features
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../supported_data_types/" class="md-nav__link">
        Supported Data Types
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../input_features/" class="md-nav__link">
        Input Features (↑)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../output_features/" class="md-nav__link">
        Output Features (↓)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../binary_features/" class="md-nav__link">
        ⇅ Binary Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../number_features/" class="md-nav__link">
        ⇅ Number Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../category_features/" class="md-nav__link">
        ⇅ Category Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../bag_features/" class="md-nav__link">
        ⇅ Bag Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../set_features/" class="md-nav__link">
        ⇅ Set Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../sequence_features/" class="md-nav__link">
        ⇅ Sequence Features
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          ⇅ Text Features
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        ⇅ Text Features
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    Preprocessing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#input-features" class="md-nav__link">
    Input Features
  </a>
  
    <nav class="md-nav" aria-label="Input Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#encoders" class="md-nav__link">
    Encoders
  </a>
  
    <nav class="md-nav" aria-label="Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-cnn-encoder" class="md-nav__link">
    Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-cnn-encoder" class="md-nav__link">
    Stacked CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-parallel-cnn-encoder" class="md-nav__link">
    Stacked Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-encoder" class="md-nav__link">
    RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-rnn-encoder" class="md-nav__link">
    CNN RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-encoder" class="md-nav__link">
    Transformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#huggingface-encoders" class="md-nav__link">
    Huggingface encoders
  </a>
  
    <nav class="md-nav" aria-label="Huggingface encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autotransformer" class="md-nav__link">
    AutoTransformer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#albert" class="md-nav__link">
    ALBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bert" class="md-nav__link">
    BERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camembert" class="md-nav__link">
    CamemBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distilbert" class="md-nav__link">
    DistilBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#electra" class="md-nav__link">
    ELECTRA
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flaubert" class="md-nav__link">
    FlauBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt" class="md-nav__link">
    GPT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt2" class="md-nav__link">
    GPT2
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#longformer" class="md-nav__link">
    Longformer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roberta" class="md-nav__link">
    RoBERTa
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t5" class="md-nav__link">
    T5
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformerxl" class="md-nav__link">
    TransformerXL
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlmroberta" class="md-nav__link">
    XLMRoBERTa
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlnet" class="md-nav__link">
    XLNet
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#output-features" class="md-nav__link">
    Output Features
  </a>
  
    <nav class="md-nav" aria-label="Output Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#decoders" class="md-nav__link">
    Decoders
  </a>
  
    <nav class="md-nav" aria-label="Decoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#generator" class="md-nav__link">
    Generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tagger" class="md-nav__link">
    Tagger
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss" class="md-nav__link">
    Loss
  </a>
  
    <nav class="md-nav" aria-label="Loss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#softmax-cross-entropy" class="md-nav__link">
    Softmax Cross Entropy
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metrics" class="md-nav__link">
    Metrics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../vector_features/" class="md-nav__link">
        ⇅ Vector Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../audio_features/" class="md-nav__link">
        ↑ Audio Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../date_features/" class="md-nav__link">
        ↑ Date Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../h3_features/" class="md-nav__link">
        ↑ H3 Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../image_features/" class="md-nav__link">
        ↑ Image Features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../time_series_features/" class="md-nav__link">
        ↑ Time Series Features
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../defaults/" class="md-nav__link">
        Defaults
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../combiner/" class="md-nav__link">
        Combiner
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../trainer/" class="md-nav__link">
        Trainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../hyperparameter_optimization/" class="md-nav__link">
        Hyperopt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../backend/" class="md-nav__link">
        Backend
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../examples/">Examples</a>
          
            <label for="__nav_5">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/llm/" class="md-nav__link">
        Large Language Models (LLMs)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/text_classification/" class="md-nav__link">
        Text Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/adult_census_income/" class="md-nav__link">
        Tabular Data Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/mnist/" class="md-nav__link">
        Image Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/multimodal_classification/" class="md-nav__link">
        Multimodal Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/hyperopt/" class="md-nav__link">
        Hyperparameter Optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/gbm_fraud/" class="md-nav__link">
        GBMs in Ludwig
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
          Example Use Cases
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          Example Use Cases
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/ner_tagging/" class="md-nav__link">
        Named Entity Recognition Tagging
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/nlu/" class="md-nav__link">
        Natural Language Understanding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/machine_translation/" class="md-nav__link">
        Machine Translation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/seq2seq/" class="md-nav__link">
        Chit-Chat Dialogue Modeling through Sequence2Sequence
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/sentiment_analysis/" class="md-nav__link">
        Sentiment Analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/oneshot/" class="md-nav__link">
        One-shot Learning with Siamese Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/visual_qa/" class="md-nav__link">
        Visual Question Answering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/speech_recognition/" class="md-nav__link">
        Spoken Digit Speech Recognition
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/speaker_verification/" class="md-nav__link">
        Speaker Verification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/titanic/" class="md-nav__link">
        Binary Classification (Titanic)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/forecasting/" class="md-nav__link">
        Timeseries forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/weather/" class="md-nav__link">
        Timeseries forecasting (Weather)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/movie_ratings/" class="md-nav__link">
        Movie rating prediction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/multi_label/" class="md-nav__link">
        Multi-label classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/multi_task/" class="md-nav__link">
        Multi-Task Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/fuel_efficiency/" class="md-nav__link">
        Simple Regression - Fuel Efficiency Prediction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/fraud/" class="md-nav__link">
        Fraud Detection
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../developer_guide/">Developer Guide</a>
          
            <label for="__nav_6">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Developer Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/contributing/" class="md-nav__link">
        How to Contribute
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/codebase_structure/" class="md-nav__link">
        Codebase Structure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/api_annotations/" class="md-nav__link">
        Ludwig API Guarantees
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_an_encoder/" class="md-nav__link">
        Add an Encoder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_combiner/" class="md-nav__link">
        Add a Combiner
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_decoder/" class="md-nav__link">
        Add a Decoder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_feature_type/" class="md-nav__link">
        Add a Feature Type
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_metric/" class="md-nav__link">
        Add a Metric
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_loss_function/" class="md-nav__link">
        Add a Loss Function
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_tokenizer/" class="md-nav__link">
        Add a Tokenizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_hyperopt/" class="md-nav__link">
        Add a Hyperopt Algorithm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_pretrained_model/" class="md-nav__link">
        Add a Pretrained Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_an_integration/" class="md-nav__link">
        Add an Integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/add_a_dataset/" class="md-nav__link">
        Add a Dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/style_guidelines_and_tests/" class="md-nav__link">
        Style Guidelines and Tests
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/unit_test_design_guidelines/" class="md-nav__link">
        Unit Test Design Guidelines
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/run_tests_on_gpu_using_ray/" class="md-nav__link">
        Run Tests on GPU Using Ray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer_guide/release_process/" class="md-nav__link">
        Release Process
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../community/" class="md-nav__link">
        Community
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../faq/" class="md-nav__link">
        FAQ
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    Preprocessing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#input-features" class="md-nav__link">
    Input Features
  </a>
  
    <nav class="md-nav" aria-label="Input Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#encoders" class="md-nav__link">
    Encoders
  </a>
  
    <nav class="md-nav" aria-label="Encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-encoder" class="md-nav__link">
    Embed Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallel-cnn-encoder" class="md-nav__link">
    Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-cnn-encoder" class="md-nav__link">
    Stacked CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacked-parallel-cnn-encoder" class="md-nav__link">
    Stacked Parallel CNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-encoder" class="md-nav__link">
    RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-rnn-encoder" class="md-nav__link">
    CNN RNN Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-encoder" class="md-nav__link">
    Transformer Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#huggingface-encoders" class="md-nav__link">
    Huggingface encoders
  </a>
  
    <nav class="md-nav" aria-label="Huggingface encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autotransformer" class="md-nav__link">
    AutoTransformer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#albert" class="md-nav__link">
    ALBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bert" class="md-nav__link">
    BERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camembert" class="md-nav__link">
    CamemBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distilbert" class="md-nav__link">
    DistilBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#electra" class="md-nav__link">
    ELECTRA
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flaubert" class="md-nav__link">
    FlauBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt" class="md-nav__link">
    GPT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt2" class="md-nav__link">
    GPT2
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#longformer" class="md-nav__link">
    Longformer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roberta" class="md-nav__link">
    RoBERTa
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t5" class="md-nav__link">
    T5
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformerxl" class="md-nav__link">
    TransformerXL
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlmroberta" class="md-nav__link">
    XLMRoBERTa
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xlnet" class="md-nav__link">
    XLNet
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#output-features" class="md-nav__link">
    Output Features
  </a>
  
    <nav class="md-nav" aria-label="Output Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#decoders" class="md-nav__link">
    Decoders
  </a>
  
    <nav class="md-nav" aria-label="Decoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#generator" class="md-nav__link">
    Generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tagger" class="md-nav__link">
    Tagger
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss" class="md-nav__link">
    Loss
  </a>
  
    <nav class="md-nav" aria-label="Loss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#softmax-cross-entropy" class="md-nav__link">
    Softmax Cross Entropy
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metrics" class="md-nav__link">
    Metrics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>⇅ Text Features</h1>

<h2 id="preprocessing">Preprocessing<a class="headerlink" href="#preprocessing" title="Permanent link">&para;</a></h2>
<p>Text features are an extension of <a href="../sequence_features">sequence features</a>. Text inputs are processed by a tokenizer
which maps the raw text input into a sequence of tokens. An integer id is assigned to each unique token. Using this
mapping, each text string is converted first to a sequence of tokens, and next to a sequence of integers.</p>
<p>The list of tokens and their integer representations (vocabulary) is stored in the metadata of the model. In the case of
a text output feature, this same mapping is used to post-process predictions to text.</p>
<div class="highlight"><pre><span></span><code><span class="nt">preprocessing</span><span class="p">:</span>
<span class="w">    </span><span class="nt">tokenizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">space_punct</span>
<span class="w">    </span><span class="nt">max_sequence_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">missing_value_strategy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fill_with_const</span>
<span class="w">    </span><span class="nt">most_common</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20000</span>
<span class="w">    </span><span class="nt">lowercase</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">ngram_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">padding_symbol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;PAD&gt;</span>
<span class="w">    </span><span class="nt">unknown_symbol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;UNK&gt;</span>
<span class="w">    </span><span class="nt">padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">right</span>
<span class="w">    </span><span class="nt">fill_value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;UNK&gt;</span>
<span class="w">    </span><span class="nt">cache_encoder_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">vocab_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">sequence_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>tokenizer</code></strong> (default: <code>space_punct</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Defines how to map from the raw string content of the dataset column to a sequence of elements. Options: <code>space</code>, <code>space_punct</code>, <code>ngram</code>, <code>characters</code>, <code>underscore</code>, <code>comma</code>, <code>untokenized</code>, <code>stripped</code>, <code>english_tokenize</code>, <code>english_tokenize_filter</code>, <code>english_tokenize_remove_stopwords</code>, <code>english_lemmatize</code>, <code>english_lemmatize_filter</code>, <code>english_lemmatize_remove_stopwords</code>, <code>italian_tokenize</code>, <code>italian_tokenize_filter</code>, <code>italian_tokenize_remove_stopwords</code>, <code>italian_lemmatize</code>, <code>italian_lemmatize_filter</code>, <code>italian_lemmatize_remove_stopwords</code>, <code>spanish_tokenize</code>, <code>spanish_tokenize_filter</code>, <code>spanish_tokenize_remove_stopwords</code>, <code>spanish_lemmatize</code>, <code>spanish_lemmatize_filter</code>, <code>spanish_lemmatize_remove_stopwords</code>, <code>german_tokenize</code>, <code>german_tokenize_filter</code>, <code>german_tokenize_remove_stopwords</code>, <code>german_lemmatize</code>, <code>german_lemmatize_filter</code>, <code>german_lemmatize_remove_stopwords</code>, <code>french_tokenize</code>, <code>french_tokenize_filter</code>, <code>french_tokenize_remove_stopwords</code>, <code>french_lemmatize</code>, <code>french_lemmatize_filter</code>, <code>french_lemmatize_remove_stopwords</code>, <code>portuguese_tokenize</code>, <code>portuguese_tokenize_filter</code>, <code>portuguese_tokenize_remove_stopwords</code>, <code>portuguese_lemmatize</code>, <code>portuguese_lemmatize_filter</code>, <code>portuguese_lemmatize_remove_stopwords</code>, <code>dutch_tokenize</code>, <code>dutch_tokenize_filter</code>, <code>dutch_tokenize_remove_stopwords</code>, <code>dutch_lemmatize</code>, <code>dutch_lemmatize_filter</code>, <code>dutch_lemmatize_remove_stopwords</code>, <code>greek_tokenize</code>, <code>greek_tokenize_filter</code>, <code>greek_tokenize_remove_stopwords</code>, <code>greek_lemmatize</code>, <code>greek_lemmatize_filter</code>, <code>greek_lemmatize_remove_stopwords</code>, <code>norwegian_tokenize</code>, <code>norwegian_tokenize_filter</code>, <code>norwegian_tokenize_remove_stopwords</code>, <code>norwegian_lemmatize</code>, <code>norwegian_lemmatize_filter</code>, <code>norwegian_lemmatize_remove_stopwords</code>, <code>lithuanian_tokenize</code>, <code>lithuanian_tokenize_filter</code>, <code>lithuanian_tokenize_remove_stopwords</code>, <code>lithuanian_lemmatize</code>, <code>lithuanian_lemmatize_filter</code>, <code>lithuanian_lemmatize_remove_stopwords</code>, <code>danish_tokenize</code>, <code>danish_tokenize_filter</code>, <code>danish_tokenize_remove_stopwords</code>, <code>danish_lemmatize</code>, <code>danish_lemmatize_filter</code>, <code>danish_lemmatize_remove_stopwords</code>, <code>polish_tokenize</code>, <code>polish_tokenize_filter</code>, <code>polish_tokenize_remove_stopwords</code>, <code>polish_lemmatize</code>, <code>polish_lemmatize_filter</code>, <code>polish_lemmatize_remove_stopwords</code>, <code>romanian_tokenize</code>, <code>romanian_tokenize_filter</code>, <code>romanian_tokenize_remove_stopwords</code>, <code>romanian_lemmatize</code>, <code>romanian_lemmatize_filter</code>, <code>romanian_lemmatize_remove_stopwords</code>, <code>japanese_tokenize</code>, <code>japanese_tokenize_filter</code>, <code>japanese_tokenize_remove_stopwords</code>, <code>japanese_lemmatize</code>, <code>japanese_lemmatize_filter</code>, <code>japanese_lemmatize_remove_stopwords</code>, <code>chinese_tokenize</code>, <code>chinese_tokenize_filter</code>, <code>chinese_tokenize_remove_stopwords</code>, <code>chinese_lemmatize</code>, <code>chinese_lemmatize_filter</code>, <code>chinese_lemmatize_remove_stopwords</code>, <code>multi_tokenize</code>, <code>multi_tokenize_filter</code>, <code>multi_tokenize_remove_stopwords</code>, <code>multi_lemmatize</code>, <code>multi_lemmatize_filter</code>, <code>multi_lemmatize_remove_stopwords</code>, <code>sentencepiece</code>, <code>clip</code>, <code>gpt2bpe</code>, <code>bert</code>, <code>hf_tokenizer</code>.</li>
<li><strong><code>max_sequence_length</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The maximum length (number of tokens) of the sequence. Sequences that are longer than this value will be truncated. Useful as a stopgap measure if <code>sequence_length</code> is set to <code>None</code>. If <code>None</code>, max sequence length will be inferred from the training dataset.</li>
<li><strong><code>missing_value_strategy</code></strong> (default: <code>fill_with_const</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: What strategy to follow when there's a missing value in a text column. Options: <code>fill_with_const</code>, <code>fill_with_mode</code>, <code>bfill</code>, <code>ffill</code>, <code>drop_row</code>. See <a href="../input_features/#missing-value-strategy">Missing Value Strategy</a> for details.</li>
<li><strong><code>most_common</code></strong> (default: <code>20000</code>): The maximum number of most common tokens in the vocabulary. If the data contains more than this amount, the most infrequent symbols will be treated as unknown.</li>
<li><strong><code>lowercase</code></strong> (default: <code>true</code>): If true, converts the string to lowercase before tokenizing. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>ngram_size</code></strong> (default: <code>2</code>): The size of the ngram when using the <code>ngram</code> tokenizer (e.g, 2 = bigram, 3 = trigram, etc.).</li>
<li><strong><code>padding_symbol</code></strong> (default: <code>&lt;PAD&gt;</code>): The string used as the padding symbol for sequence features. Ignored for features using huggingface encoders, which have their own vocabulary.</li>
<li><strong><code>unknown_symbol</code></strong> (default: <code>&lt;UNK&gt;</code>): The string used as the unknown symbol for sequence features. Ignored for features using huggingface encoders, which have their own vocabulary.</li>
<li><strong><code>padding</code></strong> (default: <code>right</code>): The direction of the padding. Options: <code>left</code>, <code>right</code>.</li>
<li><strong><code>fill_value</code></strong> (default: <code>&lt;UNK&gt;</code>): The value to replace missing values with in case the <code>missing_value_strategy</code> is <code>fill_with_const</code>.</li>
<li>
<p><strong><code>cache_encoder_embeddings</code></strong> (default: <code>false</code>): For pretrained encoders, compute encoder embeddings in preprocessing, speeding up training time considerably. Only supported when <code>encoder.trainable=false</code>. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li>
<p><strong><code>vocab_file</code></strong> (default: <code>null</code>): Filepath string to a UTF-8 encoded file containing the sequence's vocabulary. On each line the first string until <code>\t</code> or <code>\n</code> is considered a word.</p>
</li>
<li><strong><code>sequence_length</code></strong> (default: <code>null</code>): The desired length (number of tokens) of the sequence. Sequences that are longer than this value will be truncated and sequences shorter than this value will be padded. If None, sequence length will be inferred from the training dataset.</li>
</ul>
<p>Preprocessing parameters can also be defined once and applied to all text input features using the <a href="../../defaults/#type-global-preprocessing">Type-Global Preprocessing</a> section.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a text feature's encoder specifies a huggingface model, then the tokenizer for that model will be used
automatically.</p>
</div>
<h2 id="input-features">Input Features<a class="headerlink" href="#input-features" title="Permanent link">&para;</a></h2>
<p>The encoder parameters specified at the feature level are:</p>
<ul>
<li><strong><code>tied</code></strong> (default <code>null</code>): name of another input feature to tie the weights of the encoder with. It needs to be the name of
a feature of the same type and with the same encoder parameters.</li>
</ul>
<p>Example text feature entry in the input features list:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span>
<span class="nt">tied</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bert</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>type</code></strong> (default <code>parallel_cnn</code>): encoder to use for the input text feature. The available encoders include encoders
used for <a href="../sequence_features#sequence-input-features-and-encoders">Sequence Features</a> as well as pre-trained text
encoders from the
face transformers library: <code>albert</code>, <code>auto_transformer</code>, <code>bert</code>, <code>camembert</code>, <code>ctrl</code>,
<code>distilbert</code>, <code>electra</code>, <code>flaubert</code>, <code>gpt</code>, <code>gpt2</code>, <code>longformer</code>, <code>roberta</code>, <code>t5</code>, <code>mt5</code>, <code>transformer_xl</code>, <code>xlm</code>,
<code>xlmroberta</code>, <code>xlnet</code>.</li>
</ul>
<p>Encoder type and encoder parameters can also be defined once and applied to all text input features using
the <a href="../../defaults/#type-global-encoder">Type-Global Encoder</a> section.</p>
<h3 id="encoders">Encoders<a class="headerlink" href="#encoders" title="Permanent link">&para;</a></h3>
<h4 id="embed-encoder">Embed Encoder<a class="headerlink" href="#embed-encoder" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["12\n7\n43\n65\n23\n4\n1"] --&gt; B["emb_12\nemb__7\nemb_43\nemb_65\nemb_23\nemb__4\nemb__1"];
  B --&gt; C["Aggregation\n Reduce\n Operation"];
  C --&gt; ...;</code></pre></p>
<p>The embed encoder simply maps each token in the input sequence to an embedding, creating a <code>b x s x h</code> tensor where <code>b</code>
is the batch size, <code>s</code> is the length of the sequence and <code>h</code> is the embedding size.
The tensor is reduced along the <code>s</code> dimension to obtain a single vector of size <code>h</code> for each element of the batch.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">embed</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">uniform</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">embeddings_on_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">pretrained_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate applied to the embedding. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>embedding_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The maximum embedding size. The actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><strong><code>representation</code></strong> (default: <code>dense</code>): Representation of the embedding. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings. Options: <code>dense</code>, <code>sparse</code>.</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>reduce_output</code></strong> (default: <code>sum</code>): How to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</p>
</li>
<li><strong><code>embeddings_on_cpu</code></strong> (default: <code>false</code>): Whether to force the placement of the embedding matrix in regular memory and have the CPU resolve them. By default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>embeddings_trainable</code></strong> (default: <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code>; <code>sparse</code> one-hot encodings are not trainable. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li>
<p><strong><code>pretrained_embeddings</code></strong> (default: <code>null</code>): Path to a file containing pretrained embeddings. By default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</p>
</li>
</ul>
<h4 id="parallel-cnn-encoder">Parallel CNN Encoder<a class="headerlink" href="#parallel-cnn-encoder" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["12\n7\n43\n65\n23\n4\n1"] --&gt; C["emb_12\nemb__7\nemb_43\nemb_65\nemb_23\nemb__4\nemb__1"];
  C --&gt; D1["1D Conv\n Width 2"] --&gt; E1["Pool"];
  C --&gt; D2["1D Conv\n Width 3"] --&gt; E2["Pool"];
  C --&gt; D3["1D Conv\n Width 4"] --&gt; E3["Pool"];
  C --&gt; D4["1D Conv\n Width 5"] --&gt; E4["Pool"];
  E1 --&gt; F["Concat"] --&gt; G["Fully\n Connected\n Layers"] --&gt; H["..."];
  E2 --&gt; F;
  E3 --&gt; F;
  E4 --&gt; F;</code></pre></p>
<p>The parallel cnn encoder is inspired by
<a href="https://arxiv.org/abs/1408.5882">Yoon Kim's Convolutional Neural Network for Sentence Classification</a>.
It works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the
sequence) into a sequence of embeddings, then it passes the embedding through a number of parallel 1d convolutional
layers with different filter size (by default 4 layers with filter size 2, 3, 4 and 5), followed by max pooling and
concatenation.
This single vector concatenating the outputs of the parallel convolutional layers is then passed through a stack of
fully connected layers and returned as a <code>b x h</code> tensor where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">parallel_cnn</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">num_conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">embeddings_on_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="w">    </span><span class="nt">pool_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">pretrained_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate applied to the embedding. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>embedding_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The maximum embedding size. The actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><strong><code>num_conv_layers</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The number of stacked convolutional layers when <code>conv_layers</code> is <code>null</code>.</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default output_size that will be used for each layer.</li>
<li><strong><code>activation</code></strong> (default: <code>relu</code>): The default activation function that will be used for each layer. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>filter_size</code></strong> (default: <code>3</code>): Size of the 1d convolutional filter. It indicates how wide the 1d convolutional filter is.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>): The default norm that will be used for each layer. Options: <code>batch</code>, <code>layer</code>, <code>null</code>.</li>
<li><strong><code>representation</code></strong> (default: <code>dense</code>): Representation of the embedding. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings. Options: <code>dense</code>, <code>sparse</code>.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether to use a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>embeddings_on_cpu</code></strong> (default: <code>false</code>): Whether to force the placement of the embedding matrix in regular memory and have the CPU resolve them. By default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li><strong><code>embeddings_trainable</code></strong> (default: <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code>; <code>sparse</code> one-hot encodings are not trainable. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): How to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
<li>
<p><strong><code>conv_layers</code></strong> (default: <code>null</code>): 
A list of dictionaries containing the parameters of all the convolutional layers.
The length of the list determines the number of stacked convolutional layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>num_filters</code>, <code>filter_size</code>, <code>strides</code>, <code>padding</code>, <code>dilation_rate</code>, <code>use_bias</code>, <code>pool_function</code>,
<code>pool_padding</code>, <code>pool_size</code>, <code>pool_strides</code>, <code>bias_initializer</code>, <code>weights_initializer</code>. If any of those values is
missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value
<code>[{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null},
{filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}]</code>.</p>
</li>
<li>
<p><strong><code>pool_function</code></strong> (default: <code>max</code>): Pooling function to use. <code>max</code> will select the maximum value. Any of <code>average</code>, <code>avg</code>, or <code>mean</code> will compute the mean value Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</p>
</li>
<li><strong><code>pool_size</code></strong> (default: <code>null</code>): The default pool_size that will be used for each layer. If a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><strong><code>norm_params</code></strong> (default: <code>null</code>): Parameters used if norm is either <code>batch</code> or <code>layer</code>.</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>null</code>): Number of parallel fully connected layers to use.</li>
<li>
<p><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters for each fully connected layer.</p>
</li>
<li>
<p><strong><code>pretrained_embeddings</code></strong> (default: <code>null</code>): Path to a file containing pretrained embeddings. By default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</p>
</li>
<li><strong><code>num_filters</code></strong> (default: <code>256</code>): Number of filters, and by consequence number of output channels of the 1d convolution.</li>
</ul>
<h4 id="stacked-cnn-encoder">Stacked CNN Encoder<a class="headerlink" href="#stacked-cnn-encoder" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["12\n7\n43\n65\n23\n4\n1"] --&gt; B["emb_12\nemb__7\nemb_43\nemb_65\nemb_23\nemb__4\nemb__1"];
  B --&gt; C["1D Conv Layers\n Different Widths"];
  C --&gt; D["Fully\n Connected\n Layers"];
  D --&gt; ...;</code></pre></p>
<p>The stacked cnn encoder is inspired by <a href="https://arxiv.org/abs/1509.01626">Xiang Zhang at all's Character-level Convolutional Networks for Text Classification</a>.
It works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the
sequence) into a sequence of embeddings, then it passes the embedding through a stack of 1d convolutional layers with
different filter size (by default 6 layers with filter size 7, 7, 3, 3, 3 and 3), followed by an optional final pool and
by a flatten operation.
This single flatten vector is then passed through a stack of fully connected layers and returned as a <code>b x h</code> tensor
where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify the <code>pool_size</code> of all your <code>conv_layers</code> to be
<code>null</code>  and <code>reduce_output: null</code>, while if <code>pool_size</code> has a value different from <code>null</code> and <code>reduce_output: null</code> the
returned tensor will be of shape <code>b x s' x h</code>, where <code>s'</code> is width of the output of the last convolutional layer.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">stacked_cnn</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">num_conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">    </span><span class="nt">strides</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">    </span><span class="nt">conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="w">    </span><span class="nt">pool_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">dilation_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">pool_strides</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">pool_padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">same</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">embeddings_on_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">same</span>
<span class="w">    </span><span class="nt">pretrained_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate applied to the embedding. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>num_conv_layers</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The number of stacked convolutional layers when <code>conv_layers</code> is <code>null</code>.</li>
<li><strong><code>embedding_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The maximum embedding size. The actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default output_size that will be used for each layer.</li>
<li><strong><code>activation</code></strong> (default: <code>relu</code>): The default activation function that will be used for each layer. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>filter_size</code></strong> (default: <code>3</code>): Size of the 1d convolutional filter. It indicates how wide the 1d convolutional filter is.</li>
<li><strong><code>strides</code></strong> (default: <code>1</code>): Stride length of the convolution.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>): The default norm that will be used for each layer. Options: <code>batch</code>, <code>layer</code>, <code>null</code>.</li>
<li><strong><code>representation</code></strong> (default: <code>dense</code>): Representation of the embedding. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings. Options: <code>dense</code>, <code>sparse</code>.</li>
<li>
<p><strong><code>conv_layers</code></strong> (default: <code>null</code>): 
A list of dictionaries containing the parameters of all the convolutional layers.
The length of the list determines the number of stacked convolutional layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>num_filters</code>, <code>filter_size</code>, <code>strides</code>, <code>padding</code>, <code>dilation_rate</code>, <code>use_bias</code>, <code>pool_function</code>,
<code>pool_padding</code>, <code>pool_size</code>, <code>pool_strides</code>, <code>bias_initializer</code>, <code>weights_initializer</code>. If any of those values is
missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value
<code>[{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null},
{filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}]</code>.</p>
</li>
<li>
<p><strong><code>pool_function</code></strong> (default: <code>max</code>): Pooling function to use. <code>max</code> will select the maximum value. Any of <code>average</code>, <code>avg</code>, or <code>mean</code> will compute the mean value Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</p>
</li>
<li><strong><code>pool_size</code></strong> (default: <code>null</code>): The default pool_size that will be used for each layer. If a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><strong><code>dilation_rate</code></strong> (default: <code>1</code>): Dilation rate to use for dilated convolution.</li>
<li><strong><code>pool_strides</code></strong> (default: <code>null</code>): Factor to scale down.</li>
<li><strong><code>pool_padding</code></strong> (default: <code>same</code>): Padding to use. Options: <code>valid</code>, <code>same</code>.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether to use a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>embeddings_on_cpu</code></strong> (default: <code>false</code>): Whether to force the placement of the embedding matrix in regular memory and have the CPU resolve them. By default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li><strong><code>embeddings_trainable</code></strong> (default: <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code>; <code>sparse</code> one-hot encodings are not trainable. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): How to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
<li><strong><code>norm_params</code></strong> (default: <code>null</code>): Parameters used if norm is either <code>batch</code> or <code>layer</code>.</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>null</code>): Number of parallel fully connected layers to use.</li>
<li>
<p><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters for each fully connected layer.</p>
</li>
<li>
<p><strong><code>num_filters</code></strong> (default: <code>256</code>): Number of filters, and by consequence number of output channels of the 1d convolution.</p>
</li>
<li>
<p><strong><code>padding</code></strong> (default: <code>same</code>): Padding to use. Options: <code>valid</code>, <code>same</code>.</p>
</li>
<li>
<p><strong><code>pretrained_embeddings</code></strong> (default: <code>null</code>): Path to a file containing pretrained embeddings. By default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</p>
</li>
</ul>
<h4 id="stacked-parallel-cnn-encoder">Stacked Parallel CNN Encoder<a class="headerlink" href="#stacked-parallel-cnn-encoder" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["12\n7\n43\n65\n23\n4\n1"] --&gt; C["emb_12\nemb__7\nemb_43\nemb_65\nemb_23\nemb__4\nemb__1"];
  C --&gt; D1["1D Conv\n Width 2"] --&gt; E["Concat"];
  C --&gt; D2["1D Conv\n Width 3"] --&gt; E;
  C --&gt; D3["1D Conv\n Width 4"] --&gt; E;
  C --&gt; D4["1D Conv\n Width 5"] --&gt; E;
  E --&gt; F["..."];
  F --&gt; G1["1D Conv\n Width 2"] --&gt; H["Concat"];
  F --&gt; G2["1D Conv\n Width 3"] --&gt; H;
  F --&gt; G3["1D Conv\n Width 4"] --&gt; H;
  F --&gt; G4["1D Conv\n Width 5"] --&gt; H;
  H --&gt; I["Pool"] --&gt; J["Fully\n Connected\n Layers"] --&gt; K["..."];</code></pre></p>
<p>The stacked parallel cnn encoder is a combination of the Parallel CNN and the Stacked CNN encoders where each layer of
the stack is composed of parallel convolutional layers.
It works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the length of the
sequence) into a sequence of embeddings, then it passes the embedding through a stack of several parallel 1d
convolutional layers with different filter size, followed by an optional final pool and by a flatten operation.
This single flattened vector is then passed through a stack of fully connected layers and returned as a <code>b x h</code> tensor
where <code>h</code> is the output size of the last fully connected layer.
If you want to output the full <code>b x s x h</code> tensor, you can specify <code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">stacked_parallel_cnn</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">    </span><span class="nt">num_stacked_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="w">    </span><span class="nt">pool_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">embeddings_on_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">stacked_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">pretrained_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate applied to the embedding. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>embedding_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The maximum embedding size. The actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default output_size that will be used for each layer.</li>
<li><strong><code>activation</code></strong> (default: <code>relu</code>): The default activation function that will be used for each layer. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>filter_size</code></strong> (default: <code>3</code>): Size of the 1d convolutional filter. It indicates how wide the 1d convolutional filter is.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>): The default norm that will be used for each layer. Options: <code>batch</code>, <code>layer</code>, <code>null</code>.</li>
<li><strong><code>representation</code></strong> (default: <code>dense</code>): Representation of the embedding. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings. Options: <code>dense</code>, <code>sparse</code>.</li>
<li><strong><code>num_stacked_layers</code></strong> (default: <code>null</code>): If stacked_layers is null, this is the number of elements in the stack of parallel convolutional layers. </li>
<li><strong><code>pool_function</code></strong> (default: <code>max</code>): Pooling function to use. <code>max</code> will select the maximum value. Any of <code>average</code>, <code>avg</code>, or <code>mean</code> will compute the mean value Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
<li><strong><code>pool_size</code></strong> (default: <code>null</code>): The default pool_size that will be used for each layer. If a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether to use a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>embeddings_on_cpu</code></strong> (default: <code>false</code>): Whether to force the placement of the embedding matrix in regular memory and have the CPU resolve them. By default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li><strong><code>embeddings_trainable</code></strong> (default: <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code>; <code>sparse</code> one-hot encodings are not trainable. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): How to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
<li><strong><code>norm_params</code></strong> (default: <code>null</code>): Parameters used if norm is either <code>batch</code> or <code>layer</code>.</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>null</code>): Number of parallel fully connected layers to use.</li>
<li>
<p><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters for each fully connected layer.</p>
</li>
<li>
<p><strong><code>stacked_layers</code></strong> (default: <code>null</code>): a nested list of lists of dictionaries containing the parameters of the stack of parallel convolutional layers. The length of the list determines the number of stacked parallel convolutional layers, length of the sub-lists determines the number of parallel conv layers and the content of each dictionary determines the parameters for a specific layer. </p>
</li>
<li>
<p><strong><code>num_filters</code></strong> (default: <code>256</code>): Number of filters, and by consequence number of output channels of the 1d convolution.</p>
</li>
<li>
<p><strong><code>pretrained_embeddings</code></strong> (default: <code>null</code>): Path to a file containing pretrained embeddings. By default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</p>
</li>
</ul>
<h4 id="rnn-encoder">RNN Encoder<a class="headerlink" href="#rnn-encoder" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["12\n7\n43\n65\n23\n4\n1"] --&gt; B["emb_12\nemb__7\nemb_43\nemb_65\nemb_23\nemb__4\nemb__1"];
  B --&gt; C["RNN Layers"];
  C --&gt; D["Fully\n Connected\n Layers"];
  D --&gt; ...;</code></pre></p>
<p>The rnn encoder works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is the
length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of recurrent layers
(by default 1 layer), followed by a reduce operation that by default only returns the last output, but can perform other
reduce functions.
If you want to output the full <code>b x s x h</code> where <code>h</code> is the size of the output of the last rnn layer, you can specify
<code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">cell_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">state_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">recurrent_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tanh</span>
<span class="w">    </span><span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">recurrent_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sigmoid</span>
<span class="w">    </span><span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">    </span><span class="nt">unit_forget_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">recurrent_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">orthogonal</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">embeddings_on_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">last</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">bidirectional</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>cell_type</code></strong> (default: <code>rnn</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>gru</code>. For reference about the differences between the cells please refer to <a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers">torch.nn Recurrent Layers</a>. Options: <code>rnn</code>, <code>lstm</code>, <code>gru</code>.</li>
<li><strong><code>num_layers</code></strong> (default: <code>1</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The number of stacked recurrent layers.</li>
<li><strong><code>state_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The size of the state of the rnn.</li>
<li><strong><code>embedding_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The maximum embedding size. The actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default output_size that will be used for each layer.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default norm that will be used for each layer. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>.</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Number of parallel fully connected layers to use. Increasing layers adds capacity to the model, enabling it to learn more complex feature interactions.</li>
<li><strong><code>fc_dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>recurrent_dropout</code></strong> (default: <code>0.0</code>): The dropout rate for the recurrent state</li>
<li><strong><code>activation</code></strong> (default: <code>tanh</code>): The default activation function. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>fc_activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>recurrent_activation</code></strong> (default: <code>sigmoid</code>): The activation function to use in the recurrent step Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>representation</code></strong> (default: <code>dense</code>): Representation of the embedding. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings. Options: <code>dense</code>, <code>sparse</code>.</li>
<li><strong><code>unit_forget_bias</code></strong> (default: <code>true</code>): If true, add 1 to the bias of the forget gate at initialization Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>recurrent_initializer</code></strong> (default: <code>orthogonal</code>): The initializer for recurrent matrix weights Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether to use a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>embeddings_on_cpu</code></strong> (default: <code>false</code>): Whether to force the placement of the embedding matrix in regular memory and have the CPU resolve them. By default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li><strong><code>embeddings_trainable</code></strong> (default: <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code>; <code>sparse</code> one-hot encodings are not trainable. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>last</code>): How to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
<li><strong><code>norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module.</li>
<li>
<p><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</p>
</li>
<li>
<p><strong><code>bidirectional</code></strong> (default: <code>false</code>): If true, two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li>
<p><strong><code>pretrained_embeddings</code></strong> (default: <code>null</code>): Path to a file containing pretrained embeddings. By default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</p>
</li>
</ul>
<h4 id="cnn-rnn-encoder">CNN RNN Encoder<a class="headerlink" href="#cnn-rnn-encoder" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["12\n7\n43\n65\n23\n4\n1"] --&gt; B["emb_12\nemb__7\nemb_43\nemb_65\nemb_23\nemb__4\nemb__1"];
  B --&gt; C1["CNN Layers"];
  C1 --&gt; C2["RNN Layers"];
  C2 --&gt; D["Fully\n Connected\n Layers"];
  D --&gt; ...;</code></pre></p>
<p>The <code>cnnrnn</code> encoder works by first mapping the input token sequence <code>b x s</code> (where <code>b</code> is the batch size and <code>s</code> is
the length of the sequence) into a sequence of embeddings, then it passes the embedding through a stack of convolutional
layers (by default 2), that is followed by a stack of recurrent layers (by default 1), followed by a reduce operation
that by default only returns the last output, but can perform other reduce functions.
If you want to output the full <code>b x s x h</code> where <code>h</code> is the size of the output of the last rnn layer, you can specify
<code>reduce_output: null</code>.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cnnrnn</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">conv_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">cell_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="w">    </span><span class="nt">num_conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">state_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">recurrent_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tanh</span>
<span class="w">    </span><span class="nt">filter_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">    </span><span class="nt">strides</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">recurrent_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sigmoid</span>
<span class="w">    </span><span class="nt">conv_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">    </span><span class="nt">conv_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">pool_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">max</span>
<span class="w">    </span><span class="nt">pool_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">dilation_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">pool_strides</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">pool_padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">same</span>
<span class="w">    </span><span class="nt">unit_forget_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">recurrent_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">orthogonal</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">embeddings_on_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">last</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_filters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">same</span>
<span class="w">    </span><span class="nt">num_rec_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">bidirectional</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Dropout rate. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>conv_dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The dropout rate for the convolutional layers</li>
<li><strong><code>cell_type</code></strong> (default: <code>rnn</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The type of recurrent cell to use. Available values are: <code>rnn</code>, <code>lstm</code>, <code>gru</code>. For reference about the differences between the cells please refer to <a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers">torch.nn Recurrent Layers</a>. Options: <code>rnn</code>, <code>lstm</code>, <code>gru</code>.</li>
<li><strong><code>num_conv_layers</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The number of stacked convolutional layers when <code>conv_layers</code> is <code>null</code>.</li>
<li><strong><code>state_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The size of the state of the rnn.</li>
<li><strong><code>embedding_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The maximum embedding size. The actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default output_size that will be used for each layer.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default norm that will be used for each layer. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>.</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Number of parallel fully connected layers to use. Increasing layers adds capacity to the model, enabling it to learn more complex feature interactions.</li>
<li><strong><code>fc_dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>recurrent_dropout</code></strong> (default: <code>0.0</code>): The dropout rate for the recurrent state</li>
<li><strong><code>activation</code></strong> (default: <code>tanh</code>): The default activation function to use. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>filter_size</code></strong> (default: <code>5</code>): Size of the 1d convolutional filter. It indicates how wide the 1d convolutional filter is.</li>
<li><strong><code>strides</code></strong> (default: <code>1</code>): Stride length of the convolution.</li>
<li><strong><code>fc_activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>recurrent_activation</code></strong> (default: <code>sigmoid</code>): The activation function to use in the recurrent step Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>conv_activation</code></strong> (default: <code>relu</code>): The default activation function that will be used for each convolutional layer. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>representation</code></strong> (default: <code>dense</code>): Representation of the embedding. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings. Options: <code>dense</code>, <code>sparse</code>.</li>
<li>
<p><strong><code>conv_layers</code></strong> (default: <code>null</code>): 
A list of dictionaries containing the parameters of all the convolutional layers.
The length of the list determines the number of stacked convolutional layers and the content of each dictionary
determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>,
<code>norm</code>, <code>norm_params</code>, <code>num_filters</code>, <code>filter_size</code>, <code>strides</code>, <code>padding</code>, <code>dilation_rate</code>, <code>use_bias</code>, <code>pool_function</code>,
<code>pool_padding</code>, <code>pool_size</code>, <code>pool_strides</code>, <code>bias_initializer</code>, <code>weights_initializer</code>. If any of those values is
missing from the dictionary, the default one specified as a parameter of the encoder will be used instead. If both
<code>conv_layers</code> and <code>num_conv_layers</code> are <code>null</code>, a default list will be assigned to <code>conv_layers</code> with the value
<code>[{filter_size: 7, pool_size: 3}, {filter_size: 7, pool_size: 3}, {filter_size: 3, pool_size: null},
{filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: null}, {filter_size: 3, pool_size: 3}]</code>.</p>
</li>
<li>
<p><strong><code>pool_function</code></strong> (default: <code>max</code>): Pooling function to use. <code>max</code> will select the maximum value. Any of <code>average</code>, <code>avg</code>, or <code>mean</code> will compute the mean value Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</p>
</li>
<li><strong><code>pool_size</code></strong> (default: <code>null</code>): The default pool_size that will be used for each layer. If a pool_size is not already specified in conv_layers this is the default pool_size that will be used for each layer. It indicates the size of the max pooling that will be performed along the <code>s</code> sequence dimension after the convolution operation.</li>
<li><strong><code>dilation_rate</code></strong> (default: <code>1</code>): Dilation rate to use for dilated convolution.</li>
<li><strong><code>pool_strides</code></strong> (default: <code>null</code>): Factor to scale down.</li>
<li><strong><code>pool_padding</code></strong> (default: <code>same</code>): Padding to use. Options: <code>valid</code>, <code>same</code>.</li>
<li><strong><code>unit_forget_bias</code></strong> (default: <code>true</code>): If true, add 1 to the bias of the forget gate at initialization Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>recurrent_initializer</code></strong> (default: <code>orthogonal</code>): The initializer for recurrent matrix weights Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether to use a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>embeddings_on_cpu</code></strong> (default: <code>false</code>): Whether to force the placement of the embedding matrix in regular memory and have the CPU resolve them. By default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li><strong><code>embeddings_trainable</code></strong> (default: <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code>; <code>sparse</code> one-hot encodings are not trainable. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>last</code>): How to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
<li><strong><code>norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module.</li>
<li>
<p><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</p>
</li>
<li>
<p><strong><code>num_filters</code></strong> (default: <code>256</code>): Number of filters, and by consequence number of output channels of the 1d convolution.</p>
</li>
<li><strong><code>padding</code></strong> (default: <code>same</code>): Padding to use. Options: <code>valid</code>, <code>same</code>.</li>
<li><strong><code>num_rec_layers</code></strong> (default: <code>1</code>): The number of stacked recurrent layers.</li>
<li>
<p><strong><code>bidirectional</code></strong> (default: <code>false</code>): If true, two recurrent networks will perform encoding in the forward and backward direction and their outputs will be concatenated. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li>
<p><strong><code>pretrained_embeddings</code></strong> (default: <code>null</code>): Path to a file containing pretrained embeddings. By default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</p>
</li>
</ul>
<h4 id="transformer-encoder">Transformer Encoder<a class="headerlink" href="#transformer-encoder" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["12\n7\n43\n65\n23\n4\n1"] --&gt; B["emb_12\nemb__7\nemb_43\nemb_65\nemb_23\nemb__4\nemb__1"];
  B --&gt; C["Transformer\n Blocks"];
  C --&gt; D["Fully\n Connected\n Layers"];
  D --&gt; ...;</code></pre></p>
<p>The <code>transformer</code> encoder implements a stack of transformer blocks, replicating the architecture introduced in the
<a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a> paper, and adds am optional stack of fully connected
layers at the end.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">transformer</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">transformer_output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">representation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dense</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">embeddings_on_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">embeddings_trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">last</span>
<span class="w">    </span><span class="nt">norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">num_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">    </span><span class="nt">pretrained_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>dropout</code></strong> (default: <code>0.1</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The dropout rate for the transformer block. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>num_layers</code></strong> (default: <code>1</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The number of transformer layers.</li>
<li><strong><code>embedding_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The maximum embedding size. The actual size will be <code>min(vocabulary_size, embedding_size)</code> for <code>dense</code> representations and exactly <code>vocabulary_size</code> for the <code>sparse</code> encoding, where <code>vocabulary_size</code> is the number of unique strings appearing in the training set input column plus the number of special tokens (<code>&lt;UNK&gt;</code>, <code>&lt;PAD&gt;</code>, <code>&lt;SOS&gt;</code>, <code>&lt;EOS&gt;</code>).</li>
<li><strong><code>output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default output_size that will be used for each layer.</li>
<li><strong><code>norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The default norm that will be used for each layer. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>.</li>
<li><strong><code>num_fc_layers</code></strong> (default: <code>0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Number of parallel fully connected layers to use. Increasing layers adds capacity to the model, enabling it to learn more complex feature interactions.</li>
<li><strong><code>fc_dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>hidden_size</code></strong> (default: <code>256</code>): The size of the hidden representation within the transformer block. It is usually the same as the embedding_size, but if the two values are different, a projection layer will be added before the first transformer block.</li>
<li><strong><code>transformer_output_size</code></strong> (default: <code>256</code>): Size of the fully connected layer after self attention in the transformer block. This is usually the same as hidden_size and embedding_size.</li>
<li><strong><code>fc_activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>representation</code></strong> (default: <code>dense</code>): Representation of the embedding. <code>dense</code> means the embeddings are initialized randomly, <code>sparse</code> means they are initialized to be one-hot encodings. Options: <code>dense</code>, <code>sparse</code>.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether to use a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li>
<p><strong><code>bias_initializer</code></strong> (default: <code>zeros</code>): Initializer for the bias vector. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>weights_initializer</code></strong> (default: <code>xavier_uniform</code>): Initializer for the weight matrix. Options: <code>uniform</code>, <code>normal</code>, <code>constant</code>, <code>ones</code>, <code>zeros</code>, <code>eye</code>, <code>dirac</code>, <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>kaiming_uniform</code>, <code>kaiming_normal</code>, <code>orthogonal</code>, <code>sparse</code>, <code>identity</code>. 
Alternatively it is possible to specify a dictionary with a key <code>type</code> that identifies the type of initializer and
other keys for its parameters, e.g. <code>{type: normal, mean: 0, stddev: 0}</code>. For a description of the parameters of each
initializer, see <a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init</a>.</p>
</li>
<li>
<p><strong><code>embeddings_on_cpu</code></strong> (default: <code>false</code>): Whether to force the placement of the embedding matrix in regular memory and have the CPU resolve them. By default embedding matrices are stored on GPU memory if a GPU is used, as it allows for faster access, but in some cases the embedding matrix may be too large. This parameter forces the placement of the embedding matrix in regular memory and the CPU is used for embedding lookup, slightly slowing down the process as a result of data transfer between CPU and GPU memory. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li><strong><code>embeddings_trainable</code></strong> (default: <code>true</code>): If <code>true</code> embeddings are trained during the training process, if <code>false</code> embeddings are fixed. It may be useful when loading pretrained embeddings for avoiding finetuning them. This parameter has effect only when <code>representation</code> is <code>dense</code>; <code>sparse</code> one-hot encodings are not trainable. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>last</code>): How to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
<li><strong><code>norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module.</li>
<li>
<p><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</p>
</li>
<li>
<p><strong><code>num_heads</code></strong> (default: <code>8</code>): Number of attention heads in each transformer block.</p>
</li>
<li>
<p><strong><code>pretrained_embeddings</code></strong> (default: <code>null</code>): Path to a file containing pretrained embeddings. By default <code>dense</code> embeddings are initialized randomly, but this parameter allows to specify a path to a file containing embeddings in the <a href="https://nlp.stanford.edu/projects/glove/">GloVe format</a>. When the file containing the embeddings is loaded, only the embeddings with labels present in the vocabulary are kept, the others are discarded. If the vocabulary contains strings that have no match in the embeddings file, their embeddings are initialized with the average of all other embedding plus some random noise to make them different from each other. This parameter has effect only if <code>representation</code> is <code>dense</code>.</p>
</li>
</ul>
<h4 id="huggingface-encoders">Huggingface encoders<a class="headerlink" href="#huggingface-encoders" title="Permanent link">&para;</a></h4>
<p>All huggingface-based text encoders are configured with the following parameters:</p>
<ul>
<li><code>pretrained_model_name_or_path</code> (default is the huggingface default model path for the specified encoder, i.e. <code>bert-base-uncased</code> for BERT). This can be either the name of a model or a path where it was downloaded. For details on the variants available refer to the <a href="https://huggingface.co/docs/transformers/index#supported-models">Hugging Face documentation</a>.</li>
<li><code>reduce_output</code> (default <code>cls_pooled</code>): defines how to reduce the output tensor along the <code>s</code> sequence length dimension if the rank of the tensor is greater than 2. Available values are: <code>cls_pooled</code>, <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the first dimension), <code>last</code> (returns the last vector of the first dimension) and  <code>null</code> (which does not reduce and returns the full tensor).</li>
<li><code>trainable</code> (default <code>false</code>): if <code>true</code> the weights of the encoder will be trained, otherwise they will be kept frozen.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Any hyperparameter of any huggingface encoder can be overridden. Check the
<a href="https://huggingface.co/docs/transformers/index#supported-models">huggingface documentation</a> for which parameters are used for which models.</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span>
<span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bert</span>
<span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">num_attention_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span><span class="w"> </span><span class="c1"># Instead of 12</span>
</code></pre></div>
</div>
<h5 id="autotransformer">AutoTransformer<a class="headerlink" href="#autotransformer" title="Permanent link">&para;</a></h5>
<p>The <code>auto_transformer</code> encoder automatically instantiates the model architecture for the specified <code>pretrained_model_name_or_path</code>. Unlike the other HF encoders, <code>auto_transformer</code> does not provide a default value for <code>pretrained_model_name_or_path</code>, this is its only mandatory parameter. See the Hugging Face <a href="https://huggingface.co/docs/transformers/model_doc/auto">AutoModels documentation</a> for more details.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">auto_transformer</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bert-base-uncased</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>bert-base-uncased</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Name or path of the pretrained model.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor. Options: <code>last</code>, <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>attention</code>, <code>none</code>, <code>None</code>, <code>null</code>.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="albert">ALBERT<a class="headerlink" href="#albert" title="Permanent link">&para;</a></h5>
<p>The <code>albert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1909.11942">ALBERT</a> (default <code>albert-base-v2</code>) model using the Hugging Face transformers package. Albert is similar to BERT, with significantly lower memory usage and somewhat faster training time:.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">albert</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">albert-base-v2</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cls_pooled</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">768</span>
<span class="w">    </span><span class="nt">num_hidden_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">num_hidden_groups</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">num_attention_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">intermediate_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3072</span>
<span class="w">    </span><span class="nt">inner_group_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">hidden_act</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gelu_new</span>
<span class="w">    </span><span class="nt">hidden_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">attention_probs_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">max_position_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">type_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">initializer_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">layer_norm_eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-12</span>
<span class="w">    </span><span class="nt">classifier_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">position_embedding_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">absolute</span>
<span class="w">    </span><span class="nt">pad_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">bos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">eos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>albert-base-v2</code>): Name or path of the pretrained model.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>cls_pooled</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li><strong><code>embedding_size</code></strong> (default: <code>128</code>): Dimensionality of vocabulary embeddings.</li>
<li><strong><code>hidden_size</code></strong> (default: <code>768</code>): Dimensionality of the encoder layers and the pooler layer.</li>
<li><strong><code>num_hidden_layers</code></strong> (default: <code>12</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>num_hidden_groups</code></strong> (default: <code>1</code>): Number of groups for the hidden layers, parameters in the same group are shared.</li>
<li><strong><code>num_attention_heads</code></strong> (default: <code>12</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>intermediate_size</code></strong> (default: <code>3072</code>): The dimensionality of the “intermediate” (often named feed-forward) layer in the Transformer encoder.</li>
<li><strong><code>inner_group_num</code></strong> (default: <code>1</code>): The number of inner repetition of attention and ffn.</li>
<li><strong><code>hidden_act</code></strong> (default: <code>gelu_new</code>): The non-linear activation function (function or string) in the encoder and pooler. Options: <code>gelu</code>, <code>relu</code>, <code>silu</code>, <code>gelu_new</code>.</li>
<li><strong><code>hidden_dropout_prob</code></strong> (default: <code>0.0</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>attention_probs_dropout_prob</code></strong> (default: <code>0.0</code>): The dropout ratio for the attention probabilities.</li>
<li><strong><code>max_position_embeddings</code></strong> (default: <code>512</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large (e.g., 512 or 1024 or 2048).</li>
<li><strong><code>type_vocab_size</code></strong> (default: <code>2</code>): The vocabulary size of the token_type_ids passed when calling AlbertModel or TFAlbertModel.</li>
<li><strong><code>initializer_range</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</li>
<li><strong><code>layer_norm_eps</code></strong> (default: <code>1e-12</code>): The epsilon used by the layer normalization layers.</li>
<li><strong><code>classifier_dropout_prob</code></strong> (default: <code>0.1</code>): The dropout ratio for attached classifiers.</li>
<li><strong><code>position_embedding_type</code></strong> (default: <code>absolute</code>):  Options: <code>absolute</code>, <code>relative_key</code>, <code>relative_key_query</code>.</li>
<li><strong><code>pad_token_id</code></strong> (default: <code>0</code>): The ID of the token to use as padding.</li>
<li><strong><code>bos_token_id</code></strong> (default: <code>2</code>): The beginning of sequence token ID.</li>
<li><strong><code>eos_token_id</code></strong> (default: <code>3</code>): The end of sequence token ID.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="bert">BERT<a class="headerlink" href="#bert" title="Permanent link">&para;</a></h5>
<p>The bert encoder loads a pretrained BERT (default bert-base-uncased) model using the Hugging Face transformers package. BERT is a bidirectional transformer pretrained using a combination of masked language modeling objective and next sentence prediction on a large corpus comprising the Toronto Book Corpus and Wikipedia.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bert</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bert-base-uncased</span>
<span class="w">    </span><span class="nt">hidden_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">attention_probs_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">max_position_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">classifier_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cls_pooled</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">768</span>
<span class="w">    </span><span class="nt">num_hidden_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">num_attention_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">intermediate_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3072</span>
<span class="w">    </span><span class="nt">hidden_act</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gelu</span>
<span class="w">    </span><span class="nt">type_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">initializer_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">layer_norm_eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-12</span>
<span class="w">    </span><span class="nt">pad_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">gradient_checkpointing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">position_embedding_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">absolute</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>bert-base-uncased</code>): Name or path of the pretrained model.</li>
<li><strong><code>hidden_dropout_prob</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>attention_probs_dropout_prob</code></strong> (default: <code>0.1</code>): The dropout ratio for the attention probabilities.</li>
<li><strong><code>max_position_embeddings</code></strong> (default: <code>512</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</li>
<li><strong><code>classifier_dropout</code></strong> (default: <code>null</code>): The dropout ratio for the classification head.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>cls_pooled</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li><strong><code>hidden_size</code></strong> (default: <code>768</code>): Dimensionality of the encoder layers and the pooler layer.</li>
<li><strong><code>num_hidden_layers</code></strong> (default: <code>12</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>num_attention_heads</code></strong> (default: <code>12</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>intermediate_size</code></strong> (default: <code>3072</code>): Dimensionality of the “intermediate” (often named feed-forward) layer in the Transformer encoder.</li>
<li><strong><code>hidden_act</code></strong> (default: <code>gelu</code>): The non-linear activation function (function or string) in the encoder and pooler. Options: <code>gelu</code>, <code>relu</code>, <code>silu</code>, <code>gelu_new</code>.</li>
<li><strong><code>type_vocab_size</code></strong> (default: <code>2</code>): The vocabulary size of the token_type_ids passed when calling BertModel or TFBertModel.</li>
<li><strong><code>initializer_range</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</li>
<li><strong><code>layer_norm_eps</code></strong> (default: <code>1e-12</code>): The epsilon used by the layer normalization layers.</li>
<li><strong><code>pad_token_id</code></strong> (default: <code>0</code>): The ID of the token to use as padding.</li>
<li><strong><code>gradient_checkpointing</code></strong> (default: <code>false</code>): Whether to use gradient checkpointing. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>position_embedding_type</code></strong> (default: <code>absolute</code>): Type of position embedding. Options: <code>absolute</code>, <code>relative_key</code>, <code>relative_key_query</code>.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="camembert">CamemBERT<a class="headerlink" href="#camembert" title="Permanent link">&para;</a></h5>
<p>The <code>camembert</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1911.03894">CamemBERT</a> (default <code>jplu/tf-camembert-base</code>) model using the Hugging Face transformers package. CamemBERT is pre-trained on a large French language web-crawled text corpus.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">camembert</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">camembert-base</span>
<span class="w">    </span><span class="nt">hidden_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">attention_probs_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">max_position_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">514</span>
<span class="w">    </span><span class="nt">classifier_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">768</span>
<span class="w">    </span><span class="nt">hidden_act</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gelu</span>
<span class="w">    </span><span class="nt">initializer_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">num_hidden_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">num_attention_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">intermediate_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3072</span>
<span class="w">    </span><span class="nt">type_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">layer_norm_eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-05</span>
<span class="w">    </span><span class="nt">pad_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">gradient_checkpointing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">position_embedding_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">absolute</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>camembert-base</code>): Name or path of the pretrained model.</li>
<li><strong><code>hidden_dropout_prob</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>attention_probs_dropout_prob</code></strong> (default: <code>0.1</code>): The dropout ratio for the attention probabilities.</li>
<li><strong><code>max_position_embeddings</code></strong> (default: <code>514</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</li>
<li><strong><code>classifier_dropout</code></strong> (default: <code>null</code>): The dropout ratio for the classification head.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li><strong><code>hidden_size</code></strong> (default: <code>768</code>): Dimensionality of the encoder layers and the pooler layer.</li>
<li><strong><code>hidden_act</code></strong> (default: <code>gelu</code>): The non-linear activation function (function or string) in the encoder and pooler. Options: <code>gelu</code>, <code>relu</code>, <code>silu</code>, <code>gelu_new</code>.</li>
<li>
<p><strong><code>initializer_range</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</p>
</li>
<li>
<p><strong><code>num_hidden_layers</code></strong> (default: <code>12</code>): Number of hidden layers in the Transformer encoder.</p>
</li>
<li><strong><code>num_attention_heads</code></strong> (default: <code>12</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>intermediate_size</code></strong> (default: <code>3072</code>): Dimensionality of the “intermediate” (often named feed-forward) layer in the Transformer encoder.</li>
<li><strong><code>type_vocab_size</code></strong> (default: <code>1</code>): The vocabulary size of the token_type_ids passed when calling BertModel or TFBertModel.</li>
<li><strong><code>layer_norm_eps</code></strong> (default: <code>1e-05</code>): The epsilon used by the layer normalization layers.</li>
<li><strong><code>pad_token_id</code></strong> (default: <code>1</code>): The ID of the token to use as padding.</li>
<li><strong><code>gradient_checkpointing</code></strong> (default: <code>false</code>): Whether to use gradient checkpointing. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>position_embedding_type</code></strong> (default: <code>absolute</code>): Type of position embedding. Options: <code>absolute</code>, <code>relative_key</code>, <code>relative_key_query</code>.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="distilbert">DistilBERT<a class="headerlink" href="#distilbert" title="Permanent link">&para;</a></h5>
<p>The <code>distilbert</code> encoder loads a pretrained <a href="https://medium.com/huggingface/distilbert-8cf3380435b5">DistilBERT</a> (default <code>distilbert-base-uncased</code>) model using the Hugging Face transformers package. DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">distilbert</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">distilbert-base-uncased</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">max_position_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">attention_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gelu</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">initializer_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">qa_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">seq_classif_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span>
<span class="w">    </span><span class="nt">sinusoidal_pos_embds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">n_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">    </span><span class="nt">n_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">dim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">768</span>
<span class="w">    </span><span class="nt">hidden_dim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3072</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>distilbert-base-uncased</code>): Name or path of the pretrained model.</li>
<li><strong><code>dropout</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>max_position_embeddings</code></strong> (default: <code>512</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</li>
<li><strong><code>attention_dropout</code></strong> (default: <code>0.1</code>): The dropout ratio for the attention probabilities.</li>
<li><strong><code>activation</code></strong> (default: <code>gelu</code>): The non-linear activation function (function or string) in the encoder and pooler. If string, 'gelu', 'relu', 'silu' and 'gelu_new' are supported. Options: <code>gelu</code>, <code>relu</code>, <code>silu</code>, <code>gelu_new</code>.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li><strong><code>initializer_range</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</li>
<li><strong><code>qa_dropout</code></strong> (default: <code>0.1</code>): The dropout probabilities used in the question answering model DistilBertForQuestionAnswering.</li>
<li>
<p><strong><code>seq_classif_dropout</code></strong> (default: <code>0.2</code>): The dropout probabilities used in the sequence classification and the multiple choice model DistilBertForSequenceClassification.</p>
</li>
<li>
<p><strong><code>sinusoidal_pos_embds</code></strong> (default: <code>false</code>): Whether to use sinusoidal positional embeddings. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li><strong><code>n_layers</code></strong> (default: <code>6</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>n_heads</code></strong> (default: <code>12</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>dim</code></strong> (default: <code>768</code>):  Dimensionality of the encoder layers and the pooler layer.</li>
<li><strong><code>hidden_dim</code></strong> (default: <code>3072</code>): The size of the “intermediate” (often named feed-forward) layer in the Transformer encoder.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="electra">ELECTRA<a class="headerlink" href="#electra" title="Permanent link">&para;</a></h5>
<p>The `electra`` encoder loads a pretrained <a href="https://openreview.net/pdf?id=r1xMH1BtvB">ELECTRA</a> model using the Hugging Face transformers package. ELECTRA is a new pretraining approach which trains two transformer models the generator and the discriminator. The generator’s role is to replace tokens in a sequence, and is therefore trained as a masked language model. The discriminator, which is the model we’re interested in, tries to identify which tokens were replaced by the generator in the sequence.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">electra</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">google/electra-small-discriminator</span>
<span class="w">    </span><span class="nt">hidden_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">attention_probs_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">max_position_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">classifier_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">hidden_act</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gelu</span>
<span class="w">    </span><span class="nt">initializer_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">num_hidden_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">num_attention_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">intermediate_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">    </span><span class="nt">type_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">layer_norm_eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-12</span>
<span class="w">    </span><span class="nt">position_embedding_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">absolute</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>google/electra-small-discriminator</code>): Name or path of the pretrained model.</li>
<li><strong><code>hidden_dropout_prob</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>attention_probs_dropout_prob</code></strong> (default: <code>0.1</code>): The dropout ratio for the attention probabilities.</li>
<li><strong><code>max_position_embeddings</code></strong> (default: <code>512</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</li>
<li><strong><code>classifier_dropout</code></strong> (default: <code>null</code>): The dropout ratio for the classification head.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li><strong><code>embedding_size</code></strong> (default: <code>128</code>): Dimensionality of the encoder layers and the pooler layer.</li>
<li><strong><code>hidden_size</code></strong> (default: <code>256</code>): Dimensionality of the encoder layers and the pooler layer.</li>
<li><strong><code>hidden_act</code></strong> (default: <code>gelu</code>): The non-linear activation function (function or string) in the encoder and pooler. Options: <code>gelu</code>, <code>relu</code>, <code>silu</code>, <code>gelu_new</code>.</li>
<li>
<p><strong><code>initializer_range</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</p>
</li>
<li>
<p><strong><code>num_hidden_layers</code></strong> (default: <code>12</code>): Number of hidden layers in the Transformer encoder.</p>
</li>
<li><strong><code>num_attention_heads</code></strong> (default: <code>4</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>intermediate_size</code></strong> (default: <code>1024</code>): Dimensionality of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder.</li>
<li><strong><code>type_vocab_size</code></strong> (default: <code>2</code>): The vocabulary size of the token_type_ids passed when calling ElectraModel or TFElectraModel.</li>
<li><strong><code>layer_norm_eps</code></strong> (default: <code>1e-12</code>): The epsilon used by the layer normalization layers.</li>
<li><strong><code>position_embedding_type</code></strong> (default: <code>absolute</code>): Type of position embedding. Options: <code>absolute</code>, <code>relative_key</code>, <code>relative_key_query</code>.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="flaubert">FlauBERT<a class="headerlink" href="#flaubert" title="Permanent link">&para;</a></h5>
<p>The <code>flaubert`` encoder loads a pretrained [FlauBERT](https://arxiv.org/abs/1912.05372) (default</code>jplu/tf-flaubert-base-uncased``) model using the Hugging Face transformers package. FlauBERT has an architecture similar to BERT and is pre-trained on a large French language corpus.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">flaubert</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">flaubert/flaubert_small_cased</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">pre_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">layerdrop</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span>
<span class="w">    </span><span class="nt">emb_dim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">n_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">    </span><span class="nt">n_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">    </span><span class="nt">attention_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">gelu_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">sinusoidal_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">causal</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">asm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">n_langs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">use_lang_emb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">max_position_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">embed_init_std</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02209708691207961</span>
<span class="w">    </span><span class="nt">init_std</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">layer_norm_eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-06</span>
<span class="w">    </span><span class="nt">bos_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">eos_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">pad_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">unk_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">    </span><span class="nt">mask_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">    </span><span class="nt">is_encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">mask_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">lang_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>flaubert/flaubert_small_cased</code>): Name of path of the pretrained model.</li>
<li><strong><code>dropout</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li><strong><code>pre_norm</code></strong> (default: <code>true</code>): Whether to apply the layer normalization before or after the feed forward layer following the attention in each layer (Vaswani et al., Tensor2Tensor for Neural Machine Translation. 2018) Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>layerdrop</code></strong> (default: <code>0.2</code>): Probability to drop layers during training (Fan et al., Reducing Transformer Depth on Demand with Structured Dropout. ICLR 2020)</li>
<li><strong><code>emb_dim</code></strong> (default: <code>512</code>): Dimensionality of the encoder layers and the pooler layer.</li>
<li><strong><code>n_layers</code></strong> (default: <code>6</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>n_heads</code></strong> (default: <code>8</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>attention_dropout</code></strong> (default: <code>0.1</code>): The dropout probability for the attention mechanism</li>
<li><strong><code>gelu_activation</code></strong> (default: <code>true</code>): Whether or not to use a gelu activation instead of relu. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>sinusoidal_embeddings</code></strong> (default: <code>false</code>): Whether or not to use sinusoidal positional embeddings instead of absolute positional embeddings. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>causal</code></strong> (default: <code>false</code>): Whether or not the model should behave in a causal manner. Causal models use a triangular attention mask in order to only attend to the left-side context instead if a bidirectional context. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>asm</code></strong> (default: <code>false</code>): Whether or not to use an adaptive log softmax projection layer instead of a linear layer for the prediction layer. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>n_langs</code></strong> (default: <code>1</code>): The number of languages the model handles. Set to 1 for monolingual models.</li>
<li><strong><code>use_lang_emb</code></strong> (default: <code>true</code>): Whether to use language embeddings. Some models use additional language embeddings, see the multilingual models page for information on how to use them. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>max_position_embeddings</code></strong> (default: <code>512</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</li>
<li><strong><code>embed_init_std</code></strong> (default: <code>0.02209708691207961</code>): The standard deviation of the truncated_normal_initializer for initializing the embedding matrices.</li>
<li><strong><code>init_std</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices except the embedding matrices.</li>
<li><strong><code>layer_norm_eps</code></strong> (default: <code>1e-06</code>): The epsilon used by the layer normalization layers.</li>
<li><strong><code>bos_index</code></strong> (default: <code>0</code>): The index of the beginning of sentence token in the vocabulary.</li>
<li><strong><code>eos_index</code></strong> (default: <code>1</code>): The index of the end of sentence token in the vocabulary.</li>
<li><strong><code>pad_index</code></strong> (default: <code>2</code>): The index of the padding token in the vocabulary.</li>
<li><strong><code>unk_index</code></strong> (default: <code>3</code>): The index of the unknown token in the vocabulary.</li>
<li><strong><code>mask_index</code></strong> (default: <code>5</code>): The index of the masking token in the vocabulary.</li>
<li><strong><code>is_encoder</code></strong> (default: <code>true</code>): Whether or not the initialized model should be a transformer encoder or decoder as seen in Vaswani et al. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>mask_token_id</code></strong> (default: <code>0</code>): Model agnostic parameter to identify masked tokens when generating text in an MLM context.</li>
<li><strong><code>lang_id</code></strong> (default: <code>0</code>): The ID of the language used by the model. This parameter is used when generating text in a given language.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="gpt">GPT<a class="headerlink" href="#gpt" title="Permanent link">&para;</a></h5>
<p>The <code>gpt</code> encoder loads a pretrained <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a> (default <code>openai-gpt</code>) model using the Hugging Face transformers package. GPT is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long range dependencies, the Toronto Book Corpus.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpt</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">openai-gpt</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">initializer_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">n_positions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40478</span>
<span class="w">    </span><span class="nt">n_ctx</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">n_embd</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">768</span>
<span class="w">    </span><span class="nt">n_layer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">n_head</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">afn</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gelu_new</span>
<span class="w">    </span><span class="nt">resid_pdrop</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">embd_pdrop</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">attn_pdrop</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">layer_norm_epsilon</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-05</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>openai-gpt</code>): Name or path of the pretrained model.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li>
<p><strong><code>initializer_range</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</p>
</li>
<li>
<p><strong><code>n_positions</code></strong> (default: <code>40478</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</p>
</li>
<li><strong><code>n_ctx</code></strong> (default: <code>512</code>): Dimensionality of the causal mask (usually same as n_positions)</li>
<li><strong><code>n_embd</code></strong> (default: <code>768</code>): Dimensionality of the embeddings and hidden states.</li>
<li><strong><code>n_layer</code></strong> (default: <code>12</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>n_head</code></strong> (default: <code>12</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>afn</code></strong> (default: <code>gelu_new</code>): The non-linear activation function (function or string) in the encoder and pooler. Options: <code>gelu</code>, <code>relu</code>, <code>silu</code>, <code>gelu_new</code>.</li>
<li><strong><code>resid_pdrop</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>embd_pdrop</code></strong> (default: <code>0.1</code>): The dropout ratio for the embeddings.</li>
<li><strong><code>attn_pdrop</code></strong> (default: <code>0.1</code>): The dropout ratio for the attention.</li>
<li><strong><code>layer_norm_epsilon</code></strong> (default: <code>1e-05</code>): The epsilon to use in the layer normalization layers</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="gpt2">GPT2<a class="headerlink" href="#gpt2" title="Permanent link">&para;</a></h5>
<p>The <code>gpt2</code> encoder loads a pretrained <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a> (default <code>gpt2</code>) model using the Hugging Face transformers package. GPT-2 is a causal (unidirectional) transformer pretrained using language modeling on a very large corpus of ~40 GB of text data.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpt2</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpt2</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">initializer_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">n_positions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">    </span><span class="nt">n_ctx</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">    </span><span class="nt">n_embd</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">768</span>
<span class="w">    </span><span class="nt">n_layer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">n_head</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">n_inner</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">activation_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gelu_new</span>
<span class="w">    </span><span class="nt">resid_pdrop</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">embd_pdrop</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">attn_pdrop</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">layer_norm_epsilon</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-05</span>
<span class="w">    </span><span class="nt">scale_attn_weights</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>gpt2</code>): Name or path of the pretrained model.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li>
<p><strong><code>initializer_range</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</p>
</li>
<li>
<p><strong><code>n_positions</code></strong> (default: <code>1024</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</p>
</li>
<li><strong><code>n_ctx</code></strong> (default: <code>1024</code>): Dimensionality of the causal mask (usually same as n_positions)</li>
<li><strong><code>n_embd</code></strong> (default: <code>768</code>): Dimensionality of the embeddings and hidden states.</li>
<li><strong><code>n_layer</code></strong> (default: <code>12</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>n_head</code></strong> (default: <code>12</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>n_inner</code></strong> (default: <code>null</code>): Dimensionality of the inner feed-forward layers. None will set it to 4 times n_embd</li>
<li><strong><code>activation_function</code></strong> (default: <code>gelu_new</code>): Activation function, to be selected in the list ['relu', 'silu', 'gelu', 'tanh', 'gelu_new']. Options: <code>relu</code>, <code>silu</code>, <code>gelu</code>, <code>tanh</code>, <code>gelu_new</code>.</li>
<li><strong><code>resid_pdrop</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>embd_pdrop</code></strong> (default: <code>0.1</code>): The dropout ratio for the embeddings.</li>
<li><strong><code>attn_pdrop</code></strong> (default: <code>0.1</code>): The dropout ratio for the attention.</li>
<li><strong><code>layer_norm_epsilon</code></strong> (default: <code>1e-05</code>): The epsilon to use in the layer normalization layers.</li>
<li><strong><code>scale_attn_weights</code></strong> (default: <code>true</code>): Scale attention weights by dividing by sqrt(hidden_size). Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="longformer">Longformer<a class="headerlink" href="#longformer" title="Permanent link">&para;</a></h5>
<p>The <code>longformer</code> encoder loads a pretrained <a href="https://arxiv.org/pdf/2004.05150.pdf">Longformer</a> (default <code>allenai/longformer-base-4096</code>) model using the Hugging Face transformers package. Longformer is a good choice for longer text, as it supports sequences up to 4096 tokens long.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">longformer</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">allenai/longformer-base-4096</span>
<span class="w">    </span><span class="nt">max_position_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4098</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cls_pooled</span>
<span class="w">    </span><span class="nt">attention_window</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">sep_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">type_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>allenai/longformer-base-4096</code>): Name or path of the pretrained model.</li>
<li><strong><code>max_position_embeddings</code></strong> (default: <code>4098</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</li>
<li>
<p><strong><code>reduce_output</code></strong> (default: <code>cls_pooled</code>): The method used to reduce a sequence of tensors down to a single tensor.</p>
</li>
<li>
<p><strong><code>attention_window</code></strong> (default: <code>512</code>): Size of an attention window around each token. If an int, use the same size for all layers. To specify a different window size for each layer, use a List[int] where len(attention_window) == num_hidden_layers.</p>
</li>
<li>
<p><strong><code>sep_token_id</code></strong> (default: <code>2</code>): ID of the separator token, which is used when building a sequence from multiple sequences</p>
</li>
<li>
<p><strong><code>type_vocab_size</code></strong> (default: <code>1</code>): The vocabulary size of the token_type_ids passed when calling LongformerEncoder</p>
</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="roberta">RoBERTa<a class="headerlink" href="#roberta" title="Permanent link">&para;</a></h5>
<p>The <code>roberta</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a> (default <code>roberta-base</code>) model using the Hugging Face transformers package. Replication of BERT pretraining which may match or exceed the performance of BERT. RoBERTa builds on BERT and modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">roberta</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">roberta-base</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cls_pooled</span>
<span class="w">    </span><span class="nt">eos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">pad_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">bos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>roberta-base</code>): Name or path of the pretrained model.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>cls_pooled</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li>
<p><strong><code>eos_token_id</code></strong> (default: <code>2</code>): The end of sequence token ID.</p>
</li>
<li>
<p><strong><code>pad_token_id</code></strong> (default: <code>1</code>): The ID of the token to use as padding.</p>
</li>
<li><strong><code>bos_token_id</code></strong> (default: <code>0</code>): The beginning of sequence token ID.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="t5">T5<a class="headerlink" href="#t5" title="Permanent link">&para;</a></h5>
<p>The <code>t5</code> encoder loads a pretrained <a href="https://arxiv.org/pdf/1910.10683.pdf">T5</a> (default <code>t5-small</code>) model using the Hugging Face transformers package. T5 (Text-to-Text Transfer Transformer) is pre-trained on a huge text dataset crawled from the web and shows good transfer performance on multiple tasks.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">t5</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">t5-small</span>
<span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">    </span><span class="nt">dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">d_ff</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2048</span>
<span class="w">    </span><span class="nt">d_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">    </span><span class="nt">d_kv</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="w">    </span><span class="nt">num_decoder_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">    </span><span class="nt">num_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">    </span><span class="nt">relative_attention_num_buckets</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span>
<span class="w">    </span><span class="nt">layer_norm_eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-06</span>
<span class="w">    </span><span class="nt">initializer_factor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">feed_forward_proj</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>t5-small</code>): Name or path of the pretrained model.</li>
<li><strong><code>num_layers</code></strong> (default: <code>6</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>dropout_rate</code></strong> (default: <code>0.1</code>): The ratio for all dropout layers.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li>
<p><strong><code>d_ff</code></strong> (default: <code>2048</code>): Size of the intermediate feed forward layer in each T5Block.</p>
</li>
<li>
<p><strong><code>d_model</code></strong> (default: <code>512</code>): Size of the encoder layers and the pooler layer.</p>
</li>
<li><strong><code>d_kv</code></strong> (default: <code>64</code>): Size of the key, query, value projections per attention head. d_kv has to be equal to d_model // num_heads.</li>
<li><strong><code>num_decoder_layers</code></strong> (default: <code>6</code>): Number of hidden layers in the Transformer decoder. Will use the same value as num_layers if not set.</li>
<li><strong><code>num_heads</code></strong> (default: <code>8</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>relative_attention_num_buckets</code></strong> (default: <code>32</code>): The number of buckets to use for each attention layer.</li>
<li><strong><code>layer_norm_eps</code></strong> (default: <code>1e-06</code>): The epsilon used by the layer normalization layers.</li>
<li><strong><code>initializer_factor</code></strong> (default: <code>1</code>): A factor for initializing all weight matrices (should be kept to 1, used internally for initialization testing).</li>
<li><strong><code>feed_forward_proj</code></strong> (default: <code>relu</code>): Type of feed forward layer to be used. Should be one of 'relu' or 'gated-gelu'. T5v1.1 uses the 'gated-gelu' feed forward projection. Original T5 uses 'relu'. Options: <code>relu</code>, <code>gated-gelu</code>.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="transformerxl">TransformerXL<a class="headerlink" href="#transformerxl" title="Permanent link">&para;</a></h5>
<p>The <code>transformer_xl</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1901.02860">Transformer-XL</a> (default <code>transfo-xl-wt103</code>) model using the Hugging Face transformers package. Adds novel positional encoding scheme which improves understanding and generation of long-form text up to thousands of tokens. Transformer-XL is a causal (uni-directional) transformer with relative positioning (sinusoïdal) embeddings which can reuse previously computed hidden-states to attend to longer context (memory). This model also uses adaptive softmax inputs and outputs (tied).</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">transformer_xl</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">transfo-xl-wt103</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">adaptive</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">cutoffs</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20000</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40000</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">200000</span>
<span class="w">    </span><span class="nt">d_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">    </span><span class="nt">d_embed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">    </span><span class="nt">n_head</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="w">    </span><span class="nt">d_head</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="w">    </span><span class="nt">d_inner</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span>
<span class="w">    </span><span class="nt">div_val</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">pre_lnorm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">n_layer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">18</span>
<span class="w">    </span><span class="nt">mem_len</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1600</span>
<span class="w">    </span><span class="nt">clamp_len</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span>
<span class="w">    </span><span class="nt">same_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">proj_share_all_but_first</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">attn_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">sample_softmax</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span>
<span class="w">    </span><span class="nt">dropatt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">untie_r</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">init</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">normal</span>
<span class="w">    </span><span class="nt">init_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.01</span>
<span class="w">    </span><span class="nt">proj_init_std</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.01</span>
<span class="w">    </span><span class="nt">init_std</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">layer_norm_epsilon</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-05</span>
<span class="w">    </span><span class="nt">eos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>transfo-xl-wt103</code>): Name or path of the pretrained model.</li>
<li><strong><code>dropout</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li>
<p><strong><code>adaptive</code></strong> (default: <code>true</code>): Whether or not to use adaptive softmax. Options: <code>true</code>, <code>false</code>.</p>
</li>
<li>
<p><strong><code>cutoffs</code></strong> (default: <code>[20000, 40000, 200000]</code>): Cutoffs for the adaptive softmax.</p>
</li>
<li><strong><code>d_model</code></strong> (default: <code>1024</code>): Dimensionality of the model’s hidden states.</li>
<li><strong><code>d_embed</code></strong> (default: <code>1024</code>): Dimensionality of the embeddings</li>
<li><strong><code>n_head</code></strong> (default: <code>16</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>d_head</code></strong> (default: <code>64</code>): Dimensionality of the model’s heads.</li>
<li><strong><code>d_inner</code></strong> (default: <code>4096</code>):  Inner dimension in FF</li>
<li><strong><code>div_val</code></strong> (default: <code>4</code>): Divident value for adapative input and softmax.</li>
<li><strong><code>pre_lnorm</code></strong> (default: <code>false</code>): Whether or not to apply LayerNorm to the input instead of the output in the blocks. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>n_layer</code></strong> (default: <code>18</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>mem_len</code></strong> (default: <code>1600</code>): Length of the retained previous heads.</li>
<li><strong><code>clamp_len</code></strong> (default: <code>1000</code>): Use the same pos embeddings after clamp_len.</li>
<li><strong><code>same_length</code></strong> (default: <code>true</code>): Whether or not to use the same attn length for all tokens Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>proj_share_all_but_first</code></strong> (default: <code>true</code>): True to share all but first projs, False not to share. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>attn_type</code></strong> (default: <code>0</code>): Attention type. 0 for Transformer-XL, 1 for Shaw et al, 2 for Vaswani et al, 3 for Al Rfou et al.</li>
<li><strong><code>sample_softmax</code></strong> (default: <code>-1</code>): Number of samples in the sampled softmax.</li>
<li><strong><code>dropatt</code></strong> (default: <code>0.0</code>): The dropout ratio for the attention probabilities.</li>
<li><strong><code>untie_r</code></strong> (default: <code>true</code>): Whether ot not to untie relative position biases. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>init</code></strong> (default: <code>normal</code>): Parameter initializer to use.</li>
<li><strong><code>init_range</code></strong> (default: <code>0.01</code>): Parameters initialized by U(-init_range, init_range).</li>
<li><strong><code>proj_init_std</code></strong> (default: <code>0.01</code>): Parameters initialized by N(0, init_std)</li>
<li><strong><code>init_std</code></strong> (default: <code>0.02</code>): Parameters initialized by N(0, init_std)</li>
<li><strong><code>layer_norm_epsilon</code></strong> (default: <code>1e-05</code>): The epsilon to use in the layer normalization layers</li>
<li><strong><code>eos_token_id</code></strong> (default: <code>0</code>): The end of sequence token ID.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="xlmroberta">XLMRoBERTa<a class="headerlink" href="#xlmroberta" title="Permanent link">&para;</a></h5>
<p>The <code>xlmroberta</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1911.02116">XLM-RoBERTa</a> (default <code>jplu/tf-xlm-reoberta-base</code>) model using the Hugging Face transformers package. XLM-RoBERTa is a multi-language model similar to BERT, trained on 100 languages. XLM-RoBERTa is based on Facebook’s RoBERTa model released in 2019. It is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xlmroberta</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xlm-roberta-base</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cls_pooled</span>
<span class="w">    </span><span class="nt">max_position_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">514</span>
<span class="w">    </span><span class="nt">type_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">pad_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">bos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">eos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">add_pooling_layer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>xlm-roberta-base</code>): Name or path of the pretrained model.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>cls_pooled</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li><strong><code>max_position_embeddings</code></strong> (default: <code>514</code>): The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).</li>
<li>
<p><strong><code>type_vocab_size</code></strong> (default: <code>1</code>): The vocabulary size of the token_type_ids passed in.</p>
</li>
<li>
<p><strong><code>pad_token_id</code></strong> (default: <code>1</code>): The ID of the token to use as padding.</p>
</li>
<li><strong><code>bos_token_id</code></strong> (default: <code>0</code>): The beginning of sequence token ID.</li>
<li><strong><code>eos_token_id</code></strong> (default: <code>2</code>): The end of sequence token ID.</li>
<li><strong><code>add_pooling_layer</code></strong> (default: <code>true</code>): Whether to add a pooling layer to the encoder. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h5 id="xlnet">XLNet<a class="headerlink" href="#xlnet" title="Permanent link">&para;</a></h5>
<p>The <code>xlnet</code> encoder loads a pretrained <a href="https://arxiv.org/abs/1906.08237">XLNet</a> (default <code>xlnet-base-cased</code>) model using the Hugging Face transformers package. XLnet is an extension of the Transformer-XL model pre-trained using an autoregressive method to learn bidirectional contexts by maximizing the expected likelihood over all permutations of the input sequence factorization order. XLNet outperforms BERT on a variety of benchmarks.</p>
<div class="highlight"><pre><span></span><code><span class="nt">encoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xlnet</span>
<span class="w">    </span><span class="nt">use_pretrained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">trainable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">pretrained_model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xlnet-base-cased</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">reduce_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">ff_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gelu</span>
<span class="w">    </span><span class="nt">initializer_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.02</span>
<span class="w">    </span><span class="nt">summary_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tanh</span>
<span class="w">    </span><span class="nt">summary_last_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">d_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">768</span>
<span class="w">    </span><span class="nt">n_layer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">n_head</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">    </span><span class="nt">d_inner</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3072</span>
<span class="w">    </span><span class="nt">untie_r</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">attn_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bi</span>
<span class="w">    </span><span class="nt">layer_norm_eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-12</span>
<span class="w">    </span><span class="nt">mem_len</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">reuse_len</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">use_mems_eval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">use_mems_train</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">bi_data</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">clamp_len</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span>
<span class="w">    </span><span class="nt">same_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">summary_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">last</span>
<span class="w">    </span><span class="nt">summary_use_proj</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">start_n_top</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">    </span><span class="nt">end_n_top</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">    </span><span class="nt">pad_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">    </span><span class="nt">bos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">eos_token_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">pretrained_kwargs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>use_pretrained</code></strong> (default: <code>true</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to use the pretrained weights for the model. If false, the model will train from scratch which is very computationally expensive. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>trainable</code></strong> (default: <code>false</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Whether to finetune the model on your dataset. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>pretrained_model_name_or_path</code></strong> (default: <code>xlnet-base-cased</code>): Name or path of the pretrained model.</li>
<li><strong><code>dropout</code></strong> (default: <code>0.1</code>): The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</li>
<li><strong><code>reduce_output</code></strong> (default: <code>sum</code>): The method used to reduce a sequence of tensors down to a single tensor.</li>
<li><strong><code>ff_activation</code></strong> (default: <code>gelu</code>): The non-linear activation function (function or string) in the encoder and pooler. If string, 'gelu', 'relu', 'silu' and 'gelu_new' are supported. Options: <code>gelu</code>, <code>relu</code>, <code>silu</code>, <code>gelu_new</code>.</li>
<li><strong><code>initializer_range</code></strong> (default: <code>0.02</code>): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</li>
<li><strong><code>summary_activation</code></strong> (default: <code>tanh</code>): Argument used when doing sequence summary. Used in the sequence classification and multiple choice models.</li>
<li>
<p><strong><code>summary_last_dropout</code></strong> (default: <code>0.1</code>): Used in the sequence classification and multiple choice models.</p>
</li>
<li>
<p><strong><code>d_model</code></strong> (default: <code>768</code>): Dimensionality of the encoder layers and the pooler layer.</p>
</li>
<li><strong><code>n_layer</code></strong> (default: <code>12</code>): Number of hidden layers in the Transformer encoder.</li>
<li><strong><code>n_head</code></strong> (default: <code>12</code>): Number of attention heads for each attention layer in the Transformer encoder.</li>
<li><strong><code>d_inner</code></strong> (default: <code>3072</code>): Dimensionality of the “intermediate” (often named feed-forward) layer in the Transformer encoder.</li>
<li><strong><code>untie_r</code></strong> (default: <code>true</code>): Whether or not to untie relative position biases Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>attn_type</code></strong> (default: <code>bi</code>): The attention type used by the model. Currently only 'bi' is supported. Options: <code>bi</code>.</li>
<li><strong><code>layer_norm_eps</code></strong> (default: <code>1e-12</code>): The epsilon used by the layer normalization layers.</li>
<li><strong><code>mem_len</code></strong> (default: <code>null</code>): The number of tokens to cache. The key/value pairs that have already been pre-computed in a previous forward pass won’t be re-computed. </li>
<li><strong><code>reuse_len</code></strong> (default: <code>null</code>): The number of tokens in the current batch to be cached and reused in the future.</li>
<li><strong><code>use_mems_eval</code></strong> (default: <code>true</code>): Whether or not the model should make use of the recurrent memory mechanism in evaluation mode. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>use_mems_train</code></strong> (default: <code>false</code>): Whether or not the model should make use of the recurrent memory mechanism in train mode. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>bi_data</code></strong> (default: <code>false</code>): Whether or not to use bidirectional input pipeline. Usually set to True during pretraining and False during finetuning. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>clamp_len</code></strong> (default: <code>-1</code>): Clamp all relative distances larger than clamp_len. Setting this attribute to -1 means no clamping.</li>
<li><strong><code>same_length</code></strong> (default: <code>false</code>): Whether or not to use the same attention length for each token. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>summary_type</code></strong> (default: <code>last</code>): Argument used when doing sequence summary. Used in the sequence classification and multiple choice models. Options: <code>last</code>, <code>first</code>, <code>mean</code>, <code>cls_index</code>, <code>attn</code>.</li>
<li><strong><code>summary_use_proj</code></strong> (default: <code>true</code>):  Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>start_n_top</code></strong> (default: <code>5</code>): Used in the SQuAD evaluation script.</li>
<li><strong><code>end_n_top</code></strong> (default: <code>5</code>):  Used in the SQuAD evaluation script.</li>
<li><strong><code>pad_token_id</code></strong> (default: <code>5</code>): The ID of the token to use as padding.</li>
<li><strong><code>bos_token_id</code></strong> (default: <code>1</code>): The beginning of sequence token ID.</li>
<li><strong><code>eos_token_id</code></strong> (default: <code>2</code>): The end of sequence token ID.</li>
<li><strong><code>pretrained_kwargs</code></strong> (default: <code>null</code>): Additional kwargs to pass to the pretrained model.</li>
</ul>
<h2 id="output-features">Output Features<a class="headerlink" href="#output-features" title="Permanent link">&para;</a></h2>
<p>Text output features are a special case of <a href="#sequence-output-features-and-decoders">Sequence Features</a>, so all options
of sequence features are available for text features as well.</p>
<p>Text output features can be used for either tagging (classifying each token of an input sequence) or text
generation (generating text by repeatedly sampling from the model). There are two decoders available for these tasks
named <code>tagger</code> and <code>generator</code> respectively.</p>
<p>Example text output feature using default parameters:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text_column_name</span>
<span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span>
<span class="nt">reduce_input</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">dependencies</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[]</span>
<span class="nt">reduce_dependencies</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="nt">loss</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">softmax_cross_entropy</span>
<span class="w">    </span><span class="nt">confidence_penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">robust_lambda</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">class_weights</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">class_similarities_temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">decoder</span><span class="p">:</span><span class="w"> </span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">generator</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>reduce_input</code></strong> (default <code>sum</code>): defines how to reduce an input that is not a vector, but a matrix or a higher order
tensor, on the first dimension (second if you count the batch dimension). Available values are: <code>sum</code>, <code>mean</code> or <code>avg</code>,
<code>max</code>, <code>concat</code> (concatenates along the sequence dimension), <code>last</code> (returns the last vector of the sequence dimension).</li>
<li><strong><code>dependencies</code></strong> (default <code>[]</code>): the output features this one is dependent on. For a detailed explanation refer to
<a href="../output_features#output-feature-dependencies">Output Feature Dependencies</a>.</li>
<li><strong><code>reduce_dependencies</code></strong> (default <code>sum</code>): defines how to reduce the output of a dependent feature that is not a vector,
but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension). Available
values are: <code>sum</code>, <code>mean</code> or <code>avg</code>, <code>max</code>, <code>concat</code> (concatenates along the sequence dimension), <code>last</code> (returns the
last vector of the sequence dimension).</li>
<li><strong><code>loss</code></strong> (default <code>{type: softmax_cross_entropy, class_similarities_temperature: 0, class_weights: 1,
confidence_penalty: 0, robust_lambda: 0}</code>): is a dictionary containing a loss <code>type</code>. The only available loss <code>type</code> for
text features is <code>softmax_cross_entropy</code>. See <a href="#loss">Loss</a> for details.</li>
<li><strong><code>decoder</code></strong> (default: <code>{"type": "generator"}</code>): Decoder for the desired task. Options: <code>generator</code>, <code>tagger</code>. See <a href="#decoder">Decoder</a> for details.</li>
</ul>
<p>Decoder type and decoder parameters can also be defined once and applied to all text output features using
the <a href="../../defaults/#type-global-decoder">Type-Global Decoder</a> section. Loss and loss related parameters can
also be defined once in the same way.</p>
<h3 id="decoders">Decoders<a class="headerlink" href="#decoders" title="Permanent link">&para;</a></h3>
<h4 id="generator">Generator<a class="headerlink" href="#generator" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["Combiner Output"] --&gt; B["Fully\n Connected\n Layers"];
  B --&gt; C1["RNN"] --&gt; C2["RNN"] --&gt; C3["RNN"];
  GO(["GO"]) -.-o C1;
  C1 -.-o O1("Output");
  O1 -.-o C2;
  C2 -.-o O2("Output");
  O2 -.-o C3;
  C3 -.-o END(["END"]);
  subgraph DEC["DECODER.."]
  B
  C1
  C2
  C3
  end</code></pre></p>
<p>In the case of <code>generator</code> the decoder is a (potentially empty) stack of fully connected layers, followed by an RNN that
generates outputs feeding on its own previous predictions and generates a tensor of size <code>b x s' x c</code>, where <code>b</code> is the
batch size, <code>s'</code> is the length of the generated sequence and <code>c</code> is the number of classes, followed by a
softmax_cross_entropy.
During training teacher forcing is adopted, meaning the list of targets is provided as both inputs and outputs (shifted
by 1), while at evaluation time greedy decoding (generating one token at a time and feeding it as input for the next
step) is performed by beam search, using a beam of 1 by default.
In general a generator expects a <code>b x h</code> shaped input tensor, where <code>h</code> is a hidden dimension.
The <code>h</code> vectors are (after an optional stack of fully connected layers) fed into the rnn generator.
One exception is when the generator uses attention, as in that case the expected size of the input tensor is
<code>b x s x h</code>, which is the output of a sequence, text or time series input feature without reduced outputs or the output
of a sequence-based combiner.
If a <code>b x h</code> input is provided to a generator decoder using an RNN with attention instead, an error will be raised
during model building.</p>
<div class="highlight"><pre><span></span><code><span class="nt">decoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">generator</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">fc_output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">fc_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">cell_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gru</span>
<span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">reduce_input</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sum</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">fc_weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">fc_bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">fc_norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>num_fc_layers</code></strong> (default: <code>0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Number of fully-connected layers if <code>fc_layers</code> not specified. Increasing layers adds capacity to the model, enabling it to learn more complex feature interactions.</li>
<li><strong><code>fc_output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Output size of fully connected stack.</li>
<li><strong><code>fc_norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default normalization applied at the beginnging of fully connected layers. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>.</li>
<li><strong><code>fc_dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>cell_type</code></strong> (default: <code>gru</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Type of recurrent cell to use. Options: <code>rnn</code>, <code>lstm</code>, <code>gru</code>.</li>
<li><strong><code>num_layers</code></strong> (default: <code>1</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: The number of stacked recurrent layers.</li>
<li><strong><code>fc_activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>reduce_input</code></strong> (default: <code>sum</code>): How to reduce an input that is not a vector, but a matrix or a higher order tensor, on the first dimension (second if you count the batch dimension) Options: <code>sum</code>, <code>mean</code>, <code>avg</code>, <code>max</code>, <code>concat</code>, <code>last</code>.</li>
<li><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</li>
<li><strong><code>fc_use_bias</code></strong> (default: <code>true</code>): Whether the layer uses a bias vector in the fc_stack. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>fc_weights_initializer</code></strong> (default: <code>xavier_uniform</code>): The weights initializer to use for the layers in the fc_stack</li>
<li><strong><code>fc_bias_initializer</code></strong> (default: <code>zeros</code>): The bias initializer to use for the layers in the fc_stack</li>
<li><strong><code>fc_norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module.</li>
</ul>
<h4 id="tagger">Tagger<a class="headerlink" href="#tagger" title="Permanent link">&para;</a></h4>
<p><pre class="mermaid"><code>graph LR
  A["emb[0]\n....\nemb[n]"] --&gt; B["Fully\n Connected\n Layers"];
  B --&gt; C["Projection\n....\nProjection"];
  C --&gt; D["Softmax\n....\nSoftmax"];
  subgraph DEC["DECODER.."]
  B
  C
  D
  end
  subgraph COM["COMBINER OUT.."]
  A
  end</code></pre></p>
<p>In the case of <code>tagger</code> the decoder is a (potentially empty) stack of fully connected layers, followed by a projection
into a tensor of size <code>b x s x c</code>, where <code>b</code> is the batch size, <code>s</code> is the length of the sequence and <code>c</code> is the number
of classes, followed by a softmax_cross_entropy.
This decoder requires its input to be shaped as <code>b x s x h</code>, where <code>h</code> is a hidden dimension, which is the output of a
sequence, text or time series input feature without reduced outputs or the output of a sequence-based combiner.
If a <code>b x h</code> input is provided instead, an error will be raised during model building.</p>
<div class="highlight"><pre><span></span><code><span class="nt">decoder</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tagger</span>
<span class="w">    </span><span class="nt">num_fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">fc_output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">fc_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">fc_activation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">relu</span>
<span class="w">    </span><span class="nt">attention_embedding_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">fc_use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">fc_weights_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">xavier_uniform</span>
<span class="w">    </span><span class="nt">fc_bias_initializer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">zeros</span>
<span class="w">    </span><span class="nt">fc_norm_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">use_attention</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">use_bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">attention_num_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>num_fc_layers</code></strong> (default: <code>0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Number of fully-connected layers if <code>fc_layers</code> not specified. Increasing layers adds capacity to the model, enabling it to learn more complex feature interactions.</li>
<li><strong><code>fc_output_size</code></strong> (default: <code>256</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Output size of fully connected stack.</li>
<li><strong><code>fc_norm</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default normalization applied at the beginnging of fully connected layers. Options: <code>batch</code>, <code>layer</code>, <code>ghost</code>, <code>null</code>.</li>
<li><strong><code>fc_dropout</code></strong> (default: <code>0.0</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Default dropout rate applied to fully connected layers. Increasing dropout is a common form of regularization to combat overfitting. The dropout is expressed as the probability of an element to be zeroed out (0.0 means no dropout).</li>
<li><strong><code>fc_activation</code></strong> (default: <code>relu</code>): Default activation function applied to the output of the fully connected layers. Options: <code>elu</code>, <code>leakyRelu</code>, <code>logSigmoid</code>, <code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, <code>null</code>.</li>
<li><strong><code>attention_embedding_size</code></strong> (default: <code>256</code>): The embedding size of the multi-head self attention layer.</li>
<li><strong><code>fc_layers</code></strong> (default: <code>null</code>): List of dictionaries containing the parameters of all the fully connected layers. The length of the list determines the number of stacked fully connected layers and the content of each dictionary determines the parameters for a specific layer. The available parameters for each layer are: <code>activation</code>, <code>dropout</code>, <code>norm</code>, <code>norm_params</code>, <code>output_size</code>, <code>use_bias</code>, <code>bias_initializer</code> and <code>weights_initializer</code>. If any of those values is missing from the dictionary, the default one provided as a standalone parameter will be used instead.</li>
<li><strong><code>fc_use_bias</code></strong> (default: <code>true</code>): Whether the layer uses a bias vector in the fc_stack. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>fc_weights_initializer</code></strong> (default: <code>xavier_uniform</code>): The weights initializer to use for the layers in the fc_stack</li>
<li><strong><code>fc_bias_initializer</code></strong> (default: <code>zeros</code>): The bias initializer to use for the layers in the fc_stack</li>
<li><strong><code>fc_norm_params</code></strong> (default: <code>null</code>): Default parameters passed to the <code>norm</code> module.</li>
<li><strong><code>use_attention</code></strong> (default: <code>false</code>): Whether to apply a multi-head self attention layer before prediction. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>use_bias</code></strong> (default: <code>true</code>): Whether the layer uses a bias vector. Options: <code>true</code>, <code>false</code>.</li>
<li><strong><code>attention_num_heads</code></strong> (default: <code>8</code>): The number of attention heads in the multi-head self attention layer.</li>
</ul>
<h3 id="loss">Loss<a class="headerlink" href="#loss" title="Permanent link">&para;</a></h3>
<h4 id="softmax-cross-entropy">Softmax Cross Entropy<a class="headerlink" href="#softmax-cross-entropy" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="nt">loss</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">softmax_cross_entropy</span>
<span class="w">    </span><span class="nt">class_weights</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">robust_lambda</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">confidence_penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">class_similarities</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">class_similarities_temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
</code></pre></div>
<p>Parameters:</p>
<ul>
<li><strong><code>class_weights</code></strong> (default: <code>null</code>) <span class="twemoji" title="High impact parameter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.69 2h10.56c.966 0 1.75.784 1.75 1.75v17.5a.75.75 0 0 1-1.218.585L12 17.21l-5.781 4.626A.75.75 0 0 1 5 21.253L4.94 3.756A1.748 1.748 0 0 1 6.69 2Z"/></svg></span>: Weights to apply to each class in the loss. If not specified, all classes are weighted equally. The value can be a vector of weights, one for each class, that is multiplied to the loss of the datapoints that have that class as ground truth. It is an alternative to oversampling in case of unbalanced class distribution. The ordering of the vector follows the category to integer ID mapping in the JSON metadata file (the <code>&lt;UNK&gt;</code> class needs to be included too). Alternatively, the value can be a dictionary with class strings as keys and weights as values, like <code>{class_a: 0.5, class_b: 0.7, ...}</code>.</li>
<li><strong><code>robust_lambda</code></strong> (default: <code>0</code>): Replaces the loss with <code>(1 - robust_lambda) * loss + robust_lambda / c</code> where <code>c</code> is the number of classes. Useful in case of noisy labels.</li>
<li><strong><code>confidence_penalty</code></strong> (default: <code>0</code>): Penalizes overconfident predictions (low entropy) by adding an additional term that penalizes too confident predictions by adding a <code>a * (max_entropy - entropy) / max_entropy</code> term to the loss, where a is the value of this parameter. Useful in case of noisy labels.</li>
<li><strong><code>class_similarities</code></strong> (default: <code>null</code>): If not <code>null</code> it is a <code>c x c</code> matrix in the form of a list of lists that contains the mutual similarity of classes. It is used if <code>class_similarities_temperature</code> is greater than 0. The ordering of the vector follows the category to integer ID mapping in the JSON metadata file (the <code>&lt;UNK&gt;</code> class needs to be included too).</li>
<li><strong><code>class_similarities_temperature</code></strong> (default: <code>0</code>): The temperature parameter of the softmax that is performed on each row of <code>class_similarities</code>. The output of that softmax is used to determine the supervision vector to provide instead of the one hot vector that would be provided otherwise for each datapoint. The intuition behind it is that errors between similar classes are more tolerable than errors between really different classes.</li>
<li><strong><code>weight</code></strong> (default: <code>1.0</code>): Weight of the loss.</li>
</ul>
<h3 id="metrics">Metrics<a class="headerlink" href="#metrics" title="Permanent link">&para;</a></h3>
<p>The metrics available for text features are the same as for <a href="../sequence_features#sequence-features-metrics">Sequence Features</a>:</p>
<ul>
<li><code>sequence_accuracy</code> The rate at which the model predicted the correct sequence.</li>
<li><code>token_accuracy</code> The number of tokens correctly predicted divided by the total number of tokens in all sequences.</li>
<li><code>last_accuracy</code> Accuracy considering only the last element of the sequence. Useful to ensure special end-of-sequence
tokens are generated or tagged.</li>
<li><code>edit_distance</code> Levenshtein distance: the minimum number of single-token edits (insertions, deletions or substitutions)
required to change predicted sequence to ground truth.</li>
<li><code>perplexity</code> Perplexity is the inverse of the predicted probability of the ground truth sequence, normalized by the
number of tokens. The lower the perplexity, the higher the probability of predicting the true sequence.</li>
<li><code>loss</code> The value of the loss function.</li>
</ul>
<p>You can set any of the above as <code>validation_metric</code> in the <code>training</code> section of the configuration if <code>validation_field</code>
names a sequence feature.</p>


  




                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <!--
  Copyright (c) 2016-2022 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->

<!-- Footer -->
<footer class="md-footer">

    <!-- Link to previous and/or next page -->
    
    <nav class="md-footer__inner md-grid" aria-label="">

        <!-- Link to previous page -->
        
        
        <a href="../sequence_features/" class="md-footer__link md-footer__link--prev"
            aria-label="Previous: ⇅ Sequence Features" rel="prev">
            <div class="md-footer__button md-icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
                <div class="md-ellipsis">
                    <span class="md-footer__direction">
                        Previous
                    </span>
                    ⇅ Sequence Features
                </div>
            </div>
        </a>
        

        <!-- Link to next page -->
        
        
        <a href="../vector_features/" class="md-footer__link md-footer__link--next"
            aria-label="Next: ⇅ Vector Features" rel="next">
            <div class="md-footer__title">
                <div class="md-ellipsis">
                    <span class="md-footer__direction">
                        Next
                    </span>
                    ⇅ Vector Features
                </div>
            </div>
            <div class="md-footer__button md-icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
        </a>
        
    </nav>
    

    <!-- Further information -->
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">
            <!--
  Copyright (c) 2016-2021 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->

<!-- Copyright and theme information -->
<div class="md-copyright">
    
    <div class="md-copyright__highlight">
        Copyright &copy; 2018 - 2020 Uber Technologies Inc., 2021 - 2022 Linux Foundation Data & AI
    </div>
    
    

    Website by <a href="http://w4nderlu.st">w4nderlust</a> powered by
    <a href="https://www.mkdocs.org" target="_blank" rel="noopener">MkDocs</a>,
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">Material for MkDocs</a>,
    <a href="http://www.styleshout.com/" target="_blank" rel="noopener">styleshout</a> and
    <a href="http://cables.gl/" target="_blank" rel="noopener">cables</a>.
    
</div>

            <!-- Social links -->
            
        </div>
    </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.indexes", "navigation.tabs.sticky"], "search": "../../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.2a6f1dda.min.js"></script>
      
    
  </body>
</html>